{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/CNAME","path":"CNAME","modified":0,"renderable":0},{"_id":"source/img/icon_wechat.png","path":"img/icon_wechat.png","modified":0,"renderable":0},{"_id":"source/img/404-bg.jpg","path":"img/404-bg.jpg","modified":0,"renderable":0},{"_id":"themes/beantech/source/css/archive.styl","path":"css/archive.styl","modified":0,"renderable":1},{"_id":"themes/beantech/source/css/beantech.min.css","path":"css/beantech.min.css","modified":0,"renderable":1},{"_id":"themes/beantech/source/css/beantech.css","path":"css/beantech.css","modified":0,"renderable":1},{"_id":"themes/beantech/source/css/highlight.styl","path":"css/highlight.styl","modified":0,"renderable":1},{"_id":"themes/beantech/source/css/signature.styl","path":"css/signature.styl","modified":0,"renderable":1},{"_id":"themes/beantech/source/css/rocket.styl","path":"css/rocket.styl","modified":0,"renderable":1},{"_id":"themes/beantech/source/css/widget.styl","path":"css/widget.styl","modified":0,"renderable":1},{"_id":"themes/beantech/source/js/hux-blog.js","path":"js/hux-blog.js","modified":0,"renderable":1},{"_id":"themes/beantech/source/js/hux-blog.min.js","path":"js/hux-blog.min.js","modified":0,"renderable":1},{"_id":"themes/beantech/source/js/bootstrap.min.js","path":"js/bootstrap.min.js","modified":0,"renderable":1},{"_id":"themes/beantech/source/css/hux-blog.min.css","path":"css/hux-blog.min.css","modified":0,"renderable":1},{"_id":"themes/beantech/source/js/jquery.tagcloud.js","path":"js/jquery.tagcloud.js","modified":0,"renderable":1},{"_id":"themes/beantech/source/css/toc.styl","path":"css/toc.styl","modified":0,"renderable":1},{"_id":"themes/beantech/source/js/toc.js","path":"js/toc.js","modified":0,"renderable":1},{"_id":"themes/beantech/source/js/totop.js","path":"js/totop.js","modified":0,"renderable":1},{"_id":"themes/beantech/source/fonts/glyphicons-halflings-regular.woff","path":"fonts/glyphicons-halflings-regular.woff","modified":0,"renderable":1},{"_id":"themes/beantech/source/fonts/glyphicons-halflings-regular.ttf","path":"fonts/glyphicons-halflings-regular.ttf","modified":0,"renderable":1},{"_id":"source/img/header_img/Iron-Man-3.jpg","path":"img/header_img/Iron-Man-3.jpg","modified":0,"renderable":0},{"_id":"themes/beantech/source/fonts/glyphicons-halflings-regular.eot","path":"fonts/glyphicons-halflings-regular.eot","modified":0,"renderable":1},{"_id":"themes/beantech/source/fonts/glyphicons-halflings-regular.woff2","path":"fonts/glyphicons-halflings-regular.woff2","modified":0,"renderable":1},{"_id":"source/img/ironman-draw.png","path":"img/ironman-draw.png","modified":0,"renderable":0},{"_id":"themes/beantech/source/css/bootstrap.min.css","path":"css/bootstrap.min.css","modified":0,"renderable":1},{"_id":"themes/beantech/source/js/bootstrap.js","path":"js/bootstrap.js","modified":0,"renderable":1},{"_id":"themes/beantech/source/js/jquery.min.js","path":"js/jquery.min.js","modified":0,"renderable":1},{"_id":"themes/beantech/source/fonts/glyphicons-halflings-regular.svg","path":"fonts/glyphicons-halflings-regular.svg","modified":0,"renderable":1},{"_id":"source/img/signature/BeanTechSign-white.png","path":"img/signature/BeanTechSign-white.png","modified":0,"renderable":0},{"_id":"themes/beantech/source/css/bootstrap.css","path":"css/bootstrap.css","modified":0,"renderable":1},{"_id":"themes/beantech/source/css/images/ironman.png","path":"css/images/ironman.png","modified":0,"renderable":1},{"_id":"source/img/header_img/tf-logo-dark.png","path":"img/header_img/tf-logo-dark.png","modified":0,"renderable":0},{"_id":"source/img/signature/BeanTechSign-black.png","path":"img/signature/BeanTechSign-black.png","modified":0,"renderable":0},{"_id":"themes/beantech/source/js/jquery.js","path":"js/jquery.js","modified":0,"renderable":1},{"_id":"source/img/contact-bg.jpg","path":"img/contact-bg.jpg","modified":0,"renderable":0},{"_id":"themes/beantech/source/js/jquery.nav.js","path":"js/jquery.nav.js","modified":0,"renderable":1},{"_id":"themes/beantech/source/css/images/rocket.png","path":"css/images/rocket.png","modified":0,"renderable":1},{"_id":"source/img/beantech-desktop.png","path":"img/beantech-desktop.png","modified":0,"renderable":0},{"_id":"source/img/header_img/tag-bg.png","path":"img/header_img/tag-bg.png","modified":0,"renderable":0},{"_id":"source/img/header_img/home-bg-o.png","path":"img/header_img/home-bg-o.png","modified":0,"renderable":0},{"_id":"source/img/header_img/home-bg-2-dark.png","path":"img/header_img/home-bg-2-dark.png","modified":0,"renderable":0},{"_id":"source/img/header_img/archive-bg.png","path":"img/header_img/archive-bg.png","modified":0,"renderable":0}],"Cache":[{"_id":"source/.DS_Store","hash":"ec99afab3b7bb651e620c1666b95b26f71977502","modified":1540895597820},{"_id":"source/404.md","hash":"83c2c6d587beaa967a976e5969d60fa97fcdbe55","modified":1506174020000},{"_id":"source/CNAME","hash":"55d5b0b4757a7d65ee4966dd161f394d06d257b7","modified":1506174020000},{"_id":"source/_posts/Code pies.md","hash":"bb47933009a5ffdef1c5f29ab42919a1e2c8faf4","modified":1538297426887},{"_id":"source/_posts/Git使用.md","hash":"4ad4cc7842958fea428ece9093d818ab8f4e66a7","modified":1537346885066},{"_id":"source/_posts/IO模型.md","hash":"4187223b2740efcf6b54247183e3d52c45d06791","modified":1536721401812},{"_id":"source/_posts/Responses 部分.md","hash":"3efafbf3694da6997c918f324d95f82fc840e682","modified":1536721401812},{"_id":"source/_posts/elasticSearch入门.md","hash":"4dcd6eb899b40f81df30eefae0f1e6dba348178c","modified":1536721401813},{"_id":"source/_posts/docker初识.md","hash":"a9703b9ff78ef0a35fe5866ca50295e37b0f6755","modified":1536721401813},{"_id":"source/_posts/hello-world.md","hash":"0d9cae89ec13760772d807bd0465bb0c4d7c3987","modified":1540888818298},{"_id":"source/_posts/hexo-theme-beantech.md","hash":"8aa4bffe04fceed5b676692ec5cf3ea150dc1f6e","modified":1506174020000},{"_id":"source/_posts/hexo搭建个人博客.md","hash":"4574c7ee2ce3cc00ec1f38e48a6ffc97e1f2d8d4","modified":1536721401819},{"_id":"source/_posts/maven实现环境切换.md","hash":"d29411d83897dfea747d8ac9b76a60837c10b34a","modified":1536721401825},{"_id":"source/_posts/mac上使用Homebrew.md","hash":"a11d93c10d779833826e8dee33076a6cdeede14e","modified":1536721401824},{"_id":"source/_posts/shiro介绍.md","hash":"8a8e1ec8777a8f0ca2b1491732a7794b038c3e45","modified":1536721401826},{"_id":"source/_posts/spark.md","hash":"7fa00a8ebfd9698608ec7f89158d32f1f106a6ee","modified":1536721401826},{"_id":"source/_posts/关于学习的思考.md","hash":"5a8767e2dbdc76712b4bb7eb28b16df4031d0d21","modified":1536721401827},{"_id":"source/_posts/数据结构之tree.md","hash":"0f695afb1fa5f1049b79bf2bff1b5b490b14ee55","modified":1538297426756},{"_id":"source/_posts/线上问题排查.md","hash":"6cc8e5ed8db82b17e08e2271224c00e1a9236666","modified":1536721401834},{"_id":"source/_posts/.DS_Store","hash":"7fd2f684f95b611a912fd07665dc39b4065d2bbe","modified":1540895528083},{"_id":"themes/beantech/_config.yml","hash":"6afd65c055d9b1c70ae67323cc869f1b4aa60348","modified":1506174020000},{"_id":"themes/beantech/LICENSE","hash":"2b209f06bebeb2a8c2b7e187e436f3e1e1fbc8a7","modified":1506174020000},{"_id":"source/archive/index.md","hash":"279ff19668395f5c6b26417da99d2c1f3ecd5886","modified":1506174020000},{"_id":"source/about/index.md","hash":"ebca34cfe8d13ec641d17fcfec0127a966338f8e","modified":1506174020000},{"_id":"source/img/icon_wechat.png","hash":"4188058026609de06c6cac88b349a2da831a1783","modified":1506174020000},{"_id":"source/tags/index.md","hash":"9d558ce28d0d44c3463517088689bbca44bbb364","modified":1506174020000},{"_id":"themes/beantech/layout/about.ejs","hash":"edcf8fa3bf7093c974d418ffef42ac89c19af128","modified":1506174020000},{"_id":"themes/beantech/layout/404.ejs","hash":"a4d73541a53e56b7dd46249c6d27cb59f4d97422","modified":1506174020000},{"_id":"themes/beantech/layout/index.ejs","hash":"dc8a6eaa00d1e7c33a40979afe0953ed5d7b512e","modified":1506174020000},{"_id":"themes/beantech/layout/keynote.ejs","hash":"f5689862281e34dbe8402b0e72f632902e53e88b","modified":1506174020000},{"_id":"themes/beantech/layout/layout.ejs","hash":"a5af5b99ac3456ab5da1a319455904b979b91601","modified":1506174020000},{"_id":"themes/beantech/layout/page.ejs","hash":"c90797e4394c5cb63c2515109480e766d04e486e","modified":1506174020000},{"_id":"themes/beantech/layout/post.ejs","hash":"2d55684fc539dc281f9e2ec0409f09ea6ca43949","modified":1506174020000},{"_id":"themes/beantech/layout/tags.ejs","hash":"2c72eb2e89130658aa068d80d27b561b509c5dcd","modified":1506174020000},{"_id":"themes/beantech/languages_to_be_added/default.yml","hash":"97326c9e6518d9f379778178b3b8f9a58434725d","modified":1506174020000},{"_id":"themes/beantech/languages_to_be_added/de.yml","hash":"424a9c1e6ab69334d7873f6574da02ca960aa572","modified":1506174020000},{"_id":"themes/beantech/languages_to_be_added/en.yml","hash":"97326c9e6518d9f379778178b3b8f9a58434725d","modified":1506174020000},{"_id":"themes/beantech/languages_to_be_added/es.yml","hash":"cb4eeca0ed3768a77e0cd216300f2b2549628b1b","modified":1506174020000},{"_id":"themes/beantech/languages_to_be_added/pl.yml","hash":"de7eb5850ae65ba7638e907c805fea90617a988c","modified":1506174020000},{"_id":"themes/beantech/languages_to_be_added/ru.yml","hash":"42df7afeb7a35dc46d272b7f4fb880a9d9ebcaa5","modified":1506174020000},{"_id":"themes/beantech/languages_to_be_added/zh-CN.yml","hash":"7bfcb0b8e97d7e5edcfca8ab26d55d9da2573c1c","modified":1506174020000},{"_id":"themes/beantech/languages_to_be_added/zh-TW.yml","hash":"9acac6cc4f8002c3fa53ff69fb8cf66c915bd016","modified":1506174020000},{"_id":"source/_posts/hbase/hbase中HFile详解.md","hash":"069af0cf5ad724eb1229e9675775b63a0deedb33","modified":1536721401813},{"_id":"source/_posts/hbase/hbase参数调优.md","hash":"b82fe9ef8250d1292e3b8a447cd4b5c9579068dd","modified":1536721401814},{"_id":"source/_posts/hbase/hbase的BlockCache.md","hash":"e4f59855ebef866ce5c76a4cb7295252010b1e78","modified":1536721401814},{"_id":"source/_posts/hbase/hbase的HFile合并.md","hash":"0b4b6794faab9582a72757dc8f8cb534dc973f4c","modified":1536721401815},{"_id":"themes/beantech/layout/archive.ejs","hash":"72a150c8dff0031a9107d12eaa7c2e6c6ce950d2","modified":1506174020000},{"_id":"source/_posts/hbase/hbase的RegionServer定位.md","hash":"40a06e20056f2625e953545afd225bd7068ff3df","modified":1536721401815},{"_id":"source/_posts/hbase/hbase的WAL详解.md","hash":"eefab977abad1bfbe36b6fb6b7b6105cb185638a","modified":1536721401816},{"_id":"source/_posts/hbase/hbase的memstore.md","hash":"f6b4e740873cad96c1de7f28d6b857710b4b16c0","modified":1536721401816},{"_id":"source/_posts/hbase/hbase的容错.md","hash":"02d2c294c89824af10868a8082fbe578a8434841","modified":1536721401817},{"_id":"source/_posts/hbase/hbase的增删改查.md","hash":"9e44411e6626044af64ac409974be6099ce70d97","modified":1536721401816},{"_id":"source/_posts/hbase/hbase的表设计.md","hash":"add5dcbde10eeb584dbd1ea29653bbf6b9dc2069","modified":1536721401817},{"_id":"source/_posts/hbase/hbase的读写优化.md","hash":"66ad94d6f90ab0890c911b8b2496c288f928f315","modified":1536721401818},{"_id":"source/_posts/hbase/hbase的读流程.md","hash":"5b8f6b7ffaea886055b84302ba55ae590d6c8aea","modified":1536721401818},{"_id":"themes/beantech/languages_to_be_added/no.yml","hash":"8ca475a3b4f8efe6603030f0013aae39668230e1","modified":1506174020000},{"_id":"source/_posts/hbase/hbase认识与安装配置.md","hash":"69b1e1e355249348d77af20eccee7960f3a09d9c","modified":1536721401819},{"_id":"source/_posts/hbase/hbase过滤器.md","hash":"39efffb393318b2a11c342f5aa7bc3b2fe378a93","modified":1536721401819},{"_id":"source/_posts/hbase/hbase设计模型.md","hash":"bd64e7c65d948b60e2b2ce14e51a6758ab7c6d32","modified":1536721401819},{"_id":"source/_posts/java基础/java之动态代理.md","hash":"34dbce8952e121917dde9f245a776bceb99aaada","modified":1536721401823},{"_id":"source/_posts/java基础/java反射之对象创建.md","hash":"ad768ca8da60260371e7943a826dd65bc8e81534","modified":1536721401823},{"_id":"source/_posts/java基础/java反射之泛型.md","hash":"becae82fc2b3155599e236acbb00a5ead5a4c289","modified":1536721401823},{"_id":"source/_posts/java基础/动态代理.md","hash":"456e718c455ce29ea1a2266512fc817b549d8661","modified":1536721401824},{"_id":"source/_posts/java8/java8之Collector.md","hash":"5be1c273ea756cd67c6cd22517de9cda4f611438","modified":1536721401820},{"_id":"source/_posts/java8/java8之Comparator.md","hash":"a94633cb329b6f64a8d81dc8790f1a5bd8a9a648","modified":1536721401821},{"_id":"source/_posts/java8/java8之CompletableFuture.md","hash":"dbcacc5be3d45773a252ee469f7c483fc4e5be03","modified":1536721401821},{"_id":"source/_posts/java8/java8之Optional.md","hash":"12492e79f3019233b388d0f6382bd62601140782","modified":1536721401821},{"_id":"source/_posts/java8/java8之lambda表达式.md","hash":"0ee8ecc345e8f8ae88c0545f8f657e50b3f61dc8","modified":1536721401822},{"_id":"source/_posts/java8/java8之Stream流.md","hash":"39432e0243ed02caf31490ff97561612b2ca6ecc","modified":1536721401821},{"_id":"source/_posts/java8/java8之方法接口.md","hash":"b607495e5529d7bd5374babf74e3f8882d7ad267","modified":1536721401822},{"_id":"source/_posts/java8/java8之日期实现.md","hash":"0630f6d0e7f4afee188edda34bcf578c7fe8073f","modified":1536721401822},{"_id":"source/_posts/spring/.DS_Store","hash":"49ffe839e0574838726692682941d7cb601cc11f","modified":1540809678282},{"_id":"source/_posts/linux/vim编辑器.md","hash":"4e8c789c8668930b59f240d6cb349094854d3b9f","modified":1536721401824},{"_id":"source/_posts/mysql/mysql.md","hash":"0f59ae337d6feb70c6fdc229fb531a0a2daf64eb","modified":1536721401825},{"_id":"source/_posts/spring/spring boot初识.md","hash":"0de94211ea9e8ddf24374b332fc98862b2613cd2","modified":1536721401826},{"_id":"source/_posts/netty/netty.md","hash":"db67843dc9dd9f6fb05dd6579e87918da029fb8b","modified":1536721401825},{"_id":"source/_posts/spring/spring-AOP.md","hash":"d73dc8805d8b0358f8da71553180a14580763a5c","modified":1540824983007},{"_id":"source/_posts/spring/spring入门.md","hash":"fe2d48116a9906bedbc4c8a3026fed6490e87c1d","modified":1539696231458},{"_id":"source/_posts/spring/spring-IOC.md","hash":"12a4f52a04582d23ab5eb523cf79b7d28b2621bc","modified":1540872629309},{"_id":"source/_posts/多线程/JUC总览.md","hash":"ebcf7a412832e19efebd055268e8919693343b8a","modified":1536721401827},{"_id":"source/_posts/多线程/java synchronized原理.md","hash":"2ebd3fdb7d7f49e9de8e851706ffcddcbdcf2992","modified":1536721401828},{"_id":"source/_posts/多线程/java多线程.md","hash":"4aa6ab108be7c8404f1f503523fc7c9a7f55fa4a","modified":1536721401828},{"_id":"source/_posts/多线程/java并发之Condition.md","hash":"2e951a371ca3a5c6df5b6d6be29f2e7b98c35201","modified":1536721401829},{"_id":"source/_posts/多线程/java并发之AQS原理.md","hash":"89a9141e90c551eb4e444b34734aae3a1a66ecb5","modified":1536721401829},{"_id":"source/_posts/多线程/java并发之CountDownLatch.md","hash":"345fb5c8f965d329b7293bad7b138a682d8a3a10","modified":1536721401829},{"_id":"source/_posts/多线程/java并发之CyclicBarrier.md","hash":"2781a316303e834bbe680c33c6244039fe316da6","modified":1536721401830},{"_id":"source/_posts/多线程/java并发之Exchanger.md","hash":"10390b8d2d712346af6bdffbcd35c4ae6fb0f552","modified":1536721401830},{"_id":"source/_posts/多线程/java并发之LockSupport.md","hash":"76d62075e6c084151d39920dac932355eb4678af","modified":1536721401830},{"_id":"source/_posts/多线程/java并发之ReentrantLock.md","hash":"aa7adc58e0a140c75b6ccc658f596b90caaae9cf","modified":1536721401830},{"_id":"source/_posts/多线程/java并发之Semaphore.md","hash":"aff29202c0337b5e5c211032c4df3a2a2cc03460","modified":1536721401831},{"_id":"source/_posts/多线程/java并发之StampedLock.md","hash":"5d8ff242bb9cdbcb896f1188a971a823b84cb83b","modified":1536721401831},{"_id":"source/_posts/多线程/java并发之ThreadLocal.md","hash":"0fd88de64ae4f29cbd7c58c31f07e4e15c9784d6","modified":1536721401832},{"_id":"source/_posts/多线程/java并发之无锁CAS.md","hash":"5a704753a65fb12ad0cb3eebb6fee5237710fe29","modified":1536721401832},{"_id":"source/_posts/多线程/java线程.md","hash":"1233619920f07b089e8e62255538d0fe513eaaa2","modified":1536721401832},{"_id":"source/_posts/多线程/java线程池.md","hash":"a42862c62cfef2df607f61e01ab0280c0f071492","modified":1536721401833},{"_id":"source/_posts/多线程/java线程状态.md","hash":"c9f75bbe83f6b27fd517af52385d69777b0d1aa7","modified":1536721401833},{"_id":"source/_posts/spring/spring事务.md","hash":"fc3335ef9f9db66d4f30a076dea81026506eba33","modified":1538297426888},{"_id":"source/_posts/多线程/volatile.md","hash":"20c220b2c7abaae3a1aef068af1f5f52ef0db229","modified":1536721401833},{"_id":"source/_posts/多线程/ThreadPoolExecutor源码解析.md","hash":"eea2efc19d7c1437ef42c7c04f99393c7bd32677","modified":1536721401828},{"_id":"source/_posts/源码学习/mybatis-generator源码.md","hash":"662a5df0d895df8b16d113a5aa526ff52d181522","modified":1537264797053},{"_id":"source/_posts/消息队列/队列Queue.md","hash":"efb1cb7ec6093f9c80a13307f00ea4b8c4e9e4dd","modified":1536721401834},{"_id":"source/_posts/设计模式/设计模式之中介者模式.md","hash":"10d450c111f63208fe5cab8f5188b87d742eefa4","modified":1536721401835},{"_id":"source/_posts/设计模式/设计模式之享元模式.md","hash":"856fad9d6b8cb92e4081ebad2539cccde96729c8","modified":1536721401835},{"_id":"source/_posts/设计模式/设计模式之代理模式.md","hash":"a5a8f9d59cb71ccb3411966a671bac720fe9f673","modified":1536721401835},{"_id":"source/_posts/设计模式/设计模式之单例模式.md","hash":"b179f1ce91debadb6f4a781ce02fe638f180caa8","modified":1536721401835},{"_id":"source/_posts/设计模式/设计模式之原型模式.md","hash":"baed1ca82a09a89812632164bee1f16ccffefb12","modified":1536721401836},{"_id":"source/_posts/设计模式/设计模式之命令模式.md","hash":"f547b67abbfdb28e289535c9e5237c2c8ac38a85","modified":1536721401836},{"_id":"source/_posts/设计模式/设计模式之备忘录模式.md","hash":"47cb1606c127993035ec64f4b39e2a454cabf952","modified":1536721401836},{"_id":"source/_posts/设计模式/设计模式之工厂方法模式.md","hash":"fe4103c4192ffb4599afe8997ea87cd1e53950bc","modified":1536721401837},{"_id":"source/_posts/多线程/java并发之ReentrantReadWriteLock.md","hash":"74009cb7a553713e420ce21a345832f308bce54e","modified":1536721401831},{"_id":"source/_posts/设计模式/设计模式之模板方法模式.md","hash":"29012dd02a6928cab9ea58b02a36b0526db37fab","modified":1536721401838},{"_id":"source/_posts/设计模式/设计模式之桥接模式.md","hash":"d5a19d0e28ae8788a69c9b32178e4c0a06b9d62e","modified":1536721401837},{"_id":"source/_posts/设计模式/设计模式之抽象工厂模式.md","hash":"cfc69871b45d454cd86ac6f2967bcaff1527dc9f","modified":1536721401837},{"_id":"source/_posts/设计模式/设计模式之策略模式.md","hash":"9ae2e84ad390ef7ca37f6b5bd84ea2a301b98025","modified":1536721401838},{"_id":"source/_posts/设计模式/设计模式之状态模式.md","hash":"7e1e9a9e4ccf434ee208004f24df4d7017530870","modified":1536721401838},{"_id":"source/_posts/设计模式/设计模式之装饰模式.md","hash":"af2952259727cb3081df80422044fd9d02d7a91e","modified":1536721401839},{"_id":"source/_posts/设计模式/设计模式之观察者模式.md","hash":"84b7b38ff042fec7fe159c2a0fe15ab108e98955","modified":1536721401839},{"_id":"source/_posts/设计模式/设计模式之解释器模式.md","hash":"652a5e9c48db13c8f150cdf7a3ec0bbffe104a79","modified":1536721401840},{"_id":"source/_posts/设计模式/设计模式之设计原则.md","hash":"1f634ea903b033221935ab529afc50f81e4acde3","modified":1536721401840},{"_id":"source/_posts/设计模式/设计模式之访问者模式.md","hash":"30155f52a5ccd02d1761617ee6cc6bedc6f438b4","modified":1536721401840},{"_id":"source/_posts/设计模式/设计模式之责任链模式.md","hash":"e3e791be54254f7f5325edfcce1e9dd7677c601e","modified":1536721401840},{"_id":"source/_posts/设计模式/设计模式之迭代器模式.md","hash":"e505049ff98c72af3dea2c5ad67c2152e73bd07b","modified":1536721401841},{"_id":"source/_posts/设计模式/设计模式之适配器模式.md","hash":"fddd11bb36c57152da907fc88a8cef6175e2c973","modified":1536721401841},{"_id":"source/_posts/设计模式/设计模式之构建者模式.md","hash":"baf729242e4b8886a1d8fcc150fa00cd5bce06a0","modified":1536721401837},{"_id":"source/_posts/设计模式/设计模式之门面模式.md","hash":"42cedddb3b3c0a94db05c747ea38d53da19e43ad","modified":1536721401841},{"_id":"source/_posts/设计模式/设计模式之简单工厂模式.md","hash":"b80e44d98d8aaf56f338015359691fff4889106b","modified":1536721401838},{"_id":"source/_posts/设计模式/设计模式之组合模式.md","hash":"a805b1b491e24ebfefe61c496a2b3991a3993755","modified":1536721401839},{"_id":"source/img/404-bg.jpg","hash":"68f7d525269a94287e0ad18713ae232fb59dcf71","modified":1506174020000},{"_id":"themes/beantech/layout/_partial/footer.ejs","hash":"c31863b1fa66fd915bc4913440be6c610d12af80","modified":1506174020000},{"_id":"themes/beantech/layout/_partial/header.ejs","hash":"aafb744601042f0270d2e6595129ac8a73ad2608","modified":1506174020000},{"_id":"themes/beantech/layout/_partial/head.ejs","hash":"3542d15bdf73aa59f05f566b7ecd2255e83ee370","modified":1506174020000},{"_id":"themes/beantech/layout/_partial/nav.ejs","hash":"4c905166c960852e9b9a3c9d5c680091e37b481f","modified":1506174020000},{"_id":"themes/beantech/layout/_partial/pagination.ejs","hash":"557d6bb069a1d48af49ae912994653f44b32a570","modified":1506174020000},{"_id":"themes/beantech/layout/_partial/sidebar.ejs","hash":"2e4e528a555917b2a267da4db2440bcc4a7a65ab","modified":1506174020000},{"_id":"themes/beantech/layout/_partial/toc.ejs","hash":"837f01e8a20e5023b4b292d1b3141a399567da65","modified":1506174020000},{"_id":"themes/beantech/layout/_widget/category.ejs","hash":"1cf485def07dc06e870dc9613767c6c614bcf428","modified":1506174020000},{"_id":"themes/beantech/layout/_widget/featured-tags.ejs","hash":"0c9ce1942f1943dc8891a9302a922ef1ffe300c5","modified":1506174020000},{"_id":"themes/beantech/layout/_widget/friends-blog.ejs","hash":"734d3775017aedac185028924baf890a71a74548","modified":1506174020000},{"_id":"themes/beantech/layout/_widget/recent-posts.ejs","hash":"e08ab8ba60e31638006acf27f066b989a0a3c433","modified":1506174020000},{"_id":"themes/beantech/layout/_widget/short-about.ejs","hash":"3b10bd768f6ef30a42b1703fbc9a88627f9bfdf1","modified":1506174020000},{"_id":"themes/beantech/source/css/archive.styl","hash":"715bcbd085eb95ec26c9805c11c374919cde971c","modified":1506174020000},{"_id":"themes/beantech/source/css/beantech.min.css","hash":"05a06230b1a9eca0b30cece54a397008cb77dc50","modified":1506174020000},{"_id":"themes/beantech/source/css/beantech.css","hash":"4c361354fd8e9851923fb21a620bc079380ebcd8","modified":1506174020000},{"_id":"themes/beantech/source/css/highlight.styl","hash":"e842080e6d580f0f70a7df71fbde3c4e49463c19","modified":1506174020000},{"_id":"themes/beantech/source/css/signature.styl","hash":"88159b31c59d59c01a0b534af57242662a2a3969","modified":1506174020000},{"_id":"themes/beantech/source/css/rocket.styl","hash":"e15c51c8566ecd943112e57592888dd318b6fa6a","modified":1506174020000},{"_id":"themes/beantech/source/css/widget.styl","hash":"7a9f735f5ef323dc2950fbd9d76daa16c9a0f1a9","modified":1506174020000},{"_id":"themes/beantech/layout/_widget/archive.ejs","hash":"7594929d472806ca4c64d9906d9903a96de111a0","modified":1506174020000},{"_id":"themes/beantech/source/js/hux-blog.js","hash":"4b4d3c557405d04c3087d36c13e2834fe05c0f73","modified":1506174020000},{"_id":"themes/beantech/source/js/hux-blog.min.js","hash":"1563e7f70550ac6b30803d6f449719b853200e35","modified":1506174020000},{"_id":"themes/beantech/source/js/bootstrap.min.js","hash":"b3f2ef9f985e7906c9360756b73cd64bf7733647","modified":1506174020000},{"_id":"themes/beantech/source/css/hux-blog.min.css","hash":"1baef04de262aeb7023d835429b49a805ac4ab40","modified":1506174020000},{"_id":"themes/beantech/source/js/jquery.tagcloud.js","hash":"4e5fd0b07f3bd935f2e603710447e039e3677211","modified":1506174020000},{"_id":"themes/beantech/source/css/toc.styl","hash":"6c9a2d5f6f981624e0c4b64323493e8614efea29","modified":1506174020000},{"_id":"themes/beantech/source/js/toc.js","hash":"41e52551731854224c249d53010c1bae5aa92ffa","modified":1506174020000},{"_id":"themes/beantech/source/js/totop.js","hash":"c05360f6fc699ac12e794b1764b4a952713a3017","modified":1506174020000},{"_id":"themes/beantech/source/fonts/glyphicons-halflings-regular.woff","hash":"278e49a86e634da6f2a02f3b47dd9d2a8f26210f","modified":1506174020000},{"_id":"themes/beantech/source/fonts/glyphicons-halflings-regular.ttf","hash":"44bc1850f570972267b169ae18f1cb06b611ffa2","modified":1506174020000},{"_id":"source/img/header_img/Iron-Man-3.jpg","hash":"62a9a76854503c327990cc8d10de293ab6e9588f","modified":1506174020000},{"_id":"themes/beantech/source/fonts/glyphicons-halflings-regular.eot","hash":"86b6f62b7853e67d3e635f6512a5a5efc58ea3c3","modified":1506174020000},{"_id":"themes/beantech/source/fonts/glyphicons-halflings-regular.woff2","hash":"ca35b697d99cae4d1b60f2d60fcd37771987eb07","modified":1506174020000},{"_id":"source/img/ironman-draw.png","hash":"7d6a06b4b544ab146c3b3e8474edc33f14ac6e4d","modified":1506174020000},{"_id":"themes/beantech/source/css/bootstrap.min.css","hash":"fec7b176a4b9a67c0eb5d184f57b84297efc23aa","modified":1506174020000},{"_id":"themes/beantech/source/js/bootstrap.js","hash":"f8752e9ae24daec0a0baffd7819122f8c6fd9103","modified":1506174020000},{"_id":"themes/beantech/source/js/jquery.min.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1506174020000},{"_id":"themes/beantech/source/fonts/glyphicons-halflings-regular.svg","hash":"de51a8494180a6db074af2dee2383f0a363c5b08","modified":1506174020000},{"_id":"source/_posts/hexo-theme-beantech/home_posts_tag-false.png","hash":"86a3a4320012981f2d42eabc6ea172425f2f941a","modified":1506174020000},{"_id":"source/img/signature/BeanTechSign-white.png","hash":"34289ed41cf9ddac2d56be46fbb1515b7d5913cd","modified":1506174020000},{"_id":"themes/beantech/source/css/bootstrap.css","hash":"41c54bf695145ae0b4d9020a1da308ceb05dcaf3","modified":1506174020000},{"_id":"source/_posts/hexo-theme-beantech/home_posts_tag-true.png","hash":"a704520b43f26b88d650098f60689af3af5eb106","modified":1506174020000},{"_id":"themes/beantech/source/css/images/ironman.png","hash":"2f0db0ab15d466c4065d9f6102fdf829726d9e3f","modified":1506174020000},{"_id":"source/img/header_img/tf-logo-dark.png","hash":"5c7bf8ade9de134f8c77a3c59e575abe9fc6cdd4","modified":1506174020000},{"_id":"source/img/signature/BeanTechSign-black.png","hash":"94b7102e819fd6ee082d3fb0166f4de7458c22ff","modified":1506174020000},{"_id":"themes/beantech/source/js/jquery.js","hash":"1852661bd11a09ca9b9cb63d1aa6ff390fffaf4e","modified":1506174020000},{"_id":"source/img/contact-bg.jpg","hash":"6af63305c923899017e727b5ca968a2703bc08cf","modified":1506174020000},{"_id":"themes/beantech/source/js/jquery.nav.js","hash":"ef2160a456176a4d09cc0b95d52b27dfbbadf2d8","modified":1506174020000},{"_id":"themes/beantech/source/css/images/rocket.png","hash":"6dee0406955aa9b7a261161d30f2538a671e806b","modified":1506174020000},{"_id":"source/img/beantech-desktop.png","hash":"4a8f8b209c9db8fd5209f15b8e4590525e258b0f","modified":1506174020000},{"_id":"source/img/header_img/tag-bg.png","hash":"e83cd7b04ff85bcbc9bd3ebf5e57a55166e82568","modified":1506174020000},{"_id":"source/_posts/hexo-theme-beantech/Demo.png","hash":"d9fa12f1e40924a0db57761d09d52dce450b4f7b","modified":1506174020000},{"_id":"source/img/header_img/home-bg-o.png","hash":"134ece4cb4c49c7ca1403a5afe7f46d0e2f9ecbb","modified":1506174020000},{"_id":"source/img/header_img/home-bg-2-dark.png","hash":"da6a3d5ca787bdc25e69655abd879b4f821aeb30","modified":1506174020000},{"_id":"source/img/header_img/archive-bg.png","hash":"6bf9c224543ec54e250309db89cbdf46e0c4b5ba","modified":1506174020000}],"Category":[{"name":"java基础","_id":"cjnvlfne30003wlkvgf7yyd8b"},{"name":"java工具","_id":"cjnvlfneh0008wlkv2dchkkuv"},{"name":"大数据","_id":"cjnvlfnek000ewlkvhktbnamo"},{"name":"docker","_id":"cjnvlfnen000kwlkvl21n1xo0"},{"name":"Maven","_id":"cjnvlfneu000qwlkvtq81ksfn"},{"name":"权限","_id":"cjnvlfney000xwlkvo6ssy1px"},{"name":"生活","_id":"cjnvlfnf10013wlkvhgb828hf"},{"name":"java","_id":"cjnvlfnf30019wlkvnzwyvbgr"},{"name":"linux","_id":"cjnvlfnhk0044wlkvtj1mx115"},{"name":"数据库","_id":"cjnvlfnhn004cwlkvt7k3lsyu"},{"name":"spring","_id":"cjnvlfnhp004iwlkv8psja3jj"},{"name":"源码","_id":"cjnvlfnig006mwlkvs0fwrify"},{"name":"设计模式","_id":"cjnvlfnii006vwlkvd7ko77eo"}],"Data":[],"Page":[{"layout":"404","description":"你来到了没有知识的荒原 :(","header-img":"img/404-bg.jpg","_content":"","source":"404.md","raw":"---\nlayout: 404\ndescription: \"你来到了没有知识的荒原 :(\"\nheader-img: \"img/404-bg.jpg\"\n---\n","date":"2018-10-30T09:53:40.162Z","updated":"2017-09-23T13:40:20.000Z","path":"404.html","title":"","comments":1,"_id":"cjnvlfndd0000wlkvvbbsb2ni"},{"layout":"archive","title":"Archives","header-img":"img/header_img/archive-bg.png","comments":0,"date":"2017-03-20T12:49:56.000Z","description":"Hey, this is archives","_content":"","source":"archive/index.md","raw":"---\nlayout: \"archive\"\ntitle: \"Archives\"\nheader-img: \"img/header_img/archive-bg.png\"\ncomments: false\ndate: 2017-03-20 20:49:56\ndescription: \"Hey, this is archives\"\n---\n","updated":"2017-09-23T13:40:20.000Z","path":"archive/index.html","_id":"cjnvlfnfm001pwlkvri7uyia4"},{"layout":"about","title":"About","date":"2016-04-20T20:48:33.000Z","description":"Wish for the Best, Prepare for the Worst","header-img":"img/header_img/Iron-Man-3.jpg","comments":1,"_content":"\n> 光有好奇心而不去實踐，等於自願放棄成功機會\n> 別為自己畫地自限，Just Do It！！\n","source":"about/index.md","raw":"---\nlayout: \"about\"\ntitle: \"About\"\ndate: 2016-04-21 04:48:33\ndescription: \"Wish for the Best, Prepare for the Worst\"\nheader-img: \"img/header_img/Iron-Man-3.jpg\"\ncomments: true\n---\n\n> 光有好奇心而不去實踐，等於自願放棄成功機會\n> 別為自己畫地自限，Just Do It！！\n","updated":"2017-09-23T13:40:20.000Z","path":"about/index.html","_id":"cjnvlfnfn001qwlkvbvo4pxms"},{"layout":"tags","title":"Tags","description":"Hey, this is Tags.","header-img":"img/header_img/tag-bg.png","_content":"","source":"tags/index.md","raw":"---\nlayout: \"tags\"\ntitle: \"Tags\"\ndescription: \"Hey, this is Tags.\"\nheader-img: \"img/header_img/tag-bg.png\"\n---\n","date":"2018-10-30T09:53:40.150Z","updated":"2017-09-23T13:40:20.000Z","path":"tags/index.html","comments":1,"_id":"cjnvlfnfn001rwlkvq31j2rhi"}],"Post":[{"title":"Code Pieces","date":"2018-09-12T02:26:48.000Z","_content":"\n# Code Pieces\n\n- 声明一个全局不可改变的map\n\n  ```java\n  public static final Map<String, String> SHORT_IDS;\n  static {\n      Map<String, String> map = new HashMap<>(64);\n      map.put(\"ACT\", \"Australia/Darwin\");\n      map.put(\"AET\", \"Australia/Sydney\");\n      SHORT_IDS = Collections.unmodifiableMap(map);\n  }\n  ```\n\n- spring中类型强转\n\n  ```java\n  BeanDefinitionDocumentReader.class.cast(BeanUtils.instantiateClass(this.documentReaderClass))\n  ```\n\n- 转换为驼峰模式\n\n  ```java\n  public static String getCamelCaseString(String inputString,\n                                          boolean firstCharacterUppercase) {\n      StringBuilder sb = new StringBuilder();\n  \n      boolean nextUpperCase = false;\n      for (int i = 0; i < inputString.length(); i++) {\n          char c = inputString.charAt(i);\n          switch (c) {\n              case '_':\n              case '-':\n              case '@':\n              case '$':\n              case '#':\n              case ' ':\n              case '/':\n              case '&':\n                  if (sb.length() > 0) {\n                      nextUpperCase = true;\n                  }\n                  break;\n              default:\n                  if (nextUpperCase) {\n                      sb.append(Character.toUpperCase(c));\n                      nextUpperCase = false;\n                  } else {\n                      sb.append(Character.toLowerCase(c));\n                  }\n                  break;\n          }\n      }\n  \n      if (firstCharacterUppercase) {\n          sb.setCharAt(0, Character.toUpperCase(sb.charAt(0)));\n      }\n  \n      return sb.toString();\n  }\n  ```\n\n- 替换 ${}\n\n  ```java\n  private String parsePropertyTokens(String string) {\n      final String OPEN = \"${\"; //$NON-NLS-1$\n      final String CLOSE = \"}\"; //$NON-NLS-1$\n  \n      String newString = string;\n      if (newString != null) {\n          int start = newString.indexOf(OPEN);\n          int end = newString.indexOf(CLOSE);\n  \n          while (start > -1 && end > start) {\n              String prepend = newString.substring(0, start);\n              String append = newString.substring(end + CLOSE.length());\n              String propName = newString.substring(start + OPEN.length(),end);\n              String propValue = resolveProperty(propName);\n              if (propValue != null) {\n                  newString = prepend + propValue + append;\n              }\n              start = newString.indexOf(OPEN, end);\n              end = newString.indexOf(CLOSE, end);\n          }\n      }\n      return newString;\n  }\n  private String resolveProperty(String key) {\n      String property = null;\n      property = System.getProperty(key);\n      if (property == null) {\n          property = configurationProperties.getProperty(key);\n      }\n      if (property == null) {\n          property = extraProperties.getProperty(key);\n      }\n      return property;\n  }\n  ```\n\n- 字符串重复使用\n\n  ```java\n  StringBuilder sb = new StringBuilder();\n  sb.append(calculateJavaClientImplementationPackage());\n  sb.append('.');\n  sb.append(\"DAOImpl\"); //$NON-NLS-1$\n  \n  sb.setLength(0);\n  sb.append('.');\n  sb.append(\"DAO\"); //$NON-NLS-1$\n  ```\n\n- 创建实现类\n\n  ```java\n  DocumentBuilderFactory bean = FactoryFinder.find(\n                  DocumentBuilderFactory.class, \n                  \"com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderFactoryImpl\");\n  ```\n\n- for循环\n\n  ```java\n  for(;;){\n      System.out.println(\"11\");\n  }\n  ```\n\n- while循环一定执行一次\n\n  ```java\n  int counter = -1;\n  while (counter == -1 || registry.containsBeanDefinition(id)) {\n      counter++;\n      id = generatedBeanName + GENERATED_BEAN_NAME_SEPARATOR + counter;\n  }\n  ```\n","source":"_posts/Code pies.md","raw":"---\ntitle: Code Pieces\ndate: 2018-09-12 10:26:48\ntags:\n- 代码片段\ncategories:\n- java基础\n---\n\n# Code Pieces\n\n- 声明一个全局不可改变的map\n\n  ```java\n  public static final Map<String, String> SHORT_IDS;\n  static {\n      Map<String, String> map = new HashMap<>(64);\n      map.put(\"ACT\", \"Australia/Darwin\");\n      map.put(\"AET\", \"Australia/Sydney\");\n      SHORT_IDS = Collections.unmodifiableMap(map);\n  }\n  ```\n\n- spring中类型强转\n\n  ```java\n  BeanDefinitionDocumentReader.class.cast(BeanUtils.instantiateClass(this.documentReaderClass))\n  ```\n\n- 转换为驼峰模式\n\n  ```java\n  public static String getCamelCaseString(String inputString,\n                                          boolean firstCharacterUppercase) {\n      StringBuilder sb = new StringBuilder();\n  \n      boolean nextUpperCase = false;\n      for (int i = 0; i < inputString.length(); i++) {\n          char c = inputString.charAt(i);\n          switch (c) {\n              case '_':\n              case '-':\n              case '@':\n              case '$':\n              case '#':\n              case ' ':\n              case '/':\n              case '&':\n                  if (sb.length() > 0) {\n                      nextUpperCase = true;\n                  }\n                  break;\n              default:\n                  if (nextUpperCase) {\n                      sb.append(Character.toUpperCase(c));\n                      nextUpperCase = false;\n                  } else {\n                      sb.append(Character.toLowerCase(c));\n                  }\n                  break;\n          }\n      }\n  \n      if (firstCharacterUppercase) {\n          sb.setCharAt(0, Character.toUpperCase(sb.charAt(0)));\n      }\n  \n      return sb.toString();\n  }\n  ```\n\n- 替换 ${}\n\n  ```java\n  private String parsePropertyTokens(String string) {\n      final String OPEN = \"${\"; //$NON-NLS-1$\n      final String CLOSE = \"}\"; //$NON-NLS-1$\n  \n      String newString = string;\n      if (newString != null) {\n          int start = newString.indexOf(OPEN);\n          int end = newString.indexOf(CLOSE);\n  \n          while (start > -1 && end > start) {\n              String prepend = newString.substring(0, start);\n              String append = newString.substring(end + CLOSE.length());\n              String propName = newString.substring(start + OPEN.length(),end);\n              String propValue = resolveProperty(propName);\n              if (propValue != null) {\n                  newString = prepend + propValue + append;\n              }\n              start = newString.indexOf(OPEN, end);\n              end = newString.indexOf(CLOSE, end);\n          }\n      }\n      return newString;\n  }\n  private String resolveProperty(String key) {\n      String property = null;\n      property = System.getProperty(key);\n      if (property == null) {\n          property = configurationProperties.getProperty(key);\n      }\n      if (property == null) {\n          property = extraProperties.getProperty(key);\n      }\n      return property;\n  }\n  ```\n\n- 字符串重复使用\n\n  ```java\n  StringBuilder sb = new StringBuilder();\n  sb.append(calculateJavaClientImplementationPackage());\n  sb.append('.');\n  sb.append(\"DAOImpl\"); //$NON-NLS-1$\n  \n  sb.setLength(0);\n  sb.append('.');\n  sb.append(\"DAO\"); //$NON-NLS-1$\n  ```\n\n- 创建实现类\n\n  ```java\n  DocumentBuilderFactory bean = FactoryFinder.find(\n                  DocumentBuilderFactory.class, \n                  \"com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderFactoryImpl\");\n  ```\n\n- for循环\n\n  ```java\n  for(;;){\n      System.out.println(\"11\");\n  }\n  ```\n\n- while循环一定执行一次\n\n  ```java\n  int counter = -1;\n  while (counter == -1 || registry.containsBeanDefinition(id)) {\n      counter++;\n      id = generatedBeanName + GENERATED_BEAN_NAME_SEPARATOR + counter;\n  }\n  ```\n","slug":"Code pies","published":1,"updated":"2018-09-30T08:50:26.887Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfndy0001wlkvcf3u63l2"},{"title":"Git的使用","date":"2018-02-04T02:26:48.000Z","_content":"\n# Git的使用\n\n## git中的提交逻辑\n\n![image](http://omdq6di7v.bkt.clouddn.com/18-1-29/76019026.jpg)\n\n- Workspace：工作区，工作使用的地方，是当前能看到的最新的代码\n- Index / Stage：暂存区，.git目录下的index文件，通过`git status`可以查看暂存区状态\n- Repository：仓库区（或本地仓库）\n- Remote：远程仓库\n\n## Git配置\n\n- 配置git提交时的名称和邮箱\n\n  ```shell\n  git config --global user.name \"lizhi.zhang\"\n  git config --global user.email \"lizhi.zhang@xxx.com\"\n  git config --global color.ui true #开启颜色\n  git config --global alias.st status #设置命令简写\n  git config --unset user.email #删除用户email信息\n  ```\n\n\n## HEAD\n\nHEAD，它始终指向当前所处分支的最新的提交点。你所处的分支变化了，或者产生了新的提交点，HEAD就会跟着改变。\n\n## git常用的指令\n\n![image](http://omdq6di7v.bkt.clouddn.com/18-1-29/62404687.jpg)\n\n### git add\n\n```shell\ngit add .\t#添加当前目录的所有文件到暂存区(只包含新增和修改，不包括删除)\ngit add\t-A    #保存全部增删改\ngit add\t files   #添加指定文件到暂存区\n```\n\n### git rm\n\n```shell\ngit rm [file1][file2]... #删除工作区文件，并且将这次删除放入暂存区\ngit rm --cache xxx #从暂存区移除\n```\n\n### git commit\n\n```shell\ngit commit  -m \"message\" #提交暂存区的指定文件到本地仓库,message代表说明信息\ngit commit --amend -m \"message\"  #使用一次新的commit，替代上一次提交\ngit commit -v #提交时显示所有的diff信息\n```\n\n### git checkout\n\n```shell\ngit checkout [files..]\t#一般用来覆盖工作区，如果不指定提交点的时候，默认使用暂存区覆盖工作区\ngit checkout . #使用暂存区所有文件覆盖工作区\ngit checkout [commit] [files...] #使用本地仓库的commit覆盖工作区\ngit checkout head [files...] #使用本地仓库覆盖工作区\ngit checkout branchName\t#切换分支\n```\n\n### git fetch\n\n```shell\ngit fetch #获取远程库的变化到本地库\n```\n\n### git pull\n\n```shell\ngit pull = git fetch+git merge\ngit pull --rebase = git fetch + git rebase\ngit pull origin 远程分支:本地分支 #拉取远程代码到工作区分支\n```\n\n### git push\n\n```shell\ngit push [origin/bracnh] #推送本地分支变动到远程分支，如果本地和远程分支已经绑定，不需要输入名称\ngit push -u origin master –f #强行推送当前分支到远程分支，即使有冲突\n```\n\n### git reset\n\n```shell\ngit reset --soft [commit] [file]\t#只改变提交点(本地仓库)，暂存区和工作目录的内容都不改变\ngit reset --mixed [commit] [file]\t#改变提交点(本地仓库)，同时改变暂存区的内容，工作区不变\ngit reset --hard [commit] [file]\t#暂存区、工作区的内容都会被修改到与提交点完全一致的状态\ngit reset --hard HEAD [file]\t#让工作区回到上次提交时的状态\n```\n\n### git revert\n\n```shell\ngit revert head\t#撤销前一次 commit\ngit revert commitNo\t#撤销指定的提交\n```\n\nrevert和reset区别\n\n- git revert用一个新提交来消除一个历史提交所做的任何修改;git reset是直接删除指定的commit。\n- 在回滚这一操作上看，效果差不多。但是在日后继续merge以前的老版本时有区别。因为git revert是用一次逆向的commit“中和”之前的提交，因此日后合并老的branch时，导致这部分改变不会再次出现，减少冲突。但是git reset是之间把某些commit在某个branch上删除，因而和老的branch再次merge时，这些被回滚的commit应该还会被引入，产生很多冲突。\n\n- git reset 是把HEAD向后移动了一下，而git revert是HEAD继续前进，只是新的commit的内容和要revert的内容正好相反，能够抵消要被revert的内容。\n\n![image](http://omdq6di7v.bkt.clouddn.com/18-1-29/63781244.jpg)\n\n### git log\n\n用于查看git的提交历史日志\n\n```shell\ngit log --graph —pretty=oneline #查看树形的历史提交日志\ngit log --stat #查看提交记录及记录中提交的文件\ngit log -S [关键词] #根据关键词搜索提交历史\ngit log -p [file] #显示该文件相关的每一次diff\ngit blame [file] #显示该文件什么人在什么时间修改过\ngit reflog #查看当前分支最近几次提交\n```\n\n### git diff\n\n```Shell\ngit diff\t#比较工作区与暂存区区别\ngit diff head [file] #比较工作区与本地库中区别\ngit diff --cached [file] #比较暂存区与本地库区别\ngit diff [commit1] [commit2] #显示两次提交之间的区别\ngit diff branch1 branch2 [file] --stat #显示两个分支上该文件的区别\ngit show [commit] #查看提交改变的详细内容\n\n```\n\n\n### git stash\n\n当正在进行一些工作，工作区处于最新状态，这时需要切换到另外分支进行工作，但是又不想提交代码代码，这个时候就需要使用`git stash`对当前工作区进行暂存\n\n```shell\ngit status #当前很多变动\ngit stash save -a \"msg\"#暂存\ngit status # 发现没有变动了\ngit stash list # 查看暂存区列表\ngit show stash@{0} # 查看暂存的改变是什么\ngit stash apply stash@{2} #恢复暂存区，如果不指定，将恢复到最近的一个暂存\ngit stash pop      # 应用最新的一次暂存的东西,并移除一个stash\ngit stash drop <stash@{id}>  # 删除指定编号的stash，如果不指定编号，删除最新的\ngit stash clear # 清空所有的stash\ngit stash branch 分支名 stash@{id} #根据stash创建分支\n```\n\n### git cherry-pick\n\n```shell\ngit cherry-pick [commit] #可以选择另外一个分支上的一个commit，合并到当前分支\n```\n\n\n\n## 分支 branch\n\n在开发过程中往往会需要多个开发任务并行开发，或者多人同时操作一个项目时，往往会有很多冲突，这个时候就需要用到git的分支。当需要单独开发一个任务时，从主分支上拉出一个新的分支，然后开发完毕后，将主分支的代码merge到自己的分支上，解决冲突后，再讲自己的分支merge到主分支上。\n\n### 常用命令\n\n```shell\ngit branch\t#列出所有本地分支\ngit branch -r\t#列出所有远程分支\ngit branch -a\t#列出所有本地分支和远程分支\ngit branch -vv\t#查看本地分支和远程分支的关联关系\ngit branch xx\t#新建一个分支，但依然停留在当前分支\ngit checkout xx\t#切换到指定分支，并更新工作区\ngit checkout -b xx\t#新建一个分支，并切换到该分支\ngit push -u origin 本地当前分支:远程分支名\t#将本地分支推送到远程创建分支\ngit branch -d xx\t#删除分支\ngit push origin --delete [origin/branch]\t#删除远程分支\ngit branch --set-upstream-to=origin/远程分支 本地分支\t#绑定本地分支和远程分支的关系\ngit checkout -b 本地分支名x origin/远程分支名x\t#从远程分支下拉\ngit branch 本地分支名 --track orign/远程分支名\t#新建一个分支，与指定的远程分支建立追踪关系\ngit checkout -  #切换到上一个分支\n```\n\n### 合并分支\n\n#### git merge\n\n```shell\ngit merge [branch1]   #将branch1合并到当前分支上\n```\n\n#### git rebase\n\n```shell\ngit rebase [branch1] #将branch1合并到当前分支上\n```\n\n**git merge **是把远程的修改拉下来然后和本地的修改合并，然后生成一个新的commit\n\n**git rebase** 会将所有的提交合并到一条线上，并不会产生新的commit\n\n## 标签 tag\n\n在git中分支是动态的，每一次提交，分支都一直在跟着提交变动，标签是分支在某个时刻的快照，标签是固定的\n\n```shell\ngit tag  #列出所有的tag\ngit tag -l 'rex'  #搜索tag\ngit tag [tag]  #在当前的commit新建一个tag\ngit tag [tag] [commit] #在指定的commit新建一个tag\ngit tag -d [tag] #删除本地的tag  git push origin :[tag] #删除远程tag\ngit show [tag] #查看tag信息\ngit push origin [tag]  #将本地tag推送到远程\ngit push origin --tags  #将本地所有的tag推送到远程\ngit checkout -b [branch] [tag] #从tag拉一个分支\n```\n\n\n\n## 设置git的alias\n\n每次输入指令的全名称比较浪费时间，git提供了给指令设置alias的功能，通过设置alias提高命令输入速度\n\n在user目录下找到.gitconfig(没有就创建一个)然后编辑，加入以下命令\n\n```xml\n[alias]\n    br = branch\n    ch = checkout\n    co = commit\n    st = status\n    pl = pull --rebase\n    ps = push\n    dt = difftool\n    l = log --stat\n    lg = log --graph --pretty=oneline\n    ca = commit -a\n    cm = commit -m \n    rv = revert\n    re = reset\n    cl = clone\n    fe = fetch\n    sh = stash\n    brv = branch -vv\n    ad = add .\n\n```\n\n## 一些配置\n\n- 忽略一些未add的文件，避免add . 的时候将其add进去\n\n  在 .git/info/exclude 中添加要忽略的文件，如要忽略 /test.log，则填写 test.log,这样在git add . 的时候将不会添加test.log到git版本控制\n\n- 忽略已纳入版本的文件修改，如本地修改的jdbc配置，又不想提交到远程仓库，所有就想在执行git add . 的时候不要将本地的修改提交\n\n  使用 **git update-index -\\-assume-unchanged   xxx**：可以忽略这个xxx文件的修改。从而不用提交到库里面。要想恢复该文件则执行 **git update-index -\\-no-assume-unchanged xxx** 来恢复跟踪\n\n  ```shell\n  git update-index --assume-unchanged   xxx\n  git update-index --no-assume-unchanged xxx\n  ```\n\n## 解决冲突\n\n当多人在操作同一个分支的时候，由于并发工作，常常会产生代码冲突，如果在提交代码前，别的同事提交了代码，经常会由于冲突无法提交代码，这个时候就需要解决完冲突，然后重新提交。\n\n```shell\ngit push  #提交，如果有冲突，会提示提交失败\ngit pull #有冲突，拉取远程代码，\n\t#如果能自动合并，会提示auto merge成功，然后再git push提交代码\n\t#失败，需要手动解决冲突\n\t\t1. git status #查看冲突情况\n\t\t2. 打开冲突文件，解决冲突\n\t\t3. git add . #解决完冲突后，一定要执行以下该命令，不然git状态为merging状态\n\t\t4. git commit -m 'xxx' #提交代码\n\t\t5. git push #推送到远程仓库\n```\n\n\n\n### 清除git提交历史记录\n\n```shell\n1.Checkout\n\n   git checkout --orphan latest_branch\n\n2. Add all the files\n\n   git add -A\n\n3. Commit the changes\n\n   git commit -am \"commit message\"\n\n4. Delete the branch\n\n   git branch -D master\n\n5.Rename the current branch to master\n\n   git branch -m master\n\n6.Finally, force update your repository\n\n   git push -f origin master\n```\n\n## 更新fork工程\n\nfork 了别人的仓库后，原作者又更新了仓库，如何将自己的代码和原仓库保持一致\n\n```shell\ngit remote -v  #查看远程仓库\n# origin  git@github.com:aspiresnow/spring-framework.git (fetch) \n# origin  git@github.com:aspiresnow/spring-framework.git (push)\ngit remote add upstream https://github.com/spring-projects/spring-framework.git#添加被fork的远程仓库\ngit remote -v\n# origin  git@github.com:aspiresnow/spring-framework.git (fetch)\n# origin  git@github.com:aspiresnow/spring-framework.git (push)\n# upstream        https://github.com/spring-projects/spring-framework.git (fetch)\n# upstream        https://github.com/spring-projects/spring-framework.git (push)\ngit fetch upstream #同步被fork仓库的更新\ngit merge upstream/mastegit r #把 upstream/master 分支合并到本地 master 上\ngit push origin master # 推到origin远程\n\n```\n\n# 参考资料\n\n[一篇文章，教你学会Git](https://www.jianshu.com/p/072587b47515)","source":"_posts/Git使用.md","raw":"---\ntitle: Git的使用\ndate: 2018-02-04 10:26:48\ntags:\n- Git\ncategories:\n- java工具\n---\n\n# Git的使用\n\n## git中的提交逻辑\n\n![image](http://omdq6di7v.bkt.clouddn.com/18-1-29/76019026.jpg)\n\n- Workspace：工作区，工作使用的地方，是当前能看到的最新的代码\n- Index / Stage：暂存区，.git目录下的index文件，通过`git status`可以查看暂存区状态\n- Repository：仓库区（或本地仓库）\n- Remote：远程仓库\n\n## Git配置\n\n- 配置git提交时的名称和邮箱\n\n  ```shell\n  git config --global user.name \"lizhi.zhang\"\n  git config --global user.email \"lizhi.zhang@xxx.com\"\n  git config --global color.ui true #开启颜色\n  git config --global alias.st status #设置命令简写\n  git config --unset user.email #删除用户email信息\n  ```\n\n\n## HEAD\n\nHEAD，它始终指向当前所处分支的最新的提交点。你所处的分支变化了，或者产生了新的提交点，HEAD就会跟着改变。\n\n## git常用的指令\n\n![image](http://omdq6di7v.bkt.clouddn.com/18-1-29/62404687.jpg)\n\n### git add\n\n```shell\ngit add .\t#添加当前目录的所有文件到暂存区(只包含新增和修改，不包括删除)\ngit add\t-A    #保存全部增删改\ngit add\t files   #添加指定文件到暂存区\n```\n\n### git rm\n\n```shell\ngit rm [file1][file2]... #删除工作区文件，并且将这次删除放入暂存区\ngit rm --cache xxx #从暂存区移除\n```\n\n### git commit\n\n```shell\ngit commit  -m \"message\" #提交暂存区的指定文件到本地仓库,message代表说明信息\ngit commit --amend -m \"message\"  #使用一次新的commit，替代上一次提交\ngit commit -v #提交时显示所有的diff信息\n```\n\n### git checkout\n\n```shell\ngit checkout [files..]\t#一般用来覆盖工作区，如果不指定提交点的时候，默认使用暂存区覆盖工作区\ngit checkout . #使用暂存区所有文件覆盖工作区\ngit checkout [commit] [files...] #使用本地仓库的commit覆盖工作区\ngit checkout head [files...] #使用本地仓库覆盖工作区\ngit checkout branchName\t#切换分支\n```\n\n### git fetch\n\n```shell\ngit fetch #获取远程库的变化到本地库\n```\n\n### git pull\n\n```shell\ngit pull = git fetch+git merge\ngit pull --rebase = git fetch + git rebase\ngit pull origin 远程分支:本地分支 #拉取远程代码到工作区分支\n```\n\n### git push\n\n```shell\ngit push [origin/bracnh] #推送本地分支变动到远程分支，如果本地和远程分支已经绑定，不需要输入名称\ngit push -u origin master –f #强行推送当前分支到远程分支，即使有冲突\n```\n\n### git reset\n\n```shell\ngit reset --soft [commit] [file]\t#只改变提交点(本地仓库)，暂存区和工作目录的内容都不改变\ngit reset --mixed [commit] [file]\t#改变提交点(本地仓库)，同时改变暂存区的内容，工作区不变\ngit reset --hard [commit] [file]\t#暂存区、工作区的内容都会被修改到与提交点完全一致的状态\ngit reset --hard HEAD [file]\t#让工作区回到上次提交时的状态\n```\n\n### git revert\n\n```shell\ngit revert head\t#撤销前一次 commit\ngit revert commitNo\t#撤销指定的提交\n```\n\nrevert和reset区别\n\n- git revert用一个新提交来消除一个历史提交所做的任何修改;git reset是直接删除指定的commit。\n- 在回滚这一操作上看，效果差不多。但是在日后继续merge以前的老版本时有区别。因为git revert是用一次逆向的commit“中和”之前的提交，因此日后合并老的branch时，导致这部分改变不会再次出现，减少冲突。但是git reset是之间把某些commit在某个branch上删除，因而和老的branch再次merge时，这些被回滚的commit应该还会被引入，产生很多冲突。\n\n- git reset 是把HEAD向后移动了一下，而git revert是HEAD继续前进，只是新的commit的内容和要revert的内容正好相反，能够抵消要被revert的内容。\n\n![image](http://omdq6di7v.bkt.clouddn.com/18-1-29/63781244.jpg)\n\n### git log\n\n用于查看git的提交历史日志\n\n```shell\ngit log --graph —pretty=oneline #查看树形的历史提交日志\ngit log --stat #查看提交记录及记录中提交的文件\ngit log -S [关键词] #根据关键词搜索提交历史\ngit log -p [file] #显示该文件相关的每一次diff\ngit blame [file] #显示该文件什么人在什么时间修改过\ngit reflog #查看当前分支最近几次提交\n```\n\n### git diff\n\n```Shell\ngit diff\t#比较工作区与暂存区区别\ngit diff head [file] #比较工作区与本地库中区别\ngit diff --cached [file] #比较暂存区与本地库区别\ngit diff [commit1] [commit2] #显示两次提交之间的区别\ngit diff branch1 branch2 [file] --stat #显示两个分支上该文件的区别\ngit show [commit] #查看提交改变的详细内容\n\n```\n\n\n### git stash\n\n当正在进行一些工作，工作区处于最新状态，这时需要切换到另外分支进行工作，但是又不想提交代码代码，这个时候就需要使用`git stash`对当前工作区进行暂存\n\n```shell\ngit status #当前很多变动\ngit stash save -a \"msg\"#暂存\ngit status # 发现没有变动了\ngit stash list # 查看暂存区列表\ngit show stash@{0} # 查看暂存的改变是什么\ngit stash apply stash@{2} #恢复暂存区，如果不指定，将恢复到最近的一个暂存\ngit stash pop      # 应用最新的一次暂存的东西,并移除一个stash\ngit stash drop <stash@{id}>  # 删除指定编号的stash，如果不指定编号，删除最新的\ngit stash clear # 清空所有的stash\ngit stash branch 分支名 stash@{id} #根据stash创建分支\n```\n\n### git cherry-pick\n\n```shell\ngit cherry-pick [commit] #可以选择另外一个分支上的一个commit，合并到当前分支\n```\n\n\n\n## 分支 branch\n\n在开发过程中往往会需要多个开发任务并行开发，或者多人同时操作一个项目时，往往会有很多冲突，这个时候就需要用到git的分支。当需要单独开发一个任务时，从主分支上拉出一个新的分支，然后开发完毕后，将主分支的代码merge到自己的分支上，解决冲突后，再讲自己的分支merge到主分支上。\n\n### 常用命令\n\n```shell\ngit branch\t#列出所有本地分支\ngit branch -r\t#列出所有远程分支\ngit branch -a\t#列出所有本地分支和远程分支\ngit branch -vv\t#查看本地分支和远程分支的关联关系\ngit branch xx\t#新建一个分支，但依然停留在当前分支\ngit checkout xx\t#切换到指定分支，并更新工作区\ngit checkout -b xx\t#新建一个分支，并切换到该分支\ngit push -u origin 本地当前分支:远程分支名\t#将本地分支推送到远程创建分支\ngit branch -d xx\t#删除分支\ngit push origin --delete [origin/branch]\t#删除远程分支\ngit branch --set-upstream-to=origin/远程分支 本地分支\t#绑定本地分支和远程分支的关系\ngit checkout -b 本地分支名x origin/远程分支名x\t#从远程分支下拉\ngit branch 本地分支名 --track orign/远程分支名\t#新建一个分支，与指定的远程分支建立追踪关系\ngit checkout -  #切换到上一个分支\n```\n\n### 合并分支\n\n#### git merge\n\n```shell\ngit merge [branch1]   #将branch1合并到当前分支上\n```\n\n#### git rebase\n\n```shell\ngit rebase [branch1] #将branch1合并到当前分支上\n```\n\n**git merge **是把远程的修改拉下来然后和本地的修改合并，然后生成一个新的commit\n\n**git rebase** 会将所有的提交合并到一条线上，并不会产生新的commit\n\n## 标签 tag\n\n在git中分支是动态的，每一次提交，分支都一直在跟着提交变动，标签是分支在某个时刻的快照，标签是固定的\n\n```shell\ngit tag  #列出所有的tag\ngit tag -l 'rex'  #搜索tag\ngit tag [tag]  #在当前的commit新建一个tag\ngit tag [tag] [commit] #在指定的commit新建一个tag\ngit tag -d [tag] #删除本地的tag  git push origin :[tag] #删除远程tag\ngit show [tag] #查看tag信息\ngit push origin [tag]  #将本地tag推送到远程\ngit push origin --tags  #将本地所有的tag推送到远程\ngit checkout -b [branch] [tag] #从tag拉一个分支\n```\n\n\n\n## 设置git的alias\n\n每次输入指令的全名称比较浪费时间，git提供了给指令设置alias的功能，通过设置alias提高命令输入速度\n\n在user目录下找到.gitconfig(没有就创建一个)然后编辑，加入以下命令\n\n```xml\n[alias]\n    br = branch\n    ch = checkout\n    co = commit\n    st = status\n    pl = pull --rebase\n    ps = push\n    dt = difftool\n    l = log --stat\n    lg = log --graph --pretty=oneline\n    ca = commit -a\n    cm = commit -m \n    rv = revert\n    re = reset\n    cl = clone\n    fe = fetch\n    sh = stash\n    brv = branch -vv\n    ad = add .\n\n```\n\n## 一些配置\n\n- 忽略一些未add的文件，避免add . 的时候将其add进去\n\n  在 .git/info/exclude 中添加要忽略的文件，如要忽略 /test.log，则填写 test.log,这样在git add . 的时候将不会添加test.log到git版本控制\n\n- 忽略已纳入版本的文件修改，如本地修改的jdbc配置，又不想提交到远程仓库，所有就想在执行git add . 的时候不要将本地的修改提交\n\n  使用 **git update-index -\\-assume-unchanged   xxx**：可以忽略这个xxx文件的修改。从而不用提交到库里面。要想恢复该文件则执行 **git update-index -\\-no-assume-unchanged xxx** 来恢复跟踪\n\n  ```shell\n  git update-index --assume-unchanged   xxx\n  git update-index --no-assume-unchanged xxx\n  ```\n\n## 解决冲突\n\n当多人在操作同一个分支的时候，由于并发工作，常常会产生代码冲突，如果在提交代码前，别的同事提交了代码，经常会由于冲突无法提交代码，这个时候就需要解决完冲突，然后重新提交。\n\n```shell\ngit push  #提交，如果有冲突，会提示提交失败\ngit pull #有冲突，拉取远程代码，\n\t#如果能自动合并，会提示auto merge成功，然后再git push提交代码\n\t#失败，需要手动解决冲突\n\t\t1. git status #查看冲突情况\n\t\t2. 打开冲突文件，解决冲突\n\t\t3. git add . #解决完冲突后，一定要执行以下该命令，不然git状态为merging状态\n\t\t4. git commit -m 'xxx' #提交代码\n\t\t5. git push #推送到远程仓库\n```\n\n\n\n### 清除git提交历史记录\n\n```shell\n1.Checkout\n\n   git checkout --orphan latest_branch\n\n2. Add all the files\n\n   git add -A\n\n3. Commit the changes\n\n   git commit -am \"commit message\"\n\n4. Delete the branch\n\n   git branch -D master\n\n5.Rename the current branch to master\n\n   git branch -m master\n\n6.Finally, force update your repository\n\n   git push -f origin master\n```\n\n## 更新fork工程\n\nfork 了别人的仓库后，原作者又更新了仓库，如何将自己的代码和原仓库保持一致\n\n```shell\ngit remote -v  #查看远程仓库\n# origin  git@github.com:aspiresnow/spring-framework.git (fetch) \n# origin  git@github.com:aspiresnow/spring-framework.git (push)\ngit remote add upstream https://github.com/spring-projects/spring-framework.git#添加被fork的远程仓库\ngit remote -v\n# origin  git@github.com:aspiresnow/spring-framework.git (fetch)\n# origin  git@github.com:aspiresnow/spring-framework.git (push)\n# upstream        https://github.com/spring-projects/spring-framework.git (fetch)\n# upstream        https://github.com/spring-projects/spring-framework.git (push)\ngit fetch upstream #同步被fork仓库的更新\ngit merge upstream/mastegit r #把 upstream/master 分支合并到本地 master 上\ngit push origin master # 推到origin远程\n\n```\n\n# 参考资料\n\n[一篇文章，教你学会Git](https://www.jianshu.com/p/072587b47515)","slug":"Git使用","published":1,"updated":"2018-09-19T08:48:05.066Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfne10002wlkvyvx00snh"},{"_content":"# IO模型\n\n## 同步与异步\n\n- 同步和异步关注的是消息通信机制 (synchronous communication/ asynchronous communication)\n- 所谓同步，就是在发出一个*调用*时，在没有得到结果之前，该*调用*就不返回。但是一旦调用返回，就得到返回值了。换句话说，就是由*调用者*主动等待这个*调用*的结果。\n- 而异步则是相反，*调用*在发出之后，这个调用就直接返回了，所以没有返回结果。换句话说，当一个异步过程调用发出后，调用者不会立刻得到结果。而是在*调用*发出后，*被调用者*通过状态、通知来通知调用者，或通过回调函数处理这个调用。\n\n## 阻塞与非阻塞\n\n- 阻塞和非阻塞关注的是程序在等待调用结果（消息，返回值）时的状态.\n- 阻塞调用是指调用结果返回之前，当前线程会被挂起。调用线程只有在得到结果之后才会返回。\n- 非阻塞调用指在不能立刻得到结果之前，该调用不会阻塞当前线程。 \n\n 一般来说I/O模型可以分为：同步阻塞，同步非阻塞，异步阻塞，异步非阻塞IO\n\n### 同步阻塞IO：\n\n在此种方式下，用户进程在发起一个IO操作以后，必须等待IO操作的完成，只有当真正完成了IO操作以后，用户进程才能运行。JAVA传统的IO模型属于此种方式！\n\n### 同步非阻塞IO：\n在此种方式下，用户进程发起一个IO操作以后边可返回做其它事情，但是用户进程需要时不时的询问IO操作是否就绪，这就要求用户进程不停的去询问，从而引入不必要的CPU资源浪费。其中目前JAVA的NIO就属于同步非阻塞IO。\n\n### 异步阻塞IO：\n此种方式下是指应用发起一个IO操作以后，不等待内核IO操作的完成，等内核完成IO操作以后会通知应用程序，这其实就是同步和异步最关键的区别，同步必须等待或者主动的去询问IO是否完成，那么为什么说是阻塞的呢？因为此时（通知）是通过select系统调用来完成的，而select函数本身的实现方式是阻塞的，而采用select函数有个好处就是它可以同时监听多个文件句柄（就绪的没有就绪的都有监听，epoll是select的替代方式，只监听就绪的文件句柄），从而提高系统的并发性！\n\n### 异步非阻塞IO:\n\n在此种模式下，用户进程只需要发起一个IO操作然后立即返回，等IO操作真正的完成以后，应用程序会得到IO操作完成的通知，此时用户进程只需要对数据进行处理就好了，不需要进行实际的IO读写操作，因为真正的IO读取或者写入操作已经由内核完成了。目前Java中还没有支持此种IO模型。\n\n### 异步事件驱动 \n\n如果我们的业务逻辑处理使用异步事件驱动（Reactor）的方式，而又需要在本次请求中需要返回请求结果，此时属于同步获取返回值，因此此时我们只能使用阻塞异步或者“并发”“同步”的方式。\n\n如果该次请求不需要同步获取返回值，此时我们即可使用阻塞异步（Reactor）方式，也可以结合使用DeferredResult异步结果返回。\n\n\n\n  IO的方式通常分为几种，同步阻塞的BIO、同步非阻塞的NIO、异步非阻塞的AIO。\n\n一、BIO\n\n​\t同步阻塞式IO，服务器实现模式为一个连接一个线程，即客户端有连接请求时服务器端就需要启动一个线程进行处理，如果这个连接不做任何事情会造成不必要的线程开销，当然可以通过线程池机制改善。 \n\n​     在JDK1.4出来之前，我们建立网络连接的时候采用BIO模式，需要先在服务端启动一个ServerSocket，然后在客户端启动Socket来对服务端进行通信，默认情况下服务端需要对每个请求建立一堆线程等待请求，而客户端发送请求后，先咨询服务端是否有线程相应，如果没有则会一直等待或者遭到拒绝请求，如果有的话，客户端会线程会等待请求结束后才继续执行。\n\n二、NIO\n\n同步非阻塞式IO，服务器实现模式为一个请求一个线程，即客户端发送的连接请求都会注册到多路复用器上，多路复用器轮询到连接有I/O请求时才启动一个线程进行处理。  \n\n​    NIO本身是基于事件驱动思想来完成的，其主要想解决的是BIO的大并发问题： 在使用同步I/O的网络应用中，如果要同时处理多个客户端请求，或是在客户端要同时和多个服务器进行通讯，就必须使用多线程来处理。也就是说，将每一个客户端请求分配给一个线程来单独处理。这样做虽然可以达到我们的要求，但同时又会带来另外一个问题。由于每创建一个线程，就要为这个线程分配一定的内存空间（也叫工作存储器），而且操作系统本身也对线程的总数有一定的限制。如果客户端的请求过多，服务端程序可能会因为不堪重负而拒绝客户端的请求，甚至服务器可能会因此而瘫痪。\n\n​    NIO基于Reactor，当socket有流可读或可写入socket时，操作系统会相应的通知引用程序进行处理，应用再将流读取到缓冲区或写入操作系统。  也就是说，这个时候，已经不是一个连接就要对应一个处理线程了，而是有效的请求，对应一个线程，当连接没有数据时，是没有工作线程来处理的。\n\n   BIO与NIO一个比较重要的不同，是我们使用BIO的时候往往会引入多线程，每个连接一个单独的线程；而NIO则是使用单线程或者只使用少量的多线程，每个连接共用一个线程。 \n\nNIO的最重要的地方是当一个连接创建后，不需要对应一个线程，这个连接会被注册到多路复用器上面，所以所有的连接只需要一个线程就可以搞定，当这个线程中的多路复用器进行轮询的时候，发现连接上有请求的话，才开启一个线程进行处理，也就是一个请求一个线程模式。\n\n​      在NIO的处理方式中，当一个请求来的话，开启线程进行处理，可能会等待后端应用的资源(JDBC连接等)，其实这个线程就被阻塞了，当并发上来的话，还是会有BIO一样的问题。\n\n　　HTTP/1.1出现后，有了Http长连接，这样除了超时和指明特定关闭的http header外，这个链接是一直打开的状态的，这样在NIO处理中可以进一步的进化，在后端资源中可以实现资源池或者队列，当请求来的话，开启的线程把请求和请求数据传送给后端资源池或者队列里面就返回，并且在全局的地方保持住这个现场(哪个连接的哪个请求等)，这样前面的线程还是可以去接受其他的请求，而后端的应用的处理只需要执行队列里面的就可以了，这样请求处理和后端应用是异步的.当后端处理完，到全局地方得到现场，产生响应，这个就实现了异步处理。\n\n三、AIO\n\n异步非阻塞式IO，服务器实现模式为一个有效请求一个线程，客户端的I/O请求都是由OS先完成了再通知服务器应用去启动线程进行处理。 \n\n​     与NIO不同，当进行读写操作时，只须直接调用API的read或write方法即可。这两种方法均为异步的，对于读操作而言，当有流可读取时，操作系统会将可读的流传入read方法的缓冲区，并通知应用程序；对于写操作而言，当操作系统将write方法传递的流写入完毕时，操作系统主动通知应用程序。  即可以理解为，read/write方法都是异步的，完成后会主动调用回调函数。  在JDK1.7中，这部分内容被称作NIO.2，主要在java.nio.channels包下增加了下面四个异步通道：\n\n- AsynchronousSocketChannel\n- AsynchronousServerSocketChannel\n- AsynchronousFileChannel\n- AsynchronousDatagramChannel\n\n其中的read/write方法，会返回一个带回调函数的对象，当执行完读取/写入操作后，直接调用回调函数。\n\nBIO是一个连接一个线程。\n\nNIO是一个请求一个线程。\n\nAIO是一个有效请求一个线程。\n\n先来个例子理解一下概念，以银行取款为例： \n\n- 同步 ： 自己亲自出马持银行卡到银行取钱（使用同步IO时，Java自己处理IO读写）；\n- 异步 ： 委托一小弟拿银行卡到银行取钱，然后给你（使用异步IO时，Java将IO读写委托给OS处理，需要将数据缓冲区地址和大小传给OS(银行卡和密码)，OS需要支持异步IO操作API）；\n- 阻塞 ： ATM排队取款，你只能等待（使用阻塞IO时，Java调用会一直阻塞到读写完成才返回）；\n- 非阻塞 ： 柜台取款，取个号，然后坐在椅子上做其它事，等号广播会通知你办理，没到号你就不能去，你可以不断问大堂经理排到了没有，大堂经理如果说还没到你就不能去（使用非阻塞IO时，如果不能读写Java调用会马上返回，当IO事件分发器会通知可读写时再继续进行读写，不断循环直到读写完成）\n\nJava对BIO、NIO、AIO的支持：\n\n- Java BIO ： 同步并阻塞，服务器实现模式为一个连接一个线程，即客户端有连接请求时服务器端就需要启动一个线程进行处理，如果这个连接不做任何事情会造成不必要的线程开销，当然可以通过线程池机制改善。\n- Java NIO ： 同步非阻塞，服务器实现模式为一个请求一个线程，即客户端发送的连接请求都会注册到多路复用器上，多路复用器轮询到连接有I/O请求时才启动一个线程进行处理。\n- Java AIO(NIO.2) ： 异步非阻塞，服务器实现模式为一个有效请求一个线程，客户端的I/O请求都是由OS先完成了再通知服务器应用去启动线程进行处理，\n\nBIO、NIO、AIO适用场景分析:\n\n- BIO方式适用于连接数目比较小且固定的架构，这种方式对服务器资源要求比较高，并发局限于应用中，JDK1.4以前的唯一选择，但程序直观简单易理解。\n- NIO方式适用于连接数目多且连接比较短（轻操作）的架构，比如聊天服务器，并发局限于应用中，编程比较复杂，JDK1.4开始支持。\n- AIO方式使用于连接数目多且连接比较长（重操作）的架构，比如相册服务器，充分调用OS参与并发操作，编程比较复杂，JDK7开始支持。\n\n另外，I/O属于底层操作，需要操作系统支持，并发也需要操作系统的支持，所以性能方面不同操作系统差异会比较明显。\n\n在高性能的I/O设计中，有两个比较著名的模式Reactor和Proactor模式，其中Reactor模式用于同步I/O，而Proactor运用于异步I/O操作。\n\n​    在比较这两个模式之前，我们首先的搞明白几个概念，什么是阻塞和非阻塞，什么是同步和异步,同步和异步是针对应用程序和内核的交互而言的，同步指的是用户进程触发IO操作并等待或者轮询的去查看IO操作是否就绪，而异步是指用户进程触发IO操作以后便开始做自己的事情，而当IO操作已经完成的时候会得到IO完成的通知。而阻塞和非阻塞是针对于进程在访问数据的时候，根据IO操作的就绪状态来采取的不同方式，说白了是一种读取或者写入操作函数的实现方式，阻塞方式下读取或者写入函数将一直等待，而非阻塞方式下，读取或者写入函数会立即返回一个状态值。\n\n 一般来说I/O模型可以分为：同步阻塞，同步非阻塞，异步阻塞，异步非阻塞IO\n\n同步阻塞IO：在此种方式下，用户进程在发起一个IO操作以后，必须等待IO操作的完成，只有当真正完成了IO操作以后，用户进程才能运行。JAVA传统的IO模型属于此种方式！\n\n同步非阻塞IO:在此种方式下，用户进程发起一个IO操作以后边可返回做其它事情，但是用户进程需要时不时的询问IO操作是否就绪，这就要求用户进程不停的去询问，从而引入不必要的CPU资源浪费。其中目前JAVA的NIO就属于同步非阻塞IO。\n\n异步阻塞IO：此种方式下是指应用发起一个IO操作以后，不等待内核IO操作的完成，等内核完成IO操作以后会通知应用程序，这其实就是同步和异步最关键的区别，同步必须等待或者主动的去询问IO是否完成，那么为什么说是阻塞的呢？因为此时是通过select系统调用来完成的，而select函数本身的实现方式是阻塞的，而采用select函数有个好处就是它可以同时监听多个文件句柄，从而提高系统的并发性！\n\n 异步非阻塞IO:在此种模式下，用户进程只需要发起一个IO操作然后立即返回，等IO操作真正的完成以后，应用程序会得到IO操作完成的通知，此时用户进程只需要对数据进行处理就好了，不需要进行实际的IO读写操作，因为真正的IO读取或者写入操作已经由内核完成了。目前Java中还没有支持此种IO模型。    \n\n \n\n 阻塞和非阻塞忙轮询。\n\n- 非阻塞忙轮询：数据没来，进程就不停的去检测数据，直到数据来。\n- 阻塞：数据没来，啥都不做，直到数据来了，才进行下一步的处理。\n\n先说说阻塞，因为一个线程只能处理一个套接字的I/O事件，如果想同时处理多个，可以利用非阻塞忙轮询的方式,伪代码如下：  \n\n```java\nwhile true  \n{  \n    for i in stream[]  \n    {  \n        if i has data  \n        read until unavailable  \n    }  \n}\n```\n\n 我们只要把所有流从头到尾查询一遍，就可以处理多个流了，但这样做很不好，因为如果所有的流都没有I/O事件，白白浪费CPU时间片。正如有一位科学家所说，**计算机所有的问题都可以增加一个中间层来解决**，同样，为了避免这里cpu的空转，我们不让这个线程亲自去检查流中是否有事件，而是引进了一个代理(一开始是select,后来是poll)，这个代理很牛，它可以同时观察许多流的I/O事件，如果没有事件，代理就阻塞，线程就不会挨个挨个去轮询了，伪代码如下：  \n\n ```java\nwhile true  \n{  \n    select(streams[]) //这一步死在这里，知道有一个流有I/O事件时，才往下执行  \n    for i in streams[]  \n    {  \n        if i has data  \n        read until unavailable  \n    }  \n}\n ```\n\n 但是依然有个问题，我们从select那里仅仅知道了，有I/O事件发生了，却并不知道是哪那几个流（可能有一个，多个，甚至全部），我们只能无差别轮询所有流，找出能读出数据，或者写入数据的流，对他们进行操作。所以**select具有O(n)的无差别轮询复杂度**，同时处理的流越多，无差别轮询时间就越长。\n\n**epoll可以理解为event poll**，不同于忙轮询和无差别轮询，epoll会把哪个流发生了怎样的I/O事件通知我们。所以我们说epoll实际上是**事件驱动（每个事件关联上fd）**的，此时我们对这些流的操作都是有意义的。**（复杂度降低到了O(1)）**伪代码如下：\n\n ```java\nwhile true  \n{  \n    active_stream[] = epoll_wait(epollfd)  \n    for i in active_stream[]  \n    {  \n        read or write till  \n    }  \n}\n ```\n\n可以看到，select和epoll最大的区别就是：select只是告诉你一定数目的流有事件了，至于哪个流有事件，还得你一个一个地去轮询，而epoll会把发生的事件告诉你，通过发生的事件，就自然而然定位到哪个流了。不能不说epoll跟select相比，是质的飞跃，我觉得这也是一种**牺牲空间，换取时间的思想**，毕竟现在硬件越来越便宜了。\n\n更详细的Select,poll,epoll 请参考：[select、poll、epoll之间的区别(搜狗面试)](https://www.cnblogs.com/aspirant/p/9166944.html)\n\n 看下这个  https://www.cnblogs.com/aspirant/p/6877350.html?utm_source=itdadao&utm_medium=referral&from=groupmessage&isappinstalled=0\n\n \n\n ","source":"_posts/IO模型.md","raw":"# IO模型\n\n## 同步与异步\n\n- 同步和异步关注的是消息通信机制 (synchronous communication/ asynchronous communication)\n- 所谓同步，就是在发出一个*调用*时，在没有得到结果之前，该*调用*就不返回。但是一旦调用返回，就得到返回值了。换句话说，就是由*调用者*主动等待这个*调用*的结果。\n- 而异步则是相反，*调用*在发出之后，这个调用就直接返回了，所以没有返回结果。换句话说，当一个异步过程调用发出后，调用者不会立刻得到结果。而是在*调用*发出后，*被调用者*通过状态、通知来通知调用者，或通过回调函数处理这个调用。\n\n## 阻塞与非阻塞\n\n- 阻塞和非阻塞关注的是程序在等待调用结果（消息，返回值）时的状态.\n- 阻塞调用是指调用结果返回之前，当前线程会被挂起。调用线程只有在得到结果之后才会返回。\n- 非阻塞调用指在不能立刻得到结果之前，该调用不会阻塞当前线程。 \n\n 一般来说I/O模型可以分为：同步阻塞，同步非阻塞，异步阻塞，异步非阻塞IO\n\n### 同步阻塞IO：\n\n在此种方式下，用户进程在发起一个IO操作以后，必须等待IO操作的完成，只有当真正完成了IO操作以后，用户进程才能运行。JAVA传统的IO模型属于此种方式！\n\n### 同步非阻塞IO：\n在此种方式下，用户进程发起一个IO操作以后边可返回做其它事情，但是用户进程需要时不时的询问IO操作是否就绪，这就要求用户进程不停的去询问，从而引入不必要的CPU资源浪费。其中目前JAVA的NIO就属于同步非阻塞IO。\n\n### 异步阻塞IO：\n此种方式下是指应用发起一个IO操作以后，不等待内核IO操作的完成，等内核完成IO操作以后会通知应用程序，这其实就是同步和异步最关键的区别，同步必须等待或者主动的去询问IO是否完成，那么为什么说是阻塞的呢？因为此时（通知）是通过select系统调用来完成的，而select函数本身的实现方式是阻塞的，而采用select函数有个好处就是它可以同时监听多个文件句柄（就绪的没有就绪的都有监听，epoll是select的替代方式，只监听就绪的文件句柄），从而提高系统的并发性！\n\n### 异步非阻塞IO:\n\n在此种模式下，用户进程只需要发起一个IO操作然后立即返回，等IO操作真正的完成以后，应用程序会得到IO操作完成的通知，此时用户进程只需要对数据进行处理就好了，不需要进行实际的IO读写操作，因为真正的IO读取或者写入操作已经由内核完成了。目前Java中还没有支持此种IO模型。\n\n### 异步事件驱动 \n\n如果我们的业务逻辑处理使用异步事件驱动（Reactor）的方式，而又需要在本次请求中需要返回请求结果，此时属于同步获取返回值，因此此时我们只能使用阻塞异步或者“并发”“同步”的方式。\n\n如果该次请求不需要同步获取返回值，此时我们即可使用阻塞异步（Reactor）方式，也可以结合使用DeferredResult异步结果返回。\n\n\n\n  IO的方式通常分为几种，同步阻塞的BIO、同步非阻塞的NIO、异步非阻塞的AIO。\n\n一、BIO\n\n​\t同步阻塞式IO，服务器实现模式为一个连接一个线程，即客户端有连接请求时服务器端就需要启动一个线程进行处理，如果这个连接不做任何事情会造成不必要的线程开销，当然可以通过线程池机制改善。 \n\n​     在JDK1.4出来之前，我们建立网络连接的时候采用BIO模式，需要先在服务端启动一个ServerSocket，然后在客户端启动Socket来对服务端进行通信，默认情况下服务端需要对每个请求建立一堆线程等待请求，而客户端发送请求后，先咨询服务端是否有线程相应，如果没有则会一直等待或者遭到拒绝请求，如果有的话，客户端会线程会等待请求结束后才继续执行。\n\n二、NIO\n\n同步非阻塞式IO，服务器实现模式为一个请求一个线程，即客户端发送的连接请求都会注册到多路复用器上，多路复用器轮询到连接有I/O请求时才启动一个线程进行处理。  \n\n​    NIO本身是基于事件驱动思想来完成的，其主要想解决的是BIO的大并发问题： 在使用同步I/O的网络应用中，如果要同时处理多个客户端请求，或是在客户端要同时和多个服务器进行通讯，就必须使用多线程来处理。也就是说，将每一个客户端请求分配给一个线程来单独处理。这样做虽然可以达到我们的要求，但同时又会带来另外一个问题。由于每创建一个线程，就要为这个线程分配一定的内存空间（也叫工作存储器），而且操作系统本身也对线程的总数有一定的限制。如果客户端的请求过多，服务端程序可能会因为不堪重负而拒绝客户端的请求，甚至服务器可能会因此而瘫痪。\n\n​    NIO基于Reactor，当socket有流可读或可写入socket时，操作系统会相应的通知引用程序进行处理，应用再将流读取到缓冲区或写入操作系统。  也就是说，这个时候，已经不是一个连接就要对应一个处理线程了，而是有效的请求，对应一个线程，当连接没有数据时，是没有工作线程来处理的。\n\n   BIO与NIO一个比较重要的不同，是我们使用BIO的时候往往会引入多线程，每个连接一个单独的线程；而NIO则是使用单线程或者只使用少量的多线程，每个连接共用一个线程。 \n\nNIO的最重要的地方是当一个连接创建后，不需要对应一个线程，这个连接会被注册到多路复用器上面，所以所有的连接只需要一个线程就可以搞定，当这个线程中的多路复用器进行轮询的时候，发现连接上有请求的话，才开启一个线程进行处理，也就是一个请求一个线程模式。\n\n​      在NIO的处理方式中，当一个请求来的话，开启线程进行处理，可能会等待后端应用的资源(JDBC连接等)，其实这个线程就被阻塞了，当并发上来的话，还是会有BIO一样的问题。\n\n　　HTTP/1.1出现后，有了Http长连接，这样除了超时和指明特定关闭的http header外，这个链接是一直打开的状态的，这样在NIO处理中可以进一步的进化，在后端资源中可以实现资源池或者队列，当请求来的话，开启的线程把请求和请求数据传送给后端资源池或者队列里面就返回，并且在全局的地方保持住这个现场(哪个连接的哪个请求等)，这样前面的线程还是可以去接受其他的请求，而后端的应用的处理只需要执行队列里面的就可以了，这样请求处理和后端应用是异步的.当后端处理完，到全局地方得到现场，产生响应，这个就实现了异步处理。\n\n三、AIO\n\n异步非阻塞式IO，服务器实现模式为一个有效请求一个线程，客户端的I/O请求都是由OS先完成了再通知服务器应用去启动线程进行处理。 \n\n​     与NIO不同，当进行读写操作时，只须直接调用API的read或write方法即可。这两种方法均为异步的，对于读操作而言，当有流可读取时，操作系统会将可读的流传入read方法的缓冲区，并通知应用程序；对于写操作而言，当操作系统将write方法传递的流写入完毕时，操作系统主动通知应用程序。  即可以理解为，read/write方法都是异步的，完成后会主动调用回调函数。  在JDK1.7中，这部分内容被称作NIO.2，主要在java.nio.channels包下增加了下面四个异步通道：\n\n- AsynchronousSocketChannel\n- AsynchronousServerSocketChannel\n- AsynchronousFileChannel\n- AsynchronousDatagramChannel\n\n其中的read/write方法，会返回一个带回调函数的对象，当执行完读取/写入操作后，直接调用回调函数。\n\nBIO是一个连接一个线程。\n\nNIO是一个请求一个线程。\n\nAIO是一个有效请求一个线程。\n\n先来个例子理解一下概念，以银行取款为例： \n\n- 同步 ： 自己亲自出马持银行卡到银行取钱（使用同步IO时，Java自己处理IO读写）；\n- 异步 ： 委托一小弟拿银行卡到银行取钱，然后给你（使用异步IO时，Java将IO读写委托给OS处理，需要将数据缓冲区地址和大小传给OS(银行卡和密码)，OS需要支持异步IO操作API）；\n- 阻塞 ： ATM排队取款，你只能等待（使用阻塞IO时，Java调用会一直阻塞到读写完成才返回）；\n- 非阻塞 ： 柜台取款，取个号，然后坐在椅子上做其它事，等号广播会通知你办理，没到号你就不能去，你可以不断问大堂经理排到了没有，大堂经理如果说还没到你就不能去（使用非阻塞IO时，如果不能读写Java调用会马上返回，当IO事件分发器会通知可读写时再继续进行读写，不断循环直到读写完成）\n\nJava对BIO、NIO、AIO的支持：\n\n- Java BIO ： 同步并阻塞，服务器实现模式为一个连接一个线程，即客户端有连接请求时服务器端就需要启动一个线程进行处理，如果这个连接不做任何事情会造成不必要的线程开销，当然可以通过线程池机制改善。\n- Java NIO ： 同步非阻塞，服务器实现模式为一个请求一个线程，即客户端发送的连接请求都会注册到多路复用器上，多路复用器轮询到连接有I/O请求时才启动一个线程进行处理。\n- Java AIO(NIO.2) ： 异步非阻塞，服务器实现模式为一个有效请求一个线程，客户端的I/O请求都是由OS先完成了再通知服务器应用去启动线程进行处理，\n\nBIO、NIO、AIO适用场景分析:\n\n- BIO方式适用于连接数目比较小且固定的架构，这种方式对服务器资源要求比较高，并发局限于应用中，JDK1.4以前的唯一选择，但程序直观简单易理解。\n- NIO方式适用于连接数目多且连接比较短（轻操作）的架构，比如聊天服务器，并发局限于应用中，编程比较复杂，JDK1.4开始支持。\n- AIO方式使用于连接数目多且连接比较长（重操作）的架构，比如相册服务器，充分调用OS参与并发操作，编程比较复杂，JDK7开始支持。\n\n另外，I/O属于底层操作，需要操作系统支持，并发也需要操作系统的支持，所以性能方面不同操作系统差异会比较明显。\n\n在高性能的I/O设计中，有两个比较著名的模式Reactor和Proactor模式，其中Reactor模式用于同步I/O，而Proactor运用于异步I/O操作。\n\n​    在比较这两个模式之前，我们首先的搞明白几个概念，什么是阻塞和非阻塞，什么是同步和异步,同步和异步是针对应用程序和内核的交互而言的，同步指的是用户进程触发IO操作并等待或者轮询的去查看IO操作是否就绪，而异步是指用户进程触发IO操作以后便开始做自己的事情，而当IO操作已经完成的时候会得到IO完成的通知。而阻塞和非阻塞是针对于进程在访问数据的时候，根据IO操作的就绪状态来采取的不同方式，说白了是一种读取或者写入操作函数的实现方式，阻塞方式下读取或者写入函数将一直等待，而非阻塞方式下，读取或者写入函数会立即返回一个状态值。\n\n 一般来说I/O模型可以分为：同步阻塞，同步非阻塞，异步阻塞，异步非阻塞IO\n\n同步阻塞IO：在此种方式下，用户进程在发起一个IO操作以后，必须等待IO操作的完成，只有当真正完成了IO操作以后，用户进程才能运行。JAVA传统的IO模型属于此种方式！\n\n同步非阻塞IO:在此种方式下，用户进程发起一个IO操作以后边可返回做其它事情，但是用户进程需要时不时的询问IO操作是否就绪，这就要求用户进程不停的去询问，从而引入不必要的CPU资源浪费。其中目前JAVA的NIO就属于同步非阻塞IO。\n\n异步阻塞IO：此种方式下是指应用发起一个IO操作以后，不等待内核IO操作的完成，等内核完成IO操作以后会通知应用程序，这其实就是同步和异步最关键的区别，同步必须等待或者主动的去询问IO是否完成，那么为什么说是阻塞的呢？因为此时是通过select系统调用来完成的，而select函数本身的实现方式是阻塞的，而采用select函数有个好处就是它可以同时监听多个文件句柄，从而提高系统的并发性！\n\n 异步非阻塞IO:在此种模式下，用户进程只需要发起一个IO操作然后立即返回，等IO操作真正的完成以后，应用程序会得到IO操作完成的通知，此时用户进程只需要对数据进行处理就好了，不需要进行实际的IO读写操作，因为真正的IO读取或者写入操作已经由内核完成了。目前Java中还没有支持此种IO模型。    \n\n \n\n 阻塞和非阻塞忙轮询。\n\n- 非阻塞忙轮询：数据没来，进程就不停的去检测数据，直到数据来。\n- 阻塞：数据没来，啥都不做，直到数据来了，才进行下一步的处理。\n\n先说说阻塞，因为一个线程只能处理一个套接字的I/O事件，如果想同时处理多个，可以利用非阻塞忙轮询的方式,伪代码如下：  \n\n```java\nwhile true  \n{  \n    for i in stream[]  \n    {  \n        if i has data  \n        read until unavailable  \n    }  \n}\n```\n\n 我们只要把所有流从头到尾查询一遍，就可以处理多个流了，但这样做很不好，因为如果所有的流都没有I/O事件，白白浪费CPU时间片。正如有一位科学家所说，**计算机所有的问题都可以增加一个中间层来解决**，同样，为了避免这里cpu的空转，我们不让这个线程亲自去检查流中是否有事件，而是引进了一个代理(一开始是select,后来是poll)，这个代理很牛，它可以同时观察许多流的I/O事件，如果没有事件，代理就阻塞，线程就不会挨个挨个去轮询了，伪代码如下：  \n\n ```java\nwhile true  \n{  \n    select(streams[]) //这一步死在这里，知道有一个流有I/O事件时，才往下执行  \n    for i in streams[]  \n    {  \n        if i has data  \n        read until unavailable  \n    }  \n}\n ```\n\n 但是依然有个问题，我们从select那里仅仅知道了，有I/O事件发生了，却并不知道是哪那几个流（可能有一个，多个，甚至全部），我们只能无差别轮询所有流，找出能读出数据，或者写入数据的流，对他们进行操作。所以**select具有O(n)的无差别轮询复杂度**，同时处理的流越多，无差别轮询时间就越长。\n\n**epoll可以理解为event poll**，不同于忙轮询和无差别轮询，epoll会把哪个流发生了怎样的I/O事件通知我们。所以我们说epoll实际上是**事件驱动（每个事件关联上fd）**的，此时我们对这些流的操作都是有意义的。**（复杂度降低到了O(1)）**伪代码如下：\n\n ```java\nwhile true  \n{  \n    active_stream[] = epoll_wait(epollfd)  \n    for i in active_stream[]  \n    {  \n        read or write till  \n    }  \n}\n ```\n\n可以看到，select和epoll最大的区别就是：select只是告诉你一定数目的流有事件了，至于哪个流有事件，还得你一个一个地去轮询，而epoll会把发生的事件告诉你，通过发生的事件，就自然而然定位到哪个流了。不能不说epoll跟select相比，是质的飞跃，我觉得这也是一种**牺牲空间，换取时间的思想**，毕竟现在硬件越来越便宜了。\n\n更详细的Select,poll,epoll 请参考：[select、poll、epoll之间的区别(搜狗面试)](https://www.cnblogs.com/aspirant/p/9166944.html)\n\n 看下这个  https://www.cnblogs.com/aspirant/p/6877350.html?utm_source=itdadao&utm_medium=referral&from=groupmessage&isappinstalled=0\n\n \n\n ","slug":"IO模型","published":1,"date":"2018-09-12T03:03:21.812Z","updated":"2018-09-12T03:03:21.812Z","title":"","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfne90005wlkv6ineotks"},{"_content":"Requests部分\n\n\n| Header              | 解释                                                         | 示例                                                    |\n| ------------------- | ------------------------------------------------------------ | ------------------------------------------------------- |\n| Accept              | 指定客户端能够接收的内容类型                                 | Accept: text/plain, text/html                           |\n| Accept-Charset      | 浏览器可以接受的字符编码集。                                 | Accept-Charset: iso-8859-5                              |\n| Accept-Encoding     | 指定浏览器可以支持的web服务器返回内容压缩编码类型。          | Accept-Encoding: compress, gzip                         |\n| Accept-Language     | 浏览器可接受的语言                                           | Accept-Language: en,zh                                  |\n| Accept-Ranges       | 可以请求网页实体的一个或者多个子范围字段                     | Accept-Ranges: bytes                                    |\n| Authorization       | HTTP授权的授权证书                                           | Authorization: Basic QWxhZGRpbjpvcGVuIHNlc2FtZQ==       |\n| Cache-Control       | 指定请求和响应遵循的缓存机制                                 | Cache-Control: no-cache                                 |\n| Connection          | 表示是否需要持久连接。（HTTP 1.1默认进行持久连接）           | Connection: close                                       |\n| Cookie              | HTTP请求发送时，会把保存在该请求域名下的所有cookie值一起发送给web服务器。 | Cookie: $Version=1; Skin=new;                           |\n| Content-Length      | 请求的内容长度                                               | Content-Length: 348                                     |\n| Content-Type        | 请求的与实体对应的MIME信息                                   | Content-Type: application/x-www-form-urlencoded         |\n| Date                | 请求发送的日期和时间                                         | Date: Tue, 15 Nov 2010 08:12:31 GMT                     |\n| Expect              | 请求的特定的服务器行为                                       | Expect: 100-continue                                    |\n| From                | 发出请求的用户的Email                                        | From: user@email.com                                    |\n| Host                | 指定请求的服务器的域名和端口号                               | Host: www.zcmhi.com                                     |\n| If-Match            | 只有请求内容与实体相匹配才有效                               | If-Match: “737060cd8c284d8af7ad3082f209582d”            |\n| If-Modified-Since   | 如果请求的部分在指定时间之后被修改则请求成功，未被修改则返回304代码 | If-Modified-Since: Sat, 29 Oct 2010 19:43:31 GMT        |\n| If-None-Match       | 如果内容未改变返回304代码，参数为服务器先前发送的Etag，与服务器回应的Etag比较判断是否改变 | If-None-Match: “737060cd8c284d8af7ad3082f209582d”       |\n| If-Range            | 如果实体未改变，服务器发送客户端丢失的部分，否则发送整个实体。参数也为Etag | If-Range: “737060cd8c284d8af7ad3082f209582d”            |\n| If-Unmodified-Since | 只在实体在指定时间之后未被修改才请求成功                     | If-Unmodified-Since: Sat, 29 Oct 2010 19:43:31 GMT      |\n| Max-Forwards        | 限制信息通过代理和网关传送的时间                             | Max-Forwards: 10                                        |\n| Pragma              | 用来包含实现特定的指令                                       | Pragma: no-cache                                        |\n| Proxy-Authorization | 连接到代理的授权证书                                         | Proxy-Authorization: Basic QWxhZGRpbjpvcGVuIHNlc2FtZQ== |\n| Range               | 只请求实体的一部分，指定范围                                 | Range: bytes=500-999                                    |\n| Referer             | 先前网页的地址，当前请求网页紧随其后,即来路                  | Referer: http://www.zcmhi.com/archives/71.html          |\n| TE                  | 客户端愿意接受的传输编码，并通知服务器接受接受尾加头信息     | TE: trailers,deflate;q=0.5                              |\n| Upgrade             | 向服务器指定某种传输协议以便服务器进行转换（如果支持）       | Upgrade: HTTP/2.0, SHTTP/1.3, IRC/6.9, RTA/x11          |\n| User-Agent          | User-Agent的内容包含发出请求的用户信息                       | User-Agent: Mozilla/5.0 (Linux; X11)                    |\n| Via                 | 通知中间网关或代理服务器地址，通信协议                       | Via: 1.0 fred, 1.1 nowhere.com (Apache/1.1)             |\n| Warning             | 关于消息实体的警告信息                                       | Warn: 199 Miscellaneous warning                         |\n\n## Responses 部分  \n\n \n\n| Header             | 解释                                                         | 示例                                                  |\n| ------------------ | ------------------------------------------------------------ | ----------------------------------------------------- |\n| Accept-Ranges      | 表明服务器是否支持指定范围请求及哪种类型的分段请求           | Accept-Ranges: bytes                                  |\n| Age                | 从原始服务器到代理缓存形成的估算时间（以秒计，非负）         | Age: 12                                               |\n| Allow              | 对某网络资源的有效的请求行为，不允许则返回405                | Allow: GET, HEAD                                      |\n| Cache-Control      | 告诉所有的缓存机制是否可以缓存及哪种类型                     | Cache-Control: no-cache                               |\n| Content-Encoding   | web服务器支持的返回内容压缩编码类型。                        | Content-Encoding: gzip                                |\n| Content-Language   | 响应体的语言                                                 | Content-Language: en,zh                               |\n| Content-Length     | 响应体的长度                                                 | Content-Length: 348                                   |\n| Content-Location   | 请求资源可替代的备用的另一地址                               | Content-Location: /index.htm                          |\n| Content-MD5        | 返回资源的MD5校验值                                          | Content-MD5: Q2hlY2sgSW50ZWdyaXR5IQ==                 |\n| Content-Range      | 在整个返回体中本部分的字节位置                               | Content-Range: bytes 21010-47021/47022                |\n| Content-Type       | 返回内容的MIME类型                                           | Content-Type: text/html; charset=utf-8                |\n| Date               | 原始服务器消息发出的时间                                     | Date: Tue, 15 Nov 2010 08:12:31 GMT                   |\n| ETag               | 请求变量的实体标签的当前值                                   | ETag: “737060cd8c284d8af7ad3082f209582d”              |\n| Expires            | 响应过期的日期和时间                                         | Expires: Thu, 01 Dec 2010 16:00:00 GMT                |\n| Last-Modified      | 请求资源的最后修改时间                                       | Last-Modified: Tue, 15 Nov 2010 12:45:26 GMT          |\n| Location           | 用来重定向接收方到非请求URL的位置来完成请求或标识新的资源    | Location: http://www.zcmhi.com/archives/94.html       |\n| Pragma             | 包括实现特定的指令，它可应用到响应链上的任何接收方           | Pragma: no-cache                                      |\n| Proxy-Authenticate | 它指出认证方案和可应用到代理的该URL上的参数                  | Proxy-Authenticate: Basic                             |\n| refresh            | 应用于重定向或一个新的资源被创造，在5秒之后重定向（由网景提出，被大部分浏览器支持） | Refresh: 5; url=http://www.zcmhi.com/archives/94.html |\n| Retry-After        | 如果实体暂时不可取，通知客户端在指定时间之后再次尝试         | Retry-After: 120                                      |\n| Server             | web服务器软件名称                                            | Server: Apache/1.3.27 (Unix) (Red-Hat/Linux)          |\n| Set-Cookie         | 设置Http Cookie                                              | Set-Cookie: UserID=JohnDoe; Max-Age=3600; Version=1   |\n| Trailer            | 指出头域在分块传输编码的尾部存在                             | Trailer: Max-Forwards                                 |\n| Transfer-Encoding  | 文件传输编码                                                 | Transfer-Encoding:chunked                             |\n| Vary               | 告诉下游代理是使用缓存响应还是从原始服务器请求               | Vary: *                                               |\n| Via                | 告知代理客户端响应是通过哪里发送的                           | Via: 1.0 fred, 1.1 nowhere.com (Apache/1.1)           |\n| Warning            | 警告实体可能存在的问题                                       | Warning: 199 Miscellaneous warning                    |\n| WWW-Authenticate   | 表明客户端请求实体应该使用的授权方案                         | WWW-Authenticate: Basic                               |","source":"_posts/Responses 部分.md","raw":"Requests部分\n\n\n| Header              | 解释                                                         | 示例                                                    |\n| ------------------- | ------------------------------------------------------------ | ------------------------------------------------------- |\n| Accept              | 指定客户端能够接收的内容类型                                 | Accept: text/plain, text/html                           |\n| Accept-Charset      | 浏览器可以接受的字符编码集。                                 | Accept-Charset: iso-8859-5                              |\n| Accept-Encoding     | 指定浏览器可以支持的web服务器返回内容压缩编码类型。          | Accept-Encoding: compress, gzip                         |\n| Accept-Language     | 浏览器可接受的语言                                           | Accept-Language: en,zh                                  |\n| Accept-Ranges       | 可以请求网页实体的一个或者多个子范围字段                     | Accept-Ranges: bytes                                    |\n| Authorization       | HTTP授权的授权证书                                           | Authorization: Basic QWxhZGRpbjpvcGVuIHNlc2FtZQ==       |\n| Cache-Control       | 指定请求和响应遵循的缓存机制                                 | Cache-Control: no-cache                                 |\n| Connection          | 表示是否需要持久连接。（HTTP 1.1默认进行持久连接）           | Connection: close                                       |\n| Cookie              | HTTP请求发送时，会把保存在该请求域名下的所有cookie值一起发送给web服务器。 | Cookie: $Version=1; Skin=new;                           |\n| Content-Length      | 请求的内容长度                                               | Content-Length: 348                                     |\n| Content-Type        | 请求的与实体对应的MIME信息                                   | Content-Type: application/x-www-form-urlencoded         |\n| Date                | 请求发送的日期和时间                                         | Date: Tue, 15 Nov 2010 08:12:31 GMT                     |\n| Expect              | 请求的特定的服务器行为                                       | Expect: 100-continue                                    |\n| From                | 发出请求的用户的Email                                        | From: user@email.com                                    |\n| Host                | 指定请求的服务器的域名和端口号                               | Host: www.zcmhi.com                                     |\n| If-Match            | 只有请求内容与实体相匹配才有效                               | If-Match: “737060cd8c284d8af7ad3082f209582d”            |\n| If-Modified-Since   | 如果请求的部分在指定时间之后被修改则请求成功，未被修改则返回304代码 | If-Modified-Since: Sat, 29 Oct 2010 19:43:31 GMT        |\n| If-None-Match       | 如果内容未改变返回304代码，参数为服务器先前发送的Etag，与服务器回应的Etag比较判断是否改变 | If-None-Match: “737060cd8c284d8af7ad3082f209582d”       |\n| If-Range            | 如果实体未改变，服务器发送客户端丢失的部分，否则发送整个实体。参数也为Etag | If-Range: “737060cd8c284d8af7ad3082f209582d”            |\n| If-Unmodified-Since | 只在实体在指定时间之后未被修改才请求成功                     | If-Unmodified-Since: Sat, 29 Oct 2010 19:43:31 GMT      |\n| Max-Forwards        | 限制信息通过代理和网关传送的时间                             | Max-Forwards: 10                                        |\n| Pragma              | 用来包含实现特定的指令                                       | Pragma: no-cache                                        |\n| Proxy-Authorization | 连接到代理的授权证书                                         | Proxy-Authorization: Basic QWxhZGRpbjpvcGVuIHNlc2FtZQ== |\n| Range               | 只请求实体的一部分，指定范围                                 | Range: bytes=500-999                                    |\n| Referer             | 先前网页的地址，当前请求网页紧随其后,即来路                  | Referer: http://www.zcmhi.com/archives/71.html          |\n| TE                  | 客户端愿意接受的传输编码，并通知服务器接受接受尾加头信息     | TE: trailers,deflate;q=0.5                              |\n| Upgrade             | 向服务器指定某种传输协议以便服务器进行转换（如果支持）       | Upgrade: HTTP/2.0, SHTTP/1.3, IRC/6.9, RTA/x11          |\n| User-Agent          | User-Agent的内容包含发出请求的用户信息                       | User-Agent: Mozilla/5.0 (Linux; X11)                    |\n| Via                 | 通知中间网关或代理服务器地址，通信协议                       | Via: 1.0 fred, 1.1 nowhere.com (Apache/1.1)             |\n| Warning             | 关于消息实体的警告信息                                       | Warn: 199 Miscellaneous warning                         |\n\n## Responses 部分  \n\n \n\n| Header             | 解释                                                         | 示例                                                  |\n| ------------------ | ------------------------------------------------------------ | ----------------------------------------------------- |\n| Accept-Ranges      | 表明服务器是否支持指定范围请求及哪种类型的分段请求           | Accept-Ranges: bytes                                  |\n| Age                | 从原始服务器到代理缓存形成的估算时间（以秒计，非负）         | Age: 12                                               |\n| Allow              | 对某网络资源的有效的请求行为，不允许则返回405                | Allow: GET, HEAD                                      |\n| Cache-Control      | 告诉所有的缓存机制是否可以缓存及哪种类型                     | Cache-Control: no-cache                               |\n| Content-Encoding   | web服务器支持的返回内容压缩编码类型。                        | Content-Encoding: gzip                                |\n| Content-Language   | 响应体的语言                                                 | Content-Language: en,zh                               |\n| Content-Length     | 响应体的长度                                                 | Content-Length: 348                                   |\n| Content-Location   | 请求资源可替代的备用的另一地址                               | Content-Location: /index.htm                          |\n| Content-MD5        | 返回资源的MD5校验值                                          | Content-MD5: Q2hlY2sgSW50ZWdyaXR5IQ==                 |\n| Content-Range      | 在整个返回体中本部分的字节位置                               | Content-Range: bytes 21010-47021/47022                |\n| Content-Type       | 返回内容的MIME类型                                           | Content-Type: text/html; charset=utf-8                |\n| Date               | 原始服务器消息发出的时间                                     | Date: Tue, 15 Nov 2010 08:12:31 GMT                   |\n| ETag               | 请求变量的实体标签的当前值                                   | ETag: “737060cd8c284d8af7ad3082f209582d”              |\n| Expires            | 响应过期的日期和时间                                         | Expires: Thu, 01 Dec 2010 16:00:00 GMT                |\n| Last-Modified      | 请求资源的最后修改时间                                       | Last-Modified: Tue, 15 Nov 2010 12:45:26 GMT          |\n| Location           | 用来重定向接收方到非请求URL的位置来完成请求或标识新的资源    | Location: http://www.zcmhi.com/archives/94.html       |\n| Pragma             | 包括实现特定的指令，它可应用到响应链上的任何接收方           | Pragma: no-cache                                      |\n| Proxy-Authenticate | 它指出认证方案和可应用到代理的该URL上的参数                  | Proxy-Authenticate: Basic                             |\n| refresh            | 应用于重定向或一个新的资源被创造，在5秒之后重定向（由网景提出，被大部分浏览器支持） | Refresh: 5; url=http://www.zcmhi.com/archives/94.html |\n| Retry-After        | 如果实体暂时不可取，通知客户端在指定时间之后再次尝试         | Retry-After: 120                                      |\n| Server             | web服务器软件名称                                            | Server: Apache/1.3.27 (Unix) (Red-Hat/Linux)          |\n| Set-Cookie         | 设置Http Cookie                                              | Set-Cookie: UserID=JohnDoe; Max-Age=3600; Version=1   |\n| Trailer            | 指出头域在分块传输编码的尾部存在                             | Trailer: Max-Forwards                                 |\n| Transfer-Encoding  | 文件传输编码                                                 | Transfer-Encoding:chunked                             |\n| Vary               | 告诉下游代理是使用缓存响应还是从原始服务器请求               | Vary: *                                               |\n| Via                | 告知代理客户端响应是通过哪里发送的                           | Via: 1.0 fred, 1.1 nowhere.com (Apache/1.1)           |\n| Warning            | 警告实体可能存在的问题                                       | Warning: 199 Miscellaneous warning                    |\n| WWW-Authenticate   | 表明客户端请求实体应该使用的授权方案                         | WWW-Authenticate: Basic                               |","slug":"Responses 部分","published":1,"date":"2018-09-12T03:03:21.812Z","updated":"2018-09-12T03:03:21.812Z","title":"","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnec0006wlkv2ujvr1qi"},{"title":"elasticSearch入门","date":"2017-10-02T12:50:22.000Z","_content":"\n# elasticSearch入门\n\n> elasticSearch是一个实时的分布式搜索和分析引擎，基于lucene，可以用于全文搜索、结构化搜索、分析等功能。\n>\n> - 分布式的实时文件存储，每个字段都可以被索引用于搜索\n> - 分布式的实时分析搜索引擎\n> - 支持扩展，可以处理PB级结构化和非结构化的数据\n> - 面向文档存储，支持复杂的数据格式存储\n\n<!--more-->\n\n## 概念介绍\n\n- es中的概念对比关系数据库\n\n| ES    | Indexes(索引) | types  | documents | fields  |\n| ----- | ----------- | ------ | --------- | ------- |\n| 关系数据库 | databases   | tables | rows      | columns |\n1. 索引：文档数据存储的位置，相当于databases\n2. 类型：指定文档的类型，也是实体的类型，用于对文档进行归类\n3. 文档：存储的数据，默认文档的每个字段都会建立倒排索引\n4. 字段：文档一般为JSON结构，JSON中的key值就是字段\n\nElasticSearch用于处理PB级数据的存储、搜索和分析，自动完成以下功能\n\n- 将文档分区到不同容器或者分片中，可以存在一个或者多个节点中；\n- 将分片均匀的分配到各个节点上，对索引和搜索做负载均衡；\n- 冗余每一个分片，防止硬件故障导致数据丢失；\n- 将集群中的任意一个节点的请求路由到相应数据所在的节点，即资源定位；\n- 支持无缝扩展和删除节点；\n\nes可以进行全文搜索，处理同义词和根据相关性给文档打分，根据数据生成分析和聚合结果\n\nes通过restful API隐藏lucened的复杂性\n\n\n\ncurl -XGET 'localhost:9200/_count?pretty' -d '{\n\n\"query\": {\"match_all\": {}\n\n}}'","source":"_posts/elasticSearch入门.md","raw":"---\ntitle: elasticSearch入门\ndate: 2017-10-02 20:50:22\ntags:\n- elasticSearch\ncategories:\n- 大数据\n\n---\n\n# elasticSearch入门\n\n> elasticSearch是一个实时的分布式搜索和分析引擎，基于lucene，可以用于全文搜索、结构化搜索、分析等功能。\n>\n> - 分布式的实时文件存储，每个字段都可以被索引用于搜索\n> - 分布式的实时分析搜索引擎\n> - 支持扩展，可以处理PB级结构化和非结构化的数据\n> - 面向文档存储，支持复杂的数据格式存储\n\n<!--more-->\n\n## 概念介绍\n\n- es中的概念对比关系数据库\n\n| ES    | Indexes(索引) | types  | documents | fields  |\n| ----- | ----------- | ------ | --------- | ------- |\n| 关系数据库 | databases   | tables | rows      | columns |\n1. 索引：文档数据存储的位置，相当于databases\n2. 类型：指定文档的类型，也是实体的类型，用于对文档进行归类\n3. 文档：存储的数据，默认文档的每个字段都会建立倒排索引\n4. 字段：文档一般为JSON结构，JSON中的key值就是字段\n\nElasticSearch用于处理PB级数据的存储、搜索和分析，自动完成以下功能\n\n- 将文档分区到不同容器或者分片中，可以存在一个或者多个节点中；\n- 将分片均匀的分配到各个节点上，对索引和搜索做负载均衡；\n- 冗余每一个分片，防止硬件故障导致数据丢失；\n- 将集群中的任意一个节点的请求路由到相应数据所在的节点，即资源定位；\n- 支持无缝扩展和删除节点；\n\nes可以进行全文搜索，处理同义词和根据相关性给文档打分，根据数据生成分析和聚合结果\n\nes通过restful API隐藏lucened的复杂性\n\n\n\ncurl -XGET 'localhost:9200/_count?pretty' -d '{\n\n\"query\": {\"match_all\": {}\n\n}}'","slug":"elasticSearch入门","published":1,"updated":"2018-09-12T03:03:21.813Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnef0007wlkvvat16z8y"},{"title":"docker初识","date":"2018-08-04T02:26:48.000Z","_content":"\n# docker初识\n\nDocker是Container容器引擎，基于Go语言，基于linux虚拟内核技术，实现隔离，不需要操作系统另外开销。硬件是共享的,容器只能运行与底层宿主机相同或者相似的操作系统。\n\n容器与管理程序虚拟化有所不同，管理程序虚拟化通过中间层将一台或者多台独立的机器虚拟运行与物理硬件之上，而容器则是直接运行在操作系统内核之上的用户空间，容器技术可以让多个独立的用户空间运行在同一台宿主机上。 \n\n<!--more-->\n\nDocker核心：构建、运输、运行\n\nDocker组成：服务端、客户端，镜像、容器、 仓库\n\nDocker容器理念是单进程，即一个容器只起一个进程（不太现实感觉）\n\n优点：\n\n- 简化环境配置\n- 多版本测试\n- 环境配置一致性\n- 自动扩容(微服务)\n\n使用国内的ustc镜像会快点，需要修改或创建/etc/docker/daemon.json\n\n```\n{\n  \"registry-mirrors\": [\"http://hub-mirror.c.163.com\"]\n}\n```\n\n## 安装\n\n- centos7下直接使用yum安装，yum install -y docker\n\n- 启动docker\n\n  ```shell\n  systemctl start docker &  #启动docker服务\n  systemctl enable docker #开机启动\n  ```\n\n- 镜像管理\n\n  - docker search  镜像名：搜索镜像\n  - docker pull 镜像名:版本号:获取镜像，不指定版本号，默认下载latest\n  - docker rmi imageId：删除一个镜像，如果镜像创建了容器则不能删除\n  - docker images ：查看docker中的所有镜像，每个镜像都有一个唯一的image id\n  - docker save centos > /opt/centos.tar.gz ： 导出镜像\n  - docker load < /opt/centos.tar.gz ：导入镜像\n\n- 容器管理\n\n   - docker run centos:7 /bin/bash：启动centos(7为镜像版本)镜像，并执行一条指令\n     - -d：后台启动容器并打印容器id\n     - --name：指定名称\n     - -t：分配一个为终端进行登录\n     - -i：容器的标准输入为打开状态\n     - -m：指定内存\n     - -c：指定cpu占比\n     - -w：指定容器内用户的家目录\n     - -p: 指定端口映射关系\n     - -v: 指定文件目录的映射关系\n   - docker run --rm  centos：容器停止后自动删除容器 \n   - docker start 容器id：启动容器\n   - docker stop 容器id：停止容器\n   - docker rm -f 容器id：删除一个正在运行的容器\n   - docker ps：查看容器\n     - -a：显示所有的容器，包括停止的\n     - -q：只列出容器id\n   - docker attach 容器id：进入容器\n   - docker run -d centos:7 /bin/bash :后台启动，然后使用exec登录docker机器\n   - docker exec -it 容器名称：进入容器，再次exit不会停止容器\n   - exit: 退出容器，-it模式容器会自动终止，-d模式容器不会终止\n   - docker logs 容器id：查看容器id\n   - docker inspect 容器id: 查看容器运行的各种数据\n   - **nsenter**：根据pid进入容器，使用exit退出后容器不停止\n     - 安装 yum install util-linux\n     - nsenter -t Pid -u -i -n -p：根据pid登录\n\n- 容器内命令\n     - docker cp 需要拷贝的文件或目录 容器名称:容器目录\n     - docker cp 容器名称:容器目录 需要拷贝的文件或目录\n\n- 网络访问\n     - docker run -P nginx：随机映射端口，容器启动时会随机出个端口映射nginx的80端口\n     - docker run -p hostPort:containerPort：使用宿主机端口映射docker机端口\n       - -p ip:hostPort:containerPort\n       - -p ip::containerPort\n\n- 数据卷\n\n   - docker run -it -v 宿主机目录:容器目录 镜像名：将物理机上的一个目录挂载到容器指定目录\n      - 在docker inspect 中看 Mounts底下的source\n      - -v src:dst：指定物理机的目录挂载到docker上\n        - -v src:dst:rw：指定挂载目录的权限\n      - --volumes-from 容器id/名字 ：让一个容器访问另一个容器的卷，达到nfs的效果\n      - docker run -it -volumns-from nfs容器id 容器id：启动一个访问nfs的容器\n      - 数据卷容器停止之后，其他容器照样能访问数据卷容器上的目录\n\n## 镜像制作\n\n- 手动制作\n\n   - docker run --name \"mynginx\" -it centos：从centos镜像启动一个容器\n   - 安装 rmp -ivh https://mirrors.aliyun.com/epel/\n   - 安装nginx  yum install -y nginx\n   - docker commit -m \"my nginx\" 2e013dfc32c2 mynginx:v1 ：根据容器id打镜像，指定tag为v1\n   - docker images：查看是否有制作成功的 my nginx的镜像\n   - docker run -it  mynginx:v1：启动镜像，指定tag为v1,不然默认找latest的，修改nginx的配置文件\n   - vim /etc/nginx/nginx.confg：加上 daemon off;前天运行\n   - docker commit -m \"my nginx\" 2e013dfc32c2 mynginx:v2：重新 打镜像，指定tag为v2\n   - docker run -d -p 82:80 mynginx:v2 nginx：启动容器并启动nginx\n\n- **DockerFile 构建**\n\n   docker build 镜像:tag /test/dockFile\n\n   - dockerfile组成\n\n      - 基础镜像信息\n      - 维护者信息\n      - 镜像操作指令\n      - 容器启动时执行指令 \n\n   - 语法\n\n      - FROM：构建指令，**必须指定且需要在Dockerfile其他指令的前面**。后续的指令都依赖于该指令指定的image。FROM指令指定的基础image可以是官方远程仓库中的，也可以位于本地仓库\n\n         ```shell\n         #如果不指定tag，默认使用latest\n         FROM <image>:<tag>  \n         ```\n\n      - MAINTAINER：构建指令，用于将image的制作者相关的信息写入到image中。当我们对该image执行docker inspect命令时，输出中有相应的字段记录该信息。\n\n         ```shell\n         MAINTAINER <name>\n         ```\n\n      - RUN：执行命令\n\n         ```shell\n         RUN <command> (the command is run in a shell - `/bin/sh -c`)  \n         RUN [\"executable\", \"param1\", \"param2\" ... ]  (exec form)  \n         ```\n\n      - CMD：设置镜像启动时执行的指令或脚本，该指令只能在文件中存在一次，如果有多个，执行最后一条\n\n         ```sheel\n         CMD [\"executable\",\"param1\",\"param2\"] (like an exec, this is the preferred form)  \n         CMD command param1 param2 (as a shell)\n         ```\n\n      - ENTRYPOINT：设置container启动时执行的操作，可以多次设置，但是只有最后一个有效\n\n         ```sheel\n         ENTRYPOINT [\"executable\", \"param1\", \"param2\"] (like an exec, the preferred form)  \n         ENTRYPOINT command param1 param2 (as a shell) \n         ```\n\n         - 该指令的使用分为两种情况，一种是独自使用，另一种和CMD指令配合使用。\n            当独自使用时，如果你还使用了CMD命令且CMD是一个完整的可执行的命令，那么CMD指令和ENTRYPOINT会互相覆盖只有最后一个CMD或者ENTRYPOINT有效。\n            ```sheel\n            # CMD指令将不会被执行，只有ENTRYPOINT指令被执行  \n            CMD echo “Hello, World!”  \n            ENTRYPOINT ls -l  \n            ```\n         - 另一种用法和CMD指令配合使用来指定ENTRYPOINT的默认参数，这时CMD指令不是一个完整的可执行命令，仅仅是参数部分；ENTRYPOINT指令只能使用JSON方式指定执行命令，而不能指定参数。\n\n            ```sheel\n            FROM ubuntu  \n            CMD [\"-l\"]  \n            ENTRYPOINT [\"/usr/bin/ls\"]  \n            ```\n\n      - USER：设置启动容器的用户，默认是root用户。\n\n         ```shell\n         # 指定memcached的运行用户  \n         ENTRYPOINT [\"memcached\"]  \n         USER daemon  \n         或  \n         ENTRYPOINT [\"memcached\", \"-u\", \"daemon\"]  \n         ```\n\n      - EXPOSE：指定映射端口，该指令会将容器中的端口映射成宿主机器中的某个端口。当你需要访问容器的时候，可以不是用容器的IP地址而是使用宿主机器的IP地址和映射后的端口\n\n         ```shell\n         # 映射一个端口  \n         EXPOSE port1  \n         # 相应的运行容器使用的命令  \n         docker run -p port1 image  \n         # 映射多个端口  \n         EXPOSE port1 port2 port3  \n         # 相应的运行容器使用的命令  \n         docker run -p port1 -p port2 -p port3 image  \n         # 还可以指定需要映射到宿主机器上的某个端口号  \n         docker run -p host_port1:port1 -p host_port2:port2 -p host_port3:port3 image  \n         ```\n\n      - ENV：在image中设置一个环境变量\n\n         ```shell\n         ENV <key> <value>  \n         ```\n\n         设置了后，后续的RUN命令都可以使用，container启动后，可以通过docker inspect查看这个环境变量，也可以通过在docker run --env key=value时设置或修改环境变量。\n         假如你安装了JAVA程序，需要设置JAVA_HOME，那么可以在Dockerfile中这样写：\n         ENV JAVA_HOME /path/to/java/dirent\n\n      - ADD：从src复制文件到container的dest路径\n\n         ```shell\n         #<src> 是相对被构建的源目录的相对路径，可以是文件或目录的路径，也可以是一个远程的文件url;\n         #<dest> 是container中的绝对路径\n         ADD <src> <dest>  \n         ```\n\n         所有拷贝到container中的文件和文件夹权限为0755，uid和gid为0；如果是一个目录，那么会将该目录下的所有文件添加到container中，不包括目录；如果文件是可识别的压缩格式，则docker会帮忙解压缩（注意压缩格式）；如果<src>是文件且<dest>中不使用斜杠结束，则会将<dest>视为文件，<src>的内容会写入<dest>；如果<src>是文件且<dest>中使用斜杠结束，则会<src>文件拷贝到<dest>目录下\n\n      - VOLUME：指定挂载点，使容器中的一个目录具有持久化存储数据的功能，该目录可以被容器本身使用，也可以共享给其他容器使用,运行通过该Dockerfile生成image的容器，/tmp/data目录中的数据在容器关闭后，里面的数据还存在\n\n         ```shell\n         FROM base  \n         VOLUME [\"/tmp/data\"]  \n         ```\n\n      - WORKDIR：切换目录，可以多次切换(相当于cd命令)，对RUN,CMD,ENTRYPOINT生效\n\n         ```shell\n         WORKDIR /path/to/workdir\n         # 在 /p1/p2 下执行 vim a.txt  \n         WORKDIR /p1 WORKDIR p2 RUN vim a.txt  \n         ```\n\n      - ONBUILD：在子镜像中执行,构建镜像时并不执行，而是在它的子镜像中执行\n\n         ```shell\n         ONBUILD <Dockerfile关键字>  \n         ```\n","source":"_posts/docker初识.md","raw":"---\ntitle: docker初识\ndate: 2018-08-04 10:26:48\ntags:\n- docker\ncategories:\n- docker\n\n\n---\n\n# docker初识\n\nDocker是Container容器引擎，基于Go语言，基于linux虚拟内核技术，实现隔离，不需要操作系统另外开销。硬件是共享的,容器只能运行与底层宿主机相同或者相似的操作系统。\n\n容器与管理程序虚拟化有所不同，管理程序虚拟化通过中间层将一台或者多台独立的机器虚拟运行与物理硬件之上，而容器则是直接运行在操作系统内核之上的用户空间，容器技术可以让多个独立的用户空间运行在同一台宿主机上。 \n\n<!--more-->\n\nDocker核心：构建、运输、运行\n\nDocker组成：服务端、客户端，镜像、容器、 仓库\n\nDocker容器理念是单进程，即一个容器只起一个进程（不太现实感觉）\n\n优点：\n\n- 简化环境配置\n- 多版本测试\n- 环境配置一致性\n- 自动扩容(微服务)\n\n使用国内的ustc镜像会快点，需要修改或创建/etc/docker/daemon.json\n\n```\n{\n  \"registry-mirrors\": [\"http://hub-mirror.c.163.com\"]\n}\n```\n\n## 安装\n\n- centos7下直接使用yum安装，yum install -y docker\n\n- 启动docker\n\n  ```shell\n  systemctl start docker &  #启动docker服务\n  systemctl enable docker #开机启动\n  ```\n\n- 镜像管理\n\n  - docker search  镜像名：搜索镜像\n  - docker pull 镜像名:版本号:获取镜像，不指定版本号，默认下载latest\n  - docker rmi imageId：删除一个镜像，如果镜像创建了容器则不能删除\n  - docker images ：查看docker中的所有镜像，每个镜像都有一个唯一的image id\n  - docker save centos > /opt/centos.tar.gz ： 导出镜像\n  - docker load < /opt/centos.tar.gz ：导入镜像\n\n- 容器管理\n\n   - docker run centos:7 /bin/bash：启动centos(7为镜像版本)镜像，并执行一条指令\n     - -d：后台启动容器并打印容器id\n     - --name：指定名称\n     - -t：分配一个为终端进行登录\n     - -i：容器的标准输入为打开状态\n     - -m：指定内存\n     - -c：指定cpu占比\n     - -w：指定容器内用户的家目录\n     - -p: 指定端口映射关系\n     - -v: 指定文件目录的映射关系\n   - docker run --rm  centos：容器停止后自动删除容器 \n   - docker start 容器id：启动容器\n   - docker stop 容器id：停止容器\n   - docker rm -f 容器id：删除一个正在运行的容器\n   - docker ps：查看容器\n     - -a：显示所有的容器，包括停止的\n     - -q：只列出容器id\n   - docker attach 容器id：进入容器\n   - docker run -d centos:7 /bin/bash :后台启动，然后使用exec登录docker机器\n   - docker exec -it 容器名称：进入容器，再次exit不会停止容器\n   - exit: 退出容器，-it模式容器会自动终止，-d模式容器不会终止\n   - docker logs 容器id：查看容器id\n   - docker inspect 容器id: 查看容器运行的各种数据\n   - **nsenter**：根据pid进入容器，使用exit退出后容器不停止\n     - 安装 yum install util-linux\n     - nsenter -t Pid -u -i -n -p：根据pid登录\n\n- 容器内命令\n     - docker cp 需要拷贝的文件或目录 容器名称:容器目录\n     - docker cp 容器名称:容器目录 需要拷贝的文件或目录\n\n- 网络访问\n     - docker run -P nginx：随机映射端口，容器启动时会随机出个端口映射nginx的80端口\n     - docker run -p hostPort:containerPort：使用宿主机端口映射docker机端口\n       - -p ip:hostPort:containerPort\n       - -p ip::containerPort\n\n- 数据卷\n\n   - docker run -it -v 宿主机目录:容器目录 镜像名：将物理机上的一个目录挂载到容器指定目录\n      - 在docker inspect 中看 Mounts底下的source\n      - -v src:dst：指定物理机的目录挂载到docker上\n        - -v src:dst:rw：指定挂载目录的权限\n      - --volumes-from 容器id/名字 ：让一个容器访问另一个容器的卷，达到nfs的效果\n      - docker run -it -volumns-from nfs容器id 容器id：启动一个访问nfs的容器\n      - 数据卷容器停止之后，其他容器照样能访问数据卷容器上的目录\n\n## 镜像制作\n\n- 手动制作\n\n   - docker run --name \"mynginx\" -it centos：从centos镜像启动一个容器\n   - 安装 rmp -ivh https://mirrors.aliyun.com/epel/\n   - 安装nginx  yum install -y nginx\n   - docker commit -m \"my nginx\" 2e013dfc32c2 mynginx:v1 ：根据容器id打镜像，指定tag为v1\n   - docker images：查看是否有制作成功的 my nginx的镜像\n   - docker run -it  mynginx:v1：启动镜像，指定tag为v1,不然默认找latest的，修改nginx的配置文件\n   - vim /etc/nginx/nginx.confg：加上 daemon off;前天运行\n   - docker commit -m \"my nginx\" 2e013dfc32c2 mynginx:v2：重新 打镜像，指定tag为v2\n   - docker run -d -p 82:80 mynginx:v2 nginx：启动容器并启动nginx\n\n- **DockerFile 构建**\n\n   docker build 镜像:tag /test/dockFile\n\n   - dockerfile组成\n\n      - 基础镜像信息\n      - 维护者信息\n      - 镜像操作指令\n      - 容器启动时执行指令 \n\n   - 语法\n\n      - FROM：构建指令，**必须指定且需要在Dockerfile其他指令的前面**。后续的指令都依赖于该指令指定的image。FROM指令指定的基础image可以是官方远程仓库中的，也可以位于本地仓库\n\n         ```shell\n         #如果不指定tag，默认使用latest\n         FROM <image>:<tag>  \n         ```\n\n      - MAINTAINER：构建指令，用于将image的制作者相关的信息写入到image中。当我们对该image执行docker inspect命令时，输出中有相应的字段记录该信息。\n\n         ```shell\n         MAINTAINER <name>\n         ```\n\n      - RUN：执行命令\n\n         ```shell\n         RUN <command> (the command is run in a shell - `/bin/sh -c`)  \n         RUN [\"executable\", \"param1\", \"param2\" ... ]  (exec form)  \n         ```\n\n      - CMD：设置镜像启动时执行的指令或脚本，该指令只能在文件中存在一次，如果有多个，执行最后一条\n\n         ```sheel\n         CMD [\"executable\",\"param1\",\"param2\"] (like an exec, this is the preferred form)  \n         CMD command param1 param2 (as a shell)\n         ```\n\n      - ENTRYPOINT：设置container启动时执行的操作，可以多次设置，但是只有最后一个有效\n\n         ```sheel\n         ENTRYPOINT [\"executable\", \"param1\", \"param2\"] (like an exec, the preferred form)  \n         ENTRYPOINT command param1 param2 (as a shell) \n         ```\n\n         - 该指令的使用分为两种情况，一种是独自使用，另一种和CMD指令配合使用。\n            当独自使用时，如果你还使用了CMD命令且CMD是一个完整的可执行的命令，那么CMD指令和ENTRYPOINT会互相覆盖只有最后一个CMD或者ENTRYPOINT有效。\n            ```sheel\n            # CMD指令将不会被执行，只有ENTRYPOINT指令被执行  \n            CMD echo “Hello, World!”  \n            ENTRYPOINT ls -l  \n            ```\n         - 另一种用法和CMD指令配合使用来指定ENTRYPOINT的默认参数，这时CMD指令不是一个完整的可执行命令，仅仅是参数部分；ENTRYPOINT指令只能使用JSON方式指定执行命令，而不能指定参数。\n\n            ```sheel\n            FROM ubuntu  \n            CMD [\"-l\"]  \n            ENTRYPOINT [\"/usr/bin/ls\"]  \n            ```\n\n      - USER：设置启动容器的用户，默认是root用户。\n\n         ```shell\n         # 指定memcached的运行用户  \n         ENTRYPOINT [\"memcached\"]  \n         USER daemon  \n         或  \n         ENTRYPOINT [\"memcached\", \"-u\", \"daemon\"]  \n         ```\n\n      - EXPOSE：指定映射端口，该指令会将容器中的端口映射成宿主机器中的某个端口。当你需要访问容器的时候，可以不是用容器的IP地址而是使用宿主机器的IP地址和映射后的端口\n\n         ```shell\n         # 映射一个端口  \n         EXPOSE port1  \n         # 相应的运行容器使用的命令  \n         docker run -p port1 image  \n         # 映射多个端口  \n         EXPOSE port1 port2 port3  \n         # 相应的运行容器使用的命令  \n         docker run -p port1 -p port2 -p port3 image  \n         # 还可以指定需要映射到宿主机器上的某个端口号  \n         docker run -p host_port1:port1 -p host_port2:port2 -p host_port3:port3 image  \n         ```\n\n      - ENV：在image中设置一个环境变量\n\n         ```shell\n         ENV <key> <value>  \n         ```\n\n         设置了后，后续的RUN命令都可以使用，container启动后，可以通过docker inspect查看这个环境变量，也可以通过在docker run --env key=value时设置或修改环境变量。\n         假如你安装了JAVA程序，需要设置JAVA_HOME，那么可以在Dockerfile中这样写：\n         ENV JAVA_HOME /path/to/java/dirent\n\n      - ADD：从src复制文件到container的dest路径\n\n         ```shell\n         #<src> 是相对被构建的源目录的相对路径，可以是文件或目录的路径，也可以是一个远程的文件url;\n         #<dest> 是container中的绝对路径\n         ADD <src> <dest>  \n         ```\n\n         所有拷贝到container中的文件和文件夹权限为0755，uid和gid为0；如果是一个目录，那么会将该目录下的所有文件添加到container中，不包括目录；如果文件是可识别的压缩格式，则docker会帮忙解压缩（注意压缩格式）；如果<src>是文件且<dest>中不使用斜杠结束，则会将<dest>视为文件，<src>的内容会写入<dest>；如果<src>是文件且<dest>中使用斜杠结束，则会<src>文件拷贝到<dest>目录下\n\n      - VOLUME：指定挂载点，使容器中的一个目录具有持久化存储数据的功能，该目录可以被容器本身使用，也可以共享给其他容器使用,运行通过该Dockerfile生成image的容器，/tmp/data目录中的数据在容器关闭后，里面的数据还存在\n\n         ```shell\n         FROM base  \n         VOLUME [\"/tmp/data\"]  \n         ```\n\n      - WORKDIR：切换目录，可以多次切换(相当于cd命令)，对RUN,CMD,ENTRYPOINT生效\n\n         ```shell\n         WORKDIR /path/to/workdir\n         # 在 /p1/p2 下执行 vim a.txt  \n         WORKDIR /p1 WORKDIR p2 RUN vim a.txt  \n         ```\n\n      - ONBUILD：在子镜像中执行,构建镜像时并不执行，而是在它的子镜像中执行\n\n         ```shell\n         ONBUILD <Dockerfile关键字>  \n         ```\n","slug":"docker初识","published":1,"updated":"2018-09-12T03:03:21.813Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnei000bwlkvcdomqm85"},{"title":"Hello World","date":"2018-10-30T08:18:09.000Z","_content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\ndfsdfsdfsdf\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/deployment.html)\n\nbean加载解析注册过程\n![upload successful](/images/pasted-0.png)","source":"_posts/hello-world.md","raw":"title: Hello World\ndate: 2018-10-30 16:18:09\n---\nWelcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\ndfsdfsdfsdf\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/deployment.html)\n\nbean加载解析注册过程\n![upload successful](/images/pasted-0.png)","slug":"hello-world","published":1,"updated":"2018-10-30T08:40:18.298Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnej000cwlkv22kgodjh"},{"title":"[Hexo] Theme BeanTech","catalog":true,"date":"2017-03-18T02:51:24.000Z","subtitle":"This is hexo theme Demo.","header-img":"Demo.png","catagories":["Hexo"],"_content":"> Ported Theme of [Hux Blog](https://github.com/Huxpro/huxpro.github.io), Thank [Huxpro](https://github.com/Huxpro) for designing such a flawless theme.\n> \n> This BeanTech theme created by [YuHsuan](http://beantech.org) modified from the original Porter [Kaijun](http://kaijun.rocks/hexo-theme-huxblog/)\n\n# [Live Demo](http://beantech.org)\n---\n![BeanTech Desktop](http://beantech.org/img/beantech-desktop.png)\n\n# Usage\n---\nI publish the whole project for your convenience, so you can just follow the instruction down below, then you can easily customiz your own blog!\n\nLet's begin!!!\n\n## Init\n---\n```bash\ngit clone https://github.com/YenYuHsuan/hexo-theme-beantech.git ./hexo-beantech\ncd hexo-beantech\nnpm install\n```\n\n## Modify\n---\nModify `_config.yml` file with your own info.\nEspecially the section:\n### Deployment\nReplace to your own repo!\n```yml\ndeploy:\n  type: git\n  repo: https://github.com/<yourAccount>/<repo>\n  branch: <your-branch>\n```\n\n### Sidebar settings\nCopy your avatar image to `<root>/img/` and modify the `_config.yml`:\n```yml\nsidebar: true    # whether or not using Sidebar.\nsidebar-about-description: \"<your description>\"\nsidebar-avatar: img/<your avatar path>\n```\nand activate your personal widget you like\n```yml\nwidgets:         # here are widget you can use, you can comment out\n- featured-tags\n- short-about\n- recent-posts\n- friends-blog\n- archive\n- category\n```\nif you want to add sidebar widget, please add at `layout/_widget`.\n### Signature Setup\nCopy your signature image to `<root>/img/signature` and modify the `_config.yml`:\n```yml\nsignature: true   # show signature\nsignature-img: img/signature/<your-signature-ID>\n```\n### Go to top icon Setup\nMy icon is using iron man, you can change to your own icon at `css/image`.\n\n### Post tag\nYou can decide to show post tags or not.\n```yml\nhome_posts_tag: true\n```\n![home_posts_tag-true](home_posts_tag-true.png)\n```yml\nhome_posts_tag: false\n```\n![home_posts_tag-false](home_posts_tag-false.png)\n\n### Markdown render\nMy markdown render engine plugin is [hexo-renderer-markdown-it](https://github.com/celsomiranda/hexo-renderer-markdown-it).\n```yml\n# Markdown-it config\n## Docs: https://github.com/celsomiranda/hexo-renderer-markdown-it/wiki\nmarkdown:\n  render:\n    html: true\n    xhtmlOut: false\n    breaks: true\n    linkify: true\n    typographer: true\n    quotes: '“”‘’'\n```\nand if you want to change the header anchor 'ℬ', you can go to `layout/post.ejs` to change it.\n```javascript\nasync(\"https://cdn.bootcss.com/anchor-js/1.1.1/anchor.min.js\",function(){\n        anchors.options = {\n          visible: 'hover',\n          placement: 'left',\n          icon: ℬ // this is the header anchor \"unicode\" icon\n        };\n```\n\n## Hexo Basics\n---\nSome hexo command:\n```bash\nhexo new post \"<post name>\" # you can change post to another layout if you want\nhexo clean && hexo generate # generate the static file\nhexo server # run hexo in local environment\nhexo deploy # hexo will push the static files automatically into the specific branch(gh-pages) of your repo!\n```\n\n# Have fun ^_^ \n---\n<!-- Place this tag in your head or just before your close body tag. -->\n<script async defer src=\"https://buttons.github.io/buttons.js\"></script>\n<!-- Place this tag where you want the button to render. -->\n\nPlease <a class=\"github-button\" href=\"https://github.com/YenYuHsuan/hexo-theme-beantech\" data-icon=\"octicon-star\" aria-label=\"Star YenYuHsuan/hexo-theme-beantech on GitHub\">Star</a> this Project if you like it! <a class=\"github-button\" href=\"https://github.com/YenYuHsuan\" aria-label=\"Follow @YenYuHsuan on GitHub\">Follow</a> would also be appreciated!\nPeace!\n","source":"_posts/hexo-theme-beantech.md","raw":"---\ntitle: \"[Hexo] Theme BeanTech\"\ncatalog: true\ndate: 2017-03-18 10:51:24\nsubtitle: \"This is hexo theme Demo.\"\nheader-img: \"Demo.png\"\ntags:\n- Hexo\n- Blog\ncatagories:\n- Hexo\n---\n> Ported Theme of [Hux Blog](https://github.com/Huxpro/huxpro.github.io), Thank [Huxpro](https://github.com/Huxpro) for designing such a flawless theme.\n> \n> This BeanTech theme created by [YuHsuan](http://beantech.org) modified from the original Porter [Kaijun](http://kaijun.rocks/hexo-theme-huxblog/)\n\n# [Live Demo](http://beantech.org)\n---\n![BeanTech Desktop](http://beantech.org/img/beantech-desktop.png)\n\n# Usage\n---\nI publish the whole project for your convenience, so you can just follow the instruction down below, then you can easily customiz your own blog!\n\nLet's begin!!!\n\n## Init\n---\n```bash\ngit clone https://github.com/YenYuHsuan/hexo-theme-beantech.git ./hexo-beantech\ncd hexo-beantech\nnpm install\n```\n\n## Modify\n---\nModify `_config.yml` file with your own info.\nEspecially the section:\n### Deployment\nReplace to your own repo!\n```yml\ndeploy:\n  type: git\n  repo: https://github.com/<yourAccount>/<repo>\n  branch: <your-branch>\n```\n\n### Sidebar settings\nCopy your avatar image to `<root>/img/` and modify the `_config.yml`:\n```yml\nsidebar: true    # whether or not using Sidebar.\nsidebar-about-description: \"<your description>\"\nsidebar-avatar: img/<your avatar path>\n```\nand activate your personal widget you like\n```yml\nwidgets:         # here are widget you can use, you can comment out\n- featured-tags\n- short-about\n- recent-posts\n- friends-blog\n- archive\n- category\n```\nif you want to add sidebar widget, please add at `layout/_widget`.\n### Signature Setup\nCopy your signature image to `<root>/img/signature` and modify the `_config.yml`:\n```yml\nsignature: true   # show signature\nsignature-img: img/signature/<your-signature-ID>\n```\n### Go to top icon Setup\nMy icon is using iron man, you can change to your own icon at `css/image`.\n\n### Post tag\nYou can decide to show post tags or not.\n```yml\nhome_posts_tag: true\n```\n![home_posts_tag-true](home_posts_tag-true.png)\n```yml\nhome_posts_tag: false\n```\n![home_posts_tag-false](home_posts_tag-false.png)\n\n### Markdown render\nMy markdown render engine plugin is [hexo-renderer-markdown-it](https://github.com/celsomiranda/hexo-renderer-markdown-it).\n```yml\n# Markdown-it config\n## Docs: https://github.com/celsomiranda/hexo-renderer-markdown-it/wiki\nmarkdown:\n  render:\n    html: true\n    xhtmlOut: false\n    breaks: true\n    linkify: true\n    typographer: true\n    quotes: '“”‘’'\n```\nand if you want to change the header anchor 'ℬ', you can go to `layout/post.ejs` to change it.\n```javascript\nasync(\"https://cdn.bootcss.com/anchor-js/1.1.1/anchor.min.js\",function(){\n        anchors.options = {\n          visible: 'hover',\n          placement: 'left',\n          icon: ℬ // this is the header anchor \"unicode\" icon\n        };\n```\n\n## Hexo Basics\n---\nSome hexo command:\n```bash\nhexo new post \"<post name>\" # you can change post to another layout if you want\nhexo clean && hexo generate # generate the static file\nhexo server # run hexo in local environment\nhexo deploy # hexo will push the static files automatically into the specific branch(gh-pages) of your repo!\n```\n\n# Have fun ^_^ \n---\n<!-- Place this tag in your head or just before your close body tag. -->\n<script async defer src=\"https://buttons.github.io/buttons.js\"></script>\n<!-- Place this tag where you want the button to render. -->\n\nPlease <a class=\"github-button\" href=\"https://github.com/YenYuHsuan/hexo-theme-beantech\" data-icon=\"octicon-star\" aria-label=\"Star YenYuHsuan/hexo-theme-beantech on GitHub\">Star</a> this Project if you like it! <a class=\"github-button\" href=\"https://github.com/YenYuHsuan\" aria-label=\"Follow @YenYuHsuan on GitHub\">Follow</a> would also be appreciated!\nPeace!\n","slug":"hexo-theme-beantech","published":1,"updated":"2017-09-23T13:40:20.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnek000gwlkvrjy0xqfv"},{"title":"hexo搭建个人博客","date":"2017-08-31T16:17:40.000Z","_content":"\n# hexo+github搭建个人博客\n\n## 简介\n\nHexo 是一个快速、简洁且高效的博客框架。Hexo 使用 [Markdown](http://daringfireball.net/projects/markdown/)（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。由于github pages存放的都是静态文件，博客存放的不只是文章内容，还有文章列表、分类、标签、翻页等动态内容，假如每次写完一篇文章都要手动更新博文目录和相关链接信息，相信谁都会疯掉，**所以hexo所做的就是将这些md文件都放在本地**，每次写完文章后调用写好的命令来批量完成相关页面的生成，然后再将有改动的页面提交到github。\n\n<!--more-->\n\n## 安装\n\n- 安装node.js\n\n  下载对应版本的node.js安装，并配置环境变量path\n\n- 安装git\n\n- 安装hexo\n\n  ```shell\n  npm config set registry https://registry.npm.taobao.org\n  sudo npm install --unsafe-perm --verbose -g hexo\n  ```\n\n  ​\n\n## 初始化hexo\n\n- 创建一个博客存放目录 /blogs，在该目录下进行hexo初始化\n\n  ```shell\n  $ hexo init /blogs\n  $ cd /blogs\n  $ npm install\n  ```\n\n  完成后/blogs目录下生成以下文件\n\n  ```\n  ·\n  |-- _config.yml\n  |-- package.json\n  |-- scaffolds\n  |-- source\n  |   |-- _drafts\n  |   |-- _posts\n  |-- themes\n\n  _config.yml站点配置文件，很多全局配置都在这个文件中。\n  package.json 应用数据。从它可以看出hexo版本信息，以及它所默认或者说依赖的一些组件。\n  scaffolds 模版文件。当你创建一篇新的文章时，hexo会依据模版文件进行创建，主要用在你想在每篇文章都添加一些共性的内容的情况下。\n  scripts 放脚本的文件夹， 就是放js文件的地方\n  source 这个文件夹就是放文章的地方了，除了文章还有一些主要的资源，比如文章里的图片，文件等等东西。这个文件夹最好定期做一个备份，丢了它，整个站点就废了。\n  themes 主题文件夹。\n  ```\n\n- 初始化hexo完成后，安装 hexo server\n\n  ```shell\n  $ sudo npm install hexo-server \n  $ npm install hexo-generator-index --save #索引生成器\n  $ npm install hexo-generator-archive --save #归档生成器\n  $ npm install hexo-generator-category --save #分类生成器\n  $ npm install hexo-generator-tag --save #标签生成器\n  $ npm install hexo-deployer-git --save #hexo通过git发布（必装）\n  $ npm install hexo-renderer-marked@0.2.7--save #渲染器\n  $ npm install hexo-renderer-stylus@0.3.0 --save #渲染器\n  ```\n\n- 生成静态页面并打开hexo本地服务\n\n  ```shell\n  $ hexo generate #生成静态页面  (或 hexo g)\n  $ hexo server  # 启动本地hexo\n  ```\n\n  启动完成后打开http://localhost:4000查看效果\n\n## 创建博客\n\n- 执行命令创建博客\n\n  ```shell\n  $ hexo new 'hexo搭建个人博客'\n  ```\n\n  此时hexo会在source下的_posts目录下创建一个名为hexo搭建个人博客的md文件，会自动生成博客标题和时间，同时可以手动去该目录下创建博客\n\n- 使用<!—more—> 控制哪部分作为简介\n\n  ```\n  title: hexo搭建个人博客\n  date: 2017-09-01 00:17:40\n  categories: 默认分类 #分类\n  tags: hexo\n  description: 附加一段文章摘要，字数最好在140字以内，会出现在meta的description里面\n  ```\n\n\n  hexo+github搭建个人博客\n\n  简介\n\n  Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。由于github pages存放的都是静态文件，博客存放的不只是文章内容，还有文章列表、分类、标签、翻页等动态内容，假如每次写完一篇文章都要手动更新博文目录和相关链接信息，相信谁都会疯掉，所以hexo所做的就是将这些md文件都放在本地，每次写完文章后调用写好的命令来批量完成相关页面的生成，然后再将有改动的页面提交到github。\n\n  <!--more-->\n  ```\n\n## 关联github\n\n- 在github上创建以用户名.github.io的仓库，aspiresnow.github.io\n\n- 配置ssh key\n\n  ```shell\n  $ cd ~/. ssh #检查本机已存在的ssh密钥\n  $ ssh-keygen -t rsa -C \"714131254@qq.com\"\n  ```\n\n  连续点回车然后连续3次回车，最终会生成一个文件在用户目录下，打开用户目录，找到`.ssh\\id_rsa.pub`文件，记事本打开并复制里面的内容，打开你的github主页，进入个人设置 -> SSH and GPG keys -> New SSH key：\n\n- 测试ssh配置是否成功\n\n  ```shell\n  $ ssh -T git@github.com\n  ```\n\n  如果提示`Are you sure you want to continue connecting (yes/no)?`，输入yes，然后会看到\n\n  > Hi liuxianan! You’ve successfully authenticated, but GitHub does not provide shell access. \n\n  说明配置成功，此时添加git配置\n  ```shell\n  > $ git config --global user.name \"liuxianan\"// 你的github用户名，非昵称\n  > $ git config --global user.email  \"xxx@qq.com\"// 填写你的github注册邮箱\n  ```\n- 修改/blogs目录下的 **_config.yml **文件，在修改最下方的**deploy**为：(注意:后面要有空格)\n\n  ```\n  deploy:\n    type: git\n    repository: git@github.com:aspiresnow/aspiresnow.github.io.git\n    branch: master\n  ```\n\n- 安装hexo的git部署\n\n  ```shell\n  $ npm install hexo-deployer-git --save\n  ```\n\n- 将生成静态页面并部署到github的仓库中\n\n  ```shell\n  $ hexo clean\n  $ hexo d -g \n  或者\n  $ hexo generate\n  $ hexo deploy\n  ```\n\n  访问https://aspiresnow.github.io/验证效果\n\n## 修改主题\n\n- 首先将主题库clone到/blogs目录下的themes目录：\n\n  ```shell\n  $ cd /blogs/themes/\n  $ git clone https://github.com/hilanmiao/hexo-theme-lanmiao\n  ```\n\n- 安装主题\n\n  ```shell\n  $ cd hexo-theme-lanmiao\n  $ npm install\n  ```\n\n- 修改hexo的主题配置配置文件`_config.yml`中的主题标签\n\n  ```\n  # Site\n  favicon: /image/favicon.jpg\n  header-img: /image/header-img.png\n\n  # Writing\n  post_asset_folder: true\n\n  # Extensions\n  theme: hexo-theme-lanmiao#对应主题的文件夹名称\n  ```\n\n- 执行命令\n\n  ```shell\n  hexo clean #清空\n  hexo d -g  #重新部署\n  ```\n\n## 参考\n\n- 主题地址：[LanMiao](https://github.com/hilanmiao/hexo-theme-lanmiao)","source":"_posts/hexo搭建个人博客.md","raw":"---\ntitle: hexo搭建个人博客\ndate: 2017-09-01 00:17:40\ntags: hexo\n---\n\n# hexo+github搭建个人博客\n\n## 简介\n\nHexo 是一个快速、简洁且高效的博客框架。Hexo 使用 [Markdown](http://daringfireball.net/projects/markdown/)（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。由于github pages存放的都是静态文件，博客存放的不只是文章内容，还有文章列表、分类、标签、翻页等动态内容，假如每次写完一篇文章都要手动更新博文目录和相关链接信息，相信谁都会疯掉，**所以hexo所做的就是将这些md文件都放在本地**，每次写完文章后调用写好的命令来批量完成相关页面的生成，然后再将有改动的页面提交到github。\n\n<!--more-->\n\n## 安装\n\n- 安装node.js\n\n  下载对应版本的node.js安装，并配置环境变量path\n\n- 安装git\n\n- 安装hexo\n\n  ```shell\n  npm config set registry https://registry.npm.taobao.org\n  sudo npm install --unsafe-perm --verbose -g hexo\n  ```\n\n  ​\n\n## 初始化hexo\n\n- 创建一个博客存放目录 /blogs，在该目录下进行hexo初始化\n\n  ```shell\n  $ hexo init /blogs\n  $ cd /blogs\n  $ npm install\n  ```\n\n  完成后/blogs目录下生成以下文件\n\n  ```\n  ·\n  |-- _config.yml\n  |-- package.json\n  |-- scaffolds\n  |-- source\n  |   |-- _drafts\n  |   |-- _posts\n  |-- themes\n\n  _config.yml站点配置文件，很多全局配置都在这个文件中。\n  package.json 应用数据。从它可以看出hexo版本信息，以及它所默认或者说依赖的一些组件。\n  scaffolds 模版文件。当你创建一篇新的文章时，hexo会依据模版文件进行创建，主要用在你想在每篇文章都添加一些共性的内容的情况下。\n  scripts 放脚本的文件夹， 就是放js文件的地方\n  source 这个文件夹就是放文章的地方了，除了文章还有一些主要的资源，比如文章里的图片，文件等等东西。这个文件夹最好定期做一个备份，丢了它，整个站点就废了。\n  themes 主题文件夹。\n  ```\n\n- 初始化hexo完成后，安装 hexo server\n\n  ```shell\n  $ sudo npm install hexo-server \n  $ npm install hexo-generator-index --save #索引生成器\n  $ npm install hexo-generator-archive --save #归档生成器\n  $ npm install hexo-generator-category --save #分类生成器\n  $ npm install hexo-generator-tag --save #标签生成器\n  $ npm install hexo-deployer-git --save #hexo通过git发布（必装）\n  $ npm install hexo-renderer-marked@0.2.7--save #渲染器\n  $ npm install hexo-renderer-stylus@0.3.0 --save #渲染器\n  ```\n\n- 生成静态页面并打开hexo本地服务\n\n  ```shell\n  $ hexo generate #生成静态页面  (或 hexo g)\n  $ hexo server  # 启动本地hexo\n  ```\n\n  启动完成后打开http://localhost:4000查看效果\n\n## 创建博客\n\n- 执行命令创建博客\n\n  ```shell\n  $ hexo new 'hexo搭建个人博客'\n  ```\n\n  此时hexo会在source下的_posts目录下创建一个名为hexo搭建个人博客的md文件，会自动生成博客标题和时间，同时可以手动去该目录下创建博客\n\n- 使用<!—more—> 控制哪部分作为简介\n\n  ```\n  title: hexo搭建个人博客\n  date: 2017-09-01 00:17:40\n  categories: 默认分类 #分类\n  tags: hexo\n  description: 附加一段文章摘要，字数最好在140字以内，会出现在meta的description里面\n  ```\n\n\n  hexo+github搭建个人博客\n\n  简介\n\n  Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。由于github pages存放的都是静态文件，博客存放的不只是文章内容，还有文章列表、分类、标签、翻页等动态内容，假如每次写完一篇文章都要手动更新博文目录和相关链接信息，相信谁都会疯掉，所以hexo所做的就是将这些md文件都放在本地，每次写完文章后调用写好的命令来批量完成相关页面的生成，然后再将有改动的页面提交到github。\n\n  <!--more-->\n  ```\n\n## 关联github\n\n- 在github上创建以用户名.github.io的仓库，aspiresnow.github.io\n\n- 配置ssh key\n\n  ```shell\n  $ cd ~/. ssh #检查本机已存在的ssh密钥\n  $ ssh-keygen -t rsa -C \"714131254@qq.com\"\n  ```\n\n  连续点回车然后连续3次回车，最终会生成一个文件在用户目录下，打开用户目录，找到`.ssh\\id_rsa.pub`文件，记事本打开并复制里面的内容，打开你的github主页，进入个人设置 -> SSH and GPG keys -> New SSH key：\n\n- 测试ssh配置是否成功\n\n  ```shell\n  $ ssh -T git@github.com\n  ```\n\n  如果提示`Are you sure you want to continue connecting (yes/no)?`，输入yes，然后会看到\n\n  > Hi liuxianan! You’ve successfully authenticated, but GitHub does not provide shell access. \n\n  说明配置成功，此时添加git配置\n  ```shell\n  > $ git config --global user.name \"liuxianan\"// 你的github用户名，非昵称\n  > $ git config --global user.email  \"xxx@qq.com\"// 填写你的github注册邮箱\n  ```\n- 修改/blogs目录下的 **_config.yml **文件，在修改最下方的**deploy**为：(注意:后面要有空格)\n\n  ```\n  deploy:\n    type: git\n    repository: git@github.com:aspiresnow/aspiresnow.github.io.git\n    branch: master\n  ```\n\n- 安装hexo的git部署\n\n  ```shell\n  $ npm install hexo-deployer-git --save\n  ```\n\n- 将生成静态页面并部署到github的仓库中\n\n  ```shell\n  $ hexo clean\n  $ hexo d -g \n  或者\n  $ hexo generate\n  $ hexo deploy\n  ```\n\n  访问https://aspiresnow.github.io/验证效果\n\n## 修改主题\n\n- 首先将主题库clone到/blogs目录下的themes目录：\n\n  ```shell\n  $ cd /blogs/themes/\n  $ git clone https://github.com/hilanmiao/hexo-theme-lanmiao\n  ```\n\n- 安装主题\n\n  ```shell\n  $ cd hexo-theme-lanmiao\n  $ npm install\n  ```\n\n- 修改hexo的主题配置配置文件`_config.yml`中的主题标签\n\n  ```\n  # Site\n  favicon: /image/favicon.jpg\n  header-img: /image/header-img.png\n\n  # Writing\n  post_asset_folder: true\n\n  # Extensions\n  theme: hexo-theme-lanmiao#对应主题的文件夹名称\n  ```\n\n- 执行命令\n\n  ```shell\n  hexo clean #清空\n  hexo d -g  #重新部署\n  ```\n\n## 参考\n\n- 主题地址：[LanMiao](https://github.com/hilanmiao/hexo-theme-lanmiao)","slug":"hexo搭建个人博客","published":1,"updated":"2018-09-12T03:03:21.819Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnem000iwlkvlrm7cwyo"},{"title":"maven实现环境切换","date":"2018-07-30T03:23:24.000Z","_content":"\n# maven实现环境切换\n\n在项目开发过程中往往会有多个环境，不同的环境配置会不同，maven提供一种profiles切换和filter来实现在编译的时候根据环境来替换变量的功能\n\n<!--more-->\n\n## 配置过程\n\n1. 在maven的pom.xml中配置各个环境的profiles，在编译打包的时候使用 -Pprod来指定环境\n\n   ```xml\n   <profiles>\n       <profile>\n           <id>dev</id>\n           <activation>\n               <!--指定为默认-->\n               <activeByDefault>true</activeByDefault>\n           </activation>\n           <properties>\n               <profile.id>dev</profile.id>\n           </properties>\n       </profile>\n       <profile>\n           <id>beta</id>\n           <properties>\n               <profile.id>beta</profile.id>\n           </properties>\n       </profile>\n       <profile>\n           <id>prod</id>\n           <properties>\n               <profile.id>prod</profile.id>\n           </properties>\n       </profile>\n   </profiles>\n   ```\n\n2. 使用filtering=true指定使用filters中配置的文件中的变量替换\n\n   ```xml\n   <build>\n       <filters>\n   \t\t\t<!--指定用于参数替换的配置文件-->\n   \t\t\t<filter>${basedir}/config/common.properties</filter>\n   \t\t\t<!--使用profiles中各个环境不同的文件进行参数替换-->\n   \t\t\t<filter>${basedir}/config/env_${profile.id}.properties</filter>\n   \t\t</filters>\n   \n   \t\t<resources>\n   \t\t<!--filtering=true开启属性替换，由于默认是false，需要重新指定一下，资源路径还是默认的路径-->\n   \t\t\t<!--可以指定多个resource节点用于指定需要进行参数替换的文件-->\n   \t\t\t<resource>\n   \t\t\t\t<directory>${basedir}/src/main/resources</directory>\n   \t\t\t\t<excludes>\n   \t\t\t\t\t<!--排除掉不使用maven进行参数替换的文件-->\n   \t\t\t\t\t<exclude>expicate.xml</exclude>\n   \t\t\t\t</excludes>\n   \t\t\t\t<filtering>true</filtering>\n   \t\t\t</resource>\n   \t\t</resources>\n   </build>\n   ```\n\n   注意:如果filters中配置了多个用于参数替换的文件，如果多个文件中有相同的变量，那么配置在filter靠下的文件中的变量会生效，下面覆盖上面的。\n\n3. 在工程下新建config目录并添加各个环境的配置文件\n\n   `evn_deva.properties`\n\n   ```properties\n   profile_test=dev_test\n   ```\n\n   `evn_beta.properties`\n\n   ```properties\n   profile_test=beta_test\n   ```\n\n   `evn_prod.properties`\n\n   ```properties\n   profile_test=prod_test\n   ```\n\n   `common.properties`\n\n   ```properties\n   profile_test=common_test\n   ```\n\n4. 在resources目录下的application.properties中使用变量，用于被各环境参数替换\n\n  ```properties\n  profile_test=${profile_test}\n  # 也可以使用maven pom中定义的变量\n  profile.id = ${profile.id}\n  ```\n\n5. 在集成spring boot的时候，发现不能使用 ${}，这是因为工程的pom文件继承了 spring-boot-starter-parent,而在spring-boot-starter-parent的pom.xml中定义了\n\n   ```xml\n   <!-- delimiter that doesn't clash with Spring ${} placeholders -->\n   <resource.delimiter>@</resource.delimiter> \n   ```\n\n   我们可以在自己的pom中重新将 `resource.delimiter` 指定为 `${}`,当然也可以听从建议直接使用 `@变量名@`\n\n\n\n","source":"_posts/maven实现环境切换.md","raw":"---\ntitle: maven实现环境切换\ndate: 2018-07-30 11:23:24\ntags:\n- Maven\ncategories:\n- Maven\n\n---\n\n# maven实现环境切换\n\n在项目开发过程中往往会有多个环境，不同的环境配置会不同，maven提供一种profiles切换和filter来实现在编译的时候根据环境来替换变量的功能\n\n<!--more-->\n\n## 配置过程\n\n1. 在maven的pom.xml中配置各个环境的profiles，在编译打包的时候使用 -Pprod来指定环境\n\n   ```xml\n   <profiles>\n       <profile>\n           <id>dev</id>\n           <activation>\n               <!--指定为默认-->\n               <activeByDefault>true</activeByDefault>\n           </activation>\n           <properties>\n               <profile.id>dev</profile.id>\n           </properties>\n       </profile>\n       <profile>\n           <id>beta</id>\n           <properties>\n               <profile.id>beta</profile.id>\n           </properties>\n       </profile>\n       <profile>\n           <id>prod</id>\n           <properties>\n               <profile.id>prod</profile.id>\n           </properties>\n       </profile>\n   </profiles>\n   ```\n\n2. 使用filtering=true指定使用filters中配置的文件中的变量替换\n\n   ```xml\n   <build>\n       <filters>\n   \t\t\t<!--指定用于参数替换的配置文件-->\n   \t\t\t<filter>${basedir}/config/common.properties</filter>\n   \t\t\t<!--使用profiles中各个环境不同的文件进行参数替换-->\n   \t\t\t<filter>${basedir}/config/env_${profile.id}.properties</filter>\n   \t\t</filters>\n   \n   \t\t<resources>\n   \t\t<!--filtering=true开启属性替换，由于默认是false，需要重新指定一下，资源路径还是默认的路径-->\n   \t\t\t<!--可以指定多个resource节点用于指定需要进行参数替换的文件-->\n   \t\t\t<resource>\n   \t\t\t\t<directory>${basedir}/src/main/resources</directory>\n   \t\t\t\t<excludes>\n   \t\t\t\t\t<!--排除掉不使用maven进行参数替换的文件-->\n   \t\t\t\t\t<exclude>expicate.xml</exclude>\n   \t\t\t\t</excludes>\n   \t\t\t\t<filtering>true</filtering>\n   \t\t\t</resource>\n   \t\t</resources>\n   </build>\n   ```\n\n   注意:如果filters中配置了多个用于参数替换的文件，如果多个文件中有相同的变量，那么配置在filter靠下的文件中的变量会生效，下面覆盖上面的。\n\n3. 在工程下新建config目录并添加各个环境的配置文件\n\n   `evn_deva.properties`\n\n   ```properties\n   profile_test=dev_test\n   ```\n\n   `evn_beta.properties`\n\n   ```properties\n   profile_test=beta_test\n   ```\n\n   `evn_prod.properties`\n\n   ```properties\n   profile_test=prod_test\n   ```\n\n   `common.properties`\n\n   ```properties\n   profile_test=common_test\n   ```\n\n4. 在resources目录下的application.properties中使用变量，用于被各环境参数替换\n\n  ```properties\n  profile_test=${profile_test}\n  # 也可以使用maven pom中定义的变量\n  profile.id = ${profile.id}\n  ```\n\n5. 在集成spring boot的时候，发现不能使用 ${}，这是因为工程的pom文件继承了 spring-boot-starter-parent,而在spring-boot-starter-parent的pom.xml中定义了\n\n   ```xml\n   <!-- delimiter that doesn't clash with Spring ${} placeholders -->\n   <resource.delimiter>@</resource.delimiter> \n   ```\n\n   我们可以在自己的pom中重新将 `resource.delimiter` 指定为 `${}`,当然也可以听从建议直接使用 `@变量名@`\n\n\n\n","slug":"maven实现环境切换","published":1,"updated":"2018-09-12T03:03:21.825Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfneo000mwlkv7guevbds"},{"title":"mac上使用Homebrew","date":"2018-07-14T02:26:48.000Z","_content":"\n# mac上使用Homebrew\n\nHomebrew是一个包管理工具，类似linux上的yum和apt包管理，可以让你在mac上安装和更新程序变得更方便，只需要输入简单的命令，从而避免安装过程中的包依赖。\n\n## 安装homeBrew\n\n```shell\n/usr/bin/ruby -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\"\n```\n\n```shell\nbrew --version  #查看是否安装成功 Homebrew 1.6.17\n```\n\n## 软件管理\n\n```shell\nbrew install <formula>  #安装软件\nbrew install https://raw.github.com/dsr/homebrew/9b22d42f50fcbc5e52c764448b3ac002bc153bd7/Library/Formula/python3.rb\n\nbrew uninstall <formula> #卸载软件\nbrew outdated <formula> #插件软件是否过时\nbrew upgrade <formula> #更新软件\nbrew list #列出所有通过brew安装的软件\nbrew search  <formula># 搜索可以通过brew安装的软件\nbrew cleanup <formula> #卸载软件\nbrew info <formula> #查看安装的软件的信息\nbrew switch <formula> <version> #切换安装的版本\nbrew home <formula> #查看安装的软件的目录\n```\n\n## 安装路径\n\n`Homebrew`会将软件包安装到独立目录(`/usr/local/Cellar`)，并将其文件软链接至`/usr/local`。  将配置文件放到`/usr/local/etc`下，\n\n## 服务管理\n\n```shell\nbrew services list # 展示所有服务\nbrew services run xxx #启动\nbrew services start xxx #启动\nbrew services stop xxx #停止\nbrew services restart xxx #重启\nbrew services cleanup #清除所有服务\n```\n\n","source":"_posts/mac上使用Homebrew.md","raw":"---\ntitle: mac上使用Homebrew\ndate: 2018-07-14 10:26:48\ntags:\n- homebrew\ncategories:\n- java工具\n---\n\n# mac上使用Homebrew\n\nHomebrew是一个包管理工具，类似linux上的yum和apt包管理，可以让你在mac上安装和更新程序变得更方便，只需要输入简单的命令，从而避免安装过程中的包依赖。\n\n## 安装homeBrew\n\n```shell\n/usr/bin/ruby -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\"\n```\n\n```shell\nbrew --version  #查看是否安装成功 Homebrew 1.6.17\n```\n\n## 软件管理\n\n```shell\nbrew install <formula>  #安装软件\nbrew install https://raw.github.com/dsr/homebrew/9b22d42f50fcbc5e52c764448b3ac002bc153bd7/Library/Formula/python3.rb\n\nbrew uninstall <formula> #卸载软件\nbrew outdated <formula> #插件软件是否过时\nbrew upgrade <formula> #更新软件\nbrew list #列出所有通过brew安装的软件\nbrew search  <formula># 搜索可以通过brew安装的软件\nbrew cleanup <formula> #卸载软件\nbrew info <formula> #查看安装的软件的信息\nbrew switch <formula> <version> #切换安装的版本\nbrew home <formula> #查看安装的软件的目录\n```\n\n## 安装路径\n\n`Homebrew`会将软件包安装到独立目录(`/usr/local/Cellar`)，并将其文件软链接至`/usr/local`。  将配置文件放到`/usr/local/etc`下，\n\n## 服务管理\n\n```shell\nbrew services list # 展示所有服务\nbrew services run xxx #启动\nbrew services start xxx #启动\nbrew services stop xxx #停止\nbrew services restart xxx #重启\nbrew services cleanup #清除所有服务\n```\n\n","slug":"mac上使用Homebrew","published":1,"updated":"2018-09-12T03:03:21.824Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfneq000owlkvstnnk9fv"},{"title":"shiro介绍","date":"2017-09-29T07:06:24.000Z","_content":"\n# shiro介绍\n\nshiro是一个简单适用的安全框架，通过shiro可以方便的对应用进行认证、授权、加密、session管理工作。\n\n- 目标\n  - 用户登录token验证\n  - 根据用户的角色和权限信息进行权限验证\n  - 提供一个可以在任意环境使用的Session API\n  - 支持多个用户的角色权限信息来源，并进行聚合\n  - 支持单点登录\n  - 支持记忆**登录\n- shiro的组件\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-9-29/52380803.jpg)\n\n​\t**Authentication(认证)**：系统验证用户登录信息\n​\t**Authorization(授权)**：验证用户有哪些资源的访问权限\n​\t**CIpher(加解密)**：shiro支持加解密算法\n​\t**Permission(权限)**：一个功能、一个方法、一个URL，总之就是一个访问控制\n​\t**Role**：权限的集合\n​\t**Session**：用户跟application交互过程中存储信息的结构，退出登录时删除\n\n## 流程\n\n1. 获取shiro中的用户，使用Subject对象代表当前用户，如果是Web，获取到的是request请求，普通应用获取到的是当前线程对象\n\n   ```java\n   Subject currentUser = SecurityUtils.getSubject();\n   Session session = currentUser.getSession();//获取当前会话\n   ```\n\n2. 指定当前登录人的用户名密码进行一次登录\n\n   ```java\n   if ( !currentUser.isAuthenticated() ) {\n       //通过用户的信息创建token\n       UsernamePasswordToken token = new UsernamePasswordToken(\"lonestarr\", \"vespa\");\n       //指定`记住我`\n       token.setRememberMe(true);\n       try {\n       \tcurrentUser.login( token );\n       } catch ( UnknownAccountException uae ) {\n           //username wasn't in the system, show them an error message?\n       } catch ( IncorrectCredentialsException ice ) {\n           //password didn't match, try again?\n       } catch ( LockedAccountException lae ) {\n           //account for that username is locked - can't login.  Show them a message?\n       } catch ( AuthenticationException ae ) {\n           //unexpected condition - error?\n       }\n   }\n   ```\n3. 检验用户角色权限\n   ```java\n   if ( currentUser.hasRole( \"schwartz\" ) ) //校验角色\n   if ( currentUser.isPermitted( \"winnebago:drive:eagle5\" ) )//权限层级\n   ```\n## 基本原理\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-9-30/81616656.jpg)\n**Subject**：一个抽象概念，同shiro应用交互的对象的抽象，shiro提供的唯一交互接口\n**Security Manager**:shiro的核心模块,subject的后期处理都由它进行处理，Security Manager是模块化的继承，每个模块分别负责不同的功能。\n**Realm**：shiro的DAO层，提供用户、角色、权限信息，连接一个或多个数据源并将数据转换成shiro可以理解的数据\n**Authenticator**：用于验证用户登录时是否能够成功\n**Authorizer** ：负责控制用户的访问资源权限\n**SessionManager** :管理应用session，如果是web项目，是httpSession的实现\n**CacheManager** :支持第三方缓存技术用于缓存用户角色权限信息，提升系统性能\n### 用户认证流程\n\n调用Subject的login方法，提交了一个`AuthenticationTokens`信息，将请求提交到Security Manager，然后调用`Authenticator` 进行处理，`Authenticator` 会首先调用Realm的 `supports`方法，验证Realm是否支持该类型的token验证，验证通过后调用Realm中的getAuthenticationInfo(token)方法进行登录验证。\n\n在Realm中getAuthenticationInfo获取用户信息，调用用户数据源进行登录合法性验证，\n\n### 权限认证流程\n调用Subject的api的isPermitted和人checkPermission方法，首先会将请求提交给Security Manager，Security Manager调用Authorizer进行权限验证，Authorizer调用底层的多个Realm实现获取用户权限信息，将用户角色所属的权限信息和直接绑定到用户上的权限信息进行聚合，然后判断权限是否在该集合中。\n![image](http://omdq6di7v.bkt.clouddn.com/17-9-30/68338105.jpg)\n\n\n\n\n\n​\t\n\n\n\n​\t","source":"_posts/shiro介绍.md","raw":"---\ntitle: shiro介绍\ndate: 2017-09-29 15:06:24\ntags:\n- shiro\ncategories:\n- 权限\n---\n\n# shiro介绍\n\nshiro是一个简单适用的安全框架，通过shiro可以方便的对应用进行认证、授权、加密、session管理工作。\n\n- 目标\n  - 用户登录token验证\n  - 根据用户的角色和权限信息进行权限验证\n  - 提供一个可以在任意环境使用的Session API\n  - 支持多个用户的角色权限信息来源，并进行聚合\n  - 支持单点登录\n  - 支持记忆**登录\n- shiro的组件\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-9-29/52380803.jpg)\n\n​\t**Authentication(认证)**：系统验证用户登录信息\n​\t**Authorization(授权)**：验证用户有哪些资源的访问权限\n​\t**CIpher(加解密)**：shiro支持加解密算法\n​\t**Permission(权限)**：一个功能、一个方法、一个URL，总之就是一个访问控制\n​\t**Role**：权限的集合\n​\t**Session**：用户跟application交互过程中存储信息的结构，退出登录时删除\n\n## 流程\n\n1. 获取shiro中的用户，使用Subject对象代表当前用户，如果是Web，获取到的是request请求，普通应用获取到的是当前线程对象\n\n   ```java\n   Subject currentUser = SecurityUtils.getSubject();\n   Session session = currentUser.getSession();//获取当前会话\n   ```\n\n2. 指定当前登录人的用户名密码进行一次登录\n\n   ```java\n   if ( !currentUser.isAuthenticated() ) {\n       //通过用户的信息创建token\n       UsernamePasswordToken token = new UsernamePasswordToken(\"lonestarr\", \"vespa\");\n       //指定`记住我`\n       token.setRememberMe(true);\n       try {\n       \tcurrentUser.login( token );\n       } catch ( UnknownAccountException uae ) {\n           //username wasn't in the system, show them an error message?\n       } catch ( IncorrectCredentialsException ice ) {\n           //password didn't match, try again?\n       } catch ( LockedAccountException lae ) {\n           //account for that username is locked - can't login.  Show them a message?\n       } catch ( AuthenticationException ae ) {\n           //unexpected condition - error?\n       }\n   }\n   ```\n3. 检验用户角色权限\n   ```java\n   if ( currentUser.hasRole( \"schwartz\" ) ) //校验角色\n   if ( currentUser.isPermitted( \"winnebago:drive:eagle5\" ) )//权限层级\n   ```\n## 基本原理\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-9-30/81616656.jpg)\n**Subject**：一个抽象概念，同shiro应用交互的对象的抽象，shiro提供的唯一交互接口\n**Security Manager**:shiro的核心模块,subject的后期处理都由它进行处理，Security Manager是模块化的继承，每个模块分别负责不同的功能。\n**Realm**：shiro的DAO层，提供用户、角色、权限信息，连接一个或多个数据源并将数据转换成shiro可以理解的数据\n**Authenticator**：用于验证用户登录时是否能够成功\n**Authorizer** ：负责控制用户的访问资源权限\n**SessionManager** :管理应用session，如果是web项目，是httpSession的实现\n**CacheManager** :支持第三方缓存技术用于缓存用户角色权限信息，提升系统性能\n### 用户认证流程\n\n调用Subject的login方法，提交了一个`AuthenticationTokens`信息，将请求提交到Security Manager，然后调用`Authenticator` 进行处理，`Authenticator` 会首先调用Realm的 `supports`方法，验证Realm是否支持该类型的token验证，验证通过后调用Realm中的getAuthenticationInfo(token)方法进行登录验证。\n\n在Realm中getAuthenticationInfo获取用户信息，调用用户数据源进行登录合法性验证，\n\n### 权限认证流程\n调用Subject的api的isPermitted和人checkPermission方法，首先会将请求提交给Security Manager，Security Manager调用Authorizer进行权限验证，Authorizer调用底层的多个Realm实现获取用户权限信息，将用户角色所属的权限信息和直接绑定到用户上的权限信息进行聚合，然后判断权限是否在该集合中。\n![image](http://omdq6di7v.bkt.clouddn.com/17-9-30/68338105.jpg)\n\n\n\n\n\n​\t\n\n\n\n​\t","slug":"shiro介绍","published":1,"updated":"2018-09-12T03:03:21.826Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnev000swlkvkmgga9ui"},{"title":"spark初识","date":"2017-09-09T14:45:21.000Z","_content":"\n## spark初识\n\n- spark允许用户将数据加载到集群内存中反复进行运算\n- spark支持交互式使用和复杂算法，是一个通用引擎，可以用来完成各种运算，包括sql查询、文本处理、机器学习等。\n\n\n","source":"_posts/spark.md","raw":"---\ntitle: spark初识\ndate: 2017-09-09 22:45:21\ntags:\n- spark\ncategories:\n- 大数据\n---\n\n## spark初识\n\n- spark允许用户将数据加载到集群内存中反复进行运算\n- spark支持交互式使用和复杂算法，是一个通用引擎，可以用来完成各种运算，包括sql查询、文本处理、机器学习等。\n\n\n","slug":"spark","published":1,"updated":"2018-09-12T03:03:21.826Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnew000uwlkv77t959cz"},{"title":"关于学习的思考","date":"2017-10-25T15:46:13.000Z","_content":"\n# 关于学习的思考\n\n​\t这些年总感觉注意力和记忆力非常的底下，做一件事注意力集中不了几分钟就就做到另一件事上，想的东西更新千奇百怪，瞬间脑子就能想过无数事，不觉间就掉哪个坑里发呆了。记忆力更是差的离谱，干it这行本来接触的东西就比较多而且很杂，想要记住每行代码不太现实，但是对于一些原理性的东西也是刚看了就忘，这个确实有点失败。\n\n​\t随着体重即将突破170大关，体力也是直线下降，每天从家到公司都能累的半死，10号线倒完1号就累得直喘，一直再提减肥，却没有成功过。前两天百度了一下记忆力下降的问题，有个答案是压力大、焦躁、新陈代谢慢引起的。一直以来睡得都比较晚，想学东西收获一直欠缺，压力大和焦躁是有的。新陈代谢慢感觉也是有的，没感觉比别人吃的多，但是肉长得确实比别人快，曾经一直天真的以为这是吸收好，自从上次问过医生才知道，恰恰相反。\n\n​\t身体是革命的本钱，身体不行了干什么都没有精力，一直以来总觉得没有时间跑步锻炼之类的，总想着要学习，每天下班也不做其他的，每个周末也不出去玩，总想着是不是该学点什么，最终都发现其实什么都没学，时间都被浪费在不知道做了些什么的地方。**其实不去锻炼总会有无数个借口，想学习其实也是其中的一种罢了**。\n\n**每次打游戏的过程中都很爽，打完之后总会觉得很空虚；每次跑步的时候都很煎熬，跑完步神清气爽；每次生病的时候的痛苦其实远超跑步，所以还是跑步吧！**\n\n​\t学习过程中**对网络的依赖越来越严重**，碰到一个问题第一时间就是想着上网一直找，想学个知识也是上网一直找，很少有先动动脑子自己先想想，导致脑子的反应速度很难跟的上手了，直接影响了工作效率。**工作学习中动脑子的速度一定要超过手的速度**，这样工作学习效率才能提高。\n\n​\t**专注一件事，做好，弄懂，掌握原理**。总是不停的在收藏网页，收藏博客，收藏pdf，买书，存视频，求知欲很强，但是一直都没看，太多了了，根本看不完，太贪，总想一下次全学会，全弄懂，看个博客要从头看，看本书也要从头看，会的也看，不会的攒着以后看，这样根本不可能看的完，而且效率极低。\n\n​\t**学习就像是一次长跑，更多的靠的是坚持，需要时间的积累，才能跑得更远，学的更多**。在学习的时候总会有精神不振的时候，学不进去，这个时候就该想想办法调节一下，强求不得。\n\n​\t**学习更重要的是要掌握原理，不要在理解原理的时候想着节省时间**。记得在初中的时候记忆力很强，当时的英语书后面的单词本都是背着写出来的，后来慢慢的习惯不背东西，多翻书，翻个十遍八遍的多想想就记住了。慢慢的要记得东西越来越多，很多东西没办法翻很多遍，很多东西看过一遍之后可能很久都不会再看一下，这就导致看过了跟没看是一样的。。\n\n​\t学习一定要有迎难而上的精神，大家都一学就能掌握的知识那只能算是常识，学习本来就是挑战大脑舒适区的动作。**或许是长年看网络小说的原因，习惯了看书的时候不动脑子，只是在消磨时间**，直接导致看书不分重点，只过眼不过脑。以后是要改掉看网络小说的习惯，学习的时候对于不懂的地方要尝试着死扣，将问题分解，捋思路，画流程图。**学习都会遇到困难，有的人遇到困难直接放弃，最终一直不会，有的人遇到困难不断尝试，最后解决，这就是笨人和聪明人的区别**。\n\n​\t偶而会感觉抓住了些东西，但是又感觉没有抓住，总想着要抓住些东西。\n\n​\t2017年剩余的几个月里，希望能够安静下来，利用好时间去掌握几个知识、操作几个知识、见识几个知识，人嘛，天天活着总得折腾点不一样东西。\n\n　　在IT路上，我还是一只菜鸟，还在不断地学习，希望有朝一日能成为别人口中的大牛。","source":"_posts/关于学习的思考.md","raw":"---\ntitle: 关于学习的思考\ndate: 2017-10-25 23:46:13\ntags:\n- 思考\ncategories:\n- 生活\n---\n\n# 关于学习的思考\n\n​\t这些年总感觉注意力和记忆力非常的底下，做一件事注意力集中不了几分钟就就做到另一件事上，想的东西更新千奇百怪，瞬间脑子就能想过无数事，不觉间就掉哪个坑里发呆了。记忆力更是差的离谱，干it这行本来接触的东西就比较多而且很杂，想要记住每行代码不太现实，但是对于一些原理性的东西也是刚看了就忘，这个确实有点失败。\n\n​\t随着体重即将突破170大关，体力也是直线下降，每天从家到公司都能累的半死，10号线倒完1号就累得直喘，一直再提减肥，却没有成功过。前两天百度了一下记忆力下降的问题，有个答案是压力大、焦躁、新陈代谢慢引起的。一直以来睡得都比较晚，想学东西收获一直欠缺，压力大和焦躁是有的。新陈代谢慢感觉也是有的，没感觉比别人吃的多，但是肉长得确实比别人快，曾经一直天真的以为这是吸收好，自从上次问过医生才知道，恰恰相反。\n\n​\t身体是革命的本钱，身体不行了干什么都没有精力，一直以来总觉得没有时间跑步锻炼之类的，总想着要学习，每天下班也不做其他的，每个周末也不出去玩，总想着是不是该学点什么，最终都发现其实什么都没学，时间都被浪费在不知道做了些什么的地方。**其实不去锻炼总会有无数个借口，想学习其实也是其中的一种罢了**。\n\n**每次打游戏的过程中都很爽，打完之后总会觉得很空虚；每次跑步的时候都很煎熬，跑完步神清气爽；每次生病的时候的痛苦其实远超跑步，所以还是跑步吧！**\n\n​\t学习过程中**对网络的依赖越来越严重**，碰到一个问题第一时间就是想着上网一直找，想学个知识也是上网一直找，很少有先动动脑子自己先想想，导致脑子的反应速度很难跟的上手了，直接影响了工作效率。**工作学习中动脑子的速度一定要超过手的速度**，这样工作学习效率才能提高。\n\n​\t**专注一件事，做好，弄懂，掌握原理**。总是不停的在收藏网页，收藏博客，收藏pdf，买书，存视频，求知欲很强，但是一直都没看，太多了了，根本看不完，太贪，总想一下次全学会，全弄懂，看个博客要从头看，看本书也要从头看，会的也看，不会的攒着以后看，这样根本不可能看的完，而且效率极低。\n\n​\t**学习就像是一次长跑，更多的靠的是坚持，需要时间的积累，才能跑得更远，学的更多**。在学习的时候总会有精神不振的时候，学不进去，这个时候就该想想办法调节一下，强求不得。\n\n​\t**学习更重要的是要掌握原理，不要在理解原理的时候想着节省时间**。记得在初中的时候记忆力很强，当时的英语书后面的单词本都是背着写出来的，后来慢慢的习惯不背东西，多翻书，翻个十遍八遍的多想想就记住了。慢慢的要记得东西越来越多，很多东西没办法翻很多遍，很多东西看过一遍之后可能很久都不会再看一下，这就导致看过了跟没看是一样的。。\n\n​\t学习一定要有迎难而上的精神，大家都一学就能掌握的知识那只能算是常识，学习本来就是挑战大脑舒适区的动作。**或许是长年看网络小说的原因，习惯了看书的时候不动脑子，只是在消磨时间**，直接导致看书不分重点，只过眼不过脑。以后是要改掉看网络小说的习惯，学习的时候对于不懂的地方要尝试着死扣，将问题分解，捋思路，画流程图。**学习都会遇到困难，有的人遇到困难直接放弃，最终一直不会，有的人遇到困难不断尝试，最后解决，这就是笨人和聪明人的区别**。\n\n​\t偶而会感觉抓住了些东西，但是又感觉没有抓住，总想着要抓住些东西。\n\n​\t2017年剩余的几个月里，希望能够安静下来，利用好时间去掌握几个知识、操作几个知识、见识几个知识，人嘛，天天活着总得折腾点不一样东西。\n\n　　在IT路上，我还是一只菜鸟，还在不断地学习，希望有朝一日能成为别人口中的大牛。","slug":"关于学习的思考","published":1,"updated":"2018-09-12T03:03:21.827Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnex000wwlkvk4oh5n1m"},{"title":"数据结构之tree","date":"2017-11-22T09:25:26.000Z","_content":"\n问题-->逻辑结构-->存储结构-->实现操作\n\n逻辑结构\n\n- 集合\n- 线性\n- 树型\n- 图型\n\n存储结构\n\n- 顺序存储\n- 链式存储\n- 索引\n- 散列\n\n算法\n\n算法的优劣\n\n- 时间复杂度\n- 空间复杂度\n","source":"_posts/数据结构之tree.md","raw":"---\ntitle: 数据结构之tree\ndate: 2017-11-22 17:25:26\ntags:\n---\n\n问题-->逻辑结构-->存储结构-->实现操作\n\n逻辑结构\n\n- 集合\n- 线性\n- 树型\n- 图型\n\n存储结构\n\n- 顺序存储\n- 链式存储\n- 索引\n- 散列\n\n算法\n\n算法的优劣\n\n- 时间复杂度\n- 空间复杂度\n","slug":"数据结构之tree","published":1,"updated":"2018-09-30T08:50:26.756Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnez0010wlkvj055jt1g"},{"title":"线上问题排查","date":"2017-11-11T01:23:10.000Z","_content":"\n# 问题排查\n\n- Linux环境下如何查找哪个线程使用CPU最长\n  1. 获取项目的pid，jps或者ps -ef | grep java，这个前面有讲过 \n  2. top -H -p pid 或者使用 jps pid 顺序不能改变\n  3. top -H -p pid 打出来的LWP是十进制的，”jps pid”打出来的本地线程号是十六进制的，转换一下，就能定位到占用CPU高的线程的当前线程堆栈了 ","source":"_posts/线上问题排查.md","raw":"---\ntitle: 线上问题排查\ndate: 2017-11-11 09:23:10\ntags:\n- 问题排查\ncategories:\n- java\n---\n\n# 问题排查\n\n- Linux环境下如何查找哪个线程使用CPU最长\n  1. 获取项目的pid，jps或者ps -ef | grep java，这个前面有讲过 \n  2. top -H -p pid 或者使用 jps pid 顺序不能改变\n  3. top -H -p pid 打出来的LWP是十进制的，”jps pid”打出来的本地线程号是十六进制的，转换一下，就能定位到占用CPU高的线程的当前线程堆栈了 ","slug":"线上问题排查","published":1,"updated":"2018-09-12T03:03:21.834Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnf00011wlkvn4l848kr"},{"title":"hbase中HFile详解","date":"2017-09-13T16:10:14.000Z","_content":"\n# hbase中HFile详解\n\nHBase中KeyValue数据的存储格式，是Hadoop的二进制格式文件，有固定的结构。实际上StoreFile就是对HFile做了轻量级包装，即StoreFile底层就是HFile\n\n## HFile的物理结构\n\n**HFile逻辑结构**\n\nHFile V2的逻辑结构如下图所示：\n\n![1](http://omdq6di7v.bkt.clouddn.com/17-9-19/84269403.jpg)\n\n文件主要分为四个部分：Scanned block section，Non-scanned block section，Opening-time data section和Trailer。\n\nScanned block section：顾名思义，表示顺序扫描HFile时所有的数据块将会被读取，包括Leaf Index Block和Bloom Block。\n\nNon-scanned block section：表示在HFile顺序扫描的时候数据不会被读取，主要包括Meta Block和Intermediate Level Data Index Blocks两部分。\n\nLoad-on-open-section：这部分数据在HBase的region server启动时，需要加载到内存中。包括FileInfo、Bloom filter block、data block index和meta block index。\n\nTrailer：这部分主要记录了HFile的基本信息、各个部分的偏移值和寻址信息。\n\n**HFile物理结构**\n\n**![2](http://omdq6di7v.bkt.clouddn.com/17-9-19/56042852.jpg)**\n\n如上图所示， HFile会被切分为多个大小相等的block块，每个block的大小可以在创建表列簇的时候通过参数blocksize ＝> ‘65535’进行指定，默认为64k，**大号的Block有利于顺序Scan，小号Block利于随机查询**，因而需要权衡。而且所有block块都拥有相同的数据结构，如图左侧所示，HBase将block块抽象为一个统一的HFileBlock。HFileBlock支持两种类型，一种类型不支持checksum，一种不支持。为方便讲解，下图选用不支持checksum的HFileBlock内部结构：\n\n![3](http://omdq6di7v.bkt.clouddn.com/17-9-19/84308271.jpg)\n\n上图所示HFileBlock主要包括两部分：BlockHeader和BlockData。其中BlockHeader主要存储block元数据，BlockData用来存储具体数据。block元数据中最核心的字段是BlockType字段，用来标示该block块的类型，HBase中定义了8种BlockType，每种BlockType对应的block都存储不同的数据内容，有的存储用户数据，有的存储索引数据，有的存储meta元数据。对于任意一种类型的HFileBlock，都拥有相同结构的BlockHeader，但是BlockData结构却不相同。下面通过一张表简单罗列最核心的几种BlockType，下文会详细针对每种BlockType进行详细的讲解：\n\n![4](http://omdq6di7v.bkt.clouddn.com/17-9-19/64479165.jpg)\n\n**HFile中Block块解析**\n\n上文从HFile的层面将文件切分成了多种类型的block，接下来针对几种重要block进行详细的介绍，因为篇幅的原因，索引相关的block不会在本文进行介绍，接下来会写一篇单独的文章对其进行分析和讲解。首先会介绍记录HFile基本信息的TrailerBlock，再介绍用户数据的实际存储块DataBlock，最后简单介绍布隆过滤器相关的block。\n\n**Trailer Block **\n\n主要记录了HFile的基本信息、各个部分的偏移值和寻址信息，下图为Trailer内存和磁盘中的数据结构，其中只显示了部分核心字段：\n\n![5](http://omdq6di7v.bkt.clouddn.com/17-9-19/21019813.jpg)\n\nHFile在读取的时候首先会解析Trailer Block并加载到内存，然后再进一步加载LoadOnOpen区的数据，具体步骤如下：\n\n1. 首先加载version版本信息，HBase中version包含majorVersion和minorVersion两部分，前者决定了HFile的主版本： V1、V2 还是V3；后者在主版本确定的基础上决定是否支持一些微小修正，比如是否支持checksum等。不同的版本决定了使用不同的Reader对象对HFile进行读取解析\n2. 根据Version信息获取trailer的长度（不同version的trailer长度不同），再根据trailer长度加载整个HFileTrailer Block\n3. 最后加载load-on-open部分到内存中，起始偏移地址是trailer中的LoadOnOpenDataOffset字段，load-on-open部分的结束偏移量为HFile长度减去Trailer长度，load-on-open部分主要包括索引树的根节点以及FileInfo两个重要模块，FileInfo是固定长度的块，它纪录了文件的一些Meta信息，例如：AVG_KEY_LEN, AVG_VALUE_LEN, LAST_KEY, COMPARATOR, MAX_SEQ_ID_KEY等；索引树根节点放到下一篇文章进行介绍。\n\n**Data Block**\n\nDataBlock是HBase中数据存储的最小单元，默认大小为64k。Data 块是HBase I/O的基本单元，访问的时候会加载整个块到内存中，查找数据时顺序的遍历该块中的keyValue对。\n\n**如果业务请求以Get请求为主，可以考虑将块大小设置较小；如果以Scan请求为主，可以将块大小调大；默认的64K块大小是在Scan和Get之间取得的一个平衡。**\n\n通常对Data块采用压缩方式存储，压缩之后可以大大减少网络IO和磁盘IO，随之而来的开销当然是需要花费cpu进行压缩和解压缩,cpu往往比磁盘传输要快,支持两种压缩方式：Gzip，Lzo，Snappy(最优)\n\nDataBlock中主要存储用户的KeyValue数据（KeyValue后面一般会跟一个timestamp，图中未标出），而KeyValue结构是HBase存储的核心，每个数据都是以KeyValue结构在HBase中进行存储。KeyValue结构在内存和磁盘中可以表示为：\n\n![6](http://omdq6di7v.bkt.clouddn.com/17-9-19/8752401.jpg)\n\n每个KeyValue都由4个部分构成，分别为key length，value length，key和value。其中key value和value length是两个固定长度的数值，而key是一个复杂的结构，首先是rowkey的长度，接着是rowkey，然后是ColumnFamily的长度，再是ColumnFamily，最后是时间戳和KeyType（keytype有四种类型，分别是Put、Delete、 DeleteColumn和DeleteFamily），value就没有那么复杂，就是一串纯粹的二进制数据。\n\n**BloomFilter Meta Block & Bloom Block**\n\nBloomFilter对于HBase的随机读性能至关重要，对于get操作以及部分scan操作可以剔除掉不会用到的HFile文件，减少实际IO次数，提高随机读性能。在此简单地介绍一下Bloom Filter的工作原理，Bloom Filter使用位数组来实现过滤，初始状态下位数组每一位都为0，如下图所示：\n\n![7](http://omdq6di7v.bkt.clouddn.com/17-9-19/14078567.jpg)\n\n假如此时有一个集合S = {x1, x2, … xn}，Bloom Filter使用k个独立的hash函数，分别将集合中的每一个元素映射到｛1,…,m｝的范围。对于任何一个元素，被映射到的数字作为对应的位数组的索引，该位会被置为1。比如元素x1被hash函数映射到数字8，那么位数组的第8位就会被置为1。下图中集合S只有两个元素x和y，分别被3个hash函数进行映射，映射到的位置分别为（0，2，6）和（4，7，10），对应的位会被置为1:\n\n![8](http://omdq6di7v.bkt.clouddn.com/17-9-19/40774801.jpg)\n\n现在假如要判断另一个元素是否是在此集合中，只需要被这3个hash函数进行映射，查看对应的位置是否有0存在，如果有的话，表示此元素肯定不存在于这个集合，否则有可能存在。下图所示就表示z肯定不在集合｛x，y｝中：\n\n![9](http://omdq6di7v.bkt.clouddn.com/17-9-19/2549118.jpg)\n\nHBase中每个HFile都有对应的位数组，KeyValue在写入HFile时会先经过几个hash函数的映射，映射后将对应的数组位改为1，get请求进来之后再进行hash映射，如果在对应数组位上存在0，说明该get请求查询的数据不在该HFile中。\n\nHFile中的位数组就是上述Bloom Block中存储的值，可以想象，一个HFile文件越大，里面存储的KeyValue值越多，位数组就会相应越大。一旦太大就不适合直接加载到内存了，因此HFile V2在设计上将位数组进行了拆分，拆成了多个独立的位数组（根据Key进行拆分，一部分连续的Key使用一个位数组）。这样一个HFile中就会包含多个位数组，根据Key进行查询，首先会定位到具体的某个位数组，只需要加载此位数组到内存进行过滤即可，减少了内存开支。\n\n在结构上每个位数组对应HFile中一个Bloom Block，为了方便根据Key定位具体需要加载哪个位数组，HFile V2又设计了对应的索引Bloom Index Block，对应的内存和逻辑结构图如下：\n\n![10](http://omdq6di7v.bkt.clouddn.com/17-9-19/22197798.jpg)\n\nBloom Index Block结构中totalByteSize表示位数组的bit数，numChunks表示Bloom Block的个数，hashCount表示hash函数的个数，hashType表示hash函数的类型，totalKeyCount表示bloom filter当前已经包含的key的数目，totalMaxKeys表示bloom filter当前最多包含的key的数目, Bloom Index Entry对应每一个bloom filter block的索引条目，作为索引分别指向’scanned block section’部分的Bloom Block，Bloom Block中就存储了对应的位数组。\n\nBloom Index Entry的结构见上图左边所示，BlockOffset表示对应Bloom Block在HFile中的偏移量，FirstKey表示对应BloomBlock的第一个Key。根据上文所说，一次get请求进来，首先会根据key在所有的索引条目中进行二分查找，查找到对应的Bloom Index Entry，就可以定位到该key对应的位数组，加载到内存进行过滤判断。\n\n**总结**\n\n这篇小文首先从宏观的层面对HFile的逻辑结构和物理存储结构进行了讲解，并且将HFile从逻辑上分解为各种类型的Block，再接着从微观的视角分别对Trailer Block、Data Block在结构上进行了解析：通过对trailer block的解析，可以获取hfile的版本以及hfile中其他几个部分的偏移量，在读取的时候可以直接通过偏移量对其进行加载；而对data block的解析可以知道用户数据在hdfs中是如何实际存储的；最后通过介绍Bloom Filter的工作原理以及相关的Block块了解HFile中Bloom Filter的存储结构。接下来会以本文为基础，再写一篇文章分析HFile中索引块的结构以及相应的索引机制。\n\n## HFile索引机制\n\n**HFile索引结构解析**\n\nHFile中索引结构根据索引层级的不同分为两种：single-level和mutil-level，前者表示单层索引，后者表示多级索引，一般为两级或三级。HFile V1版本中只有single-level一种索引结构，V2版本中引入多级索引。之所以引入多级索引，是因为随着HFile文件越来越大，Data Block越来越多，索引数据也越来越大，已经无法全部加载到内存中（V1版本中一个Region Server的索引数据加载到内存会占用几乎6G空间），多级索引可以只加载部分索引，降低内存使用空间。Bloom Filter内存使用问题是促使V1版本升级到V2版本的一个原因，再加上这个原因，这两个原因就是V1版本升级到V2版本最重要的两个因素。\n\nV2版本Index Block有两类：Root Index Block和NonRoot Index Block，其中NonRoot Index Block又分为Intermediate Index Block和Leaf Index Block两种。HFile中索引结构类似于一棵树，Root Index Block表示索引数根节点，Intermediate Index Block表示中间节点，Leaf Index block表示叶子节点，叶子节点直接指向实际数据块。\n\nHFile中除了Data Block需要索引之外，上一篇文章提到过Bloom Block也需要索引，索引结构实际上就是采用了single-level结构，文中Bloom Index Block就是一种Root Index Block。\n\n对于Data Block，由于HFile刚开始数据量较小，索引采用single-level结构，只有Root Index一层索引，直接指向数据块。当数据量慢慢变大，Root Index Block满了之后，索引就会变为mutil-level结构，由一层索引变为两层，根节点指向叶子节点，叶子节点指向实际数据块。如果数据量再变大，索引层级就会变为三层。\n\n下面就针对Root index Block和NonRoot index Block两种结构进行解析，因为Root Index Block已经在上面一篇文章中分析过，此处简单带过，重点介绍NonRoot Index Block结构（InterMediate Index Block和Ieaf Index Block在内存和磁盘中存储格式相同，都为NonRoot Index Block格式）。\n\n**Root Index Block**\n\nRoot Index Block表示索引树根节点索引块，可以作为bloom的直接索引，也可以作为data索引的根索引。而且对于single-level和mutil-level两种索引结构对应的Root Index Block略有不同，本文以mutil-level索引结构为例进行分析（single-level索引结构是mutual-level的一种简化场景），在内存和磁盘中的格式如下图所示：\n\n![22](http://omdq6di7v.bkt.clouddn.com/17-9-19/39022390.jpg)\n\n其中Index Entry表示具体的索引对象，每个索引对象由3个字段组成，Block Offset表示索引指向数据块的偏移量，BlockDataSize表示索引指向数据块在磁盘上的大小，BlockKey表示索引指向数据块中的第一个key。除此之外，还有另外3个字段用来记录MidKey的相关信息，MidKey表示HFile所有Data Block中中间的一个Data Block，用于在对HFile进行split操作时，快速定位HFile的中间位置。需要注意的是single-level索引结构和mutil-level结构相比，就只缺少MidKey这三个字段。\n\nRoot Index Block会在HFile解析的时候直接加载到内存中，此处需要注意在Trailer Block中有一个字段为dataIndexCount，就表示此处Index Entry的个数。因为Index Entry并不定长，只有知道Entry的个数才能正确的将所有Index Entry加载到内存。\n\n**NonRoot Index Block**\n\n当HFile中Data Block越来越多，single-level结构的索引已经不足以支撑所有数据都加载到内存，需要分化为mutil-level结构。mutil-level结构中NonRoot Index Block作为中间层节点或者叶子节点存在，无论是中间节点还是叶子节点，其都拥有相同的结构，如下图所示：\n\n![23](http://omdq6di7v.bkt.clouddn.com/17-9-19/29023829.jpg)\n\n和Root Index Block相同，NonRoot Index Block中最核心的字段也是Index Entry，用于指向叶子节点块或者数据块。不同的是，NonRoot Index Block结构中增加了block块的内部索引entry Offset字段，entry Offset表示index Entry在该block中的相对偏移量（相对于第一个index Entry)，用于实现block内的二分查找。所有非根节点索引块，包括Intermediate index block和leaf index block，在其内部定位一个key的具体索引并不是通过遍历实现，而是使用二分查找算法，这样可以更加高效快速地定位到待查找key。\n\n**HFile数据完整索引流程**\n\n了解了HFile中数据索引块的两种结构之后，就来看看如何使用这些索引数据块进行数据的高效检索。整个索引体系类似于MySQL的B+树结构，但是又有所不同，比B+树简单，并没有复杂的分裂操作。具体见下图所示：\n\n![24](http://omdq6di7v.bkt.clouddn.com/17-9-19/12082475.jpg)\n\n图中上面三层为索引层，在数据量不大的时候只有最上面一层，数据量大了之后开始分裂为多层，最多三层，如图所示。最下面一层为数据层，存储用户的实际keyvalue数据。这个索引树结构类似于InnoSQL的聚集索引，只是HBase并没有辅助索引的概念。\n\n图中红线表示一次查询的索引过程（HBase中相关类为HFileBlockIndex和HFileReaderV2），基本流程可以表示为：\n\n1. 用户输入rowkey为fb，在root index block中通过二分查找定位到fb在’a’和’m’之间，因此需要访问索引’a’指向的中间节点。因为root index block常驻内存，所以这个过程很快。\n2. 将索引’a’指向的中间节点索引块加载到内存，然后通过二分查找定位到fb在index ‘d’和’h’之间，接下来访问索引’d’指向的叶子节点。\n3. 同理，将索引’d’指向的中间节点索引块加载到内存，一样通过二分查找定位找到fb在index ‘f’和’g’之间，最后需要访问索引’f’指向的数据块节点。\n4. 将索引’f’指向的数据块加载到内存，通过遍历的方式找到对应的keyvalue。\n\n上述流程中因为中间节点、叶子节点和数据块都需要加载到内存，所以io次数正常为3次。但是实际上HBase为block提供了缓存机制，可以将频繁使用的block缓存在内存中，可以进一步加快实际读取过程。所以，在HBase中，通常一次随机读请求最多会产生3次io，如果数据量小（只有一层索引），数据已经缓存到了内存，就不会产生io。\n\n**索引块分裂**\n\n上文中已经提到，当数据量少、文件小的时候，只需要一个root index block就可以完成索引，即索引树只有一层。当数据不断写入，文件变大之后，索引数据也会相应变大，索引结构就会由single-level变为mulit-level，期间涉及到索引块的写入和分裂，本节来关注一下数据写入是如何引起索引块分裂的。\n\n如果大家之前看过HBase系列另一篇博文[《HBase数据写入之Memstore Flush》](http://hbasefly.com/2016/03/23/hbase-memstore-flush/)，可以知道memstore flush主要分为3个阶段，第一个阶段会讲memstore中的keyvalue数据snapshot，第二阶段再将这部分数据flush的HFile，并生成在临时目录，第三阶段将临时文件移动到指定的ColumnFamily目录下。很显然，第二阶段将keyvalue数据flush到HFile将会是关注的重点（flush相关代码在DefaultStoreFlusher类中）。整个flush阶段又可以分为两阶段：\n\n1. append阶段：memstore中keyvalue首先会写入到HFile中数据块\n\n2. finalize阶段：修改HFlie中meta元数据块，索引数据块以及Trailer数据块等\n\n**append流程**\n\n具体keyvalue数据的append以及finalize过程在HFileWriterV2文件中，其中append流程可以大体表征为：\n\n![25](http://omdq6di7v.bkt.clouddn.com/17-9-19/76049260.jpg)\n\na. 预检查：检查key的大小是否大于前一个key，如果大于则不符合HBase顺序排列的原理，抛出异常；检查value是否是null，如果为null也抛出异常\n\nb. block是否写满：检查当前Data Block是否已经写满，如果没有写满就直接写入keyvalue；否则就需要执行数据块落盘以及索引块修改操作；\n\nc. 数据落盘并修改索引：如果DataBlock写满，首先将block块写入流；再生成一个leaf index entry，写入leaf Index block；再检查该leaf index block是否已经写满需要落盘，如果已经写满，就将该leaf index block写入到输出流，并且为索引树根节点root index block新增一个索引，指向叶子节点(second-level index)\n\nd. 生成一个新的block：重新reset输出流，初始化startOffset为-1\n\ne. 写入keyvalue：将keyvalue以流的方式写入输出流，同时需要写入memstoreTS；除此之外，如果该key是当前block的第一个key，需要赋值给变量firstKeyInBlock\n\n**finalize阶段**\n\nmemstore中所有keyvalue都经过append阶段输出到HFile后，会执行一次finalize过程，主要更新HFile中meta元数据块、索引数据块以及Trailer数据块，其中对索引数据块的更新是我们关心的重点，此处详细解析，上述append流程中c步骤’数据落盘并修改索引’会使得root index block不断增多，当增大到一定程度之后就需要分裂，分裂示意图如下图所示：\n\n![26](http://omdq6di7v.bkt.clouddn.com/17-9-19/3817222.jpg)\n\n上图所示，分裂前索引结构为second-level结构，图中没有画出Data Blocks，根节点索引指向叶子节点索引块。finalize阶段系统会对Root Index Block进行大小检查，如果大小大于规定的大小就需要进行分裂，图中分裂过程实际上就是将原来的Root Index Block块分割成4块，每块独立形成中间节点InterMediate Index Block，系统再重新生成一个Root Index Block（图中红色部分），分别指向分割形成的4个interMediate Index Block。此时索引结构就变成了third-level结构。\n\n**总结**\n\n这篇文章是HFile结构解析的第二篇文章，主要集中介绍HFile中的数据索引块。首先分Root Index Block和NonRoot Index Block两部分对HFile中索引块进行了解析，紧接着基于此介绍了HBase如何使用索引对数据进行检索，最后结合Memstore Flush的相关知识分析了keyvalue数据写入的过程中索引块的分裂过程。希望通过这两篇文章的介绍，能够对HBase中数据存储文件HFile有一个更加全面深入的认识。\n\n## 怎样从一系列的HFile中找到某个rowkey?\n\n​     如果创建表时，指定了booleamFilter，那么就根据booleamFilter快速的判断该rowkey是否在这个HFile中。\n\n​     如果没有定义booleamFilter，hbase在查找先会根据时间戳或者查询列的信息来进行过滤，过滤掉那些肯定不含有所需数据的storefile或者memstore，尽量把我们的查询目标范围缩小。\n\n​     尽管缩小了，但仍可能会有多个文件需要扫描的。storefile的内部有序的，但是各个storefile之间并不是有序的。storefile的rowkey的范围很有可能有交叉。所以查询数据的过程也不可能是对storefile的顺序查找。\nhbase会首先查看每个storefile的最小的rowkey，然后按照从小到大的顺序进行排序，结果放到一个队列中，排序的算法就是按照hbase的三维顺序，按照rowkey，column，ts进行排序，rowkey和column是升序，而ts是降序。\n实际上并不是所有满足时间戳和列过滤的文件都会加到这个队列中，hbase会首先对各个storefile中的数据进行探测，只会扫描扫描那些存在比当前查询的rowkey大的记录的storefile。\n​    下面开始查询数据，整个过程用到了类似归并排序的算法，首先通过poll取出队列的头storefile，会从storefile读取一条记录返回；接下来呢，该storefile的下条记录并不一定是查询结果的下一条记录，因为队列的比较顺序是比较的每个storefile的第一条符合要求的rowkey。所以，hbase会继续从队列中剩下的storefile取第一条记录，把该记录与头storefile的第二条记录做比较，如果前者大，那么返回头storefile的第二条记录；如果后者大，则会把头storefile放回队列重新排序，在重新取队列的头storefile。然后重复上面的整个过程，直到找到key所在的HFile。范围缩小到该HFile后，就根据上面介绍的索引查找定位到块，快速的找到对应的记录。","source":"_posts/hbase/hbase中HFile详解.md","raw":"---\ntitle: hbase中HFile详解\ndate: 2017-09-14 00:10:14\ntags:\n- hbase\ncategories:\n- 大数据\n---\n\n# hbase中HFile详解\n\nHBase中KeyValue数据的存储格式，是Hadoop的二进制格式文件，有固定的结构。实际上StoreFile就是对HFile做了轻量级包装，即StoreFile底层就是HFile\n\n## HFile的物理结构\n\n**HFile逻辑结构**\n\nHFile V2的逻辑结构如下图所示：\n\n![1](http://omdq6di7v.bkt.clouddn.com/17-9-19/84269403.jpg)\n\n文件主要分为四个部分：Scanned block section，Non-scanned block section，Opening-time data section和Trailer。\n\nScanned block section：顾名思义，表示顺序扫描HFile时所有的数据块将会被读取，包括Leaf Index Block和Bloom Block。\n\nNon-scanned block section：表示在HFile顺序扫描的时候数据不会被读取，主要包括Meta Block和Intermediate Level Data Index Blocks两部分。\n\nLoad-on-open-section：这部分数据在HBase的region server启动时，需要加载到内存中。包括FileInfo、Bloom filter block、data block index和meta block index。\n\nTrailer：这部分主要记录了HFile的基本信息、各个部分的偏移值和寻址信息。\n\n**HFile物理结构**\n\n**![2](http://omdq6di7v.bkt.clouddn.com/17-9-19/56042852.jpg)**\n\n如上图所示， HFile会被切分为多个大小相等的block块，每个block的大小可以在创建表列簇的时候通过参数blocksize ＝> ‘65535’进行指定，默认为64k，**大号的Block有利于顺序Scan，小号Block利于随机查询**，因而需要权衡。而且所有block块都拥有相同的数据结构，如图左侧所示，HBase将block块抽象为一个统一的HFileBlock。HFileBlock支持两种类型，一种类型不支持checksum，一种不支持。为方便讲解，下图选用不支持checksum的HFileBlock内部结构：\n\n![3](http://omdq6di7v.bkt.clouddn.com/17-9-19/84308271.jpg)\n\n上图所示HFileBlock主要包括两部分：BlockHeader和BlockData。其中BlockHeader主要存储block元数据，BlockData用来存储具体数据。block元数据中最核心的字段是BlockType字段，用来标示该block块的类型，HBase中定义了8种BlockType，每种BlockType对应的block都存储不同的数据内容，有的存储用户数据，有的存储索引数据，有的存储meta元数据。对于任意一种类型的HFileBlock，都拥有相同结构的BlockHeader，但是BlockData结构却不相同。下面通过一张表简单罗列最核心的几种BlockType，下文会详细针对每种BlockType进行详细的讲解：\n\n![4](http://omdq6di7v.bkt.clouddn.com/17-9-19/64479165.jpg)\n\n**HFile中Block块解析**\n\n上文从HFile的层面将文件切分成了多种类型的block，接下来针对几种重要block进行详细的介绍，因为篇幅的原因，索引相关的block不会在本文进行介绍，接下来会写一篇单独的文章对其进行分析和讲解。首先会介绍记录HFile基本信息的TrailerBlock，再介绍用户数据的实际存储块DataBlock，最后简单介绍布隆过滤器相关的block。\n\n**Trailer Block **\n\n主要记录了HFile的基本信息、各个部分的偏移值和寻址信息，下图为Trailer内存和磁盘中的数据结构，其中只显示了部分核心字段：\n\n![5](http://omdq6di7v.bkt.clouddn.com/17-9-19/21019813.jpg)\n\nHFile在读取的时候首先会解析Trailer Block并加载到内存，然后再进一步加载LoadOnOpen区的数据，具体步骤如下：\n\n1. 首先加载version版本信息，HBase中version包含majorVersion和minorVersion两部分，前者决定了HFile的主版本： V1、V2 还是V3；后者在主版本确定的基础上决定是否支持一些微小修正，比如是否支持checksum等。不同的版本决定了使用不同的Reader对象对HFile进行读取解析\n2. 根据Version信息获取trailer的长度（不同version的trailer长度不同），再根据trailer长度加载整个HFileTrailer Block\n3. 最后加载load-on-open部分到内存中，起始偏移地址是trailer中的LoadOnOpenDataOffset字段，load-on-open部分的结束偏移量为HFile长度减去Trailer长度，load-on-open部分主要包括索引树的根节点以及FileInfo两个重要模块，FileInfo是固定长度的块，它纪录了文件的一些Meta信息，例如：AVG_KEY_LEN, AVG_VALUE_LEN, LAST_KEY, COMPARATOR, MAX_SEQ_ID_KEY等；索引树根节点放到下一篇文章进行介绍。\n\n**Data Block**\n\nDataBlock是HBase中数据存储的最小单元，默认大小为64k。Data 块是HBase I/O的基本单元，访问的时候会加载整个块到内存中，查找数据时顺序的遍历该块中的keyValue对。\n\n**如果业务请求以Get请求为主，可以考虑将块大小设置较小；如果以Scan请求为主，可以将块大小调大；默认的64K块大小是在Scan和Get之间取得的一个平衡。**\n\n通常对Data块采用压缩方式存储，压缩之后可以大大减少网络IO和磁盘IO，随之而来的开销当然是需要花费cpu进行压缩和解压缩,cpu往往比磁盘传输要快,支持两种压缩方式：Gzip，Lzo，Snappy(最优)\n\nDataBlock中主要存储用户的KeyValue数据（KeyValue后面一般会跟一个timestamp，图中未标出），而KeyValue结构是HBase存储的核心，每个数据都是以KeyValue结构在HBase中进行存储。KeyValue结构在内存和磁盘中可以表示为：\n\n![6](http://omdq6di7v.bkt.clouddn.com/17-9-19/8752401.jpg)\n\n每个KeyValue都由4个部分构成，分别为key length，value length，key和value。其中key value和value length是两个固定长度的数值，而key是一个复杂的结构，首先是rowkey的长度，接着是rowkey，然后是ColumnFamily的长度，再是ColumnFamily，最后是时间戳和KeyType（keytype有四种类型，分别是Put、Delete、 DeleteColumn和DeleteFamily），value就没有那么复杂，就是一串纯粹的二进制数据。\n\n**BloomFilter Meta Block & Bloom Block**\n\nBloomFilter对于HBase的随机读性能至关重要，对于get操作以及部分scan操作可以剔除掉不会用到的HFile文件，减少实际IO次数，提高随机读性能。在此简单地介绍一下Bloom Filter的工作原理，Bloom Filter使用位数组来实现过滤，初始状态下位数组每一位都为0，如下图所示：\n\n![7](http://omdq6di7v.bkt.clouddn.com/17-9-19/14078567.jpg)\n\n假如此时有一个集合S = {x1, x2, … xn}，Bloom Filter使用k个独立的hash函数，分别将集合中的每一个元素映射到｛1,…,m｝的范围。对于任何一个元素，被映射到的数字作为对应的位数组的索引，该位会被置为1。比如元素x1被hash函数映射到数字8，那么位数组的第8位就会被置为1。下图中集合S只有两个元素x和y，分别被3个hash函数进行映射，映射到的位置分别为（0，2，6）和（4，7，10），对应的位会被置为1:\n\n![8](http://omdq6di7v.bkt.clouddn.com/17-9-19/40774801.jpg)\n\n现在假如要判断另一个元素是否是在此集合中，只需要被这3个hash函数进行映射，查看对应的位置是否有0存在，如果有的话，表示此元素肯定不存在于这个集合，否则有可能存在。下图所示就表示z肯定不在集合｛x，y｝中：\n\n![9](http://omdq6di7v.bkt.clouddn.com/17-9-19/2549118.jpg)\n\nHBase中每个HFile都有对应的位数组，KeyValue在写入HFile时会先经过几个hash函数的映射，映射后将对应的数组位改为1，get请求进来之后再进行hash映射，如果在对应数组位上存在0，说明该get请求查询的数据不在该HFile中。\n\nHFile中的位数组就是上述Bloom Block中存储的值，可以想象，一个HFile文件越大，里面存储的KeyValue值越多，位数组就会相应越大。一旦太大就不适合直接加载到内存了，因此HFile V2在设计上将位数组进行了拆分，拆成了多个独立的位数组（根据Key进行拆分，一部分连续的Key使用一个位数组）。这样一个HFile中就会包含多个位数组，根据Key进行查询，首先会定位到具体的某个位数组，只需要加载此位数组到内存进行过滤即可，减少了内存开支。\n\n在结构上每个位数组对应HFile中一个Bloom Block，为了方便根据Key定位具体需要加载哪个位数组，HFile V2又设计了对应的索引Bloom Index Block，对应的内存和逻辑结构图如下：\n\n![10](http://omdq6di7v.bkt.clouddn.com/17-9-19/22197798.jpg)\n\nBloom Index Block结构中totalByteSize表示位数组的bit数，numChunks表示Bloom Block的个数，hashCount表示hash函数的个数，hashType表示hash函数的类型，totalKeyCount表示bloom filter当前已经包含的key的数目，totalMaxKeys表示bloom filter当前最多包含的key的数目, Bloom Index Entry对应每一个bloom filter block的索引条目，作为索引分别指向’scanned block section’部分的Bloom Block，Bloom Block中就存储了对应的位数组。\n\nBloom Index Entry的结构见上图左边所示，BlockOffset表示对应Bloom Block在HFile中的偏移量，FirstKey表示对应BloomBlock的第一个Key。根据上文所说，一次get请求进来，首先会根据key在所有的索引条目中进行二分查找，查找到对应的Bloom Index Entry，就可以定位到该key对应的位数组，加载到内存进行过滤判断。\n\n**总结**\n\n这篇小文首先从宏观的层面对HFile的逻辑结构和物理存储结构进行了讲解，并且将HFile从逻辑上分解为各种类型的Block，再接着从微观的视角分别对Trailer Block、Data Block在结构上进行了解析：通过对trailer block的解析，可以获取hfile的版本以及hfile中其他几个部分的偏移量，在读取的时候可以直接通过偏移量对其进行加载；而对data block的解析可以知道用户数据在hdfs中是如何实际存储的；最后通过介绍Bloom Filter的工作原理以及相关的Block块了解HFile中Bloom Filter的存储结构。接下来会以本文为基础，再写一篇文章分析HFile中索引块的结构以及相应的索引机制。\n\n## HFile索引机制\n\n**HFile索引结构解析**\n\nHFile中索引结构根据索引层级的不同分为两种：single-level和mutil-level，前者表示单层索引，后者表示多级索引，一般为两级或三级。HFile V1版本中只有single-level一种索引结构，V2版本中引入多级索引。之所以引入多级索引，是因为随着HFile文件越来越大，Data Block越来越多，索引数据也越来越大，已经无法全部加载到内存中（V1版本中一个Region Server的索引数据加载到内存会占用几乎6G空间），多级索引可以只加载部分索引，降低内存使用空间。Bloom Filter内存使用问题是促使V1版本升级到V2版本的一个原因，再加上这个原因，这两个原因就是V1版本升级到V2版本最重要的两个因素。\n\nV2版本Index Block有两类：Root Index Block和NonRoot Index Block，其中NonRoot Index Block又分为Intermediate Index Block和Leaf Index Block两种。HFile中索引结构类似于一棵树，Root Index Block表示索引数根节点，Intermediate Index Block表示中间节点，Leaf Index block表示叶子节点，叶子节点直接指向实际数据块。\n\nHFile中除了Data Block需要索引之外，上一篇文章提到过Bloom Block也需要索引，索引结构实际上就是采用了single-level结构，文中Bloom Index Block就是一种Root Index Block。\n\n对于Data Block，由于HFile刚开始数据量较小，索引采用single-level结构，只有Root Index一层索引，直接指向数据块。当数据量慢慢变大，Root Index Block满了之后，索引就会变为mutil-level结构，由一层索引变为两层，根节点指向叶子节点，叶子节点指向实际数据块。如果数据量再变大，索引层级就会变为三层。\n\n下面就针对Root index Block和NonRoot index Block两种结构进行解析，因为Root Index Block已经在上面一篇文章中分析过，此处简单带过，重点介绍NonRoot Index Block结构（InterMediate Index Block和Ieaf Index Block在内存和磁盘中存储格式相同，都为NonRoot Index Block格式）。\n\n**Root Index Block**\n\nRoot Index Block表示索引树根节点索引块，可以作为bloom的直接索引，也可以作为data索引的根索引。而且对于single-level和mutil-level两种索引结构对应的Root Index Block略有不同，本文以mutil-level索引结构为例进行分析（single-level索引结构是mutual-level的一种简化场景），在内存和磁盘中的格式如下图所示：\n\n![22](http://omdq6di7v.bkt.clouddn.com/17-9-19/39022390.jpg)\n\n其中Index Entry表示具体的索引对象，每个索引对象由3个字段组成，Block Offset表示索引指向数据块的偏移量，BlockDataSize表示索引指向数据块在磁盘上的大小，BlockKey表示索引指向数据块中的第一个key。除此之外，还有另外3个字段用来记录MidKey的相关信息，MidKey表示HFile所有Data Block中中间的一个Data Block，用于在对HFile进行split操作时，快速定位HFile的中间位置。需要注意的是single-level索引结构和mutil-level结构相比，就只缺少MidKey这三个字段。\n\nRoot Index Block会在HFile解析的时候直接加载到内存中，此处需要注意在Trailer Block中有一个字段为dataIndexCount，就表示此处Index Entry的个数。因为Index Entry并不定长，只有知道Entry的个数才能正确的将所有Index Entry加载到内存。\n\n**NonRoot Index Block**\n\n当HFile中Data Block越来越多，single-level结构的索引已经不足以支撑所有数据都加载到内存，需要分化为mutil-level结构。mutil-level结构中NonRoot Index Block作为中间层节点或者叶子节点存在，无论是中间节点还是叶子节点，其都拥有相同的结构，如下图所示：\n\n![23](http://omdq6di7v.bkt.clouddn.com/17-9-19/29023829.jpg)\n\n和Root Index Block相同，NonRoot Index Block中最核心的字段也是Index Entry，用于指向叶子节点块或者数据块。不同的是，NonRoot Index Block结构中增加了block块的内部索引entry Offset字段，entry Offset表示index Entry在该block中的相对偏移量（相对于第一个index Entry)，用于实现block内的二分查找。所有非根节点索引块，包括Intermediate index block和leaf index block，在其内部定位一个key的具体索引并不是通过遍历实现，而是使用二分查找算法，这样可以更加高效快速地定位到待查找key。\n\n**HFile数据完整索引流程**\n\n了解了HFile中数据索引块的两种结构之后，就来看看如何使用这些索引数据块进行数据的高效检索。整个索引体系类似于MySQL的B+树结构，但是又有所不同，比B+树简单，并没有复杂的分裂操作。具体见下图所示：\n\n![24](http://omdq6di7v.bkt.clouddn.com/17-9-19/12082475.jpg)\n\n图中上面三层为索引层，在数据量不大的时候只有最上面一层，数据量大了之后开始分裂为多层，最多三层，如图所示。最下面一层为数据层，存储用户的实际keyvalue数据。这个索引树结构类似于InnoSQL的聚集索引，只是HBase并没有辅助索引的概念。\n\n图中红线表示一次查询的索引过程（HBase中相关类为HFileBlockIndex和HFileReaderV2），基本流程可以表示为：\n\n1. 用户输入rowkey为fb，在root index block中通过二分查找定位到fb在’a’和’m’之间，因此需要访问索引’a’指向的中间节点。因为root index block常驻内存，所以这个过程很快。\n2. 将索引’a’指向的中间节点索引块加载到内存，然后通过二分查找定位到fb在index ‘d’和’h’之间，接下来访问索引’d’指向的叶子节点。\n3. 同理，将索引’d’指向的中间节点索引块加载到内存，一样通过二分查找定位找到fb在index ‘f’和’g’之间，最后需要访问索引’f’指向的数据块节点。\n4. 将索引’f’指向的数据块加载到内存，通过遍历的方式找到对应的keyvalue。\n\n上述流程中因为中间节点、叶子节点和数据块都需要加载到内存，所以io次数正常为3次。但是实际上HBase为block提供了缓存机制，可以将频繁使用的block缓存在内存中，可以进一步加快实际读取过程。所以，在HBase中，通常一次随机读请求最多会产生3次io，如果数据量小（只有一层索引），数据已经缓存到了内存，就不会产生io。\n\n**索引块分裂**\n\n上文中已经提到，当数据量少、文件小的时候，只需要一个root index block就可以完成索引，即索引树只有一层。当数据不断写入，文件变大之后，索引数据也会相应变大，索引结构就会由single-level变为mulit-level，期间涉及到索引块的写入和分裂，本节来关注一下数据写入是如何引起索引块分裂的。\n\n如果大家之前看过HBase系列另一篇博文[《HBase数据写入之Memstore Flush》](http://hbasefly.com/2016/03/23/hbase-memstore-flush/)，可以知道memstore flush主要分为3个阶段，第一个阶段会讲memstore中的keyvalue数据snapshot，第二阶段再将这部分数据flush的HFile，并生成在临时目录，第三阶段将临时文件移动到指定的ColumnFamily目录下。很显然，第二阶段将keyvalue数据flush到HFile将会是关注的重点（flush相关代码在DefaultStoreFlusher类中）。整个flush阶段又可以分为两阶段：\n\n1. append阶段：memstore中keyvalue首先会写入到HFile中数据块\n\n2. finalize阶段：修改HFlie中meta元数据块，索引数据块以及Trailer数据块等\n\n**append流程**\n\n具体keyvalue数据的append以及finalize过程在HFileWriterV2文件中，其中append流程可以大体表征为：\n\n![25](http://omdq6di7v.bkt.clouddn.com/17-9-19/76049260.jpg)\n\na. 预检查：检查key的大小是否大于前一个key，如果大于则不符合HBase顺序排列的原理，抛出异常；检查value是否是null，如果为null也抛出异常\n\nb. block是否写满：检查当前Data Block是否已经写满，如果没有写满就直接写入keyvalue；否则就需要执行数据块落盘以及索引块修改操作；\n\nc. 数据落盘并修改索引：如果DataBlock写满，首先将block块写入流；再生成一个leaf index entry，写入leaf Index block；再检查该leaf index block是否已经写满需要落盘，如果已经写满，就将该leaf index block写入到输出流，并且为索引树根节点root index block新增一个索引，指向叶子节点(second-level index)\n\nd. 生成一个新的block：重新reset输出流，初始化startOffset为-1\n\ne. 写入keyvalue：将keyvalue以流的方式写入输出流，同时需要写入memstoreTS；除此之外，如果该key是当前block的第一个key，需要赋值给变量firstKeyInBlock\n\n**finalize阶段**\n\nmemstore中所有keyvalue都经过append阶段输出到HFile后，会执行一次finalize过程，主要更新HFile中meta元数据块、索引数据块以及Trailer数据块，其中对索引数据块的更新是我们关心的重点，此处详细解析，上述append流程中c步骤’数据落盘并修改索引’会使得root index block不断增多，当增大到一定程度之后就需要分裂，分裂示意图如下图所示：\n\n![26](http://omdq6di7v.bkt.clouddn.com/17-9-19/3817222.jpg)\n\n上图所示，分裂前索引结构为second-level结构，图中没有画出Data Blocks，根节点索引指向叶子节点索引块。finalize阶段系统会对Root Index Block进行大小检查，如果大小大于规定的大小就需要进行分裂，图中分裂过程实际上就是将原来的Root Index Block块分割成4块，每块独立形成中间节点InterMediate Index Block，系统再重新生成一个Root Index Block（图中红色部分），分别指向分割形成的4个interMediate Index Block。此时索引结构就变成了third-level结构。\n\n**总结**\n\n这篇文章是HFile结构解析的第二篇文章，主要集中介绍HFile中的数据索引块。首先分Root Index Block和NonRoot Index Block两部分对HFile中索引块进行了解析，紧接着基于此介绍了HBase如何使用索引对数据进行检索，最后结合Memstore Flush的相关知识分析了keyvalue数据写入的过程中索引块的分裂过程。希望通过这两篇文章的介绍，能够对HBase中数据存储文件HFile有一个更加全面深入的认识。\n\n## 怎样从一系列的HFile中找到某个rowkey?\n\n​     如果创建表时，指定了booleamFilter，那么就根据booleamFilter快速的判断该rowkey是否在这个HFile中。\n\n​     如果没有定义booleamFilter，hbase在查找先会根据时间戳或者查询列的信息来进行过滤，过滤掉那些肯定不含有所需数据的storefile或者memstore，尽量把我们的查询目标范围缩小。\n\n​     尽管缩小了，但仍可能会有多个文件需要扫描的。storefile的内部有序的，但是各个storefile之间并不是有序的。storefile的rowkey的范围很有可能有交叉。所以查询数据的过程也不可能是对storefile的顺序查找。\nhbase会首先查看每个storefile的最小的rowkey，然后按照从小到大的顺序进行排序，结果放到一个队列中，排序的算法就是按照hbase的三维顺序，按照rowkey，column，ts进行排序，rowkey和column是升序，而ts是降序。\n实际上并不是所有满足时间戳和列过滤的文件都会加到这个队列中，hbase会首先对各个storefile中的数据进行探测，只会扫描扫描那些存在比当前查询的rowkey大的记录的storefile。\n​    下面开始查询数据，整个过程用到了类似归并排序的算法，首先通过poll取出队列的头storefile，会从storefile读取一条记录返回；接下来呢，该storefile的下条记录并不一定是查询结果的下一条记录，因为队列的比较顺序是比较的每个storefile的第一条符合要求的rowkey。所以，hbase会继续从队列中剩下的storefile取第一条记录，把该记录与头storefile的第二条记录做比较，如果前者大，那么返回头storefile的第二条记录；如果后者大，则会把头storefile放回队列重新排序，在重新取队列的头storefile。然后重复上面的整个过程，直到找到key所在的HFile。范围缩小到该HFile后，就根据上面介绍的索引查找定位到块，快速的找到对应的记录。","slug":"hbase/hbase中HFile详解","published":1,"updated":"2018-09-12T03:03:21.813Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnge001swlkvqeynj8rt"},{"title":"hbase调优","date":"2017-09-09T06:42:10.000Z","_content":"\n# Hbase调优\n\n[[HBase优化相关](http://www.cnblogs.com/skyl/p/4814347.html)]\n\n\n\nzookeeper.session.timeout\n默认值：3分钟(180000ms)\n说明：RegionServer与Zookeeper间的连接超时时间。当超时时间到后，ReigonServer会被Zookeeper从RS集群清单中移除，HMaster收到移除通知后，会对这台server负责的regions重新balance，让其他存活的RegionServer接管.\n调优：这个timeout决定了RegionServer是否能够及时的failover。设置成1分钟或更低，可以减少因等待超时而被延长的failover时间。\n不过需要注意的是，对于一些Online应用，RegionServer从宕机到恢复时间本身就很短的(网络闪断，crash等故障，运维可快速介入)，如果调低timeout时间，反而会得不偿失。因为当ReigonServer被正式从RS集群中移除时，HMaster就开始做balance了 (让其他RS根据故障机器记录的WAL日志进行恢复)。当故障的RS在人工介入恢复后，这个balance动作是毫无意义的，反而会使负载不均匀，给RS 带来更多负担。特别是那些固定分配regions的场景。\n\nhbase.regionserver.handler.count\n默认值：10\n说明：RegionServer的请求处理IO线程数。\n调优：这个参数的调优与内存息息相关。\n较少的IO线程，适用于处理单次请求内存消耗较高的Big PUT场景(大容量单次PUT或设置了较大cache的scan，均属于Big PUT)或ReigonServer的内存比较紧张的场景。\n较多的IO线程，适用于单次请求内存消耗低，TPS要求非常高的场景。设置该值的时候，以监控内存为主要参考。\n这里需要注意的是如果server的region数量很少，大量的请求都落在一个region上，因快速充满memstore触发flush导致的读写锁会影响全局TPS，不是IO线程数越高越好。\n压测时，开启Enabling RPC-level logging，可以同时监控每次请求的内存消耗和GC的状况，最后通过多次压测结果来合理调节IO线程数。\n\nhbase.hregion.max.filesize\n默认值：256M\n说明：在当前ReigonServer上单个Reigon的最大存储空间，单个Region超过该值时，这个Region会被自动split成更小的region。\n调优：小region对split和compaction友好，因为拆分region或compact小region里的storefile速度很快，内存占用低。缺点是split和compaction会很频繁。特别是数量较多的小region不停地split, compaction，会导致集群响应时间波动很大，region数量太多不仅给管理上带来麻烦，甚至会引发一些Hbase的bug。一般512以下的都算小region。\n大region，则不太适合经常split和compaction，因为做一次compact和split会产生较长时间的停顿，对应用的读写性能冲击非常大。此外，大region意味着较大的storefile，compaction时对内存也是一个挑战。\n当然，大region也有其用武之地。如果你的应用场景中，某个时间点的访问量较低，那么在此时做compact和split，既能顺利完成split和compaction，又能保证绝大多数时间平稳的读写性能。\n内存方面，小region在设置memstore的大小值上比较灵活，大region则过大过小都不行，过大会导致flush时app的IO wait增高，过小则因store file过多影响读性能。\n\n既然split和compaction如此影响性能，有没有办法去掉?\ncompaction是无法避免的，split倒是可以从自动调整为手动。\n只要通过将这个参数值调大到某个很难达到的值，比如100G，就可以间接禁用自动split(RegionServer不会对未到达100G的region做split)。\n再配合RegionSplitter这个工具，在需要split时，手动split。\n手动split在灵活性和稳定性上比起自动split要高很多，相反，管理成本增加不多，比较推荐online实时系统使用。\n\nhbase.regionserver.global.memstore.upperLimit/lowerLimit\n默认值：0.4/0.35\nupperlimit说明：hbase.hregion.memstore.flush.size 这个参数的作用是:当单个memstore达到指定值时，flush该memstore。但是，一台ReigonServer可能有成百上千个memstore，每个memstore也许未达到flush.size，jvm的heap就不够用了。该参数就是为了限制memstores占用的总内存。\n当ReigonServer内所有的memstore所占用的内存总和达到heap的40%时，HBase会强制block所有的更新并flush这些memstore以释放所有memstore占用的内存。\nlowerLimit说明：同upperLimit，只不过当全局memstore的内存达到35%时，它不会flush所有的memstore，它会找一些内存占用较大的memstore，做个别flush，当然更新还是会被block。lowerLimit算是一个在全局flush导致性能暴跌前的补救措施。为什么说是性能暴跌?可以想象一下，如果memstore需要在一段较长的时间内做全量flush，且这段时间内无法接受任何读写请求，对HBase集群的性能影响是很大的。\n调优：这是一个Heap内存保护参数，默认值已经能适用大多数场景。它的调整一般是为了配合某些专属优化，比如读密集型应用，将读缓存开大，降低该值，腾出更多内存给其他模块使用。\n\n这个参数会给使用者带来什么影响?\n比如，10G内存，100个region，每个memstore 64M，假设每个region只有一个memstore，那么当100个memstore平均占用到50%左右时，就会达到lowerLimit的限制。假设此时，其他memstore同样有很多的写请求进来。在那些大的region未flush完，就可能又超过了upperlimit，则所有 region都会被block，开始触发全局flush。\n不过，除了你的内存非常小或你的应用场景里大多数都是读，我觉得不需要去调这个参数。\n\n\n\nhfile.block.cache.size\n默认值：0.2\n说明：storefile的读缓存占用Heap的大小百分比，0.2表示20%。该值直接影响数据读的性能。\n调优：当然是越大越好，如果读比写多，开到0.4-0.5也没问题。如果读写较均衡，0.3左右。如果读比写少，果断默认吧。设置这个值的时候，你同时要参考 hbase.regionserver.global.memstore.upperLimit ，该值是memstore占heap的最大百分比，两个参数一个影响读，一个影响写。如果两值加起来超过80-90%，会有OOM的风险，谨慎设置。\n\nhbase.hstore.blockingStoreFiles\n默认值：7\n说明：在compaction时，如果一个Store(Coulmn Family)内有超过7个storefile需要合并，则阻塞block所有的写请求，进行flush，限制storefile数量增长过快。\n调优：block写请求会影响当前region的性能，将值设为单个region可以支撑的最大store file数量会是个不错的选择，即允许comapction时，memstore继续生成storefile。最大storefile数量可通过 region size/memstore size来计算。如果你将region size设为无限大，那么你需要预估一个region可能产生的最大storefile数。\n\nhbase.hregion.memstore.block.multiplier\n默认值：2\n说明：当一个region里的memstore超过单个memstore.size两倍的大小时，block该region的所有请求，进行 flush，释放内存。虽然我们设置了memstore的总大小，比如64M，但想象一下，在最后63.9M的时候，我Put了一个100M的数据，此时 memstore的大小会瞬间暴涨到超过预期的memstore.size。这个参数的作用是当memstore的大小增至超过 memstore.size时，block所有请求，遏制风险进一步扩大。\n调优：这个参数的默认值还是比较靠谱的。如果你预估你的正常应用场景(不包括异常)不会出现突发写或写的量可控，那么保持默认值即可。如果正常情况下，你的写请求量就会经常暴长到正常的几倍，那么你应该调大这个倍数并调整其他参数值，比如hfile.block.cache.size和 hbase.regionserver.global.memstore.upperLimit/lowerLimit，以预留更多内存，防止HBase server OOM。\n\n启用LZO压缩\nLZO对比Hbase默认的GZip，前者性能较高，后者压缩比较高，具体参见 Using LZO Compression 。对于想提高HBase读写性能的开发者，采用LZO是比较好的选择。对于非常在乎存储空间的开发者，则建议保持默认。\n\n不要定义太多的Column Family\nHbase目前不能良好的处理超过包含2-3个CF的表。因为某个CF在flush发生时，它邻近的CF也会因关联效应被触发flush，最终导致系统产生更多IO。\n\n批量导入\n在批量导入数据到Hbase前，你可以通过预先创建regions，来平衡数据的负载。详见 Table Creation: Pre-Creating Regions\n\n避免CMS concurrent mode failure\nHBase使用CMS GC。默认触发GC的时机是当年老代内存达到90%的时候，这个百分比由 -XX:CMSInitiatingOccupancyFraction=N 这个参数来设置。concurrent mode failed发生在这样一个场景：\n当年老代内存达到90%的时候，CMS开始进行并发垃圾收集，于此同时，新生代还在迅速不断地晋升对象到年老代。当年老代CMS还未完成并发标记时，年老代满了，悲剧就发生了。CMS因为没内存可用不得不暂停mark，并触发一次全jvm的stop the world(挂起所有线程)，然后采用单线程拷贝方式清理所有垃圾对象。这个过程会非常漫长。为了避免出现concurrent mode failed，我们应该让GC在未到90%时，就触发。\n通过设置 -XX:CMSInitiatingOccupancyFraction=N\n这个百分比， 可以简单的这么计算。如果你的 hfile.block.cache.size 和 hbase.regionserver.global.memstore.upperLimit 加起来有60%(默认)，那么你可以设置 70-80，一般高10%左右差不多。\n\nHbase客户端优化\nAutoFlush(默认是true)\n将HTable的setAutoFlush设为false，可以支持客户端批量更新。即当Put填满客户端flush缓存时，才发送到服务端。\n\nScan Caching\nscanner一次缓存多少数据来scan(从服务端一次抓多少数据回来scan)。\n默认值是 1，一次只取一条。\n\nScan Attribute Selection\nscan时建议指定需要的Column Family，减少通信量，否则scan操作默认会返回整个row的所有数据(所有Coulmn Family)。\n\nClose ResultScanners\n通过scan取完数据后，记得要关闭ResultScanner，否则RegionServer可能会出现问题(对应的Server资源无法释放)。\n\nOptimal Loading of Row Keys\n当你scan一张表的时候，返回结果只需要row key(不需要CF, qualifier,values,timestaps)时，你可以在scan实例中添加一个filterList，并设置 MUST_PASS_ALL 操作，filterList中add FirstKeyOnlyFilter或KeyOnlyFilter。这样可以减少网络通信量。\n\nTurn off WAL on Puts\n当Put某些非重要数据时，你可以设置writeToWAL(false)，来进一步提高写性能。writeToWAL(false)会在Put时放弃写WAL log。风险是:当RegionServer宕机时，可能你刚才Put的那些数据会丢失，且无法恢复。\n\n启用Bloom Filter\nBloom Filter通过空间换时间，提高读操作性能。\n\n\n\n3.In Memory\n\n创建表的时候，可以通过HColumnDescriptor.setInMemory(true)将表放到RegionServer的缓存中，保证在读取的时候被cache命中。\n\n4.Max Version\n\n创建表的时候，可以通过HColumnDescriptor.setMaxVersions(intmaxVersions)设置表中数据的最大版本，如果只需要保存最新版本的数据，那么可以设置setMaxVersions(1)。\n\n5.Time to Live(设置数据存储的生命周期)\n\n创建表的时候，可以通过HColumnDescriptor.setTimeToLive(inttimeToLive)设置表中数据的存储生命期，过期数据将自动被删除，例如如果只需要存储最近两天的数据，那么可以设置setTimeToLive(2 * 24 * 60 * 60)。\n\n6.Compact & Split\n\nHBase的Compact分为两类：一类叫Minor Compact(部分文件合并), 一类叫Major Compact(全部文件合并). \n\n两者区别在于：Minor Compact是在Store内StoreFile数量达到阈值(hbase.hstore.blockingStoreFiles, 默认是7)时触发，将Store内的多个小StoreFile合并成一个大的StoreFile.\n\nMajor Compact除了将给定Region中一个列族的所有StoreFile合并成一个大的StoreFile外，还会将其中的Delete标记项进行删除。Major Compact是HBase清理被删除记录的唯一机会，因为我们不能保证被删除的记录和墓碑标记记录在同一个Store内。----一个Region只保存一个Table的数据，一张Table的所有数据分布在多个Region上。一个Region包含多个Store。一个Store只保存一个Column Family的数据，一个Column Family的所有数据分布在多个Store内。\n\n由于Major Compact非常消耗资源，实际应用中，可以考虑必要时手动进行。当Region内StoreFile的大小达到一定阈值后，等分Split为两个StoreFile。\n\n7.Pre-Creating Regions\n\n默认情况下，在创建HBase表的时候会自动创建一个Region分区，当导入数据的时候，所有的HBase客户端都向这一个Region写数据，直到这个Region足够大了才进行切分。一种可以加快批量写入速度的方法是通过预先创建一些空的Regions，这样当数据写入HBase时，会按照Region分区情况，在集群内做数据的负载均衡\n\n\n\n8.HBase模式设计之ID顺序增长（rowkey顺序增长）\n在设计RowKey的时候，常常有应用的RowKey必须包含ID部分，这样才可以支持查询访问。但ID自增长，会导致写入数据的时候压力集中在某一个或少数几个Region上，这是HBase设计的大忌。\n经过多个应用的实践，使用ID的二进制反转的方式来避免。\n简单说明: 比如ID是Byte型(一般为int或者long，此处为方便解释)，RowKey=ID+timestamp，1,2,3,4……这样增长，对应二进制为0000 0001，0000 0010，0000 0011,0000 0100……，因为前面的bit是不会变化的，所以以ID为RowKey（或者ID打头）的数据写入的时候会集中在一个region上，然后又集中在下一个region上。为此将变化的部分放到RowKey的前面，来分散写入的压力。前面的增长在RowKey的ID上就变成1000 0000， 0100 0000， 1100 0000，0010 0000……我们预分区，假如需要16-1个分区，就可以分为[,0x01)，[0x01,0x02),[0x02,0x03)……[0xFE,0xFF), [0xFF,)，注意算一下，这样，1,2,3,4……就会写到不同的区间上，从而分散到不同的region了。（提醒：为什么只拿ID说事，不考虑timestamp呢，因为HBase的RowKey时字节码比较的，先从高位开始，高位分出胜负，后面就不care了~）\n\n \n\n优点：转顺序为分散，均衡集群压力；可以做到预分区；不用hash，不用考虑ID的hash碰撞，从而节约存储空间；\n限制：scan只能在同一ID打头的rowkey内进行，连续ID的scan不能直接支持，需要程序逻辑处理。\n\n\n\n## 根据业务访问特点优化\n\n根据业务访问特点，将Hbase的工作负载大致分为以下四类：\n\n(1)随机读密集型\n\n对于随机读密集型工作负载，高效利用**缓存**和更好地**索引**会给HBase系统带来更高的性能。\n\n(2)顺序读密集型\n\n对于顺序读密集型工作负载，读缓存不会带来太多好处；除非顺序读的规模很小并且限定在一个特定的行键范围内，否则很可能使用缓存会比不使用缓存需要更频繁地访问硬盘。\n\n(3)写密集型\n\n写密集型工作负载的优化方法需要有别于读密集型负载。缓存不再起到重要作用。写操作总是进入MemStore，然后被刷写生成新的Hfile，以后再被合并。获得更好写性能的办法是**不要太频繁刷写、合并或者拆分**，因为在这段时间里IO压力上升，系统会变慢。\n\n(4)混合型\n\n对于完全混合型工作负载，优化方法会变得复杂些。优化时，需要混合调整多个参数来得到一个最优的组合。","source":"_posts/hbase/hbase参数调优.md","raw":"---\ntitle: hbase调优\ndate: 2017-09-09 14:42:10\ntags:\n- hbase\ncategories:\n- 大数据\n---\n\n# Hbase调优\n\n[[HBase优化相关](http://www.cnblogs.com/skyl/p/4814347.html)]\n\n\n\nzookeeper.session.timeout\n默认值：3分钟(180000ms)\n说明：RegionServer与Zookeeper间的连接超时时间。当超时时间到后，ReigonServer会被Zookeeper从RS集群清单中移除，HMaster收到移除通知后，会对这台server负责的regions重新balance，让其他存活的RegionServer接管.\n调优：这个timeout决定了RegionServer是否能够及时的failover。设置成1分钟或更低，可以减少因等待超时而被延长的failover时间。\n不过需要注意的是，对于一些Online应用，RegionServer从宕机到恢复时间本身就很短的(网络闪断，crash等故障，运维可快速介入)，如果调低timeout时间，反而会得不偿失。因为当ReigonServer被正式从RS集群中移除时，HMaster就开始做balance了 (让其他RS根据故障机器记录的WAL日志进行恢复)。当故障的RS在人工介入恢复后，这个balance动作是毫无意义的，反而会使负载不均匀，给RS 带来更多负担。特别是那些固定分配regions的场景。\n\nhbase.regionserver.handler.count\n默认值：10\n说明：RegionServer的请求处理IO线程数。\n调优：这个参数的调优与内存息息相关。\n较少的IO线程，适用于处理单次请求内存消耗较高的Big PUT场景(大容量单次PUT或设置了较大cache的scan，均属于Big PUT)或ReigonServer的内存比较紧张的场景。\n较多的IO线程，适用于单次请求内存消耗低，TPS要求非常高的场景。设置该值的时候，以监控内存为主要参考。\n这里需要注意的是如果server的region数量很少，大量的请求都落在一个region上，因快速充满memstore触发flush导致的读写锁会影响全局TPS，不是IO线程数越高越好。\n压测时，开启Enabling RPC-level logging，可以同时监控每次请求的内存消耗和GC的状况，最后通过多次压测结果来合理调节IO线程数。\n\nhbase.hregion.max.filesize\n默认值：256M\n说明：在当前ReigonServer上单个Reigon的最大存储空间，单个Region超过该值时，这个Region会被自动split成更小的region。\n调优：小region对split和compaction友好，因为拆分region或compact小region里的storefile速度很快，内存占用低。缺点是split和compaction会很频繁。特别是数量较多的小region不停地split, compaction，会导致集群响应时间波动很大，region数量太多不仅给管理上带来麻烦，甚至会引发一些Hbase的bug。一般512以下的都算小region。\n大region，则不太适合经常split和compaction，因为做一次compact和split会产生较长时间的停顿，对应用的读写性能冲击非常大。此外，大region意味着较大的storefile，compaction时对内存也是一个挑战。\n当然，大region也有其用武之地。如果你的应用场景中，某个时间点的访问量较低，那么在此时做compact和split，既能顺利完成split和compaction，又能保证绝大多数时间平稳的读写性能。\n内存方面，小region在设置memstore的大小值上比较灵活，大region则过大过小都不行，过大会导致flush时app的IO wait增高，过小则因store file过多影响读性能。\n\n既然split和compaction如此影响性能，有没有办法去掉?\ncompaction是无法避免的，split倒是可以从自动调整为手动。\n只要通过将这个参数值调大到某个很难达到的值，比如100G，就可以间接禁用自动split(RegionServer不会对未到达100G的region做split)。\n再配合RegionSplitter这个工具，在需要split时，手动split。\n手动split在灵活性和稳定性上比起自动split要高很多，相反，管理成本增加不多，比较推荐online实时系统使用。\n\nhbase.regionserver.global.memstore.upperLimit/lowerLimit\n默认值：0.4/0.35\nupperlimit说明：hbase.hregion.memstore.flush.size 这个参数的作用是:当单个memstore达到指定值时，flush该memstore。但是，一台ReigonServer可能有成百上千个memstore，每个memstore也许未达到flush.size，jvm的heap就不够用了。该参数就是为了限制memstores占用的总内存。\n当ReigonServer内所有的memstore所占用的内存总和达到heap的40%时，HBase会强制block所有的更新并flush这些memstore以释放所有memstore占用的内存。\nlowerLimit说明：同upperLimit，只不过当全局memstore的内存达到35%时，它不会flush所有的memstore，它会找一些内存占用较大的memstore，做个别flush，当然更新还是会被block。lowerLimit算是一个在全局flush导致性能暴跌前的补救措施。为什么说是性能暴跌?可以想象一下，如果memstore需要在一段较长的时间内做全量flush，且这段时间内无法接受任何读写请求，对HBase集群的性能影响是很大的。\n调优：这是一个Heap内存保护参数，默认值已经能适用大多数场景。它的调整一般是为了配合某些专属优化，比如读密集型应用，将读缓存开大，降低该值，腾出更多内存给其他模块使用。\n\n这个参数会给使用者带来什么影响?\n比如，10G内存，100个region，每个memstore 64M，假设每个region只有一个memstore，那么当100个memstore平均占用到50%左右时，就会达到lowerLimit的限制。假设此时，其他memstore同样有很多的写请求进来。在那些大的region未flush完，就可能又超过了upperlimit，则所有 region都会被block，开始触发全局flush。\n不过，除了你的内存非常小或你的应用场景里大多数都是读，我觉得不需要去调这个参数。\n\n\n\nhfile.block.cache.size\n默认值：0.2\n说明：storefile的读缓存占用Heap的大小百分比，0.2表示20%。该值直接影响数据读的性能。\n调优：当然是越大越好，如果读比写多，开到0.4-0.5也没问题。如果读写较均衡，0.3左右。如果读比写少，果断默认吧。设置这个值的时候，你同时要参考 hbase.regionserver.global.memstore.upperLimit ，该值是memstore占heap的最大百分比，两个参数一个影响读，一个影响写。如果两值加起来超过80-90%，会有OOM的风险，谨慎设置。\n\nhbase.hstore.blockingStoreFiles\n默认值：7\n说明：在compaction时，如果一个Store(Coulmn Family)内有超过7个storefile需要合并，则阻塞block所有的写请求，进行flush，限制storefile数量增长过快。\n调优：block写请求会影响当前region的性能，将值设为单个region可以支撑的最大store file数量会是个不错的选择，即允许comapction时，memstore继续生成storefile。最大storefile数量可通过 region size/memstore size来计算。如果你将region size设为无限大，那么你需要预估一个region可能产生的最大storefile数。\n\nhbase.hregion.memstore.block.multiplier\n默认值：2\n说明：当一个region里的memstore超过单个memstore.size两倍的大小时，block该region的所有请求，进行 flush，释放内存。虽然我们设置了memstore的总大小，比如64M，但想象一下，在最后63.9M的时候，我Put了一个100M的数据，此时 memstore的大小会瞬间暴涨到超过预期的memstore.size。这个参数的作用是当memstore的大小增至超过 memstore.size时，block所有请求，遏制风险进一步扩大。\n调优：这个参数的默认值还是比较靠谱的。如果你预估你的正常应用场景(不包括异常)不会出现突发写或写的量可控，那么保持默认值即可。如果正常情况下，你的写请求量就会经常暴长到正常的几倍，那么你应该调大这个倍数并调整其他参数值，比如hfile.block.cache.size和 hbase.regionserver.global.memstore.upperLimit/lowerLimit，以预留更多内存，防止HBase server OOM。\n\n启用LZO压缩\nLZO对比Hbase默认的GZip，前者性能较高，后者压缩比较高，具体参见 Using LZO Compression 。对于想提高HBase读写性能的开发者，采用LZO是比较好的选择。对于非常在乎存储空间的开发者，则建议保持默认。\n\n不要定义太多的Column Family\nHbase目前不能良好的处理超过包含2-3个CF的表。因为某个CF在flush发生时，它邻近的CF也会因关联效应被触发flush，最终导致系统产生更多IO。\n\n批量导入\n在批量导入数据到Hbase前，你可以通过预先创建regions，来平衡数据的负载。详见 Table Creation: Pre-Creating Regions\n\n避免CMS concurrent mode failure\nHBase使用CMS GC。默认触发GC的时机是当年老代内存达到90%的时候，这个百分比由 -XX:CMSInitiatingOccupancyFraction=N 这个参数来设置。concurrent mode failed发生在这样一个场景：\n当年老代内存达到90%的时候，CMS开始进行并发垃圾收集，于此同时，新生代还在迅速不断地晋升对象到年老代。当年老代CMS还未完成并发标记时，年老代满了，悲剧就发生了。CMS因为没内存可用不得不暂停mark，并触发一次全jvm的stop the world(挂起所有线程)，然后采用单线程拷贝方式清理所有垃圾对象。这个过程会非常漫长。为了避免出现concurrent mode failed，我们应该让GC在未到90%时，就触发。\n通过设置 -XX:CMSInitiatingOccupancyFraction=N\n这个百分比， 可以简单的这么计算。如果你的 hfile.block.cache.size 和 hbase.regionserver.global.memstore.upperLimit 加起来有60%(默认)，那么你可以设置 70-80，一般高10%左右差不多。\n\nHbase客户端优化\nAutoFlush(默认是true)\n将HTable的setAutoFlush设为false，可以支持客户端批量更新。即当Put填满客户端flush缓存时，才发送到服务端。\n\nScan Caching\nscanner一次缓存多少数据来scan(从服务端一次抓多少数据回来scan)。\n默认值是 1，一次只取一条。\n\nScan Attribute Selection\nscan时建议指定需要的Column Family，减少通信量，否则scan操作默认会返回整个row的所有数据(所有Coulmn Family)。\n\nClose ResultScanners\n通过scan取完数据后，记得要关闭ResultScanner，否则RegionServer可能会出现问题(对应的Server资源无法释放)。\n\nOptimal Loading of Row Keys\n当你scan一张表的时候，返回结果只需要row key(不需要CF, qualifier,values,timestaps)时，你可以在scan实例中添加一个filterList，并设置 MUST_PASS_ALL 操作，filterList中add FirstKeyOnlyFilter或KeyOnlyFilter。这样可以减少网络通信量。\n\nTurn off WAL on Puts\n当Put某些非重要数据时，你可以设置writeToWAL(false)，来进一步提高写性能。writeToWAL(false)会在Put时放弃写WAL log。风险是:当RegionServer宕机时，可能你刚才Put的那些数据会丢失，且无法恢复。\n\n启用Bloom Filter\nBloom Filter通过空间换时间，提高读操作性能。\n\n\n\n3.In Memory\n\n创建表的时候，可以通过HColumnDescriptor.setInMemory(true)将表放到RegionServer的缓存中，保证在读取的时候被cache命中。\n\n4.Max Version\n\n创建表的时候，可以通过HColumnDescriptor.setMaxVersions(intmaxVersions)设置表中数据的最大版本，如果只需要保存最新版本的数据，那么可以设置setMaxVersions(1)。\n\n5.Time to Live(设置数据存储的生命周期)\n\n创建表的时候，可以通过HColumnDescriptor.setTimeToLive(inttimeToLive)设置表中数据的存储生命期，过期数据将自动被删除，例如如果只需要存储最近两天的数据，那么可以设置setTimeToLive(2 * 24 * 60 * 60)。\n\n6.Compact & Split\n\nHBase的Compact分为两类：一类叫Minor Compact(部分文件合并), 一类叫Major Compact(全部文件合并). \n\n两者区别在于：Minor Compact是在Store内StoreFile数量达到阈值(hbase.hstore.blockingStoreFiles, 默认是7)时触发，将Store内的多个小StoreFile合并成一个大的StoreFile.\n\nMajor Compact除了将给定Region中一个列族的所有StoreFile合并成一个大的StoreFile外，还会将其中的Delete标记项进行删除。Major Compact是HBase清理被删除记录的唯一机会，因为我们不能保证被删除的记录和墓碑标记记录在同一个Store内。----一个Region只保存一个Table的数据，一张Table的所有数据分布在多个Region上。一个Region包含多个Store。一个Store只保存一个Column Family的数据，一个Column Family的所有数据分布在多个Store内。\n\n由于Major Compact非常消耗资源，实际应用中，可以考虑必要时手动进行。当Region内StoreFile的大小达到一定阈值后，等分Split为两个StoreFile。\n\n7.Pre-Creating Regions\n\n默认情况下，在创建HBase表的时候会自动创建一个Region分区，当导入数据的时候，所有的HBase客户端都向这一个Region写数据，直到这个Region足够大了才进行切分。一种可以加快批量写入速度的方法是通过预先创建一些空的Regions，这样当数据写入HBase时，会按照Region分区情况，在集群内做数据的负载均衡\n\n\n\n8.HBase模式设计之ID顺序增长（rowkey顺序增长）\n在设计RowKey的时候，常常有应用的RowKey必须包含ID部分，这样才可以支持查询访问。但ID自增长，会导致写入数据的时候压力集中在某一个或少数几个Region上，这是HBase设计的大忌。\n经过多个应用的实践，使用ID的二进制反转的方式来避免。\n简单说明: 比如ID是Byte型(一般为int或者long，此处为方便解释)，RowKey=ID+timestamp，1,2,3,4……这样增长，对应二进制为0000 0001，0000 0010，0000 0011,0000 0100……，因为前面的bit是不会变化的，所以以ID为RowKey（或者ID打头）的数据写入的时候会集中在一个region上，然后又集中在下一个region上。为此将变化的部分放到RowKey的前面，来分散写入的压力。前面的增长在RowKey的ID上就变成1000 0000， 0100 0000， 1100 0000，0010 0000……我们预分区，假如需要16-1个分区，就可以分为[,0x01)，[0x01,0x02),[0x02,0x03)……[0xFE,0xFF), [0xFF,)，注意算一下，这样，1,2,3,4……就会写到不同的区间上，从而分散到不同的region了。（提醒：为什么只拿ID说事，不考虑timestamp呢，因为HBase的RowKey时字节码比较的，先从高位开始，高位分出胜负，后面就不care了~）\n\n \n\n优点：转顺序为分散，均衡集群压力；可以做到预分区；不用hash，不用考虑ID的hash碰撞，从而节约存储空间；\n限制：scan只能在同一ID打头的rowkey内进行，连续ID的scan不能直接支持，需要程序逻辑处理。\n\n\n\n## 根据业务访问特点优化\n\n根据业务访问特点，将Hbase的工作负载大致分为以下四类：\n\n(1)随机读密集型\n\n对于随机读密集型工作负载，高效利用**缓存**和更好地**索引**会给HBase系统带来更高的性能。\n\n(2)顺序读密集型\n\n对于顺序读密集型工作负载，读缓存不会带来太多好处；除非顺序读的规模很小并且限定在一个特定的行键范围内，否则很可能使用缓存会比不使用缓存需要更频繁地访问硬盘。\n\n(3)写密集型\n\n写密集型工作负载的优化方法需要有别于读密集型负载。缓存不再起到重要作用。写操作总是进入MemStore，然后被刷写生成新的Hfile，以后再被合并。获得更好写性能的办法是**不要太频繁刷写、合并或者拆分**，因为在这段时间里IO压力上升，系统会变慢。\n\n(4)混合型\n\n对于完全混合型工作负载，优化方法会变得复杂些。优化时，需要混合调整多个参数来得到一个最优的组合。","slug":"hbase/hbase参数调优","published":1,"updated":"2018-09-12T03:03:21.814Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfngf001twlkvu51vko8b"},{"title":"hbase的BlockCache","date":"2017-09-18T23:34:35.000Z","_content":"\n和其他数据库一样，优化IO也是HBase提升性能的不二法宝，而提供缓存更是优化的重中之重。最理想的情况是，所有数据都能够缓存到内存，这样就不会有任何文件IO请求，读写性能必然会提升到极致。然而现实是残酷的，随着请求数据的不断增多，将数据全部缓存到内存显得不合实际。幸运的是，我们并不需要将所有数据都缓存起来，根据二八法则，80%的业务请求都集中在20%的热点数据上，因此将这部分数据缓存起就可以极大地提升系统性能。\n\nHBase在实现中提供了两种缓存结构：MemStore和BlockCache。其中MemStore称为写缓存，HBase执行写操作首先会将数据写入MemStore，并顺序写入HLog，等满足一定条件后统一将MemStore中数据刷新到磁盘，这种设计可以极大地提升HBase的写性能。不仅如此，MemStore对于读性能也至关重要，假如没有MemStore，读取刚写入的数据就需要从文件中通过IO查找，这种代价显然是昂贵的！BlockCache称为读缓存，HBase会将一次文件查找的Block块缓存到Cache中，以便后续同一请求或者邻近数据查找请求，可以直接从内存中获取，避免昂贵的IO操作。MemStore相关知识可以戳这里，本文将重点分析BlockCache。\n\n在介绍BlockCache之前，简单地回顾一下HBase中Block的概念，详细介绍戳这里。 Block是HBase中最小的数据存储单元，默认为64K，在建表语句中可以通过参数BlockSize指定。HBase中Block分为四种类型：Data Block，Index Block，Bloom Block和Meta Block。其中Data Block用于存储实际数据，通常情况下每个Data Block可以存放多条KeyValue数据对；Index Block和Bloom Block都用于优化随机读的查找路径，其中Index Block通过存储索引数据加快数据查找，而Bloom Block通过一定算法可以过滤掉部分一定不存在待查KeyValue的数据文件，减少不必要的IO操作；Meta Block主要存储整个HFile的元数据。\n\nBlockCache是Region Server级别的，一个Region Server只有一个Block Cache，在Region Server启动的时候完成Block Cache的初始化工作。到目前为止，HBase先后实现了3种Block Cache方案，LRUBlockCache是最初的实现方案，也是默认的实现方案；HBase 0.92版本实现了第二种方案SlabCache，见[HBASE-4027](https://issues.apache.org/jira/browse/HBASE-4027)；HBase 0.96之后官方提供了另一种可选方案BucketCache，见[HBASE-7404](https://issues.apache.org/jira/browse/HBASE-7404)。\n\n这三种方案的不同之处在于对内存的管理模式，其中LRUBlockCache是将所有数据都放入JVM Heap中，交给JVM进行管理。而后两者采用了不同机制将部分数据存储在堆外，交给HBase自己管理。这种演变过程是因为LRUBlockCache方案中JVM垃圾回收机制经常会导致程序长时间暂停，而采用堆外内存对数据进行管理可以有效避免这种情况发生。\n\n**LRUBlockCache**\n\nHBase默认的BlockCache实现方案。Block数据块都存储在 JVM heap内，由JVM进行垃圾回收管理。它将内存从逻辑上分为了三块：single-access区、mutil-access区、in-memory区，分别占到整个BlockCache大小的25%、50%、25%。一次随机读中，一个Block块从HDFS中加载出来之后首先放入signle区，后续如果有多次请求访问到这块数据的话，就会将这块数据移到mutil-access区。而in-memory区表示数据可以常驻内存，一般用来存放访问频繁、数据量小的数据，比如元数据，用户也可以在建表的时候通过设置列族属性IN-MEMORY= true将此列族放入in-memory区。很显然，这种设计策略类似于JVM中young区、old区以及perm区。无论哪个区，系统都会采用严格的Least-Recently-Used算法，当BlockCache总量达到一定阈值之后就会启动淘汰机制，最少使用的Block会被置换出来，为新加载的Block预留空间。\n\n**SlabCache**\n\n为了解决LRUBlockCache方案中因为JVM垃圾回收导致的服务中断，SlabCache方案使用Java NIO DirectByteBuffer技术实现了堆外内存存储，不再由JVM管理数据内存。默认情况下，系统在初始化的时候会分配两个缓存区，分别占整个BlockCache大小的80%和20%，每个缓存区分别存储固定大小的Block块，其中前者主要存储小于等于64K大小的Block，后者存储小于等于128K Block，如果一个Block太大就会导致两个区都无法缓存。和LRUBlockCache相同，SlabCache也使用Least-Recently-Used算法对过期Block进行淘汰。和LRUBlockCache不同的是，SlabCache淘汰Block的时候只需要将对应的bufferbyte标记为空闲，后续cache对其上的内存直接进行覆盖即可。\n\n线上集群环境中，不同表不同列族设置的BlockSize都可能不同，很显然，默认只能存储两种固定大小Block的SlabCache方案不能满足部分用户场景，比如用户设置BlockSize = 256K，简单使用SlabCache方案就不能达到这部分Block缓存的目的。因此HBase实际实现中将SlabCache和LRUBlockCache搭配使用，称为DoubleBlockCache。一次随机读中，一个Block块从HDFS中加载出来之后会在两个Cache中分别存储一份；缓存读时首先在LRUBlockCache中查找，如果Cache Miss再在SlabCache中查找，此时如果命中再将该Block放入LRUBlockCache中。\n\n经过实际测试，DoubleBlockCache方案有很多弊端。比如SlabCache设计中固定大小内存设置会导致实际内存使用率比较低，而且使用LRUBlockCache缓存Block依然会因为JVM GC产生大量内存碎片。因此在HBase 0.98版本之后，该方案已经被不建议使用。\n\n**BucketCache**\n\nSlabCache方案在实际应用中并没有很大程度改善原有LRUBlockCache方案的GC弊端，还额外引入了诸如堆外内存使用率低的缺陷。然而它的设计并不是一无是处，至少在使用堆外内存这个方面给予了阿里大牛们很多启发。站在SlabCache的肩膀上，他们开发了BucketCache缓存方案并贡献给了社区。\n\nBucketCache通过配置可以工作在三种模式下：heap，offheap和file。无论工作在那种模式下，BucketCache都会申请许多带有固定大小标签的Bucket，和SlabCache一样，一种Bucket存储一种指定BlockSize的数据块，但和SlabCache不同的是，BucketCache会在初始化的时候申请14个不同大小的Bucket，而且即使在某一种Bucket空间不足的情况下，系统也会从其他Bucket空间借用内存使用，不会出现内存使用率低的情况。接下来再来看看不同工作模式，heap模式表示这些Bucket是从JVM Heap中申请，offheap模式使用DirectByteBuffer技术实现堆外内存存储管理，而file模式使用类似SSD的高速缓存文件存储数据块。\n\n实际实现中，HBase将BucketCache和LRUBlockCache搭配使用，称为CombinedBlockCache。和DoubleBlockCache不同，系统在LRUBlockCache中主要存储Index Block和Bloom Block，而将Data Block存储在BucketCache中。因此一次随机读需要首先在LRUBlockCache中查到对应的Index Block，然后再到BucketCache查找对应数据块。BucketCache通过更加合理的设计修正了SlabCache的弊端，极大降低了JVM GC对业务请求的实际影响，但也存在一些问题，比如使用堆外内存会存在拷贝内存的问题，一定程度上会影响读写性能。当然，在后来的版本中这个问题也得到了解决，见[HBASE-11425](https://issues.apache.org/jira/browse/HBASE-11425)。\n\n\n\nHBase BlockCache系列第一篇文章《走进BlockCache》从全局视角对HBase中缓存、Memstore等作了简要概述，并重点介绍了几种BlockCache方案及其演进过程，对此还不了解的可以点[这里](http://hbasefly.com/2016/04/08/hbase-blockcache-1/)。本文在上文的基础上深入BlockCache内部，对各种BlockCache方案具体工作原理进行详细分析。Note：因为SlabCache方案在0.98版本已经不被建议使用，因此本文不针对该方案进行讲解；至于LRU方案和Bucket方案，因为后者更加复杂，本文也会花更多篇幅详细介绍该方案的实现细节。\n\n### **LRUBlockCache**\n\nLRUBlockCache是HBase目前默认的BlockCache机制，实现机制比较简单。它使用一个ConcurrentHashMap管理BlockKey到Block的映射关系，缓存Block只需要将BlockKey和对应的Block放入该HashMap中，查询缓存就根据BlockKey从HashMap中获取即可。同时该方案采用严格的LRU淘汰算法，当Block Cache总量达到一定阈值之后就会启动淘汰机制，最近最少使用的Block会被置换出来。在具体的实现细节方面，需要关注三点：\n\n\\1. 缓存**分层策略**\n\nHBase在LRU缓存基础上，采用了缓存分层设计，将整个BlockCache分为三个部分：single-access、mutil-access和inMemory。需要特别注意的是，HBase系统元数据存放在InMemory区，因此设置数据属性InMemory = true需要非常谨慎，确保此列族数据量很小且访问频繁，否则有可能会将hbase.meta元数据挤出内存，严重影响所有业务性能。\n\n\\2. LRU淘汰算法实现\n\n系统在每次cache block时将BlockKey和Block放入HashMap后都会检查BlockCache总量是否达到阈值，如果达到阈值，就会唤醒淘汰线程对Map中的Block进行淘汰。系统设置三个MinMaxPriorityQueue队列，分别对应上述三个分层，每个队列中的元素按照最近最少被使用排列，系统会优先poll出最近最少使用的元素，将其对应的内存释放。可见，三个分层中的Block会分别执行LRU淘汰算法进行淘汰。\n\n\\3. LRU方案优缺点\n\nLRU方案使用JVM提供的HashMap管理缓存，简单有效。但随着数据从single-access区晋升到mutil-access区，基本就伴随着对应的内存对象从young区到old区 ，晋升到old区的Block被淘汰后会变为内存垃圾，最终由CMS回收掉（Conccurent Mark Sweep，一种标记清除算法），然而这种算法会带来大量的内存碎片，碎片空间一直累计就会产生臭名昭著的Full GC。尤其在大内存条件下，一次Full GC很可能会持续较长时间，甚至达到分钟级别。大家知道Full GC是会将整个进程暂停的（称为stop-the-wold暂停），因此长时间Full GC必然会极大影响业务的正常读写请求。也正因为这样的弊端，SlabCache方案和BucketCache方案才会横空出世。\n\n### **BucketCache**\n\n相比LRUBlockCache，BucketCache实现相对比较复杂。它没有使用JVM 内存管理算法来管理缓存，而是自己对内存进行管理，因此不会因为出现大量碎片导致Full GC的情况发生。本节主要介绍BucketCache的具体实现方式（包括BucketCache的内存组织形式、缓存写入读取流程等）以及如何配置使用BucketCache。\n\n#### **内存组织形式**\n\n下图是BucketCache的内存组织形式图，其中上面部分是逻辑组织结构，下面部分是对应的物理组织结构。HBase启动之后会在内存中申请大量的bucket，如下图中黄色矩形所示，每个bucket的大小默认都为2MB。每个bucket会有一个baseoffset变量和一个size标签，其中baseoffset变量表示这个bucket在实际物理空间中的起始地址，因此block的物理地址就可以通过baseoffset和该block在bucket的偏移量唯一确定；而size标签表示这个bucket可以存放的block块的大小，比如图中左侧bucket的size标签为65KB，表示可以存放64KB的block，右侧bucket的size标签为129KB，表示可以存放128KB的block。\n\n![70074](http://hbasefly.com/wp-content/uploads/2016/04/70074.png)\n\nHBase中使用BucketAllocator类实现对Bucket的组织管理：\n\n\\1. HBase会根据每个bucket的size标签对bucket进行分类，相同size标签的bucket由同一个BucketSizeInfo管理，如上图，左侧存放64KB block的bucket由65KB BucketSizeInfo管理，右侧存放128KB block的bucket由129KB BucketSizeInfo管理。\n\n\\2. HBase在启动的时候就决定了size标签的分类，默认标签有(4+1)K、(8+1)K、(16+1)K … (48+1)K、(56+1)K、(64+1)K、(96+1)K … (512+1)K。而且系统会首先从小到大遍历一次所有size标签，为每种size标签分配一个bucket，最后所有剩余的bucket都分配最大的size标签，默认分配 (512+1)K，如下图所示：\n\n![22222](http://hbasefly.com/wp-content/uploads/2016/04/22222.png)\n\n3. Bucket的size标签可以动态调整，比如64K的block数目比较多，65K的bucket被用完了以后，其他size标签的完全空闲的bucket可以转换成为65K的bucket，但是至少保留一个该size的bucket。\n\n#### **Block缓存写入、读取流程**\n\n下图是block写入缓存以及从缓存中读取block的流程示意图，图中主要包括5个模块，其中RAMCache是一个存储blockkey和block对应关系的HashMap；WriteThead是整个block写入的中心枢纽，主要负责异步的写入block到内存空间；BucketAllocator在上一节详细介绍过，主要实现对bucket的组织管理，为block分配内存空间；IOEngine是具体的内存管理模块，主要实现将block数据写入对应地址的内存空间；BackingMap也是一个HashMap，用来存储blockKey与对应物理内存偏移量的映射关系，用来根据blockkey定位具体的block；其中紫线表示cache block流程，绿线表示get block流程。\n\n![33333](http://hbasefly.com/wp-content/uploads/2016/04/33333.png)\n\nBlock缓存写入流程\n\n\\1. 将block写入RAMCache。实际实现中，HBase设置了多个RAMCache，系统首先会根据blockkey进行hash，根据hash结果将block分配到对应的RAMCache中；\n\n\\2. WriteThead从RAMCache中取出所有的block。和RAMCache相同，HBase会同时启动多个WriteThead并发的执行异步写入，每个WriteThead对应一个RAMCache;\n\n\\3. 每个WriteThead会将遍历RAMCache中所有block数据，分别调用bucketAllocator为这些block分配内存空间；\n\n\\4. BucketAllocator会选择与block大小对应的bucket进行存放（具体细节可以参考上节‘内存组织形式’所述），并且返回对应的物理地址偏移量offset；\n\n\\5. WriteThead将block以及分配好的物理地址偏移量传给IOEngine模块，执行具体的内存写入操作；\n\n\\6. 写入成功后，将类似<blockkey,offset>这样的映射关系写入BackingMap中，方便后续查找时根据blockkey可以直接定位；\n\nBlock缓存读取流程\n\n\\1. 首先从RAMCache中查找。对于还没有来得及写入到bucket的缓存block，一定存储在RAMCache中；\n\n\\2. 如果在RAMCache中没有找到，再在BackingMap中根据blockKey找到对应物理偏移地址offset；\n\n\\3. 根据物理偏移地址offset可以直接从内存中查找对应的block数据；\n\n#### **BucketCache工作模式**\n\nBucketCache默认有三种工作模式：heap、offheap和file；这三种工作模式在内存逻辑组织形式以及缓存流程上都是相同的，参见上节讲解。不同的是三者对应的最终存储介质有所不同，即上述所讲的IOEngine有所不同。\n\n其中heap模式和offheap模式都使用内存作为最终存储介质，内存分配查询也都使用Java NIO ByteBuffer技术，不同的是，heap模式分配内存会调用byteBuffer.allocate方法，从JVM提供的heap区分配，而后者会调用byteBuffer.allocateDirect方法，直接从操作系统分配。这两种内存分配模式会对HBase实际工作性能产生一定的影响。影响最大的无疑是GC ，相比heap模式，offheap模式因为内存属于操作系统，所以基本不会产生CMS GC，也就在任何情况下都不会因为内存碎片导致触发Full GC。除此之外，在内存分配以及读取方面，两者性能也有不同，比如，内存分配时heap模式需要首先从操作系统分配内存再拷贝到JVM heap，相比offheap直接从操作系统分配内存更耗时；但是反过来，读取缓存时heap模式可以从JVM heap中直接读取，而offheap模式则需要首先从操作系统拷贝到JVM heap再读取，显得后者更费时。\n\nfile模式和前面两者不同，它使用Fussion-IO或者SSD等作为存储介质，相比昂贵的内存，这样可以提供更大的存储容量，因此可以极大地提升缓存命中率。\n\n#### **BucketCache配置使用**\n\nBucketCache方案的配置说明一直被HBaser所诟病，官方一直没有相关文档对此进行介绍。本人也是一直被其所困，后来通过查看源码才基本了解清楚，在此分享出来，以便大家学习。需要注意的是，BucketCache三种工作模式的配置会有所不同，下面也是分开介绍，并且没有列出很多不重要的参数：\n\nheap模式\n\n```\n<hbase.bucketcache.ioengine>heap</hbase.bucketcache.ioengine>\n//bucketcache占用整个jvm内存大小的比例\n<hbase.bucketcache.size>0.4</hbase.bucketcache.size>\n//bucketcache在combinedcache中的占比\n<hbase.bucketcache.combinedcache.percentage>0.9</hbase.bucketcache.combinedcache.percentage>\n```\n\noffheap模式\n\n```\n<hbase.bucketcache.ioengine>offheap</hbase.bucketcache.ioengine>\n<hbase.bucketcache.size>0.4</hbase.bucketcache.size>\n<hbase.bucketcache.combinedcache.percentage>0.9</hbase.bucketcache.combinedcache.percentage>\n```\n\nfile模式\n\n```\n<hbase.bucketcache.ioengine>file:/cache_path</hbase.bucketcache.ioengine>\n//bucketcache缓存空间大小，单位为MB\n<hbase.bucketcache.size>10 * 1024</hbase.bucketcache.size>\n//高速缓存路径\n<hbase.bucketcache.persistent.path>file:/cache_path</hbase.bucketcache.persistent.path>\n```\n\n### **总结**","source":"_posts/hbase/hbase的BlockCache.md","raw":"---\ntitle: hbase的BlockCache\ndate: 2017-09-19 07:34:35\ntags:\n- hbase\ncategories:\n- 大数据\n---\n\n和其他数据库一样，优化IO也是HBase提升性能的不二法宝，而提供缓存更是优化的重中之重。最理想的情况是，所有数据都能够缓存到内存，这样就不会有任何文件IO请求，读写性能必然会提升到极致。然而现实是残酷的，随着请求数据的不断增多，将数据全部缓存到内存显得不合实际。幸运的是，我们并不需要将所有数据都缓存起来，根据二八法则，80%的业务请求都集中在20%的热点数据上，因此将这部分数据缓存起就可以极大地提升系统性能。\n\nHBase在实现中提供了两种缓存结构：MemStore和BlockCache。其中MemStore称为写缓存，HBase执行写操作首先会将数据写入MemStore，并顺序写入HLog，等满足一定条件后统一将MemStore中数据刷新到磁盘，这种设计可以极大地提升HBase的写性能。不仅如此，MemStore对于读性能也至关重要，假如没有MemStore，读取刚写入的数据就需要从文件中通过IO查找，这种代价显然是昂贵的！BlockCache称为读缓存，HBase会将一次文件查找的Block块缓存到Cache中，以便后续同一请求或者邻近数据查找请求，可以直接从内存中获取，避免昂贵的IO操作。MemStore相关知识可以戳这里，本文将重点分析BlockCache。\n\n在介绍BlockCache之前，简单地回顾一下HBase中Block的概念，详细介绍戳这里。 Block是HBase中最小的数据存储单元，默认为64K，在建表语句中可以通过参数BlockSize指定。HBase中Block分为四种类型：Data Block，Index Block，Bloom Block和Meta Block。其中Data Block用于存储实际数据，通常情况下每个Data Block可以存放多条KeyValue数据对；Index Block和Bloom Block都用于优化随机读的查找路径，其中Index Block通过存储索引数据加快数据查找，而Bloom Block通过一定算法可以过滤掉部分一定不存在待查KeyValue的数据文件，减少不必要的IO操作；Meta Block主要存储整个HFile的元数据。\n\nBlockCache是Region Server级别的，一个Region Server只有一个Block Cache，在Region Server启动的时候完成Block Cache的初始化工作。到目前为止，HBase先后实现了3种Block Cache方案，LRUBlockCache是最初的实现方案，也是默认的实现方案；HBase 0.92版本实现了第二种方案SlabCache，见[HBASE-4027](https://issues.apache.org/jira/browse/HBASE-4027)；HBase 0.96之后官方提供了另一种可选方案BucketCache，见[HBASE-7404](https://issues.apache.org/jira/browse/HBASE-7404)。\n\n这三种方案的不同之处在于对内存的管理模式，其中LRUBlockCache是将所有数据都放入JVM Heap中，交给JVM进行管理。而后两者采用了不同机制将部分数据存储在堆外，交给HBase自己管理。这种演变过程是因为LRUBlockCache方案中JVM垃圾回收机制经常会导致程序长时间暂停，而采用堆外内存对数据进行管理可以有效避免这种情况发生。\n\n**LRUBlockCache**\n\nHBase默认的BlockCache实现方案。Block数据块都存储在 JVM heap内，由JVM进行垃圾回收管理。它将内存从逻辑上分为了三块：single-access区、mutil-access区、in-memory区，分别占到整个BlockCache大小的25%、50%、25%。一次随机读中，一个Block块从HDFS中加载出来之后首先放入signle区，后续如果有多次请求访问到这块数据的话，就会将这块数据移到mutil-access区。而in-memory区表示数据可以常驻内存，一般用来存放访问频繁、数据量小的数据，比如元数据，用户也可以在建表的时候通过设置列族属性IN-MEMORY= true将此列族放入in-memory区。很显然，这种设计策略类似于JVM中young区、old区以及perm区。无论哪个区，系统都会采用严格的Least-Recently-Used算法，当BlockCache总量达到一定阈值之后就会启动淘汰机制，最少使用的Block会被置换出来，为新加载的Block预留空间。\n\n**SlabCache**\n\n为了解决LRUBlockCache方案中因为JVM垃圾回收导致的服务中断，SlabCache方案使用Java NIO DirectByteBuffer技术实现了堆外内存存储，不再由JVM管理数据内存。默认情况下，系统在初始化的时候会分配两个缓存区，分别占整个BlockCache大小的80%和20%，每个缓存区分别存储固定大小的Block块，其中前者主要存储小于等于64K大小的Block，后者存储小于等于128K Block，如果一个Block太大就会导致两个区都无法缓存。和LRUBlockCache相同，SlabCache也使用Least-Recently-Used算法对过期Block进行淘汰。和LRUBlockCache不同的是，SlabCache淘汰Block的时候只需要将对应的bufferbyte标记为空闲，后续cache对其上的内存直接进行覆盖即可。\n\n线上集群环境中，不同表不同列族设置的BlockSize都可能不同，很显然，默认只能存储两种固定大小Block的SlabCache方案不能满足部分用户场景，比如用户设置BlockSize = 256K，简单使用SlabCache方案就不能达到这部分Block缓存的目的。因此HBase实际实现中将SlabCache和LRUBlockCache搭配使用，称为DoubleBlockCache。一次随机读中，一个Block块从HDFS中加载出来之后会在两个Cache中分别存储一份；缓存读时首先在LRUBlockCache中查找，如果Cache Miss再在SlabCache中查找，此时如果命中再将该Block放入LRUBlockCache中。\n\n经过实际测试，DoubleBlockCache方案有很多弊端。比如SlabCache设计中固定大小内存设置会导致实际内存使用率比较低，而且使用LRUBlockCache缓存Block依然会因为JVM GC产生大量内存碎片。因此在HBase 0.98版本之后，该方案已经被不建议使用。\n\n**BucketCache**\n\nSlabCache方案在实际应用中并没有很大程度改善原有LRUBlockCache方案的GC弊端，还额外引入了诸如堆外内存使用率低的缺陷。然而它的设计并不是一无是处，至少在使用堆外内存这个方面给予了阿里大牛们很多启发。站在SlabCache的肩膀上，他们开发了BucketCache缓存方案并贡献给了社区。\n\nBucketCache通过配置可以工作在三种模式下：heap，offheap和file。无论工作在那种模式下，BucketCache都会申请许多带有固定大小标签的Bucket，和SlabCache一样，一种Bucket存储一种指定BlockSize的数据块，但和SlabCache不同的是，BucketCache会在初始化的时候申请14个不同大小的Bucket，而且即使在某一种Bucket空间不足的情况下，系统也会从其他Bucket空间借用内存使用，不会出现内存使用率低的情况。接下来再来看看不同工作模式，heap模式表示这些Bucket是从JVM Heap中申请，offheap模式使用DirectByteBuffer技术实现堆外内存存储管理，而file模式使用类似SSD的高速缓存文件存储数据块。\n\n实际实现中，HBase将BucketCache和LRUBlockCache搭配使用，称为CombinedBlockCache。和DoubleBlockCache不同，系统在LRUBlockCache中主要存储Index Block和Bloom Block，而将Data Block存储在BucketCache中。因此一次随机读需要首先在LRUBlockCache中查到对应的Index Block，然后再到BucketCache查找对应数据块。BucketCache通过更加合理的设计修正了SlabCache的弊端，极大降低了JVM GC对业务请求的实际影响，但也存在一些问题，比如使用堆外内存会存在拷贝内存的问题，一定程度上会影响读写性能。当然，在后来的版本中这个问题也得到了解决，见[HBASE-11425](https://issues.apache.org/jira/browse/HBASE-11425)。\n\n\n\nHBase BlockCache系列第一篇文章《走进BlockCache》从全局视角对HBase中缓存、Memstore等作了简要概述，并重点介绍了几种BlockCache方案及其演进过程，对此还不了解的可以点[这里](http://hbasefly.com/2016/04/08/hbase-blockcache-1/)。本文在上文的基础上深入BlockCache内部，对各种BlockCache方案具体工作原理进行详细分析。Note：因为SlabCache方案在0.98版本已经不被建议使用，因此本文不针对该方案进行讲解；至于LRU方案和Bucket方案，因为后者更加复杂，本文也会花更多篇幅详细介绍该方案的实现细节。\n\n### **LRUBlockCache**\n\nLRUBlockCache是HBase目前默认的BlockCache机制，实现机制比较简单。它使用一个ConcurrentHashMap管理BlockKey到Block的映射关系，缓存Block只需要将BlockKey和对应的Block放入该HashMap中，查询缓存就根据BlockKey从HashMap中获取即可。同时该方案采用严格的LRU淘汰算法，当Block Cache总量达到一定阈值之后就会启动淘汰机制，最近最少使用的Block会被置换出来。在具体的实现细节方面，需要关注三点：\n\n\\1. 缓存**分层策略**\n\nHBase在LRU缓存基础上，采用了缓存分层设计，将整个BlockCache分为三个部分：single-access、mutil-access和inMemory。需要特别注意的是，HBase系统元数据存放在InMemory区，因此设置数据属性InMemory = true需要非常谨慎，确保此列族数据量很小且访问频繁，否则有可能会将hbase.meta元数据挤出内存，严重影响所有业务性能。\n\n\\2. LRU淘汰算法实现\n\n系统在每次cache block时将BlockKey和Block放入HashMap后都会检查BlockCache总量是否达到阈值，如果达到阈值，就会唤醒淘汰线程对Map中的Block进行淘汰。系统设置三个MinMaxPriorityQueue队列，分别对应上述三个分层，每个队列中的元素按照最近最少被使用排列，系统会优先poll出最近最少使用的元素，将其对应的内存释放。可见，三个分层中的Block会分别执行LRU淘汰算法进行淘汰。\n\n\\3. LRU方案优缺点\n\nLRU方案使用JVM提供的HashMap管理缓存，简单有效。但随着数据从single-access区晋升到mutil-access区，基本就伴随着对应的内存对象从young区到old区 ，晋升到old区的Block被淘汰后会变为内存垃圾，最终由CMS回收掉（Conccurent Mark Sweep，一种标记清除算法），然而这种算法会带来大量的内存碎片，碎片空间一直累计就会产生臭名昭著的Full GC。尤其在大内存条件下，一次Full GC很可能会持续较长时间，甚至达到分钟级别。大家知道Full GC是会将整个进程暂停的（称为stop-the-wold暂停），因此长时间Full GC必然会极大影响业务的正常读写请求。也正因为这样的弊端，SlabCache方案和BucketCache方案才会横空出世。\n\n### **BucketCache**\n\n相比LRUBlockCache，BucketCache实现相对比较复杂。它没有使用JVM 内存管理算法来管理缓存，而是自己对内存进行管理，因此不会因为出现大量碎片导致Full GC的情况发生。本节主要介绍BucketCache的具体实现方式（包括BucketCache的内存组织形式、缓存写入读取流程等）以及如何配置使用BucketCache。\n\n#### **内存组织形式**\n\n下图是BucketCache的内存组织形式图，其中上面部分是逻辑组织结构，下面部分是对应的物理组织结构。HBase启动之后会在内存中申请大量的bucket，如下图中黄色矩形所示，每个bucket的大小默认都为2MB。每个bucket会有一个baseoffset变量和一个size标签，其中baseoffset变量表示这个bucket在实际物理空间中的起始地址，因此block的物理地址就可以通过baseoffset和该block在bucket的偏移量唯一确定；而size标签表示这个bucket可以存放的block块的大小，比如图中左侧bucket的size标签为65KB，表示可以存放64KB的block，右侧bucket的size标签为129KB，表示可以存放128KB的block。\n\n![70074](http://hbasefly.com/wp-content/uploads/2016/04/70074.png)\n\nHBase中使用BucketAllocator类实现对Bucket的组织管理：\n\n\\1. HBase会根据每个bucket的size标签对bucket进行分类，相同size标签的bucket由同一个BucketSizeInfo管理，如上图，左侧存放64KB block的bucket由65KB BucketSizeInfo管理，右侧存放128KB block的bucket由129KB BucketSizeInfo管理。\n\n\\2. HBase在启动的时候就决定了size标签的分类，默认标签有(4+1)K、(8+1)K、(16+1)K … (48+1)K、(56+1)K、(64+1)K、(96+1)K … (512+1)K。而且系统会首先从小到大遍历一次所有size标签，为每种size标签分配一个bucket，最后所有剩余的bucket都分配最大的size标签，默认分配 (512+1)K，如下图所示：\n\n![22222](http://hbasefly.com/wp-content/uploads/2016/04/22222.png)\n\n3. Bucket的size标签可以动态调整，比如64K的block数目比较多，65K的bucket被用完了以后，其他size标签的完全空闲的bucket可以转换成为65K的bucket，但是至少保留一个该size的bucket。\n\n#### **Block缓存写入、读取流程**\n\n下图是block写入缓存以及从缓存中读取block的流程示意图，图中主要包括5个模块，其中RAMCache是一个存储blockkey和block对应关系的HashMap；WriteThead是整个block写入的中心枢纽，主要负责异步的写入block到内存空间；BucketAllocator在上一节详细介绍过，主要实现对bucket的组织管理，为block分配内存空间；IOEngine是具体的内存管理模块，主要实现将block数据写入对应地址的内存空间；BackingMap也是一个HashMap，用来存储blockKey与对应物理内存偏移量的映射关系，用来根据blockkey定位具体的block；其中紫线表示cache block流程，绿线表示get block流程。\n\n![33333](http://hbasefly.com/wp-content/uploads/2016/04/33333.png)\n\nBlock缓存写入流程\n\n\\1. 将block写入RAMCache。实际实现中，HBase设置了多个RAMCache，系统首先会根据blockkey进行hash，根据hash结果将block分配到对应的RAMCache中；\n\n\\2. WriteThead从RAMCache中取出所有的block。和RAMCache相同，HBase会同时启动多个WriteThead并发的执行异步写入，每个WriteThead对应一个RAMCache;\n\n\\3. 每个WriteThead会将遍历RAMCache中所有block数据，分别调用bucketAllocator为这些block分配内存空间；\n\n\\4. BucketAllocator会选择与block大小对应的bucket进行存放（具体细节可以参考上节‘内存组织形式’所述），并且返回对应的物理地址偏移量offset；\n\n\\5. WriteThead将block以及分配好的物理地址偏移量传给IOEngine模块，执行具体的内存写入操作；\n\n\\6. 写入成功后，将类似<blockkey,offset>这样的映射关系写入BackingMap中，方便后续查找时根据blockkey可以直接定位；\n\nBlock缓存读取流程\n\n\\1. 首先从RAMCache中查找。对于还没有来得及写入到bucket的缓存block，一定存储在RAMCache中；\n\n\\2. 如果在RAMCache中没有找到，再在BackingMap中根据blockKey找到对应物理偏移地址offset；\n\n\\3. 根据物理偏移地址offset可以直接从内存中查找对应的block数据；\n\n#### **BucketCache工作模式**\n\nBucketCache默认有三种工作模式：heap、offheap和file；这三种工作模式在内存逻辑组织形式以及缓存流程上都是相同的，参见上节讲解。不同的是三者对应的最终存储介质有所不同，即上述所讲的IOEngine有所不同。\n\n其中heap模式和offheap模式都使用内存作为最终存储介质，内存分配查询也都使用Java NIO ByteBuffer技术，不同的是，heap模式分配内存会调用byteBuffer.allocate方法，从JVM提供的heap区分配，而后者会调用byteBuffer.allocateDirect方法，直接从操作系统分配。这两种内存分配模式会对HBase实际工作性能产生一定的影响。影响最大的无疑是GC ，相比heap模式，offheap模式因为内存属于操作系统，所以基本不会产生CMS GC，也就在任何情况下都不会因为内存碎片导致触发Full GC。除此之外，在内存分配以及读取方面，两者性能也有不同，比如，内存分配时heap模式需要首先从操作系统分配内存再拷贝到JVM heap，相比offheap直接从操作系统分配内存更耗时；但是反过来，读取缓存时heap模式可以从JVM heap中直接读取，而offheap模式则需要首先从操作系统拷贝到JVM heap再读取，显得后者更费时。\n\nfile模式和前面两者不同，它使用Fussion-IO或者SSD等作为存储介质，相比昂贵的内存，这样可以提供更大的存储容量，因此可以极大地提升缓存命中率。\n\n#### **BucketCache配置使用**\n\nBucketCache方案的配置说明一直被HBaser所诟病，官方一直没有相关文档对此进行介绍。本人也是一直被其所困，后来通过查看源码才基本了解清楚，在此分享出来，以便大家学习。需要注意的是，BucketCache三种工作模式的配置会有所不同，下面也是分开介绍，并且没有列出很多不重要的参数：\n\nheap模式\n\n```\n<hbase.bucketcache.ioengine>heap</hbase.bucketcache.ioengine>\n//bucketcache占用整个jvm内存大小的比例\n<hbase.bucketcache.size>0.4</hbase.bucketcache.size>\n//bucketcache在combinedcache中的占比\n<hbase.bucketcache.combinedcache.percentage>0.9</hbase.bucketcache.combinedcache.percentage>\n```\n\noffheap模式\n\n```\n<hbase.bucketcache.ioengine>offheap</hbase.bucketcache.ioengine>\n<hbase.bucketcache.size>0.4</hbase.bucketcache.size>\n<hbase.bucketcache.combinedcache.percentage>0.9</hbase.bucketcache.combinedcache.percentage>\n```\n\nfile模式\n\n```\n<hbase.bucketcache.ioengine>file:/cache_path</hbase.bucketcache.ioengine>\n//bucketcache缓存空间大小，单位为MB\n<hbase.bucketcache.size>10 * 1024</hbase.bucketcache.size>\n//高速缓存路径\n<hbase.bucketcache.persistent.path>file:/cache_path</hbase.bucketcache.persistent.path>\n```\n\n### **总结**","slug":"hbase/hbase的BlockCache","published":1,"updated":"2018-09-12T03:03:21.814Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfngg001vwlkvvaq4q6wh"},{"title":"hbase的HFile合并","date":"2017-09-21T13:24:35.000Z","_content":"\n了解HBase的童鞋都知道，HBase是一种Log-Structured Merge Tree架构模式，用户数据写入先写WAL，再写缓存，满足一定条件后缓存数据会执行flush操作真正落盘，形成一个数据文件HFile。随着数据写入不断增多，flush次数也会不断增多，进而HFile数据文件就会越来越多。然而，太多数据文件会导致数据查询IO次数增多，因此HBase尝试着不断对这些文件进行合并，这个合并过程称为Compaction。\n\nCompaction会从一个region的一个store中选择一些hfile文件进行合并。合并说来原理很简单，先从这些待合并的数据文件中读出KeyValues，再按照由小到大排列后写入一个新的文件中。之后，这个新生成的文件就会取代之前待合并的所有文件对外提供服务。HBase根据合并规模将Compaction分为了两类：MinorCompaction和MajorCompaction\n\n- Minor Compaction是指选取一些小的、相邻的StoreFile将他们合并成一个更大的StoreFile，在这个过程中不会处理已经Deleted或Expired的Cell。一次Minor Compaction的结果是更少并且更大的StoreFile。\n- Major Compaction是指将所有的StoreFile合并成一个StoreFile，这个过程还会清理三类无意义数据：被删除的数据、TTL过期数据、版本号超过设定版本号的数据。另外，一般情况下，Major Compaction时间会持续比较长，整个过程会消耗大量系统资源，对上层业务有比较大的影响。因此线上业务都会将关闭自动触发Major Compaction功能，改为手动在业务低峰期触发。\n\n### **Compaction作用 | 副作用**\n\n上文提到，随着hfile文件数不断增多，一次查询就可能会需要越来越多的IO操作，延迟必然会越来越大，如下图一所示，随着数据写入不断增加，文件数不断增多，读取延时也在不断变大。而执行compaction会使得文件数基本稳定，进而IO Seek次数会比较稳定，延迟就会稳定在一定范围。然而，compaction操作重写文件会带来很大的带宽压力以及短时间IO压力。因此可以认为，Compaction就是使用短时间的IO消耗以及带宽消耗换取后续查询的低延迟。从图上来看，就是延迟有很大的毛刺，但总体趋势基本稳定不变，见下图二。\n\n![11](http://hbasefly.com/wp-content/uploads/2016/07/11.png)\n\n![22](http://hbasefly.com/wp-content/uploads/2016/07/22.png)\n\n为了换取后续查询的低延迟，除了短时间的读放大之外，Compaction对写入也会有很大的影响。我们首先假设一个现象：当写请求非常多，导致不断生成HFile，但compact的速度远远跟不上HFile生成的速度，这样就会使HFile的数量会越来越多，导致读性能急剧下降。为了避免这种情况，在HFile的数量过多的时候会限制写请求的速度：在每次执行MemStore flush的操作前，如果HStore的HFile数超过hbase.hstore.blockingStoreFiles （默认7），则会阻塞flush操作hbase.hstore.blockingWaitTime时间，在这段时间内，如果compact操作使得HStore文件数下降到回这个值，则停止阻塞。另外阻塞超过时间后，也会恢复执行flush操作。这样做就可以有效地控制大量写请求的速度，但同时这也是影响写请求速度的主要原因之一。\n\n可见，Compaction会使得数据读取延迟一直比较平稳，但付出的代价是大量的读延迟毛刺和一定的写阻塞。\n\n### Compaction流程\n\n了解了一定的背景知识后，接下来需要从全局角度对Compaction进行了解。整个Compaction始于特定的触发条件，比如flush操作、周期性地Compaction检查操作等。一旦触发，HBase会将该Compaction交由一个独立的线程处理，该线程首先会从对应store中选择合适的hfile文件进行合并，这一步是整个Compaction的核心，选取文件需要遵循很多条件，比如文件数不能太多、不能太少、文件大小不能太大等等，最理想的情况是，选取那些承载IO负载重、文件小的文件集，实际实现中，HBase提供了多个文件选取算法：RatioBasedCompactionPolicy、ExploringCompactionPolicy和StripeCompactionPolicy等，用户也可以通过特定接口实现自己的Compaction算法；选出待合并的文件后，HBase会根据这些hfile文件总大小挑选对应的线程池处理，最后对这些文件执行具体的合并操作。可以通过下图简单地梳理上述流程：\n\n![33](http://hbasefly.com/wp-content/uploads/2016/07/33.png)\n\n#### **触发时机**\n\nHBase中可以触发compaction的因素有很多，最常见的因素有这么三种：Memstore Flush、后台线程周期性检查、手动触发。\n\n\\1. Memstore Flush: 应该说compaction操作的源头就来自flush操作，memstore flush会产生HFile文件，文件越来越多就需要compact。因此在每次执行完Flush操作之后，都会对当前Store中的文件数进行判断，一旦文件数＃ > ，就会触发compaction。需要说明的是，compaction都是以Store为单位进行的，而在Flush触发条件下，整个Region的所有Store都会执行compact，所以会在短时间内执行多次compaction。\n\n\\2. 后台线程周期性检查：后台线程CompactionChecker定期触发检查是否需要执行compaction，检查周期为：hbase.server.thread.wakefrequency*hbase.server.compactchecker.interval.multiplier。和flush不同的是，该线程优先检查文件数＃是否大于，一旦大于就会触发compaction。如果不满足，它会接着检查是否满足major compaction条件，简单来说，如果当前store中hfile的最早更新时间早于某个值mcTime，就会触发major compaction，HBase预想通过这种机制定期删除过期数据。上文mcTime是一个浮动值，浮动区间默认为［7-7*0.2，7+7*0.2］，其中7为hbase.hregion.majorcompaction，0.2为hbase.hregion.majorcompaction.jitter，可见默认在7天左右就会执行一次major compaction。用户如果想禁用major compaction，只需要将参数hbase.hregion.majorcompaction设为0\n\n\\3. 手动触发：一般来讲，手动触发compaction通常是为了执行major compaction，原因有三，其一是因为很多业务担心自动major compaction影响读写性能，因此会选择低峰期手动触发；其二也有可能是用户在执行完alter操作之后希望立刻生效，执行手动触发major compaction；其三是HBase管理员发现硬盘容量不够的情况下手动触发major compaction删除大量过期数据；无论哪种触发动机，一旦手动触发，HBase会不做很多自动化检查，直接执行合并。\n\n#### **选择合适HFile合并**\n\n选择合适的文件进行合并是整个compaction的核心，因为合并文件的大小以及其当前承载的IO数直接决定了compaction的效果。最理想的情况是，这些文件承载了大量IO请求但是大小很小，这样compaction本身不会消耗太多IO，而且合并完成之后对读的性能会有显著提升。然而现实情况可能大部分都不会是这样，在0.96版本和0.98版本，分别提出了两种选择策略，在充分考虑整体情况的基础上选择最佳方案。无论哪种选择策略，都会首先对该Store中所有HFile进行一一排查，排除不满足条件的部分文件：\n\n\\1. 排除当前正在执行compact的文件及其比这些文件更新的所有文件（SequenceId更大）\n\n\\2. 排除某些过大的单个文件，如果文件大小大于hbase.hzstore.compaction.max.size（默认Long最大值），则被排除，否则会产生大量IO消耗\n\n经过排除的文件称为候选文件，HBase接下来会再判断是否满足major compaction条件，如果满足，就会选择全部文件进行合并。判断条件有下面三条，只要满足其中一条就会执行major compaction：\n\n\\1. 用户强制执行major compaction\n\n2. 长时间没有进行compact（CompactionChecker的判断条件2）且候选文件数小于hbase.hstore.compaction.max（默认10）\n\n\\3. Store中含有Reference文件，Reference文件是split region产生的临时文件，只是简单的引用文件，一般必须在compact过程中删除\n\n如果不满足major compaction条件，就必然为minor compaction，HBase主要有两种minor策略：RatioBasedCompactionPolicy和ExploringCompactionPolicy，下面分别进行介绍：\n\n**RatioBasedCompactionPolicy**\n\n从老到新逐一扫描所有候选文件，满足其中条件之一便停止扫描：\n\n（1）当前文件大小 < 比它更新的所有文件大小总和 * ratio，其中ratio是一个可变的比例，在高峰期时ratio为1.2，非高峰期为5，也就是非高峰期允许compact更大的文件。那什么时候是高峰期，什么时候是非高峰期呢？用户可以配置参数hbase.offpeak.start.hour和hbase.offpeak.end.hour来设置高峰期\n\n（2）当前所剩候选文件数 <= hbase.store.compaction.min（默认为3）\n\n停止扫描后，待合并文件就选择出来了，即为当前扫描文件+比它更新的所有文件\n\n**ExploringCompactionPolicy**\n\n该策略思路基本和RatioBasedCompactionPolicy相同，不同的是，Ratio策略在找到一个合适的文件集合之后就停止扫描了，而Exploring策略会记录下所有合适的文件集合，并在这些文件集合中寻找最优解。最优解可以理解为：待合并文件数最多或者待合并文件数相同的情况下文件大小较小，这样有利于减少compaction带来的IO消耗。具体流程戳[这里](http://my.oschina.net/u/220934/blog/363270)\n\n需要注意的是，Ratio策略是0.94版本的默认策略，而0.96版本之后默认策略就换为了Exploring策略，在cloudera博文[《what-are-hbase-compactions》](http://blog.cloudera.com/blog/2013/12/what-are-hbase-compactions/)中，作者给出了一个两者的简单性能对比，基本可以看出后者在节省IO方面会有10%左右的提升：\n\n![44](http://hbasefly.com/wp-content/uploads/2016/07/44.png)\n\n截止到此，HBase基本上就选择出来了待合并的文件集合，后续通过挑选合适的处理线程，就会对这些文件进行真正的合并 。\n\n#### **挑选合适的线程池**\n\nHBase实现中有一个专门的线程CompactSplitThead负责接收compact请求以及split请求，而且为了能够独立处理这些请求，这个线程内部构造了多个线程池：largeCompactions、smallCompactions以及splits等，其中splits线程池负责处理所有的split请求，largeCompactions和smallCompaction负责处理所有的compaction请求，其中前者用来处理大规模compaction，后者处理小规模compaction。这里需要明白三点：\n\n\\1. 上述设计目的是为了能够将请求独立处理，提供系统的处理性能。\n\n\\2. 哪些compaction应该分配给largeCompactions处理，哪些应该分配给smallCompactions处理？是不是Major Compaction就应该交给largeCompactions线程池处理？不对。这里有个分配原则：待compact的文件总大小如果大于值throttlePoint（可以通过参数hbase.regionserver.thread.compaction.throttle配置，默认为2.5G），分配给largeCompactions处理，否则分配给smallCompactions处理。\n\n\\3. largeCompactions线程池和smallCompactions线程池默认都只有一个线程，用户可以通过参数hbase.regionserver.thread.compaction.large和hbase.regionserver.thread.compaction.small进行配置\n\n#### **执行HFile文件合并**\n\n上文一方面选出了待合并的HFile集合，一方面也选出来了合适的处理线程，万事俱备，只欠最后真正的合并。合并流程说起来也简单，主要分为如下几步：\n\n\\1. 分别读出待合并hfile文件的KV，并顺序写到位于./tmp目录下的临时文件中\n\n\\2. 将临时文件移动到对应region的数据目录\n\n\\3. 将compaction的输入文件路径和输出文件路径封装为KV写入WAL日志，并打上compaction标记，最后强制执行sync\n\n\\4. 将对应region数据目录下的compaction输入文件全部删除\n\n上述四个步骤看起来简单，但实际是很严谨的，具有很强的容错性和完美的幂等性：\n\n\\1. 如果RS在步骤2之前发生异常，本次compaction会被认为失败，如果继续进行同样的compaction，上次异常对接下来的compaction不会有任何影响，也不会对读写有任何影响。唯一的影响就是多了一份多余的数据。\n\n\\2. 如果RS在步骤2之后、步骤3之前发生异常，同样的，仅仅会多一份冗余数据。\n\n\\3. 如果在步骤3之后、步骤4之前发生异常，RS在重新打开region之后首先会从WAL中看到标有compaction的日志，因为此时输入文件和输出文件已经持久化到HDFS，因此只需要根据WAL移除掉compaction输入文件即可\n\n\n\n\n\ncompaction的核心作用是通过合并大量小文件为一个大文件来减少hfile的总数量，进而保证读延迟的稳定。合并文件首先是读出所有小文件的KVs，再写入同一个大文件，这个过程会带来严重的IO压力和带宽压力，对整个系统的读请求和写请求带来不同程度的影响。\n\n因此HBase对于compaction的设计总是会追求一个平衡点，一方面需要保证compaction的基本效果，另一方面又不会带来严重的IO压力。然而，并没有一种设计策略能够适用于所有应用场景或所有数据集。在意识到这样的问题之后，HBase就希望能够提供一种机制可以在不同业务场景下针对不同设计策略进行测试，另一方面也可以让用户针对自己的业务场景选择合适的compaction策略。因此，在0.96版本中HBase对架构进行了一定的调整，一方面提供了Compaction插件接口，用户只需要实现这些特定的接口，就可以根据自己的应用场景以及数据集定制特定的compaction策略。另一方面，0.96版本之后Compaction可以支持table/cf粒度的策略设置，使得用户可以根据应用场景为不同表/列族选择不同的compaction策略，比如：\n\n```\nalter ’table1’ , CONFIGURATION => {‘hbase.store.engine.class’ => ‘org.apache.hadoop.hbase.regionserver.StripStoreEngine’, … } \n```\n\n上述两方面的调整为compaction的改进和优化提供了最基本的保障，同时提出了一个非常重要的理念：compaction到底选择什么样的策略需要根据不同的业务场景、不同数据集特征进行确定。那接下来就根据不同的应用场景介绍几种不同的compaction策略。\n\n在介绍具体的compaction策略之前，还是有必要对优化compaction的共性特征进行提取，总结起来有如下几个方面：\n\n\\1. 减少参与compaction的文件数：这个很好理解，实现起来却比较麻烦，首先需要将文件根据rowkey、version或其他属性进行分割，再根据这些属性挑选部分重要的文件参与合并；另一方面，尽量不要合并那些大文件，减少参与合并的文件数。\n\n2. 不要合并那些不需要合并的文件：比如OpenTSDB应用场景下的老数据，这些数据基本不会查询到，因此不进行合并也不会影响查询性能\n\n\\3. 小region更有利于compaction：大region会生成大量文件，不利于compaction；相反，小region只会生成少量文件，这些文件合并不会引起很大的IO放大\n\n接下来就介绍几个典型的compaction策略以及其适应的应用场景：\n\n### **FIFO Compaction（HBASE-14468）**\n\nFIFO Compaction策略主要参考了[rocksdb的实现](https://github.com/facebook/rocksdb/wiki/FIFO-compaction-style)，它会选择那些过期的数据文件，即该文件内所有数据都已经过期。因此，对应业务的列族必须设置TTL，否则肯定不适合该策略。需要注意的是，该策略只做这么一件事情：收集所有已经过期的文件并删除。这样的应用场景主要包括：\n\n\\1. 大量短时间存储的原始数据，比如推荐业务，上层业务只需要最近时间内用户的行为特征，利用这些行为特征进行聚合为用户进行推荐。再比如Nginx日志，用户只需要存储最近几天的日志，方便查询某个用户最近一段时间的操作行为等等\n\n\\2. 所有数据能够全部加载到block cache（RAM/SSD），假如HBase有1T大小的SSD作为block cache，理论上就完全不需要做合并，因为所有读操作都是内存操作。\n\n因为FIFO Compaction只是收集所有过期的数据文件并删除，并没有真正执行重写（几个小文件合并成大文件），因此不会消耗任何CPU和IO资源，也不会从block cache中淘汰任何热点数据。所以，无论对于读还是写，该策略都会提升吞吐量、降低延迟。\n\n开启FIFO Compaction（表设置&列族设置）\n\n```\nHTableDescriptor desc = new HTableDescriptor(tableName);\n    desc.setConfiguration(DefaultStoreEngine.DEFAULT_COMPACTION_POLICY_CLASS_KEY, \n      FIFOCompactionPolicy.class.getName());\n```\n\n```\nHColumnDescriptor desc = new HColumnDescriptor(family);\n    desc.setConfiguration(DefaultStoreEngine.DEFAULT_COMPACTION_POLICY_CLASS_KEY, \n      FIFOCompactionPolicy.class.getName());\n```\n\n### **Tier-Based Compaction（HBASE-7055）（HBASE-14477）**\n\n之前所讲到的所有‘文件选取策略’实际上都不够灵活，基本上没有考虑到热点数据的情况。然而现实业务中，有很大比例的业务都存在明显的热点数据，而其中最常见的情况是：最近写入到的数据总是最有可能被访问到，而老数据被访问到的频率就相对比较低。按照之前的文件选择策略，并没有对新文件和老文件进行一定的‘区别对待’，每次compaction都有可能会有很多老文件参与合并，这必然会影响compaction效率，却对降低读延迟没有太大的帮助。\n\n针对这种情况，HBase社区借鉴Facebook HBase分支的解决方案，引入了Tier-Based Compaction。这种方案会根据候选文件的新老程度将其分为多个不同的等级，每个等级都有对应等级的参数，比如参数Compation Ratio，表示该等级文件选择时的选择几率，Ratio越大，该等级的文件越有可能被选中参与Compaction。而等级数、每个等级参数都可以通过CF属性在线更新。\n\n可见，Tier-Based Compaction方案通过引入时间等级和Compaction Ratio等概念，使得Compaction更加灵活，不同业务场景只需要调整参数就可以达到更好的Compaction效率。目前HBase计划在2.0.0版本发布基于时间划分等级的实现方式－Date Tierd Compaction Policy，后续我们也重点基于该方案进行介绍。\n\n该方案的具体实现思路，HBase更多地参考了Cassandra的实现方案：基于时间窗的时间概念。如下图所示，时间窗的大小可以进行配置，其中参数base_time_seconds代表初始化时间窗的大小，默认为1h，表示最近一小时内flush的文件数据都会落入这个时间窗内，所有想读到最近一小时数据请求只需要读取这个时间窗内的文件即可。后面的时间窗窗口会越来越大，另一个参数max_age_days表示比其更老的文件不会参与compaction。\n\n![1](http://hbasefly.com/wp-content/uploads/2016/07/1-1.png)\n\n![312737.png](file://c:/Users/hzfanxinxin/AppData/Local/YNote/data/hzfanxinxin@corp.netease.com/1326b0125fb44c708cc9788ca161981f/312737.png)\n\n上图所示，时间窗随着时间推移朝右移动，图一中没有任何时间窗包含4个（可以通过参数min_thresold配置）文件，因此compaction不会被触发。随着时间推移来到图二所示状态，此时就有一个时间窗包含了4个HFile文件，compaction就会被触发，这四个文件就会被合并为一个大文件。\n\n对比上文说到的分级策略以及Compaction Ratio参数，Cassandra的实现方案中通过设置多个时间窗来实现分级，时间窗的窗口大小类似于Compaction Ratio参数的作用，可以通过调整时间窗的大小来调整不同时间窗文件选择的优先级，比如可以将最右边的时间窗窗口调大，那新文件被选择参与Compaction的概率就会大大增加。然而，这个方案里面并没有类似于当前HBase中的Major Compaction策略来实现过期文件清理的功能，只能借助于TTL来主动清理过期的文件，比如这个文件中所有数据都过期了，就可以将这个文件清理掉。\n\n因此，我们可以总结得到使用Date Tierd Compaction Policy需要遵守的原则：\n\n\\1. 特别适合使用的场景：时间序列数据，默认使用TTL删除。类似于“获取最近一小时／三小时／一天”场景，同时不会执行delete操作。最典型的例子就是基于Open-TSDB的监控系统，如下图所示：\n\n![2](http://hbasefly.com/wp-content/uploads/2016/07/2-1.png)\n\n![372163.png](file://c:/Users/hzfanxinxin/AppData/Local/YNote/data/hzfanxinxin@corp.netease.com/5f2126df4edc4a69a3ec222662a25863/372163.png)\n\n\\2. 比较适合的应用场景：时间序列数据，但是会有全局数据的更新操作以及少部分的删除操作。\n\n\\3. 不适合的应用场景：非时间序列数据，或者大量的更新数据更新操作和删除操作。\n\n### **Stripe Compaction （HBASE-7667）**\n\n通常情况下，major compaction都是无法绕过的，很多业务都会执行delete/update操作，并设置TTL和Version，这样就需要通过执行major compaction清理被删除的数据以及过期版本数据、过期TTL数据。然而，接触过HBase的童鞋都知道，major compaction是一个特别昂贵的操作，会消耗大量系统资源，而且执行一次可能会持续几个小时，严重影响业务应用。因此，一般线上都会选择关闭major compaction自动触发，而是选择在业务低峰期的时候手动触发。为了彻底消除major compaction所带来的影响，hbase社区提出了strip compaction方案。\n\n其实，解决major compaction的最直接办法是减少region的大小，最好整个集群都是由很多小region组成，这样参与compaction的文件总大小就必然不会太大。可是，region设置小会导致region数量很多，这一方面会导致hbase管理region的开销很大，另一方面，region过多也要求hbase能够分配出来更多的内存作为memstore使用，否则有可能导致整个regionserver级别的flush，进而引起长时间的写阻塞。因此单纯地通过将region大小设置过小并不能本质解决问题。\n\n#### **Level Compaction**\n\n此时，社区开发者将目光转向了leveldb的compaction策略：level compaction。level compaction设计思路是将store中的所有数据划分为很多层，每一层都会有一部分数据，如下图所示：\n\n![3](http://hbasefly.com/wp-content/uploads/2016/07/3-1.png)\n\n![663348.png](file://c:/Users/hzfanxinxin/AppData/Local/YNote/data/hzfanxinxin@corp.netease.com/273f13693df9498eaa6d8af45f25f41d/663348.png)\n\n\\1. 数据组织形式不再按照时间前后进行组织，而是按照KeyRange进行组织，每个KeyRange中会包含多个文件，这些文件所有数据的Key必须分布在同一个范围。比如Key分布在Key0~KeyN之间的所有数据都会落在第一个KeyRange区间的文件中，Key分布在KeyN+1~KeyT之间的所有数据会分布在第二个区间的文件中，以此类推。\n\n\\2. 整个数据体系会被划分为很多层，最上层（Level 0）表示最新数据，最下层（Level 6）表示最旧数据。每一层都由大量KeyRange块组成（Level 0除外），KeyRange之间没有Key重合。而且层数越大，对应层的每个KeyRange块大小越大，下层KeyRange块大小是上一层大小的10倍。图中range颜色越深，对应的range块越大。\n\n\\3. 数据从Memstore中flush之后，会首先落入Level 0，此时落入Level 0的数据可能包含所有可能的Key。此时如果需要执行compaction，只需要将Level 0中的KV一个一个读出来，然后按照Key的分布分别插入Level 1中对应KeyRange块的文件中，如果此时刚好Level 1中的某个KeyRange块大小超过了一定阈值，就会继续往下一层合并。\n\n\\4. level compaction依然会有major compaction的概念，发生major compaction只需要将部分Range块内的文件执行合并就可以，而不需要合并整个region内的数据文件。\n\n可见，这种compaction在合并的过程中，从上到下只需要部分文件参与，而不需要对所有文件执行compaction操作。另外，level compaction还有另外一个好处，对于很多‘只读最近写入数据’的业务来说，大部分读请求都会落到level 0，这样可以使用SSD作为上层level存储介质，进一步优化读。然而，这种compaction因为level层数太多导致compaction的次数明显增多，经过测试，发现这种compaction并没有对IO利用率有任何提升。\n\n#### **Stripe Compaction 实现**\n\n虽然原生的level compaction并不适用于HBase，但是这种compaction的思想却激发了HBaser的灵感，再结合之前提到的小region策略，就形成了本节的主角－stripe compaction。同level compaction相同，stripe compaction会将整个store中的文件按照Key划分为多个Range，在这里称为stripe，stripe的数量可以通过参数设定，相邻的stripe之间key不会重合。实际上在概念上来看这个stripe类似于sub-region的概念，即将一个大region切分成了很多小的sub-region。\n\n随着数据写入，memstore执行flush之后形成hfile，这些hfile并不会马上写入对应的stripe，而是放到一个称为L0的地方，用户可以配置L0可以放置hfile的数量。一旦L0放置的文件数超过设定值，系统就会将这些hfile写入对应的stripe：首先读出hfile的KVs，再根据KV的key定位到具体的stripe，将该KV插入对应stripe的文件中即可，如下图所示。之前说过stripe就是一个个小的region，所以在stripe内部，依然会像正常region一样执行minor compaction和major compaction，可以预想到，stripe内部的major compaction并不会太多消耗系统资源。另外，数据读取也很简单，系统可以根据对应的Key查找到对应的stripe，然后在stripe内部执行查找，因为stripe内数据量相对很小，所以也会一定程度上提升数据查找性能。\n\n![4](http://hbasefly.com/wp-content/uploads/2016/07/4-1.png)\n\n![884122.png](file://c:/Users/hzfanxinxin/AppData/Local/YNote/data/hzfanxinxin@corp.netease.com/d851e63ac1d943bcab7c3f76db6fdbde/884122.png)\n\n官方对stripe compaction进行了测试，给出的测试结果如下：\n\n![5](http://hbasefly.com/wp-content/uploads/2016/07/5-1.png)\n\n![532361.png](file://c:/Users/hzfanxinxin/AppData/Local/YNote/data/hzfanxinxin@corp.netease.com/d6bca64dbb9f4aaebc430c6801845c9c/532361.png)\n\n上图主要测定了在不同的stripe数量以及不同的L0数量下的读写延迟对比情况，参考对照组可以看出，基本上任何配置下的读响应延迟都有所降低，而写响应延迟却有所升高。\n\n![6](http://hbasefly.com/wp-content/uploads/2016/07/6-1.png)\n\n![882584.png](file://c:/Users/hzfanxinxin/AppData/Local/YNote/data/hzfanxinxin@corp.netease.com/d2511efb2f8b4ea29edcd323fdf8bfb3/882584.png)\n\n上图是默认配置和12-stripes配置下读写稳定性测试，其中两条蓝线分别表示默认情况下的读写延迟曲线，而两条红线表示strips情况下读写延迟曲线，可以明显看出来，无论读还是写，12-stripes配置下的稳定性都明显好于默认配置，不会出现明显的卡顿现象。\n\n到此为止，我们能够看出来stripe compaction设计上的高明之处，同时通过实验数据也可以明显看出其在读写稳定性上的卓越表现。然而，和任何一种compaction机制一样，stripe compaction也有它特别擅长的业务场景，也有它并不擅长的业务场景。下面是两种stripe compaction比较擅长的业务场景：\n\n\\1. 大Region。小region没有必要切分为stripes，一旦切分，反而会带来额外的管理开销。一般默认如果region大小小于2G，就不适合使用stripe compaction。\n\n\\2. RowKey具有统一格式，stripe compaction要求所有数据按照Key进行切分，切分为多个stripe。如果rowkey不具有统一格式的话，无法进行切分。\n\n------\n\n上述几种策略都是根据不同的业务场景设置对应的文件选择策略，核心都是减少参与compaction的文件数，缩短整个compaction执行的时间，间接降低compaction的IO放大效应，减少对业务读写的延迟影响。然而，如果不对Compaction执行阶段的读写吞吐量进行限制的话也会引起短时间大量系统资源消耗，影响用户业务延迟。HBase社区也意识到了这个问题，也提出了一定的应对策略：\n\n### **Limit Compaction Speed**\n\n该优化方案通过感知Compaction的压力情况自动调节系统的Compaction吞吐量，在压力大的时候降低合并吞吐量，压力小的时候增加合并吞吐量。基本原理为：\n\n\\1. 在正常情况下，用户需要设置吞吐量下限参数“hbase.hstore.compaction.throughput.lower.bound”(默认10MB/sec) 和上限参数“hbase.hstore.compaction.throughput.higher.bound”(默认20MB/sec)，而hbase实际会工作在吞吐量为lower + (higer – lower) * ratio的情况下，其中ratio是一个取值范围在0到1的小数，它由当前store中待参与compation的file数量决定，数量越多，ratio越小，反之越大。\n\n\\2. 如果当前store中hfile的数量太多，并且超过了参数blockingFileCount，此时所有写请求就会阻塞等待compaction完成，这种场景下上述限制会自动失效。\n\n截至目前，我们一直都在关注Compaction带来的IO放大效应，然而在某些情况下Compaction还会因为大量消耗带宽资源从而严重影响其他业务。为什么Compaction会大量消耗带宽资源呢？主要有两点原因：\n\n\\1. 正常请求下，compaction尤其是major compaction会将大量数据文件合并为一个大HFile，读出所有数据文件的KVs，然后重新排序之后写入另一个新建的文件。如果待合并文件都在本地，那么读就是本地读，不会出现垮网络的情况。但是因为数据文件都是三副本，因此写的时候就会垮网络执行，必然会消耗带宽资源。\n\n\\2. 原因1的前提是所有待合并文件都在本地的情况，那在有些场景下待合并文件有可能并不全在本地，即本地化率没有达到100%，比如执行过balance之后就会有很多文件并不在本地。这种情况下读文件的时候就会垮网络读，如果是major compaction，必然也会大量消耗带宽资源。\n\n可以看出来，垮网络读是可以通过一定优化避免的，而垮网络写却是不可能避免的。因此优化Compaction带宽消耗，一方面需要提升本地化率（一个优化专题，在此不详细说明），减少垮网络读；另一方面，虽然垮网络写不可避免，但也可以通过控制手段使得资源消耗控制在一个限定范围，HBase在这方面也参考fb也做了一些工作：\n\n### **Compaction BandWidth Limit**\n\n原理其实和Limit Compaction Speed思路基本一致，它主要涉及两个参数：compactBwLimit和numOfFilesDisableCompactLimit，作用分别如下：\n\n1. compactBwLimit：一次compaction的最大带宽使用量，如果compaction所使用的带宽高于该值，就会强制令其sleep一段时间\n\n2. numOfFilesDisableCompactLimit：很显然，在写请求非常大的情况下，限制compaction带宽的使用量必然会导致HFile堆积，进而会影响到读请求响应延时。因此该值意义就很明显，一旦store中hfile数量超过该设定值，带宽限制就会失效。","source":"_posts/hbase/hbase的HFile合并.md","raw":"---\ntitle: hbase的HFile合并\ndate: 2017-09-21 21:24:35\ntags:\n- hbase\ncategories:\n- 大数据\n---\n\n了解HBase的童鞋都知道，HBase是一种Log-Structured Merge Tree架构模式，用户数据写入先写WAL，再写缓存，满足一定条件后缓存数据会执行flush操作真正落盘，形成一个数据文件HFile。随着数据写入不断增多，flush次数也会不断增多，进而HFile数据文件就会越来越多。然而，太多数据文件会导致数据查询IO次数增多，因此HBase尝试着不断对这些文件进行合并，这个合并过程称为Compaction。\n\nCompaction会从一个region的一个store中选择一些hfile文件进行合并。合并说来原理很简单，先从这些待合并的数据文件中读出KeyValues，再按照由小到大排列后写入一个新的文件中。之后，这个新生成的文件就会取代之前待合并的所有文件对外提供服务。HBase根据合并规模将Compaction分为了两类：MinorCompaction和MajorCompaction\n\n- Minor Compaction是指选取一些小的、相邻的StoreFile将他们合并成一个更大的StoreFile，在这个过程中不会处理已经Deleted或Expired的Cell。一次Minor Compaction的结果是更少并且更大的StoreFile。\n- Major Compaction是指将所有的StoreFile合并成一个StoreFile，这个过程还会清理三类无意义数据：被删除的数据、TTL过期数据、版本号超过设定版本号的数据。另外，一般情况下，Major Compaction时间会持续比较长，整个过程会消耗大量系统资源，对上层业务有比较大的影响。因此线上业务都会将关闭自动触发Major Compaction功能，改为手动在业务低峰期触发。\n\n### **Compaction作用 | 副作用**\n\n上文提到，随着hfile文件数不断增多，一次查询就可能会需要越来越多的IO操作，延迟必然会越来越大，如下图一所示，随着数据写入不断增加，文件数不断增多，读取延时也在不断变大。而执行compaction会使得文件数基本稳定，进而IO Seek次数会比较稳定，延迟就会稳定在一定范围。然而，compaction操作重写文件会带来很大的带宽压力以及短时间IO压力。因此可以认为，Compaction就是使用短时间的IO消耗以及带宽消耗换取后续查询的低延迟。从图上来看，就是延迟有很大的毛刺，但总体趋势基本稳定不变，见下图二。\n\n![11](http://hbasefly.com/wp-content/uploads/2016/07/11.png)\n\n![22](http://hbasefly.com/wp-content/uploads/2016/07/22.png)\n\n为了换取后续查询的低延迟，除了短时间的读放大之外，Compaction对写入也会有很大的影响。我们首先假设一个现象：当写请求非常多，导致不断生成HFile，但compact的速度远远跟不上HFile生成的速度，这样就会使HFile的数量会越来越多，导致读性能急剧下降。为了避免这种情况，在HFile的数量过多的时候会限制写请求的速度：在每次执行MemStore flush的操作前，如果HStore的HFile数超过hbase.hstore.blockingStoreFiles （默认7），则会阻塞flush操作hbase.hstore.blockingWaitTime时间，在这段时间内，如果compact操作使得HStore文件数下降到回这个值，则停止阻塞。另外阻塞超过时间后，也会恢复执行flush操作。这样做就可以有效地控制大量写请求的速度，但同时这也是影响写请求速度的主要原因之一。\n\n可见，Compaction会使得数据读取延迟一直比较平稳，但付出的代价是大量的读延迟毛刺和一定的写阻塞。\n\n### Compaction流程\n\n了解了一定的背景知识后，接下来需要从全局角度对Compaction进行了解。整个Compaction始于特定的触发条件，比如flush操作、周期性地Compaction检查操作等。一旦触发，HBase会将该Compaction交由一个独立的线程处理，该线程首先会从对应store中选择合适的hfile文件进行合并，这一步是整个Compaction的核心，选取文件需要遵循很多条件，比如文件数不能太多、不能太少、文件大小不能太大等等，最理想的情况是，选取那些承载IO负载重、文件小的文件集，实际实现中，HBase提供了多个文件选取算法：RatioBasedCompactionPolicy、ExploringCompactionPolicy和StripeCompactionPolicy等，用户也可以通过特定接口实现自己的Compaction算法；选出待合并的文件后，HBase会根据这些hfile文件总大小挑选对应的线程池处理，最后对这些文件执行具体的合并操作。可以通过下图简单地梳理上述流程：\n\n![33](http://hbasefly.com/wp-content/uploads/2016/07/33.png)\n\n#### **触发时机**\n\nHBase中可以触发compaction的因素有很多，最常见的因素有这么三种：Memstore Flush、后台线程周期性检查、手动触发。\n\n\\1. Memstore Flush: 应该说compaction操作的源头就来自flush操作，memstore flush会产生HFile文件，文件越来越多就需要compact。因此在每次执行完Flush操作之后，都会对当前Store中的文件数进行判断，一旦文件数＃ > ，就会触发compaction。需要说明的是，compaction都是以Store为单位进行的，而在Flush触发条件下，整个Region的所有Store都会执行compact，所以会在短时间内执行多次compaction。\n\n\\2. 后台线程周期性检查：后台线程CompactionChecker定期触发检查是否需要执行compaction，检查周期为：hbase.server.thread.wakefrequency*hbase.server.compactchecker.interval.multiplier。和flush不同的是，该线程优先检查文件数＃是否大于，一旦大于就会触发compaction。如果不满足，它会接着检查是否满足major compaction条件，简单来说，如果当前store中hfile的最早更新时间早于某个值mcTime，就会触发major compaction，HBase预想通过这种机制定期删除过期数据。上文mcTime是一个浮动值，浮动区间默认为［7-7*0.2，7+7*0.2］，其中7为hbase.hregion.majorcompaction，0.2为hbase.hregion.majorcompaction.jitter，可见默认在7天左右就会执行一次major compaction。用户如果想禁用major compaction，只需要将参数hbase.hregion.majorcompaction设为0\n\n\\3. 手动触发：一般来讲，手动触发compaction通常是为了执行major compaction，原因有三，其一是因为很多业务担心自动major compaction影响读写性能，因此会选择低峰期手动触发；其二也有可能是用户在执行完alter操作之后希望立刻生效，执行手动触发major compaction；其三是HBase管理员发现硬盘容量不够的情况下手动触发major compaction删除大量过期数据；无论哪种触发动机，一旦手动触发，HBase会不做很多自动化检查，直接执行合并。\n\n#### **选择合适HFile合并**\n\n选择合适的文件进行合并是整个compaction的核心，因为合并文件的大小以及其当前承载的IO数直接决定了compaction的效果。最理想的情况是，这些文件承载了大量IO请求但是大小很小，这样compaction本身不会消耗太多IO，而且合并完成之后对读的性能会有显著提升。然而现实情况可能大部分都不会是这样，在0.96版本和0.98版本，分别提出了两种选择策略，在充分考虑整体情况的基础上选择最佳方案。无论哪种选择策略，都会首先对该Store中所有HFile进行一一排查，排除不满足条件的部分文件：\n\n\\1. 排除当前正在执行compact的文件及其比这些文件更新的所有文件（SequenceId更大）\n\n\\2. 排除某些过大的单个文件，如果文件大小大于hbase.hzstore.compaction.max.size（默认Long最大值），则被排除，否则会产生大量IO消耗\n\n经过排除的文件称为候选文件，HBase接下来会再判断是否满足major compaction条件，如果满足，就会选择全部文件进行合并。判断条件有下面三条，只要满足其中一条就会执行major compaction：\n\n\\1. 用户强制执行major compaction\n\n2. 长时间没有进行compact（CompactionChecker的判断条件2）且候选文件数小于hbase.hstore.compaction.max（默认10）\n\n\\3. Store中含有Reference文件，Reference文件是split region产生的临时文件，只是简单的引用文件，一般必须在compact过程中删除\n\n如果不满足major compaction条件，就必然为minor compaction，HBase主要有两种minor策略：RatioBasedCompactionPolicy和ExploringCompactionPolicy，下面分别进行介绍：\n\n**RatioBasedCompactionPolicy**\n\n从老到新逐一扫描所有候选文件，满足其中条件之一便停止扫描：\n\n（1）当前文件大小 < 比它更新的所有文件大小总和 * ratio，其中ratio是一个可变的比例，在高峰期时ratio为1.2，非高峰期为5，也就是非高峰期允许compact更大的文件。那什么时候是高峰期，什么时候是非高峰期呢？用户可以配置参数hbase.offpeak.start.hour和hbase.offpeak.end.hour来设置高峰期\n\n（2）当前所剩候选文件数 <= hbase.store.compaction.min（默认为3）\n\n停止扫描后，待合并文件就选择出来了，即为当前扫描文件+比它更新的所有文件\n\n**ExploringCompactionPolicy**\n\n该策略思路基本和RatioBasedCompactionPolicy相同，不同的是，Ratio策略在找到一个合适的文件集合之后就停止扫描了，而Exploring策略会记录下所有合适的文件集合，并在这些文件集合中寻找最优解。最优解可以理解为：待合并文件数最多或者待合并文件数相同的情况下文件大小较小，这样有利于减少compaction带来的IO消耗。具体流程戳[这里](http://my.oschina.net/u/220934/blog/363270)\n\n需要注意的是，Ratio策略是0.94版本的默认策略，而0.96版本之后默认策略就换为了Exploring策略，在cloudera博文[《what-are-hbase-compactions》](http://blog.cloudera.com/blog/2013/12/what-are-hbase-compactions/)中，作者给出了一个两者的简单性能对比，基本可以看出后者在节省IO方面会有10%左右的提升：\n\n![44](http://hbasefly.com/wp-content/uploads/2016/07/44.png)\n\n截止到此，HBase基本上就选择出来了待合并的文件集合，后续通过挑选合适的处理线程，就会对这些文件进行真正的合并 。\n\n#### **挑选合适的线程池**\n\nHBase实现中有一个专门的线程CompactSplitThead负责接收compact请求以及split请求，而且为了能够独立处理这些请求，这个线程内部构造了多个线程池：largeCompactions、smallCompactions以及splits等，其中splits线程池负责处理所有的split请求，largeCompactions和smallCompaction负责处理所有的compaction请求，其中前者用来处理大规模compaction，后者处理小规模compaction。这里需要明白三点：\n\n\\1. 上述设计目的是为了能够将请求独立处理，提供系统的处理性能。\n\n\\2. 哪些compaction应该分配给largeCompactions处理，哪些应该分配给smallCompactions处理？是不是Major Compaction就应该交给largeCompactions线程池处理？不对。这里有个分配原则：待compact的文件总大小如果大于值throttlePoint（可以通过参数hbase.regionserver.thread.compaction.throttle配置，默认为2.5G），分配给largeCompactions处理，否则分配给smallCompactions处理。\n\n\\3. largeCompactions线程池和smallCompactions线程池默认都只有一个线程，用户可以通过参数hbase.regionserver.thread.compaction.large和hbase.regionserver.thread.compaction.small进行配置\n\n#### **执行HFile文件合并**\n\n上文一方面选出了待合并的HFile集合，一方面也选出来了合适的处理线程，万事俱备，只欠最后真正的合并。合并流程说起来也简单，主要分为如下几步：\n\n\\1. 分别读出待合并hfile文件的KV，并顺序写到位于./tmp目录下的临时文件中\n\n\\2. 将临时文件移动到对应region的数据目录\n\n\\3. 将compaction的输入文件路径和输出文件路径封装为KV写入WAL日志，并打上compaction标记，最后强制执行sync\n\n\\4. 将对应region数据目录下的compaction输入文件全部删除\n\n上述四个步骤看起来简单，但实际是很严谨的，具有很强的容错性和完美的幂等性：\n\n\\1. 如果RS在步骤2之前发生异常，本次compaction会被认为失败，如果继续进行同样的compaction，上次异常对接下来的compaction不会有任何影响，也不会对读写有任何影响。唯一的影响就是多了一份多余的数据。\n\n\\2. 如果RS在步骤2之后、步骤3之前发生异常，同样的，仅仅会多一份冗余数据。\n\n\\3. 如果在步骤3之后、步骤4之前发生异常，RS在重新打开region之后首先会从WAL中看到标有compaction的日志，因为此时输入文件和输出文件已经持久化到HDFS，因此只需要根据WAL移除掉compaction输入文件即可\n\n\n\n\n\ncompaction的核心作用是通过合并大量小文件为一个大文件来减少hfile的总数量，进而保证读延迟的稳定。合并文件首先是读出所有小文件的KVs，再写入同一个大文件，这个过程会带来严重的IO压力和带宽压力，对整个系统的读请求和写请求带来不同程度的影响。\n\n因此HBase对于compaction的设计总是会追求一个平衡点，一方面需要保证compaction的基本效果，另一方面又不会带来严重的IO压力。然而，并没有一种设计策略能够适用于所有应用场景或所有数据集。在意识到这样的问题之后，HBase就希望能够提供一种机制可以在不同业务场景下针对不同设计策略进行测试，另一方面也可以让用户针对自己的业务场景选择合适的compaction策略。因此，在0.96版本中HBase对架构进行了一定的调整，一方面提供了Compaction插件接口，用户只需要实现这些特定的接口，就可以根据自己的应用场景以及数据集定制特定的compaction策略。另一方面，0.96版本之后Compaction可以支持table/cf粒度的策略设置，使得用户可以根据应用场景为不同表/列族选择不同的compaction策略，比如：\n\n```\nalter ’table1’ , CONFIGURATION => {‘hbase.store.engine.class’ => ‘org.apache.hadoop.hbase.regionserver.StripStoreEngine’, … } \n```\n\n上述两方面的调整为compaction的改进和优化提供了最基本的保障，同时提出了一个非常重要的理念：compaction到底选择什么样的策略需要根据不同的业务场景、不同数据集特征进行确定。那接下来就根据不同的应用场景介绍几种不同的compaction策略。\n\n在介绍具体的compaction策略之前，还是有必要对优化compaction的共性特征进行提取，总结起来有如下几个方面：\n\n\\1. 减少参与compaction的文件数：这个很好理解，实现起来却比较麻烦，首先需要将文件根据rowkey、version或其他属性进行分割，再根据这些属性挑选部分重要的文件参与合并；另一方面，尽量不要合并那些大文件，减少参与合并的文件数。\n\n2. 不要合并那些不需要合并的文件：比如OpenTSDB应用场景下的老数据，这些数据基本不会查询到，因此不进行合并也不会影响查询性能\n\n\\3. 小region更有利于compaction：大region会生成大量文件，不利于compaction；相反，小region只会生成少量文件，这些文件合并不会引起很大的IO放大\n\n接下来就介绍几个典型的compaction策略以及其适应的应用场景：\n\n### **FIFO Compaction（HBASE-14468）**\n\nFIFO Compaction策略主要参考了[rocksdb的实现](https://github.com/facebook/rocksdb/wiki/FIFO-compaction-style)，它会选择那些过期的数据文件，即该文件内所有数据都已经过期。因此，对应业务的列族必须设置TTL，否则肯定不适合该策略。需要注意的是，该策略只做这么一件事情：收集所有已经过期的文件并删除。这样的应用场景主要包括：\n\n\\1. 大量短时间存储的原始数据，比如推荐业务，上层业务只需要最近时间内用户的行为特征，利用这些行为特征进行聚合为用户进行推荐。再比如Nginx日志，用户只需要存储最近几天的日志，方便查询某个用户最近一段时间的操作行为等等\n\n\\2. 所有数据能够全部加载到block cache（RAM/SSD），假如HBase有1T大小的SSD作为block cache，理论上就完全不需要做合并，因为所有读操作都是内存操作。\n\n因为FIFO Compaction只是收集所有过期的数据文件并删除，并没有真正执行重写（几个小文件合并成大文件），因此不会消耗任何CPU和IO资源，也不会从block cache中淘汰任何热点数据。所以，无论对于读还是写，该策略都会提升吞吐量、降低延迟。\n\n开启FIFO Compaction（表设置&列族设置）\n\n```\nHTableDescriptor desc = new HTableDescriptor(tableName);\n    desc.setConfiguration(DefaultStoreEngine.DEFAULT_COMPACTION_POLICY_CLASS_KEY, \n      FIFOCompactionPolicy.class.getName());\n```\n\n```\nHColumnDescriptor desc = new HColumnDescriptor(family);\n    desc.setConfiguration(DefaultStoreEngine.DEFAULT_COMPACTION_POLICY_CLASS_KEY, \n      FIFOCompactionPolicy.class.getName());\n```\n\n### **Tier-Based Compaction（HBASE-7055）（HBASE-14477）**\n\n之前所讲到的所有‘文件选取策略’实际上都不够灵活，基本上没有考虑到热点数据的情况。然而现实业务中，有很大比例的业务都存在明显的热点数据，而其中最常见的情况是：最近写入到的数据总是最有可能被访问到，而老数据被访问到的频率就相对比较低。按照之前的文件选择策略，并没有对新文件和老文件进行一定的‘区别对待’，每次compaction都有可能会有很多老文件参与合并，这必然会影响compaction效率，却对降低读延迟没有太大的帮助。\n\n针对这种情况，HBase社区借鉴Facebook HBase分支的解决方案，引入了Tier-Based Compaction。这种方案会根据候选文件的新老程度将其分为多个不同的等级，每个等级都有对应等级的参数，比如参数Compation Ratio，表示该等级文件选择时的选择几率，Ratio越大，该等级的文件越有可能被选中参与Compaction。而等级数、每个等级参数都可以通过CF属性在线更新。\n\n可见，Tier-Based Compaction方案通过引入时间等级和Compaction Ratio等概念，使得Compaction更加灵活，不同业务场景只需要调整参数就可以达到更好的Compaction效率。目前HBase计划在2.0.0版本发布基于时间划分等级的实现方式－Date Tierd Compaction Policy，后续我们也重点基于该方案进行介绍。\n\n该方案的具体实现思路，HBase更多地参考了Cassandra的实现方案：基于时间窗的时间概念。如下图所示，时间窗的大小可以进行配置，其中参数base_time_seconds代表初始化时间窗的大小，默认为1h，表示最近一小时内flush的文件数据都会落入这个时间窗内，所有想读到最近一小时数据请求只需要读取这个时间窗内的文件即可。后面的时间窗窗口会越来越大，另一个参数max_age_days表示比其更老的文件不会参与compaction。\n\n![1](http://hbasefly.com/wp-content/uploads/2016/07/1-1.png)\n\n![312737.png](file://c:/Users/hzfanxinxin/AppData/Local/YNote/data/hzfanxinxin@corp.netease.com/1326b0125fb44c708cc9788ca161981f/312737.png)\n\n上图所示，时间窗随着时间推移朝右移动，图一中没有任何时间窗包含4个（可以通过参数min_thresold配置）文件，因此compaction不会被触发。随着时间推移来到图二所示状态，此时就有一个时间窗包含了4个HFile文件，compaction就会被触发，这四个文件就会被合并为一个大文件。\n\n对比上文说到的分级策略以及Compaction Ratio参数，Cassandra的实现方案中通过设置多个时间窗来实现分级，时间窗的窗口大小类似于Compaction Ratio参数的作用，可以通过调整时间窗的大小来调整不同时间窗文件选择的优先级，比如可以将最右边的时间窗窗口调大，那新文件被选择参与Compaction的概率就会大大增加。然而，这个方案里面并没有类似于当前HBase中的Major Compaction策略来实现过期文件清理的功能，只能借助于TTL来主动清理过期的文件，比如这个文件中所有数据都过期了，就可以将这个文件清理掉。\n\n因此，我们可以总结得到使用Date Tierd Compaction Policy需要遵守的原则：\n\n\\1. 特别适合使用的场景：时间序列数据，默认使用TTL删除。类似于“获取最近一小时／三小时／一天”场景，同时不会执行delete操作。最典型的例子就是基于Open-TSDB的监控系统，如下图所示：\n\n![2](http://hbasefly.com/wp-content/uploads/2016/07/2-1.png)\n\n![372163.png](file://c:/Users/hzfanxinxin/AppData/Local/YNote/data/hzfanxinxin@corp.netease.com/5f2126df4edc4a69a3ec222662a25863/372163.png)\n\n\\2. 比较适合的应用场景：时间序列数据，但是会有全局数据的更新操作以及少部分的删除操作。\n\n\\3. 不适合的应用场景：非时间序列数据，或者大量的更新数据更新操作和删除操作。\n\n### **Stripe Compaction （HBASE-7667）**\n\n通常情况下，major compaction都是无法绕过的，很多业务都会执行delete/update操作，并设置TTL和Version，这样就需要通过执行major compaction清理被删除的数据以及过期版本数据、过期TTL数据。然而，接触过HBase的童鞋都知道，major compaction是一个特别昂贵的操作，会消耗大量系统资源，而且执行一次可能会持续几个小时，严重影响业务应用。因此，一般线上都会选择关闭major compaction自动触发，而是选择在业务低峰期的时候手动触发。为了彻底消除major compaction所带来的影响，hbase社区提出了strip compaction方案。\n\n其实，解决major compaction的最直接办法是减少region的大小，最好整个集群都是由很多小region组成，这样参与compaction的文件总大小就必然不会太大。可是，region设置小会导致region数量很多，这一方面会导致hbase管理region的开销很大，另一方面，region过多也要求hbase能够分配出来更多的内存作为memstore使用，否则有可能导致整个regionserver级别的flush，进而引起长时间的写阻塞。因此单纯地通过将region大小设置过小并不能本质解决问题。\n\n#### **Level Compaction**\n\n此时，社区开发者将目光转向了leveldb的compaction策略：level compaction。level compaction设计思路是将store中的所有数据划分为很多层，每一层都会有一部分数据，如下图所示：\n\n![3](http://hbasefly.com/wp-content/uploads/2016/07/3-1.png)\n\n![663348.png](file://c:/Users/hzfanxinxin/AppData/Local/YNote/data/hzfanxinxin@corp.netease.com/273f13693df9498eaa6d8af45f25f41d/663348.png)\n\n\\1. 数据组织形式不再按照时间前后进行组织，而是按照KeyRange进行组织，每个KeyRange中会包含多个文件，这些文件所有数据的Key必须分布在同一个范围。比如Key分布在Key0~KeyN之间的所有数据都会落在第一个KeyRange区间的文件中，Key分布在KeyN+1~KeyT之间的所有数据会分布在第二个区间的文件中，以此类推。\n\n\\2. 整个数据体系会被划分为很多层，最上层（Level 0）表示最新数据，最下层（Level 6）表示最旧数据。每一层都由大量KeyRange块组成（Level 0除外），KeyRange之间没有Key重合。而且层数越大，对应层的每个KeyRange块大小越大，下层KeyRange块大小是上一层大小的10倍。图中range颜色越深，对应的range块越大。\n\n\\3. 数据从Memstore中flush之后，会首先落入Level 0，此时落入Level 0的数据可能包含所有可能的Key。此时如果需要执行compaction，只需要将Level 0中的KV一个一个读出来，然后按照Key的分布分别插入Level 1中对应KeyRange块的文件中，如果此时刚好Level 1中的某个KeyRange块大小超过了一定阈值，就会继续往下一层合并。\n\n\\4. level compaction依然会有major compaction的概念，发生major compaction只需要将部分Range块内的文件执行合并就可以，而不需要合并整个region内的数据文件。\n\n可见，这种compaction在合并的过程中，从上到下只需要部分文件参与，而不需要对所有文件执行compaction操作。另外，level compaction还有另外一个好处，对于很多‘只读最近写入数据’的业务来说，大部分读请求都会落到level 0，这样可以使用SSD作为上层level存储介质，进一步优化读。然而，这种compaction因为level层数太多导致compaction的次数明显增多，经过测试，发现这种compaction并没有对IO利用率有任何提升。\n\n#### **Stripe Compaction 实现**\n\n虽然原生的level compaction并不适用于HBase，但是这种compaction的思想却激发了HBaser的灵感，再结合之前提到的小region策略，就形成了本节的主角－stripe compaction。同level compaction相同，stripe compaction会将整个store中的文件按照Key划分为多个Range，在这里称为stripe，stripe的数量可以通过参数设定，相邻的stripe之间key不会重合。实际上在概念上来看这个stripe类似于sub-region的概念，即将一个大region切分成了很多小的sub-region。\n\n随着数据写入，memstore执行flush之后形成hfile，这些hfile并不会马上写入对应的stripe，而是放到一个称为L0的地方，用户可以配置L0可以放置hfile的数量。一旦L0放置的文件数超过设定值，系统就会将这些hfile写入对应的stripe：首先读出hfile的KVs，再根据KV的key定位到具体的stripe，将该KV插入对应stripe的文件中即可，如下图所示。之前说过stripe就是一个个小的region，所以在stripe内部，依然会像正常region一样执行minor compaction和major compaction，可以预想到，stripe内部的major compaction并不会太多消耗系统资源。另外，数据读取也很简单，系统可以根据对应的Key查找到对应的stripe，然后在stripe内部执行查找，因为stripe内数据量相对很小，所以也会一定程度上提升数据查找性能。\n\n![4](http://hbasefly.com/wp-content/uploads/2016/07/4-1.png)\n\n![884122.png](file://c:/Users/hzfanxinxin/AppData/Local/YNote/data/hzfanxinxin@corp.netease.com/d851e63ac1d943bcab7c3f76db6fdbde/884122.png)\n\n官方对stripe compaction进行了测试，给出的测试结果如下：\n\n![5](http://hbasefly.com/wp-content/uploads/2016/07/5-1.png)\n\n![532361.png](file://c:/Users/hzfanxinxin/AppData/Local/YNote/data/hzfanxinxin@corp.netease.com/d6bca64dbb9f4aaebc430c6801845c9c/532361.png)\n\n上图主要测定了在不同的stripe数量以及不同的L0数量下的读写延迟对比情况，参考对照组可以看出，基本上任何配置下的读响应延迟都有所降低，而写响应延迟却有所升高。\n\n![6](http://hbasefly.com/wp-content/uploads/2016/07/6-1.png)\n\n![882584.png](file://c:/Users/hzfanxinxin/AppData/Local/YNote/data/hzfanxinxin@corp.netease.com/d2511efb2f8b4ea29edcd323fdf8bfb3/882584.png)\n\n上图是默认配置和12-stripes配置下读写稳定性测试，其中两条蓝线分别表示默认情况下的读写延迟曲线，而两条红线表示strips情况下读写延迟曲线，可以明显看出来，无论读还是写，12-stripes配置下的稳定性都明显好于默认配置，不会出现明显的卡顿现象。\n\n到此为止，我们能够看出来stripe compaction设计上的高明之处，同时通过实验数据也可以明显看出其在读写稳定性上的卓越表现。然而，和任何一种compaction机制一样，stripe compaction也有它特别擅长的业务场景，也有它并不擅长的业务场景。下面是两种stripe compaction比较擅长的业务场景：\n\n\\1. 大Region。小region没有必要切分为stripes，一旦切分，反而会带来额外的管理开销。一般默认如果region大小小于2G，就不适合使用stripe compaction。\n\n\\2. RowKey具有统一格式，stripe compaction要求所有数据按照Key进行切分，切分为多个stripe。如果rowkey不具有统一格式的话，无法进行切分。\n\n------\n\n上述几种策略都是根据不同的业务场景设置对应的文件选择策略，核心都是减少参与compaction的文件数，缩短整个compaction执行的时间，间接降低compaction的IO放大效应，减少对业务读写的延迟影响。然而，如果不对Compaction执行阶段的读写吞吐量进行限制的话也会引起短时间大量系统资源消耗，影响用户业务延迟。HBase社区也意识到了这个问题，也提出了一定的应对策略：\n\n### **Limit Compaction Speed**\n\n该优化方案通过感知Compaction的压力情况自动调节系统的Compaction吞吐量，在压力大的时候降低合并吞吐量，压力小的时候增加合并吞吐量。基本原理为：\n\n\\1. 在正常情况下，用户需要设置吞吐量下限参数“hbase.hstore.compaction.throughput.lower.bound”(默认10MB/sec) 和上限参数“hbase.hstore.compaction.throughput.higher.bound”(默认20MB/sec)，而hbase实际会工作在吞吐量为lower + (higer – lower) * ratio的情况下，其中ratio是一个取值范围在0到1的小数，它由当前store中待参与compation的file数量决定，数量越多，ratio越小，反之越大。\n\n\\2. 如果当前store中hfile的数量太多，并且超过了参数blockingFileCount，此时所有写请求就会阻塞等待compaction完成，这种场景下上述限制会自动失效。\n\n截至目前，我们一直都在关注Compaction带来的IO放大效应，然而在某些情况下Compaction还会因为大量消耗带宽资源从而严重影响其他业务。为什么Compaction会大量消耗带宽资源呢？主要有两点原因：\n\n\\1. 正常请求下，compaction尤其是major compaction会将大量数据文件合并为一个大HFile，读出所有数据文件的KVs，然后重新排序之后写入另一个新建的文件。如果待合并文件都在本地，那么读就是本地读，不会出现垮网络的情况。但是因为数据文件都是三副本，因此写的时候就会垮网络执行，必然会消耗带宽资源。\n\n\\2. 原因1的前提是所有待合并文件都在本地的情况，那在有些场景下待合并文件有可能并不全在本地，即本地化率没有达到100%，比如执行过balance之后就会有很多文件并不在本地。这种情况下读文件的时候就会垮网络读，如果是major compaction，必然也会大量消耗带宽资源。\n\n可以看出来，垮网络读是可以通过一定优化避免的，而垮网络写却是不可能避免的。因此优化Compaction带宽消耗，一方面需要提升本地化率（一个优化专题，在此不详细说明），减少垮网络读；另一方面，虽然垮网络写不可避免，但也可以通过控制手段使得资源消耗控制在一个限定范围，HBase在这方面也参考fb也做了一些工作：\n\n### **Compaction BandWidth Limit**\n\n原理其实和Limit Compaction Speed思路基本一致，它主要涉及两个参数：compactBwLimit和numOfFilesDisableCompactLimit，作用分别如下：\n\n1. compactBwLimit：一次compaction的最大带宽使用量，如果compaction所使用的带宽高于该值，就会强制令其sleep一段时间\n\n2. numOfFilesDisableCompactLimit：很显然，在写请求非常大的情况下，限制compaction带宽的使用量必然会导致HFile堆积，进而会影响到读请求响应延时。因此该值意义就很明显，一旦store中hfile数量超过该设定值，带宽限制就会失效。","slug":"hbase/hbase的HFile合并","published":1,"updated":"2018-09-12T03:03:21.815Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfngh001wwlkvw2p4phbo"},{"title":"hbase的RegionServer定位","date":"2017-09-13T15:48:56.000Z","_content":"\n# hbase的RegionServer定位 \n\n### Hbase 使用三层类似B+树的结构来保存region位置：\n\n1. 第一层是保存zookeeper里面的文件，它持有root region的位置。\n2. 第二层root region是.META.表的第一个region其中保存了.META.z表其它region的位置。通过root region，我们就可以访问.META.表的数据。\n3. .META.是第三层，它是一个特殊的表，保存了Hbase中所有数据表的region 位置信息。\n\n### -ROOT- 和 .META. 表\n\n- -ROOT-表：记录了.META.表对应的HRS信息，**-ROOT-表永远不会被split，只有一个Region**。\n\n- ZK中保存了-ROOT-表对应的HRS位置，默认的路径是 \"/hbase/root-region-server\"\n\n- .META.表：记录了用户表对应的HRS信息，由于.META.表太大，会被切分成多个HR，存储在不同的HRS中。\n\n- 读取数据的流程：ZooKeeper --> -ROOT-(单个Region) --> .META.(多个) --> HRS --> 用户Table。3次网络操作\n\n  读请求处理过程(无需借助HMaster)\n\n- client会将查询过的位置信息保存缓存起来，缓存不会主动失效，因此如果client上的缓存全部失效，则需要进行6次网络来回，才能定位到正确的region(其中三次用来发现缓存失效，另外三次用来获取位置信息)。\n\n\n\n 在HBase中，大部分的操作都是在RegionServer完成的，Client端想要插入，删除，查询数据都需要先找到相应的RegionServer。什么叫相应的RegionServer？就是管理你要操作的那个Region的RegionServer。Client本身并不知道哪个RegionServer管理哪个Region，那么它是如何找到相应的RegionServer的？本文就是在研究源码的基础上揭秘这个过程。\n\n在前面的文章“HBase存储架构”中我们已经讨论了HBase基本的存储架构。在此基础上我们引入两个特殊的概念：-ROOT-和.META.。这是什么？它们是HBase的两张内置表，从存储结构和操作方法的角度来说，它们和其他HBase的表没有任何区别，你可以认为这就是两张普通的表，对于普通表的操作对它们都适用。它们与众不同的地方是HBase用它们来存贮一个重要的系统信息——Region的分布情况以及每个Region的详细信息。\n\n好了，既然我们前面说到**-ROOT-**和**.META.**可以被看作是两张普通的表，那么它们和其他表一样就应该有自己的表结构。没错，它们有自己的表结构，并且这两张表的表结构是相同的，在分析源码之后我将这个表结构大致的画了出来：\n\n**-ROOT-和.META.表结构**\n\n![-ROOT-和.META.表结构](http://dl.iteye.com/upload/picture/pic/124503/5120c136-5b0e-3d02-9ebc-f7ed08800532.jpg)\n\n我们来仔细分析一下这个结构，每条Row记录了一个Region的信息。\n\n首先是RowKey，RowKey由三部分组成：TableName, StartKey 和 TimeStamp。RowKey存储的内容我们又称之为Region的Name。哦，还记得吗？我们在前面的文章中提到的，用来存放Region的文件夹的名字是RegionName的Hash值，因为RegionName可能包含某些非法字符。现在你应该知道为什么RegionName会包含非法字符了吧，因为StartKey是被允许包含任何值的。将组成RowKey的三个部分用逗号连接就构成了整个RowKey，这里TimeStamp使用十进制的数字字符串来表示的。这里有一个RowKey的例子： \n\nJava代码  [![收藏代码](http://greatwqs.iteye.com/images/icon_star.png)]()\n\n1. Table1,RK10000,12345678  \n\n 然后是表中最主要的Family：info，info里面包含三个Column：regioninfo, server, serverstartcode。其中regioninfo就是Region的详细信息，包括StartKey, EndKey 以及每个Family的信息等等。server存储的就是管理这个Region的RegionServer的地址。\n\n所以当Region被拆分、合并或者重新分配的时候，都需要来修改这张表的内容。\n\n到目前为止我们已经学习了必须的背景知识，下面我们要正式开始介绍Client端寻找RegionServer的整个过程。我打算用一个假想的例子来学习这个过程，因此我先构建了假想的-ROOT-表和.META.表。\n\n我们先来看.META.表，假设HBase中只有两张用户表：Table1和Table2，Table1非常大，被划分成了很多Region，因此在.META.表中有很多条Row用来记录这些Region。而Table2很小，只是被划分成了两个Region，因此在.META.中只有两条Row用来记录。这个表的内容看上去是这个样子的： \n\n**.META.行记录结构**\n\n![.META.行记录结构](http://dl.iteye.com/upload/picture/pic/124499/951c379d-cc22-3ccd-a377-7a24d09ed479.jpg)\n\n现在假设我们要从Table2里面插寻一条RowKey是RK10000的数据。那么我们应该遵循以下步骤：\n\n\\1. 从.META.表里面查询哪个Region包含这条数据。\n\n\\2. 获取管理这个Region的RegionServer地址。\n\n\\3. 连接这个RegionServer, 查到这条数据。\n\n好，我们先来第一步。问题是.META.也是一张普通的表，我们需要先知道哪个RegionServer管理了.META.表，怎么办？有一个方法，我们把管理.META.表的RegionServer的地址放到ZooKeeper上面不久行了，这样大家都知道了谁在管理.META.。\n\n貌似问题解决了，但对于这个例子我们遇到了一个新问题。因为Table1实在太大了，它的Region实在太多了，.META.为了存储这些Region信息，花费了大量的空间，自己也需要划分成多个Region。这就意味着可能有多个RegionServer在管理.META.。怎么办？在ZooKeeper里面存储所有管理.META.的RegionServer地址让Client自己去遍历？HBase并不是这么做的。\n\nHBase的做法是用另外一个表来记录.META.的Region信息，就和.META.记录用户表的Region信息一模一样。这个表就是-ROOT-表。这也解释了为什么-ROOT-和.META.拥有相同的表结构，因为他们的原理是一模一样的。\n\n假设.META.表被分成了两个Region，那么-ROOT-的内容看上去大概是这个样子的：\n\n**-ROOT-行记录结构**\n\n![-ROOT-行记录结构](http://dl.iteye.com/upload/picture/pic/124501/d1f2e0e1-52a2-3946-8a0d-a6c7bda41cff.jpg)\n\n这么一来Client端就需要先去访问-ROOT-表。所以需要知道管理-ROOT-表的RegionServer的地址。这个地址被存在ZooKeeper中。默认的路径是： \n\nJava代码  [![收藏代码](http://greatwqs.iteye.com/images/icon_star.png)]()\n\n1. /hbase/root-region-server  \n\n 等等，如果-ROOT-表太大了，要被分成多个Region怎么办？嘿嘿，HBase认为-ROOT-表不会大到那个程度，因此-ROOT-只会有一个Region，这个Region的信息也是被存在HBase内部的。 \n\n现在让我们从头来过，我们要查询Table2中RowKey是RK10000的数据。整个路由过程的主要代码在org.apache.hadoop.hbase.client.HConnectionManager.TableServers中： \n\nJava代码  [![收藏代码](http://greatwqs.iteye.com/images/icon_star.png)]()\n\n1. private HRegionLocation locateRegion(final byte[] tableName,  \n2. ​        final byte[] row, boolean useCache) throws IOException {  \n3. ​    if (tableName == null || tableName.length == 0) {  \n4. ​        throw new IllegalArgumentException(\"table name cannot be null or zero length\");  \n5. ​    }  \n6. ​    if (Bytes.equals(tableName, ROOT_TABLE_NAME)) {  \n7. ​        synchronized (rootRegionLock) {  \n8. ​            // This block guards against two threads trying to find the root  \n9. ​            // region at the same time. One will go do the find while the  \n10. ​            // second waits. The second thread will not do find.  \n11. ​            if (!useCache || rootRegionLocation == null) {  \n12. ​                this.rootRegionLocation = locateRootRegion();  \n13. ​            }  \n14. ​            return this.rootRegionLocation;  \n15. ​        }  \n16. ​    } else if (Bytes.equals(tableName, META_TABLE_NAME)) {  \n17. ​        return locateRegionInMeta(ROOT_TABLE_NAME, tableName, row, useCache, metaRegionLock);  \n18. ​    } else {  \n19. ​        // Region not in the cache – have to go to the meta RS  \n20. ​        return locateRegionInMeta(META_TABLE_NAME, tableName, row, useCache, userRegionLock);  \n21. ​    }  \n22. }  \n\n 这是一个递归调用的过程： \n\nJava代码  [![收藏代码](http://greatwqs.iteye.com/images/icon_star.png)]()\n\n1. 获取Table2，RowKey为RK10000的RegionServer => 获取.META.，RowKey为Table2,RK10000, 99999999999999的RegionServer => 获取-ROOT-，RowKey为.META.,Table2,RK10000,99999999999999,99999999999999的RegionServer => 获取-ROOT-的RegionServer => 从ZooKeeper得到-ROOT-的RegionServer => 从-ROOT-表中查到RowKey最接近（小于） .META.,Table2,RK10000,99999999999999,99999999999999的一条Row，并得到.META.的RegionServer => 从.META.表中查到RowKey最接近（小于）Table2,RK10000, 99999999999999的一条Row，并得到Table2的RegionServer => 从Table2中查到RK10000的Row  \n\n 到此为止Client完成了路由RegionServer的整个过程，在整个过程中使用了添加“99999999999999”后缀并查找最接近（小于）RowKey的方法。对于这个方法大家可以仔细揣摩一下，并不是很难理解。\n\n最后要提醒大家注意两件事情：\n\n\\1. 在整个路由过程中并没有涉及到MasterServer，也就是说HBase日常的数据操作并不需要MasterServer，不会造成MasterServer的负担。\n\n\\2. Client端并不会每次数据操作都做这整个路由过程，很多数据都会被Cache起来。至于如何Cache，则不在本文的讨论范围之内。\n\n原","source":"_posts/hbase/hbase的RegionServer定位.md","raw":"---\ntitle: hbase的RegionServer定位\ndate: 2017-09-13 23:48:56\ntags:\n- hbase\ncategories:\n- 大数据\n---\n\n# hbase的RegionServer定位 \n\n### Hbase 使用三层类似B+树的结构来保存region位置：\n\n1. 第一层是保存zookeeper里面的文件，它持有root region的位置。\n2. 第二层root region是.META.表的第一个region其中保存了.META.z表其它region的位置。通过root region，我们就可以访问.META.表的数据。\n3. .META.是第三层，它是一个特殊的表，保存了Hbase中所有数据表的region 位置信息。\n\n### -ROOT- 和 .META. 表\n\n- -ROOT-表：记录了.META.表对应的HRS信息，**-ROOT-表永远不会被split，只有一个Region**。\n\n- ZK中保存了-ROOT-表对应的HRS位置，默认的路径是 \"/hbase/root-region-server\"\n\n- .META.表：记录了用户表对应的HRS信息，由于.META.表太大，会被切分成多个HR，存储在不同的HRS中。\n\n- 读取数据的流程：ZooKeeper --> -ROOT-(单个Region) --> .META.(多个) --> HRS --> 用户Table。3次网络操作\n\n  读请求处理过程(无需借助HMaster)\n\n- client会将查询过的位置信息保存缓存起来，缓存不会主动失效，因此如果client上的缓存全部失效，则需要进行6次网络来回，才能定位到正确的region(其中三次用来发现缓存失效，另外三次用来获取位置信息)。\n\n\n\n 在HBase中，大部分的操作都是在RegionServer完成的，Client端想要插入，删除，查询数据都需要先找到相应的RegionServer。什么叫相应的RegionServer？就是管理你要操作的那个Region的RegionServer。Client本身并不知道哪个RegionServer管理哪个Region，那么它是如何找到相应的RegionServer的？本文就是在研究源码的基础上揭秘这个过程。\n\n在前面的文章“HBase存储架构”中我们已经讨论了HBase基本的存储架构。在此基础上我们引入两个特殊的概念：-ROOT-和.META.。这是什么？它们是HBase的两张内置表，从存储结构和操作方法的角度来说，它们和其他HBase的表没有任何区别，你可以认为这就是两张普通的表，对于普通表的操作对它们都适用。它们与众不同的地方是HBase用它们来存贮一个重要的系统信息——Region的分布情况以及每个Region的详细信息。\n\n好了，既然我们前面说到**-ROOT-**和**.META.**可以被看作是两张普通的表，那么它们和其他表一样就应该有自己的表结构。没错，它们有自己的表结构，并且这两张表的表结构是相同的，在分析源码之后我将这个表结构大致的画了出来：\n\n**-ROOT-和.META.表结构**\n\n![-ROOT-和.META.表结构](http://dl.iteye.com/upload/picture/pic/124503/5120c136-5b0e-3d02-9ebc-f7ed08800532.jpg)\n\n我们来仔细分析一下这个结构，每条Row记录了一个Region的信息。\n\n首先是RowKey，RowKey由三部分组成：TableName, StartKey 和 TimeStamp。RowKey存储的内容我们又称之为Region的Name。哦，还记得吗？我们在前面的文章中提到的，用来存放Region的文件夹的名字是RegionName的Hash值，因为RegionName可能包含某些非法字符。现在你应该知道为什么RegionName会包含非法字符了吧，因为StartKey是被允许包含任何值的。将组成RowKey的三个部分用逗号连接就构成了整个RowKey，这里TimeStamp使用十进制的数字字符串来表示的。这里有一个RowKey的例子： \n\nJava代码  [![收藏代码](http://greatwqs.iteye.com/images/icon_star.png)]()\n\n1. Table1,RK10000,12345678  \n\n 然后是表中最主要的Family：info，info里面包含三个Column：regioninfo, server, serverstartcode。其中regioninfo就是Region的详细信息，包括StartKey, EndKey 以及每个Family的信息等等。server存储的就是管理这个Region的RegionServer的地址。\n\n所以当Region被拆分、合并或者重新分配的时候，都需要来修改这张表的内容。\n\n到目前为止我们已经学习了必须的背景知识，下面我们要正式开始介绍Client端寻找RegionServer的整个过程。我打算用一个假想的例子来学习这个过程，因此我先构建了假想的-ROOT-表和.META.表。\n\n我们先来看.META.表，假设HBase中只有两张用户表：Table1和Table2，Table1非常大，被划分成了很多Region，因此在.META.表中有很多条Row用来记录这些Region。而Table2很小，只是被划分成了两个Region，因此在.META.中只有两条Row用来记录。这个表的内容看上去是这个样子的： \n\n**.META.行记录结构**\n\n![.META.行记录结构](http://dl.iteye.com/upload/picture/pic/124499/951c379d-cc22-3ccd-a377-7a24d09ed479.jpg)\n\n现在假设我们要从Table2里面插寻一条RowKey是RK10000的数据。那么我们应该遵循以下步骤：\n\n\\1. 从.META.表里面查询哪个Region包含这条数据。\n\n\\2. 获取管理这个Region的RegionServer地址。\n\n\\3. 连接这个RegionServer, 查到这条数据。\n\n好，我们先来第一步。问题是.META.也是一张普通的表，我们需要先知道哪个RegionServer管理了.META.表，怎么办？有一个方法，我们把管理.META.表的RegionServer的地址放到ZooKeeper上面不久行了，这样大家都知道了谁在管理.META.。\n\n貌似问题解决了，但对于这个例子我们遇到了一个新问题。因为Table1实在太大了，它的Region实在太多了，.META.为了存储这些Region信息，花费了大量的空间，自己也需要划分成多个Region。这就意味着可能有多个RegionServer在管理.META.。怎么办？在ZooKeeper里面存储所有管理.META.的RegionServer地址让Client自己去遍历？HBase并不是这么做的。\n\nHBase的做法是用另外一个表来记录.META.的Region信息，就和.META.记录用户表的Region信息一模一样。这个表就是-ROOT-表。这也解释了为什么-ROOT-和.META.拥有相同的表结构，因为他们的原理是一模一样的。\n\n假设.META.表被分成了两个Region，那么-ROOT-的内容看上去大概是这个样子的：\n\n**-ROOT-行记录结构**\n\n![-ROOT-行记录结构](http://dl.iteye.com/upload/picture/pic/124501/d1f2e0e1-52a2-3946-8a0d-a6c7bda41cff.jpg)\n\n这么一来Client端就需要先去访问-ROOT-表。所以需要知道管理-ROOT-表的RegionServer的地址。这个地址被存在ZooKeeper中。默认的路径是： \n\nJava代码  [![收藏代码](http://greatwqs.iteye.com/images/icon_star.png)]()\n\n1. /hbase/root-region-server  \n\n 等等，如果-ROOT-表太大了，要被分成多个Region怎么办？嘿嘿，HBase认为-ROOT-表不会大到那个程度，因此-ROOT-只会有一个Region，这个Region的信息也是被存在HBase内部的。 \n\n现在让我们从头来过，我们要查询Table2中RowKey是RK10000的数据。整个路由过程的主要代码在org.apache.hadoop.hbase.client.HConnectionManager.TableServers中： \n\nJava代码  [![收藏代码](http://greatwqs.iteye.com/images/icon_star.png)]()\n\n1. private HRegionLocation locateRegion(final byte[] tableName,  \n2. ​        final byte[] row, boolean useCache) throws IOException {  \n3. ​    if (tableName == null || tableName.length == 0) {  \n4. ​        throw new IllegalArgumentException(\"table name cannot be null or zero length\");  \n5. ​    }  \n6. ​    if (Bytes.equals(tableName, ROOT_TABLE_NAME)) {  \n7. ​        synchronized (rootRegionLock) {  \n8. ​            // This block guards against two threads trying to find the root  \n9. ​            // region at the same time. One will go do the find while the  \n10. ​            // second waits. The second thread will not do find.  \n11. ​            if (!useCache || rootRegionLocation == null) {  \n12. ​                this.rootRegionLocation = locateRootRegion();  \n13. ​            }  \n14. ​            return this.rootRegionLocation;  \n15. ​        }  \n16. ​    } else if (Bytes.equals(tableName, META_TABLE_NAME)) {  \n17. ​        return locateRegionInMeta(ROOT_TABLE_NAME, tableName, row, useCache, metaRegionLock);  \n18. ​    } else {  \n19. ​        // Region not in the cache – have to go to the meta RS  \n20. ​        return locateRegionInMeta(META_TABLE_NAME, tableName, row, useCache, userRegionLock);  \n21. ​    }  \n22. }  \n\n 这是一个递归调用的过程： \n\nJava代码  [![收藏代码](http://greatwqs.iteye.com/images/icon_star.png)]()\n\n1. 获取Table2，RowKey为RK10000的RegionServer => 获取.META.，RowKey为Table2,RK10000, 99999999999999的RegionServer => 获取-ROOT-，RowKey为.META.,Table2,RK10000,99999999999999,99999999999999的RegionServer => 获取-ROOT-的RegionServer => 从ZooKeeper得到-ROOT-的RegionServer => 从-ROOT-表中查到RowKey最接近（小于） .META.,Table2,RK10000,99999999999999,99999999999999的一条Row，并得到.META.的RegionServer => 从.META.表中查到RowKey最接近（小于）Table2,RK10000, 99999999999999的一条Row，并得到Table2的RegionServer => 从Table2中查到RK10000的Row  \n\n 到此为止Client完成了路由RegionServer的整个过程，在整个过程中使用了添加“99999999999999”后缀并查找最接近（小于）RowKey的方法。对于这个方法大家可以仔细揣摩一下，并不是很难理解。\n\n最后要提醒大家注意两件事情：\n\n\\1. 在整个路由过程中并没有涉及到MasterServer，也就是说HBase日常的数据操作并不需要MasterServer，不会造成MasterServer的负担。\n\n\\2. Client端并不会每次数据操作都做这整个路由过程，很多数据都会被Cache起来。至于如何Cache，则不在本文的讨论范围之内。\n\n原","slug":"hbase/hbase的RegionServer定位","published":1,"updated":"2018-09-12T03:03:21.815Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfngi001ywlkvhufvk1gk"},{"title":"hbase的WAL详解","date":"2017-09-13T16:12:39.000Z","_content":"\n# hbase的WAL详解\n\nWAL(Write-Ahead Logging)是一种高效的日志算法，基本原理是在数据写入之前首先顺序写入日志，然后再写入缓存，等到缓存写满之后统一落盘。之所以能够提升写性能，是因为WAL将一次随机写转化为了一次顺序写加一次内存写。提升写性能的同时，WAL可以保证数据的可靠性，即在任何情况下数据不丢失。假如一次写入完成之后发生了宕机，即使所有缓存中的数据丢失，也可以通过恢复日志还原出丢失的数据。\n\n<!--more-->\n\n## WAL持久化等级\n\nHBase中可以通过设置WAL的持久化等级决定是否开启WAL机制、以及HLog的落盘方式put.setDurability();持久化等级分为如下四个等级：\n\n1. SKIP_WAL：只写缓存，不写HLog日志。这种方式因为只写内存，因此可以极大的提升写入性能，但是数据有丢失的风险。在实际应用过程中并不建议设置此等级，除非确认不要求数据的可靠性。\n2. ASYNC_WAL：异步将数据写入HLog日志中。\n3. SYNC_WAL：同步将数据写入日志文件中，需要注意的是数据只是被写入文件系统中，并没有真正落盘。\n4. FSYNC_WAL：同步将数据写入日志文件并强制落盘。最严格的日志写入等级，可以保证数据不会丢失，但是性能相对比较差。\n5. USER_DEFAULT：默认如果用户没有指定持久化等级，HBase使用SYNC_WAL等级持久化数据。\n\n## hbase中的WAL操作\n\n- **每个Region Server维护一个Hlog，而不是每个Region一个**。这样不同Region(来自不同table)的日志会混在一起，这样做的目的是不断追加单个文件相对于同时写多个文件而言，可以减少磁盘寻道次数同时也可以减少日志文件，因此可以提高对table的写性能。带来的麻烦是，如果一台Region Server下线，为了恢复其上的Region，需要将Region Server上的log进行拆分，然后分发到其它Region Server上进行恢复\n- 当HRS意外终止后，HMaster会通过ZK感知到，**HMaster根据HR的不同对HLog进行拆分Split，并分配给对应的HR。**领取到这些HLog的HRS在Load HRegion的过程中，发现有历史HLog需要处理，因此会“重做”Replay HLog中的数据到mem Store中，然后Flush到Store File，完成数据恢复\n- HLog存放在HDFS上，会定期回滚产生新的\n- WAL(预写日志)每次更新数据时，都会先将数据记录到提交日志中，然后才会将这些数据写入到内存中的memstore，但是写入达到阈值，会将memstore中数据持久化为HFIle文件刷写到磁盘，之后系统会丢弃对应的提交日志，只保留未持久化到磁盘的数据的提交日志。在系统将数据移出memstore写入磁盘的过程中可以不阻塞系统的读写，会使用一个新的memstore接收写入数据，将满的旧memstore转换成一个storeFile。memstore中的数据时按行键顺序排序的，持久化到磁盘上的时候也是按照这个顺序。\n\n### HLog File\n\n- HBase中WAL的存储格式{HLogKey,WALEdit}，物理上是Hadoop的Sequence File\n\n- HLog文件就是一个普通的Hadoop Sequence File，Sequence File 的Key是HLogKey对象，HLogKey中记录了写入数据的归属信息，除了table和region名字外，同时还包括 sequence number和timestamp，timestamp是“写入时间”，sequence number的起始值为0，或者是最近一次存入文件系统中sequence number。\n\n- HLog Sequece File的Value是HBase的KeyValue对象，即对应HFile中的KeyValue.\n\n  ![image](http://omdq6di7v.bkt.clouddn.com/17-9-14/87066631.jpg)\n\nregion name和table name分别表征该段日志属于哪个region以及哪张表；cluster ids用于将日志复制到集群中其他机器上。\n\n## 参考资料\n\n[HBase － 数据写入流程解析](http://hbasefly.com/2016/03/23/hbase_writer/)","source":"_posts/hbase/hbase的WAL详解.md","raw":"---\ntitle: hbase的WAL详解\ndate: 2017-09-14 00:12:39\ntags:\n- hbase\ncategories:\n- 大数据\n---\n\n# hbase的WAL详解\n\nWAL(Write-Ahead Logging)是一种高效的日志算法，基本原理是在数据写入之前首先顺序写入日志，然后再写入缓存，等到缓存写满之后统一落盘。之所以能够提升写性能，是因为WAL将一次随机写转化为了一次顺序写加一次内存写。提升写性能的同时，WAL可以保证数据的可靠性，即在任何情况下数据不丢失。假如一次写入完成之后发生了宕机，即使所有缓存中的数据丢失，也可以通过恢复日志还原出丢失的数据。\n\n<!--more-->\n\n## WAL持久化等级\n\nHBase中可以通过设置WAL的持久化等级决定是否开启WAL机制、以及HLog的落盘方式put.setDurability();持久化等级分为如下四个等级：\n\n1. SKIP_WAL：只写缓存，不写HLog日志。这种方式因为只写内存，因此可以极大的提升写入性能，但是数据有丢失的风险。在实际应用过程中并不建议设置此等级，除非确认不要求数据的可靠性。\n2. ASYNC_WAL：异步将数据写入HLog日志中。\n3. SYNC_WAL：同步将数据写入日志文件中，需要注意的是数据只是被写入文件系统中，并没有真正落盘。\n4. FSYNC_WAL：同步将数据写入日志文件并强制落盘。最严格的日志写入等级，可以保证数据不会丢失，但是性能相对比较差。\n5. USER_DEFAULT：默认如果用户没有指定持久化等级，HBase使用SYNC_WAL等级持久化数据。\n\n## hbase中的WAL操作\n\n- **每个Region Server维护一个Hlog，而不是每个Region一个**。这样不同Region(来自不同table)的日志会混在一起，这样做的目的是不断追加单个文件相对于同时写多个文件而言，可以减少磁盘寻道次数同时也可以减少日志文件，因此可以提高对table的写性能。带来的麻烦是，如果一台Region Server下线，为了恢复其上的Region，需要将Region Server上的log进行拆分，然后分发到其它Region Server上进行恢复\n- 当HRS意外终止后，HMaster会通过ZK感知到，**HMaster根据HR的不同对HLog进行拆分Split，并分配给对应的HR。**领取到这些HLog的HRS在Load HRegion的过程中，发现有历史HLog需要处理，因此会“重做”Replay HLog中的数据到mem Store中，然后Flush到Store File，完成数据恢复\n- HLog存放在HDFS上，会定期回滚产生新的\n- WAL(预写日志)每次更新数据时，都会先将数据记录到提交日志中，然后才会将这些数据写入到内存中的memstore，但是写入达到阈值，会将memstore中数据持久化为HFIle文件刷写到磁盘，之后系统会丢弃对应的提交日志，只保留未持久化到磁盘的数据的提交日志。在系统将数据移出memstore写入磁盘的过程中可以不阻塞系统的读写，会使用一个新的memstore接收写入数据，将满的旧memstore转换成一个storeFile。memstore中的数据时按行键顺序排序的，持久化到磁盘上的时候也是按照这个顺序。\n\n### HLog File\n\n- HBase中WAL的存储格式{HLogKey,WALEdit}，物理上是Hadoop的Sequence File\n\n- HLog文件就是一个普通的Hadoop Sequence File，Sequence File 的Key是HLogKey对象，HLogKey中记录了写入数据的归属信息，除了table和region名字外，同时还包括 sequence number和timestamp，timestamp是“写入时间”，sequence number的起始值为0，或者是最近一次存入文件系统中sequence number。\n\n- HLog Sequece File的Value是HBase的KeyValue对象，即对应HFile中的KeyValue.\n\n  ![image](http://omdq6di7v.bkt.clouddn.com/17-9-14/87066631.jpg)\n\nregion name和table name分别表征该段日志属于哪个region以及哪张表；cluster ids用于将日志复制到集群中其他机器上。\n\n## 参考资料\n\n[HBase － 数据写入流程解析](http://hbasefly.com/2016/03/23/hbase_writer/)","slug":"hbase/hbase的WAL详解","published":1,"updated":"2018-09-12T03:03:21.816Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfngl0022wlkvg7mlleuh"},{"title":"hbase的memstore","date":"2017-09-14T16:00:56.000Z","_content":"\nMemstore是HBase框架中非常重要的组成部分之一，是HBase能够实现高性能随机读写至关重要的一环。深入理解Memstore的工作原理、运行机制以及相关配置，对hbase集群管理、性能调优都有着非常重要的帮助。\n\n**Memstore 概述**\n\nHBase中，Region是集群节点上最小的数据服务单元，用户数据表由一个或多个Region组成。在Region中每个ColumnFamily的数据组成一个Store。每个Store由一个Memstore和多个HFile组成，如下图所示：\n\n![0](http://hbasefly.com/wp-content/uploads/2016/03/0.png)\n\n之前我们提到，HBase是基于LSM-Tree模型的，所有的数据更新插入操作都首先写入Memstore中（同时会顺序写到日志HLog中），达到指定大小之后再将这些修改操作批量写入磁盘，生成一个新的HFile文件，这种设计可以极大地提升HBase的写入性能；另外，HBase为了方便按照RowKey进行检索，要求HFile中数据都按照RowKey进行排序，Memstore数据在flush为HFile之前会进行一次排序，将数据有序化；还有，根据局部性原理，新写入的数据会更大概率被读取，因此HBase在读取数据的时候首先检查请求的数据是否在Memstore，写缓存未命中的话再到读缓存中查找，读缓存还未命中才会到HFile文件中查找，最终返回merged的一个结果给用户。\n\n可见，Memstore无论是对HBase的写入性能还是读取性能都至关重要。其中flush操作又是Memstore最核心的操作，接下来重点针对Memstore的flush操作进行深入地解析：首先分析HBase在哪些场景下会触发flush，然后结合源代码分析整个flush的操作流程，最后再重点整理总结和flush相关的配置参数，这些参数对于性能调优、问题定位都非常重要。\n\n**Memstore Flush触发条件**\n\nHBase会在如下几种情况下触发flush操作，**需要注意的是MemStore的最小flush单元是HRegion而不是单个MemStore**。可想而知，如果一个HRegion中Memstore过多，每次flush的开销必然会很大，因此我们也建议在进行表设计的时候尽量减少ColumnFamily的个数。\n\n1. Memstore级别限制：当Region中任意一个MemStore的大小达到了上限（hbase.hregion.memstore.flush.size，默认128MB），会触发Memstore刷新。\n2. Region级别限制：当Region中所有Memstore的大小总和达到了上限（hbase.hregion.memstore.block.multiplier * hbase.hregion.memstore.flush.size，默认 2* 128M = 256M），会触发memstore刷新。\n3. Region Server级别限制：当一个Region Server中所有Memstore的大小总和达到了上限（hbase.regionserver.global.memstore.upperLimit ＊ hbase_heapsize，默认 40%的JVM内存使用量），会触发部分Memstore刷新。Flush顺序是按照Memstore由大到小执行，先Flush Memstore最大的Region，再执行次大的，直至总体Memstore内存使用量低于阈值（hbase.regionserver.global.memstore.lowerLimit ＊ hbase_heapsize，默认 38%的JVM内存使用量）。\n4. 当一个Region Server中HLog数量达到上限（可通过参数hbase.regionserver.maxlogs配置）时，系统会选取最早的一个 HLog对应的一个或多个Region进行flush\n5. HBase定期刷新Memstore：默认周期为1小时，确保Memstore不会长时间没有持久化。为避免所有的MemStore在同一时间都进行flush导致的问题，定期的flush操作有20000左右的随机延时。\n6. 手动执行flush：用户可以通过shell命令 flush ‘tablename’或者flush ‘region name’分别对一个表或者一个Region进行flush。\n\n**Memstore Flush流程**\n\n为了减少flush过程对读写的影响，HBase采用了类似于两阶段提交的方式，将整个flush过程分为三个阶段：\n\n1. prepare阶段：遍历当前Region中的所有Memstore，将Memstore中当前数据集kvset做一个快照snapshot，然后再新建一个新的kvset。后期的所有写入操作都会写入新的kvset中，而整个flush阶段读操作会首先分别遍历kvset和snapshot，如果查找不到再会到HFile中查找。prepare阶段需要加一把updateLock对写请求阻塞，结束之后会释放该锁。因为此阶段没有任何费时操作，因此持锁时间很短。\n2. flush阶段：遍历所有Memstore，将prepare阶段生成的snapshot持久化为临时文件，临时文件会统一放到目录.tmp下。这个过程因为涉及到磁盘IO操作，因此相对比较耗时。\n3. commit阶段：遍历所有的Memstore，将flush阶段生成的临时文件移到指定的ColumnFamily目录下，针对HFile生成对应的storefile和Reader，把storefile添加到HStore的storefiles列表中，最后再清空prepare阶段生成的snapshot。\n\n上述flush流程可以通过日志信息查看：\n\n```\n/******* prepare阶段 ********/\n2016-02-04 03:32:41,516 INFO  [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for sentry_sgroup1_data,{\\xD4\\x00\\x00\\x01|\\x00\\x00\\x03\\x82\\x00\\x00\\x00?\\x06\\xDA`\\x13\\xCAE\\xD3C\\xA3:_1\\xD6\\x99:\\x88\\x7F\\xAA_\\xD6[L\\xF0\\x92\\xA6\\xFB^\\xC7\\xA4\\xC7\\xD7\\x8Fv\\xCAT\\xD2\\xAF,1452217805884.572ddf0e8cf0b11aee2273a95bd07879., current region memstore size 128.9 M\n\n/******* flush阶段 ********/\n2016-02-04 03:32:42,423 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1726212642, memsize=128.9 M, hasBloomFilter=true, into tmp file hdfs://hbase1/hbase/data/default/sentry_sgroup1_data/572ddf0e8cf0b11aee2273a95bd07879/.tmp/021a430940244993a9450dccdfdcb91d\n\n/******* commit阶段 ********/\n2016-02-04 03:32:42,464 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://hbase1/hbase/data/default/sentry_sgroup1_data/572ddf0e8cf0b11aee2273a95bd07879/d/021a430940244993a9450dccdfdcb91d, entries=643656, sequenceid=1726212642, filesize=7.1 M\n```\n\n整个flush过程可能涉及到compact操作和split操作，因为过于复杂，在此暂时略过不表。\n\n**Memstore Flush对业务读写的影响**\n\n上文介绍了HBase在什么场景下会触发flush操作以及flush操作的基本流程，想必对于HBase用户来说，最关心的是flush行为会对读写请求造成哪些影响以及如何避免。因为不同触发方式下的flush操作对用户请求影响不尽相同，因此下面会根据flush的不同触发方式分别进行总结，并且会根据影响大小进行归类：\n\n**影响甚微**\n\n正常情况下，大部分Memstore Flush操作都不会对业务读写产生太大影响，比如这几种场景：HBase定期刷新Memstore、手动执行flush操作、触发Memstore级别限制、触发HLog数量限制以及触发Region级别限制等，这几种场景只会阻塞对应Region上的写请求，阻塞时间很短，毫秒级别。\n\n**影响较大**\n\n然而一旦触发Region Server级别限制导致flush，就会对用户请求产生较大的影响。会阻塞所有落在该Region Server上的更新操作，阻塞时间很长，甚至可以达到分钟级别。一般情况下Region Server级别限制很难触发，但在一些极端情况下也不排除有触发的可能，下面分析一种可能触发这种flush操作的场景：\n\n相关JVM配置以及HBase配置：\n\n```\nmaxHeap = 71\nhbase.regionserver.global.memstore.upperLimit = 0.35\nhbase.regionserver.global.memstore.lowerLimit = 0.30\n```\n\n基于上述配置，可以得到触发Region Server级别的总Memstore内存和为24.9G，如下所示：\n\n```\n2015-10-12 13:05:16,232 INFO  [regionserver60020] regionserver.MemStoreFlusher: globalMemStoreLimit=24.9 G, globalMemStoreLimitLowMark=21.3 G, maxHeap=71 G\n```\n\n假设每个Memstore大小为默认128M，在上述配置下如果每个Region有两个Memstore，整个Region Server上运行了100个region，根据计算可得总消耗内存 = 128M * 100 * 2 = 25.6G > 24.9G，很显然，这种情况下就会触发Region Server级别限制，对用户影响相当大。\n\n根据上面的分析，导致触发Region Server级别限制的因素主要有一个Region Server上运行的Region总数，一个是Region上的Store数（即表的ColumnFamily数）。对于前者，根据读写请求量一般建议线上一个Region Server上运行的Region保持在50~80个左右，太小的话会浪费资源，太大的话有可能触发其他异常；对于后者，建议ColumnFamily越少越好，如果从逻辑上确实需要多个ColumnFamily，最好控制在3个以内。","source":"_posts/hbase/hbase的memstore.md","raw":"---\ntitle: hbase的memstore\ndate: 2017-09-15 00:00:56\ntags:\n- hbase\ncategories:\n- 大数据\n---\n\nMemstore是HBase框架中非常重要的组成部分之一，是HBase能够实现高性能随机读写至关重要的一环。深入理解Memstore的工作原理、运行机制以及相关配置，对hbase集群管理、性能调优都有着非常重要的帮助。\n\n**Memstore 概述**\n\nHBase中，Region是集群节点上最小的数据服务单元，用户数据表由一个或多个Region组成。在Region中每个ColumnFamily的数据组成一个Store。每个Store由一个Memstore和多个HFile组成，如下图所示：\n\n![0](http://hbasefly.com/wp-content/uploads/2016/03/0.png)\n\n之前我们提到，HBase是基于LSM-Tree模型的，所有的数据更新插入操作都首先写入Memstore中（同时会顺序写到日志HLog中），达到指定大小之后再将这些修改操作批量写入磁盘，生成一个新的HFile文件，这种设计可以极大地提升HBase的写入性能；另外，HBase为了方便按照RowKey进行检索，要求HFile中数据都按照RowKey进行排序，Memstore数据在flush为HFile之前会进行一次排序，将数据有序化；还有，根据局部性原理，新写入的数据会更大概率被读取，因此HBase在读取数据的时候首先检查请求的数据是否在Memstore，写缓存未命中的话再到读缓存中查找，读缓存还未命中才会到HFile文件中查找，最终返回merged的一个结果给用户。\n\n可见，Memstore无论是对HBase的写入性能还是读取性能都至关重要。其中flush操作又是Memstore最核心的操作，接下来重点针对Memstore的flush操作进行深入地解析：首先分析HBase在哪些场景下会触发flush，然后结合源代码分析整个flush的操作流程，最后再重点整理总结和flush相关的配置参数，这些参数对于性能调优、问题定位都非常重要。\n\n**Memstore Flush触发条件**\n\nHBase会在如下几种情况下触发flush操作，**需要注意的是MemStore的最小flush单元是HRegion而不是单个MemStore**。可想而知，如果一个HRegion中Memstore过多，每次flush的开销必然会很大，因此我们也建议在进行表设计的时候尽量减少ColumnFamily的个数。\n\n1. Memstore级别限制：当Region中任意一个MemStore的大小达到了上限（hbase.hregion.memstore.flush.size，默认128MB），会触发Memstore刷新。\n2. Region级别限制：当Region中所有Memstore的大小总和达到了上限（hbase.hregion.memstore.block.multiplier * hbase.hregion.memstore.flush.size，默认 2* 128M = 256M），会触发memstore刷新。\n3. Region Server级别限制：当一个Region Server中所有Memstore的大小总和达到了上限（hbase.regionserver.global.memstore.upperLimit ＊ hbase_heapsize，默认 40%的JVM内存使用量），会触发部分Memstore刷新。Flush顺序是按照Memstore由大到小执行，先Flush Memstore最大的Region，再执行次大的，直至总体Memstore内存使用量低于阈值（hbase.regionserver.global.memstore.lowerLimit ＊ hbase_heapsize，默认 38%的JVM内存使用量）。\n4. 当一个Region Server中HLog数量达到上限（可通过参数hbase.regionserver.maxlogs配置）时，系统会选取最早的一个 HLog对应的一个或多个Region进行flush\n5. HBase定期刷新Memstore：默认周期为1小时，确保Memstore不会长时间没有持久化。为避免所有的MemStore在同一时间都进行flush导致的问题，定期的flush操作有20000左右的随机延时。\n6. 手动执行flush：用户可以通过shell命令 flush ‘tablename’或者flush ‘region name’分别对一个表或者一个Region进行flush。\n\n**Memstore Flush流程**\n\n为了减少flush过程对读写的影响，HBase采用了类似于两阶段提交的方式，将整个flush过程分为三个阶段：\n\n1. prepare阶段：遍历当前Region中的所有Memstore，将Memstore中当前数据集kvset做一个快照snapshot，然后再新建一个新的kvset。后期的所有写入操作都会写入新的kvset中，而整个flush阶段读操作会首先分别遍历kvset和snapshot，如果查找不到再会到HFile中查找。prepare阶段需要加一把updateLock对写请求阻塞，结束之后会释放该锁。因为此阶段没有任何费时操作，因此持锁时间很短。\n2. flush阶段：遍历所有Memstore，将prepare阶段生成的snapshot持久化为临时文件，临时文件会统一放到目录.tmp下。这个过程因为涉及到磁盘IO操作，因此相对比较耗时。\n3. commit阶段：遍历所有的Memstore，将flush阶段生成的临时文件移到指定的ColumnFamily目录下，针对HFile生成对应的storefile和Reader，把storefile添加到HStore的storefiles列表中，最后再清空prepare阶段生成的snapshot。\n\n上述flush流程可以通过日志信息查看：\n\n```\n/******* prepare阶段 ********/\n2016-02-04 03:32:41,516 INFO  [MemStoreFlusher.1] regionserver.HRegion: Started memstore flush for sentry_sgroup1_data,{\\xD4\\x00\\x00\\x01|\\x00\\x00\\x03\\x82\\x00\\x00\\x00?\\x06\\xDA`\\x13\\xCAE\\xD3C\\xA3:_1\\xD6\\x99:\\x88\\x7F\\xAA_\\xD6[L\\xF0\\x92\\xA6\\xFB^\\xC7\\xA4\\xC7\\xD7\\x8Fv\\xCAT\\xD2\\xAF,1452217805884.572ddf0e8cf0b11aee2273a95bd07879., current region memstore size 128.9 M\n\n/******* flush阶段 ********/\n2016-02-04 03:32:42,423 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=1726212642, memsize=128.9 M, hasBloomFilter=true, into tmp file hdfs://hbase1/hbase/data/default/sentry_sgroup1_data/572ddf0e8cf0b11aee2273a95bd07879/.tmp/021a430940244993a9450dccdfdcb91d\n\n/******* commit阶段 ********/\n2016-02-04 03:32:42,464 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://hbase1/hbase/data/default/sentry_sgroup1_data/572ddf0e8cf0b11aee2273a95bd07879/d/021a430940244993a9450dccdfdcb91d, entries=643656, sequenceid=1726212642, filesize=7.1 M\n```\n\n整个flush过程可能涉及到compact操作和split操作，因为过于复杂，在此暂时略过不表。\n\n**Memstore Flush对业务读写的影响**\n\n上文介绍了HBase在什么场景下会触发flush操作以及flush操作的基本流程，想必对于HBase用户来说，最关心的是flush行为会对读写请求造成哪些影响以及如何避免。因为不同触发方式下的flush操作对用户请求影响不尽相同，因此下面会根据flush的不同触发方式分别进行总结，并且会根据影响大小进行归类：\n\n**影响甚微**\n\n正常情况下，大部分Memstore Flush操作都不会对业务读写产生太大影响，比如这几种场景：HBase定期刷新Memstore、手动执行flush操作、触发Memstore级别限制、触发HLog数量限制以及触发Region级别限制等，这几种场景只会阻塞对应Region上的写请求，阻塞时间很短，毫秒级别。\n\n**影响较大**\n\n然而一旦触发Region Server级别限制导致flush，就会对用户请求产生较大的影响。会阻塞所有落在该Region Server上的更新操作，阻塞时间很长，甚至可以达到分钟级别。一般情况下Region Server级别限制很难触发，但在一些极端情况下也不排除有触发的可能，下面分析一种可能触发这种flush操作的场景：\n\n相关JVM配置以及HBase配置：\n\n```\nmaxHeap = 71\nhbase.regionserver.global.memstore.upperLimit = 0.35\nhbase.regionserver.global.memstore.lowerLimit = 0.30\n```\n\n基于上述配置，可以得到触发Region Server级别的总Memstore内存和为24.9G，如下所示：\n\n```\n2015-10-12 13:05:16,232 INFO  [regionserver60020] regionserver.MemStoreFlusher: globalMemStoreLimit=24.9 G, globalMemStoreLimitLowMark=21.3 G, maxHeap=71 G\n```\n\n假设每个Memstore大小为默认128M，在上述配置下如果每个Region有两个Memstore，整个Region Server上运行了100个region，根据计算可得总消耗内存 = 128M * 100 * 2 = 25.6G > 24.9G，很显然，这种情况下就会触发Region Server级别限制，对用户影响相当大。\n\n根据上面的分析，导致触发Region Server级别限制的因素主要有一个Region Server上运行的Region总数，一个是Region上的Store数（即表的ColumnFamily数）。对于前者，根据读写请求量一般建议线上一个Region Server上运行的Region保持在50~80个左右，太小的话会浪费资源，太大的话有可能触发其他异常；对于后者，建议ColumnFamily越少越好，如果从逻辑上确实需要多个ColumnFamily，最好控制在3个以内。","slug":"hbase/hbase的memstore","published":1,"updated":"2018-09-12T03:03:21.816Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfngm0025wlkvrovcbq6i"},{"title":"hbase的容错","date":"2017-09-13T16:01:46.000Z","_content":"\n# HBase容错性\n\nMaster容错：Zookeeper重新选择一个新的Master\n　　1).无Master过程中，数据读取仍照常进行；\n　　2).无master过程中，region切分、负载均衡等无法进行；\nRegionServer容错：定时向Zookeeper汇报心跳，如果一旦时间内未出现心跳\n　　1).Master将该RegionServer上的Region重新分配到其他RegionServer上；\n　　2).失效服务器上“预写”HLog日志由主服务器进行分割并派送给新的RegionServer\nZookeeper容错：Zookeeper是一个可靠地服务\n　　1).一般配置3或5个Zookeeper实例。\n\n\n\nregion分配\n\n　　任何时刻，一个region只能分配给一个region server。master记录了当前有哪些可用的region server。以及当前哪些region分配给了哪些region server，哪些region还没有分配。当存在未分配的region，并且有一个region server上有可用空间时，master就给这个region server发送一个装载请求，把region分配给这个region server。region server得到请求后，就开始对此region提供服务。","source":"_posts/hbase/hbase的容错.md","raw":"---\ntitle: hbase的容错\ndate: 2017-09-14 00:01:46\ntags:\n- hbase\ncategories:\n- 大数据\n---\n\n# HBase容错性\n\nMaster容错：Zookeeper重新选择一个新的Master\n　　1).无Master过程中，数据读取仍照常进行；\n　　2).无master过程中，region切分、负载均衡等无法进行；\nRegionServer容错：定时向Zookeeper汇报心跳，如果一旦时间内未出现心跳\n　　1).Master将该RegionServer上的Region重新分配到其他RegionServer上；\n　　2).失效服务器上“预写”HLog日志由主服务器进行分割并派送给新的RegionServer\nZookeeper容错：Zookeeper是一个可靠地服务\n　　1).一般配置3或5个Zookeeper实例。\n\n\n\nregion分配\n\n　　任何时刻，一个region只能分配给一个region server。master记录了当前有哪些可用的region server。以及当前哪些region分配给了哪些region server，哪些region还没有分配。当存在未分配的region，并且有一个region server上有可用空间时，master就给这个region server发送一个装载请求，把region分配给这个region server。region server得到请求后，就开始对此region提供服务。","slug":"hbase/hbase的容错","published":1,"updated":"2018-09-12T03:03:21.817Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfngo0029wlkvfqhvlrdm"},{"title":"hbase读写操作","date":"2017-09-08T14:23:32.000Z","_content":"\n# hbase的增删改查\n\n## hbase写操作\n\n### 客户端流程解析\n\n1. 用户提交put请求后，HBase客户端会将put请求添加到本地buffer中，符合一定条件就会通过AsyncProcess异步批量提交。HBase默认设置autoflush=true，表示put请求直接会提交给服务器进行处理；用户可以设置autoflush=false，这样的话put请求会首先放到本地buffer，等到本地buffer大小超过一定阈值（默认为2M，可以通过配置文件配置）之后才会提交。很显然，后者采用group commit机制提交请求，可以极大地提升写入性能，但是因为没有保护机制，如果客户端崩溃的话会导致提交的请求丢失。\n2. 在提交之前，HBase根据rowkey找到它们归属的RegionServer，这个定位的过程是通过HConnection的locateRegion方法获得的。如果是批量请求的话还会把这些rowkey按照HRegionLocation分组，**每个分组可以对应一次RPC请求**。\n3. HBase会为每个HRegionLocation构造一个远程RPC请求MultiServerCallable<Row>，然后通过rpcCallerFactory.<MultiResponse> newCaller()执行调用，忽略掉失败重新提交和错误处理，客户端的提交操作到此结束。\n\n### 服务器端流程解析\n\n服务器端RegionServer接收到客户端的写入请求后，首先会反序列化为Put对象，然后执行各种检查操作，比如检查region是否是只读、memstore大小是否超过blockingMemstoreSize等。检查完成之后，一次写事务保证了数据写入memstore和WAL中才结束，然后对读操作可见。\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-9-14/89638286.jpg)\n\n1. 获取行锁、Region更新共享锁： HBase中使用行锁保证对同一行数据的更新都是互斥操作，用以保证更新的原子性，要么更新成功，要么失败。\n\n2. 开始写事务：获取write number，用于实现MVCC，实现数据的非锁定读，在保证读写一致性的前提下提高读取性能。\n\n3. 写缓存memstore：HBase中每列族都会对应一个store，用来存储该列数据。每个store都会有个写缓存memstore，用于缓存写入数据。HBase并不会直接将数据落盘，而是先按rowKey排序写入缓存，等缓存满足一定大小之后再一起落盘。\n\n4. Append HLog：HBase使用WAL机制保证数据可靠性，即使发生宕机，也可以通过恢复HLog还原出原始数据。该步骤就是将数据构造为WALEdit对象，然后顺序写入HLog中，此时不需要执行sync操作。\n\n5. 释放行锁以及共享锁\n\n6. Sync HLog：HLog真正sync到HDFS，在释放行锁之后执行sync操作是为了尽量减少持锁时间，提升写性能。如果Sync失败，执行回滚操作将memstore中已经写入的数据移除。\n\n7. 结束写事务：此时该线程的更新操作才会对其他读请求可见，更新才实际生效。\n\n8. flush memstore：当写缓存满64M之后，会启动flush线程将数据刷新到硬盘。新创建一个memStore接受请求，异步将旧的memStore刷写成一个StoreFile存储磁盘。\n\n**先写memstore后写日志**\n\n   1. 将写内存（memstore）放在lock保护的临界区内是为了保证写的内存可见性。因为存在多线程写，如果写内存放到临界区外（WAL的默认顺序：先刷日志再写内存），即使本线程已经完成sync wal，并推进了全局读取点(使新数据可被读取到)，但是仍然不能够保证写入memstore的数据版本对其他线程可见，所以这才将写内存这个操作提前到lock保护的临界区内\n   2. sync WAL太耗时，所以把它放到临界区外，由递增的write num来保证WAL写的顺序性。这一点同样是通过lock来保证write num在内存中的可见性，因为write num在释放行锁之前创建，由java内存模型的Happens-Before来保证这一点。\n\n### hbase删操作\n\nDelete命令并不立即删除内容。实际上，它只是给记录打上删除的标记“墓碑”(tombstone)。墓碑记录不能在Get和Scan命令中返回结果。因为HFile是只读文件，这些墓碑记录直到执行一次大合并(major compaction)才会被删除。\n\n## hbase读操作\n\nRegionServer接收到客户端的get/scan请求之后，先后做了两件事情：构建scanner体系,　scanner体系的核心在于三层scanner：RegionScanner、StoreScanner以及StoreFileScanner。三者是层级的关系，一个RegionScanner由多个StoreScanner,构成，一张表由多个列族组成，就有多少个StoreScanner负责该列族的数据扫描。一个StoreScanner又是由多个StoreFileScanner组成。每个Store的数据由内存中的MemStore和磁盘上的StoreFile文件组成，相对应的，StoreScanner对象会雇佣一个MemStoreScanner和N个StoreFileScanner来进行实际的数据读取，每个StoreFile文件对应一个StoreFileScanner，注意：StoreFileScanner和MemstoreScanner是整个scan的最终执行者。\n\nRegionScanner会根据列族构建StoreScanner，有多少列族就构建多少StoreScanner，用于负责该列族的数据检索\n　　1.1 构建StoreFileScanner：每个StoreScanner会为当前该Store中每个HFile构造一个StoreFileScanner，用于实际执行对应文件的检索。同时会为对应Memstore构造一个MemstoreScanner，用于执行该Store中Memstore的数据检索\n\n1.2 过滤淘汰StoreFileScanner：根据Time Range以及RowKey Range对StoreFileScanner以及MemstoreScanner进行过滤，淘汰肯定不存在待检索结果的Scanner。\n\n1.3 Seek rowkey：所有StoreFileScanner开始做准备工作，在负责的HFile中定位到满足条件的起始Row。定位Block Offset：在Blockcache中读取该HFile的索引树结构，根据索引树检索对应RowKey所在的Block Offset和Block Size,Load Block：根据BlockOffset首先在BlockCache中查找Data Block，如果不在缓存，再在HFile中加载\n,Seek Key：在Data Block内部通过二分查找的方式定位具体的RowKey\n\n1.4 StoreFileScanner合并构建最小堆：将该Store中所有StoreFileScanner和MemstoreScanner合并形成一个heap(最小堆)，所谓heap是一个优先级队列，队列中元素是所有scanner，排序规则按照scanner seek到的keyvalue大小由小到大进行排序。\n\nHBase中KeyValue是什么样的结构?\n　　HBase中KeyValue并不是简单的KV数据对，而是一个具有复杂元素的结构体，其中Key由RowKey，ColumnFamily，Qualifier ，TimeStamp，KeyType等多部分组成，Value是一个简单的二进制数据。Key中元素KeyType表示该KeyValue的类型，取值分别为Put/Delete/Delete Column/Delete Family四种。\n\nHBase中更新删除操作并不直接操作原数据，而是生成一个新纪录，那问题来了，如何知道一条记录到底是插入操作还是更新操作亦或是删除操作呢?这正是KeyType和Timestamp的用武之地。上文中提到KeyType取值为分别为Put/Delete/Delete Column/Delete Family四种，如果KeyType取值为Put，表示该条记录为插入或者更新操作，而无论是插入或者更新，都可以使用版本号(Timestamp)对记录进行选择;如果KeyType为Delete，表示该条记录为整行删除操作;相应的KeyType为Delete Column和Delete Family分别表示删除某行某列以及某行某列族操作;\n\n上文提到KeyValue中Key由RowKey，ColumnFamily，Qualifier ，TimeStamp，KeyType等5部分组成，HBase设定Key大小首先比较RowKey，RowKey越小Key就越小;RowKey如果相同就看CF，CF越小Key越小;CF如果相同看Qualifier，Qualifier越小Key越小;Qualifier如果相同再看Timestamp，Timestamp越大表示时间越新，对应的Key越小。如果Timestamp还相同，就看KeyType，KeyType按照DeleteFamily -> DeleteColumn -> Delete -> Put 顺序依次对应的Key越来越大。\n\n\n\nHBase中有两张特殊的Table，-ROOT-和.META.\n\n.META.：记录了用户表的Region信息，.META.可以有多个regoin，以及RegionServer的服务器地址。\n\n-ROOT-：记录了.META.表的Region信息，-ROOT-只有一个region\n\n&Oslash; Zookeeper中记录了-ROOT-表的location\n\nClient访问用户数据之前需要首先访问zookeeper，然后访问-ROOT-表，接着访问.META.表，最后才能找到用户数据的位置去访问，中间需要多次网络操作，不过client端会做cache缓存。\n\n​    1、Client会通过内部缓存的相关的-ROOT-中的信息和.META.中的信息直接连接与请求数据匹配的HRegion server； \n​    2、然后直接定位到该服务器上与客户请求对应的region，客户请求首先会查询该region在内存中的缓存——memstore(memstore是是一个按key排序的树形结构的缓冲区)； \n​    3、如果在memstore中查到结果则直接将结果返回给client； \n​    4、在memstore中没有查到匹配的数据，接下来会读已持久化的storefile文件中的数据。storefile也是按key排序的树形结构的文件——并且是特别为范围查询或block查询优化过的，；另外hbase读取磁盘文件是按其基本I/O单元(即 hbase block)读数据的。具体就是过程就是： \n​    如果在BlockCache中能查到要造的数据则这届返回结果，否则就读去相应的storefile文件中读取一block的数据，如果还没有读到要查的数据，就将该数据block放到HRegion Server的blockcache中，然后接着读下一block块儿的数据，一直到这样循环的block数据直到找到要请求的数据并返回结果；如果将该region中的数据都没有查到要找的数据，最后接直接返回null，表示没有找的匹配的数据。当然blockcache会在其大小大于一的阀值（heapsize * hfile.block.cache.size * 0.85）后启动基于LRU算法的淘汰机制，将最老最不常用的block删除。\n\n**2.1 多HTable并发写**\n\n创建多个HTable客户端用于写操作，提高写数据的吞吐量，一个例子：\n\n**2.2 HTable参数设置**\n\n**2.2.1 Auto Flush**\n\n通过调用HTable.setAutoFlush(false)方法可以将HTable写客户端的自动flush关闭，这样可以批量写入数据到 HBase，而不是有一条put就执行一次更新，只有当put填满客户端写缓存时，才实际向HBase服务端发起写请求。默认情况下auto flush是开启的。保证最后手动HTable.flushCommits()或HTable.close()。\n\n**2.2.2 Write Buffer**\n\n通过调用HTable.setWriteBufferSize(writeBufferSize)方法可以设置 HTable客户端的写buffer大小，如果新设置的buffer小于当前写buffer中的数据时，buffer将会被flush到服务端。其 中，writeBufferSize的单位是byte字节数，可以根据实际写入数据量的多少来设置该值。\n\n**2.2.3 WAL Flag**\n\n在HBae中，客户端向集群中的RegionServer提交数据时（Put/Delete操作），首先会先写WAL（Write Ahead Log）日志（即HLog，一个RegionServer上的所有Region共享一个HLog），只有当WAL日志写成功后，再接着写 MemStore，然后客户端被通知提交数据成功；如果写WAL日志失败，客户端则被通知提交失败。这样做的好处是可以做到RegionServer宕机 后的数据恢复。\n\n因此，对于相对不太重要的数据，可以在Put/Delete操作时，通过调用Put.setWriteToWAL(false)或Delete.setWriteToWAL(false)函数，放弃写WAL日志，从而提高数据写入的性能。\n\n值得注意的是：谨慎选择关闭WAL日志，因为这样的话，一旦RegionServer宕机，Put/Delete的数据将会无法根据WAL日志进行恢复。\n\n**2.3 批量写**\n\n通过调用HTable.put(Put)方法可以将一个指定的row key记录写入HBase，同样HBase提供了另一个方法：通过调用HTable.put(List<Put>)方法可以将指定的row key列表，批量写入多行记录，这样做的好处是批量执行，只需要一次网络I/O开销，这对于对数据实时性要求高，网络传输RTT高的情景下可能带来明显的性能提升。\n\n**2.4 多线程并发写**\n\n在客户端开启多个HTable写线程，每个写线程负责一个HTable对象的flush操作，这样结合定时flush和写 buffer（writeBufferSize），可以既保证在数据量小的时候，数据可以在较短时间内被flush（如1秒内），同时又保证在数据量大的 时候，写buffer一满就及时进行flush。下面给个具体的例子：\n\n## 3、读表操作\n\n**3.1 多HTable并发读**\n\n创建多个HTable客户端用于读操作，提高读数据的吞吐量，一个例子：\n\n**3.2 HTable参数设置**\n\n**3.2.1 Scanner Caching**\n\nhbase.client.scanner.caching配置项可以设置HBase scanner一次从服务端抓取的数据条数，默认情况下一次一条。通过将其设置成一个合理的值，可以减少scan过程中next()的时间开销，代价是 scanner需要通过客户端的内存来维持这些被cache的行记录。\n\n有三个地方可以进行配置：1）在HBase的conf配置文件中进行配置；2）通过调用HTable.setScannerCaching(int scannerCaching)进行配置；3）通过调用Scan.setCaching(int caching)进行配置。三者的优先级越来越高。\n\n**3.2.2 Scan AttributeSelection**\n\nscan时指定需要的Column Family，可以减少网络传输数据量，否则默认scan操作会返回整行所有Column Family的数据。\n\n**3.2.3 Close ResultScanner**\n\n通过scan取完数据后，记得要关闭ResultScanner，否则RegionServer可能会出现问题（对应的Server资源无法释放）。\n\n**3.3 批量读**\n\n通过调用HTable.get(Get)方法可以根据一个指定的row key获取一行记录，同样HBase提供了另一个方法：通过调用HTable.get(List<Get>)方法可以根据一个指定的rowkey列表，批量获取多行记录，这样做的好处是批量执行，只需要一次网络I/O开销，这对于对数据实时性要求高而且网络传输RTT高的情景下可能带来明显 的性能提升。\n\n**3.4 多线程并发读**\n\n在客户端开启多个HTable读线程，每个读线程负责通过HTable对象进行get操作。下面是一个多线程并发读取HBase，获取店铺一天内各分钟PV值的例子：\n\n**3.5 缓存查询结果**\n\n对于频繁查询HBase的应用场景，可以考虑在应用程序中做缓存，当有新的查询请求时，首先在缓存中查找，如果存在则直接返回，不再查询HBase；否则对HBase发起读请求查询，然后在应用程序中将查询结果缓存起来。至于缓存的替换策略，可以考虑LRU等常用的策略。\n\n**3.6 Blockcache**\n\nHBase上Regionserver的内存分为两个部分，一部分作为Memstore，主要用来写；另外一部分作为BlockCache，主要用于读。写请求会先写入Memstore，Regionserver会给每个region提供一个Memstore，当Memstore满64MB以后，会创建一个新的MemStore，并将旧的MemStore flush刷新到磁盘。当Memstore的总大小超过限制时（heapsize * hbase.regionserver.global.memstore.upperLimit * 0.9），会强行启动flush进程，从最大的Memstore开始flush直到低于限制。读请求先到Memstore中查数据，查不到就到BlockCache中查，再查不到就会到磁盘上读，并把读的结果放入BlockCache。由于 BlockCache采用的是LRU策略，因此BlockCache达到上限(heapsize *hfile.block.cache.size * 0.85)后，会启动淘汰机制，淘汰掉最老的一批数据。一个Regionserver上有一个BlockCache和N个Memstore，它们的大小之和不能大于等于heapsize * 0.8，否则HBase不能启动。默认BlockCache为0.2，而Memstore为0.4。对于注重读响应时间的系统，可以将 BlockCache设大些，比如设置BlockCache=0.4，Memstore=0.39，以加大缓存的命中率。","source":"_posts/hbase/hbase的增删改查.md","raw":"---\ntitle: hbase读写操作\ndate: 2017-09-08 22:23:32\ntags:\n- hbase\ncategories:\n- 大数据\n---\n\n# hbase的增删改查\n\n## hbase写操作\n\n### 客户端流程解析\n\n1. 用户提交put请求后，HBase客户端会将put请求添加到本地buffer中，符合一定条件就会通过AsyncProcess异步批量提交。HBase默认设置autoflush=true，表示put请求直接会提交给服务器进行处理；用户可以设置autoflush=false，这样的话put请求会首先放到本地buffer，等到本地buffer大小超过一定阈值（默认为2M，可以通过配置文件配置）之后才会提交。很显然，后者采用group commit机制提交请求，可以极大地提升写入性能，但是因为没有保护机制，如果客户端崩溃的话会导致提交的请求丢失。\n2. 在提交之前，HBase根据rowkey找到它们归属的RegionServer，这个定位的过程是通过HConnection的locateRegion方法获得的。如果是批量请求的话还会把这些rowkey按照HRegionLocation分组，**每个分组可以对应一次RPC请求**。\n3. HBase会为每个HRegionLocation构造一个远程RPC请求MultiServerCallable<Row>，然后通过rpcCallerFactory.<MultiResponse> newCaller()执行调用，忽略掉失败重新提交和错误处理，客户端的提交操作到此结束。\n\n### 服务器端流程解析\n\n服务器端RegionServer接收到客户端的写入请求后，首先会反序列化为Put对象，然后执行各种检查操作，比如检查region是否是只读、memstore大小是否超过blockingMemstoreSize等。检查完成之后，一次写事务保证了数据写入memstore和WAL中才结束，然后对读操作可见。\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-9-14/89638286.jpg)\n\n1. 获取行锁、Region更新共享锁： HBase中使用行锁保证对同一行数据的更新都是互斥操作，用以保证更新的原子性，要么更新成功，要么失败。\n\n2. 开始写事务：获取write number，用于实现MVCC，实现数据的非锁定读，在保证读写一致性的前提下提高读取性能。\n\n3. 写缓存memstore：HBase中每列族都会对应一个store，用来存储该列数据。每个store都会有个写缓存memstore，用于缓存写入数据。HBase并不会直接将数据落盘，而是先按rowKey排序写入缓存，等缓存满足一定大小之后再一起落盘。\n\n4. Append HLog：HBase使用WAL机制保证数据可靠性，即使发生宕机，也可以通过恢复HLog还原出原始数据。该步骤就是将数据构造为WALEdit对象，然后顺序写入HLog中，此时不需要执行sync操作。\n\n5. 释放行锁以及共享锁\n\n6. Sync HLog：HLog真正sync到HDFS，在释放行锁之后执行sync操作是为了尽量减少持锁时间，提升写性能。如果Sync失败，执行回滚操作将memstore中已经写入的数据移除。\n\n7. 结束写事务：此时该线程的更新操作才会对其他读请求可见，更新才实际生效。\n\n8. flush memstore：当写缓存满64M之后，会启动flush线程将数据刷新到硬盘。新创建一个memStore接受请求，异步将旧的memStore刷写成一个StoreFile存储磁盘。\n\n**先写memstore后写日志**\n\n   1. 将写内存（memstore）放在lock保护的临界区内是为了保证写的内存可见性。因为存在多线程写，如果写内存放到临界区外（WAL的默认顺序：先刷日志再写内存），即使本线程已经完成sync wal，并推进了全局读取点(使新数据可被读取到)，但是仍然不能够保证写入memstore的数据版本对其他线程可见，所以这才将写内存这个操作提前到lock保护的临界区内\n   2. sync WAL太耗时，所以把它放到临界区外，由递增的write num来保证WAL写的顺序性。这一点同样是通过lock来保证write num在内存中的可见性，因为write num在释放行锁之前创建，由java内存模型的Happens-Before来保证这一点。\n\n### hbase删操作\n\nDelete命令并不立即删除内容。实际上，它只是给记录打上删除的标记“墓碑”(tombstone)。墓碑记录不能在Get和Scan命令中返回结果。因为HFile是只读文件，这些墓碑记录直到执行一次大合并(major compaction)才会被删除。\n\n## hbase读操作\n\nRegionServer接收到客户端的get/scan请求之后，先后做了两件事情：构建scanner体系,　scanner体系的核心在于三层scanner：RegionScanner、StoreScanner以及StoreFileScanner。三者是层级的关系，一个RegionScanner由多个StoreScanner,构成，一张表由多个列族组成，就有多少个StoreScanner负责该列族的数据扫描。一个StoreScanner又是由多个StoreFileScanner组成。每个Store的数据由内存中的MemStore和磁盘上的StoreFile文件组成，相对应的，StoreScanner对象会雇佣一个MemStoreScanner和N个StoreFileScanner来进行实际的数据读取，每个StoreFile文件对应一个StoreFileScanner，注意：StoreFileScanner和MemstoreScanner是整个scan的最终执行者。\n\nRegionScanner会根据列族构建StoreScanner，有多少列族就构建多少StoreScanner，用于负责该列族的数据检索\n　　1.1 构建StoreFileScanner：每个StoreScanner会为当前该Store中每个HFile构造一个StoreFileScanner，用于实际执行对应文件的检索。同时会为对应Memstore构造一个MemstoreScanner，用于执行该Store中Memstore的数据检索\n\n1.2 过滤淘汰StoreFileScanner：根据Time Range以及RowKey Range对StoreFileScanner以及MemstoreScanner进行过滤，淘汰肯定不存在待检索结果的Scanner。\n\n1.3 Seek rowkey：所有StoreFileScanner开始做准备工作，在负责的HFile中定位到满足条件的起始Row。定位Block Offset：在Blockcache中读取该HFile的索引树结构，根据索引树检索对应RowKey所在的Block Offset和Block Size,Load Block：根据BlockOffset首先在BlockCache中查找Data Block，如果不在缓存，再在HFile中加载\n,Seek Key：在Data Block内部通过二分查找的方式定位具体的RowKey\n\n1.4 StoreFileScanner合并构建最小堆：将该Store中所有StoreFileScanner和MemstoreScanner合并形成一个heap(最小堆)，所谓heap是一个优先级队列，队列中元素是所有scanner，排序规则按照scanner seek到的keyvalue大小由小到大进行排序。\n\nHBase中KeyValue是什么样的结构?\n　　HBase中KeyValue并不是简单的KV数据对，而是一个具有复杂元素的结构体，其中Key由RowKey，ColumnFamily，Qualifier ，TimeStamp，KeyType等多部分组成，Value是一个简单的二进制数据。Key中元素KeyType表示该KeyValue的类型，取值分别为Put/Delete/Delete Column/Delete Family四种。\n\nHBase中更新删除操作并不直接操作原数据，而是生成一个新纪录，那问题来了，如何知道一条记录到底是插入操作还是更新操作亦或是删除操作呢?这正是KeyType和Timestamp的用武之地。上文中提到KeyType取值为分别为Put/Delete/Delete Column/Delete Family四种，如果KeyType取值为Put，表示该条记录为插入或者更新操作，而无论是插入或者更新，都可以使用版本号(Timestamp)对记录进行选择;如果KeyType为Delete，表示该条记录为整行删除操作;相应的KeyType为Delete Column和Delete Family分别表示删除某行某列以及某行某列族操作;\n\n上文提到KeyValue中Key由RowKey，ColumnFamily，Qualifier ，TimeStamp，KeyType等5部分组成，HBase设定Key大小首先比较RowKey，RowKey越小Key就越小;RowKey如果相同就看CF，CF越小Key越小;CF如果相同看Qualifier，Qualifier越小Key越小;Qualifier如果相同再看Timestamp，Timestamp越大表示时间越新，对应的Key越小。如果Timestamp还相同，就看KeyType，KeyType按照DeleteFamily -> DeleteColumn -> Delete -> Put 顺序依次对应的Key越来越大。\n\n\n\nHBase中有两张特殊的Table，-ROOT-和.META.\n\n.META.：记录了用户表的Region信息，.META.可以有多个regoin，以及RegionServer的服务器地址。\n\n-ROOT-：记录了.META.表的Region信息，-ROOT-只有一个region\n\n&Oslash; Zookeeper中记录了-ROOT-表的location\n\nClient访问用户数据之前需要首先访问zookeeper，然后访问-ROOT-表，接着访问.META.表，最后才能找到用户数据的位置去访问，中间需要多次网络操作，不过client端会做cache缓存。\n\n​    1、Client会通过内部缓存的相关的-ROOT-中的信息和.META.中的信息直接连接与请求数据匹配的HRegion server； \n​    2、然后直接定位到该服务器上与客户请求对应的region，客户请求首先会查询该region在内存中的缓存——memstore(memstore是是一个按key排序的树形结构的缓冲区)； \n​    3、如果在memstore中查到结果则直接将结果返回给client； \n​    4、在memstore中没有查到匹配的数据，接下来会读已持久化的storefile文件中的数据。storefile也是按key排序的树形结构的文件——并且是特别为范围查询或block查询优化过的，；另外hbase读取磁盘文件是按其基本I/O单元(即 hbase block)读数据的。具体就是过程就是： \n​    如果在BlockCache中能查到要造的数据则这届返回结果，否则就读去相应的storefile文件中读取一block的数据，如果还没有读到要查的数据，就将该数据block放到HRegion Server的blockcache中，然后接着读下一block块儿的数据，一直到这样循环的block数据直到找到要请求的数据并返回结果；如果将该region中的数据都没有查到要找的数据，最后接直接返回null，表示没有找的匹配的数据。当然blockcache会在其大小大于一的阀值（heapsize * hfile.block.cache.size * 0.85）后启动基于LRU算法的淘汰机制，将最老最不常用的block删除。\n\n**2.1 多HTable并发写**\n\n创建多个HTable客户端用于写操作，提高写数据的吞吐量，一个例子：\n\n**2.2 HTable参数设置**\n\n**2.2.1 Auto Flush**\n\n通过调用HTable.setAutoFlush(false)方法可以将HTable写客户端的自动flush关闭，这样可以批量写入数据到 HBase，而不是有一条put就执行一次更新，只有当put填满客户端写缓存时，才实际向HBase服务端发起写请求。默认情况下auto flush是开启的。保证最后手动HTable.flushCommits()或HTable.close()。\n\n**2.2.2 Write Buffer**\n\n通过调用HTable.setWriteBufferSize(writeBufferSize)方法可以设置 HTable客户端的写buffer大小，如果新设置的buffer小于当前写buffer中的数据时，buffer将会被flush到服务端。其 中，writeBufferSize的单位是byte字节数，可以根据实际写入数据量的多少来设置该值。\n\n**2.2.3 WAL Flag**\n\n在HBae中，客户端向集群中的RegionServer提交数据时（Put/Delete操作），首先会先写WAL（Write Ahead Log）日志（即HLog，一个RegionServer上的所有Region共享一个HLog），只有当WAL日志写成功后，再接着写 MemStore，然后客户端被通知提交数据成功；如果写WAL日志失败，客户端则被通知提交失败。这样做的好处是可以做到RegionServer宕机 后的数据恢复。\n\n因此，对于相对不太重要的数据，可以在Put/Delete操作时，通过调用Put.setWriteToWAL(false)或Delete.setWriteToWAL(false)函数，放弃写WAL日志，从而提高数据写入的性能。\n\n值得注意的是：谨慎选择关闭WAL日志，因为这样的话，一旦RegionServer宕机，Put/Delete的数据将会无法根据WAL日志进行恢复。\n\n**2.3 批量写**\n\n通过调用HTable.put(Put)方法可以将一个指定的row key记录写入HBase，同样HBase提供了另一个方法：通过调用HTable.put(List<Put>)方法可以将指定的row key列表，批量写入多行记录，这样做的好处是批量执行，只需要一次网络I/O开销，这对于对数据实时性要求高，网络传输RTT高的情景下可能带来明显的性能提升。\n\n**2.4 多线程并发写**\n\n在客户端开启多个HTable写线程，每个写线程负责一个HTable对象的flush操作，这样结合定时flush和写 buffer（writeBufferSize），可以既保证在数据量小的时候，数据可以在较短时间内被flush（如1秒内），同时又保证在数据量大的 时候，写buffer一满就及时进行flush。下面给个具体的例子：\n\n## 3、读表操作\n\n**3.1 多HTable并发读**\n\n创建多个HTable客户端用于读操作，提高读数据的吞吐量，一个例子：\n\n**3.2 HTable参数设置**\n\n**3.2.1 Scanner Caching**\n\nhbase.client.scanner.caching配置项可以设置HBase scanner一次从服务端抓取的数据条数，默认情况下一次一条。通过将其设置成一个合理的值，可以减少scan过程中next()的时间开销，代价是 scanner需要通过客户端的内存来维持这些被cache的行记录。\n\n有三个地方可以进行配置：1）在HBase的conf配置文件中进行配置；2）通过调用HTable.setScannerCaching(int scannerCaching)进行配置；3）通过调用Scan.setCaching(int caching)进行配置。三者的优先级越来越高。\n\n**3.2.2 Scan AttributeSelection**\n\nscan时指定需要的Column Family，可以减少网络传输数据量，否则默认scan操作会返回整行所有Column Family的数据。\n\n**3.2.3 Close ResultScanner**\n\n通过scan取完数据后，记得要关闭ResultScanner，否则RegionServer可能会出现问题（对应的Server资源无法释放）。\n\n**3.3 批量读**\n\n通过调用HTable.get(Get)方法可以根据一个指定的row key获取一行记录，同样HBase提供了另一个方法：通过调用HTable.get(List<Get>)方法可以根据一个指定的rowkey列表，批量获取多行记录，这样做的好处是批量执行，只需要一次网络I/O开销，这对于对数据实时性要求高而且网络传输RTT高的情景下可能带来明显 的性能提升。\n\n**3.4 多线程并发读**\n\n在客户端开启多个HTable读线程，每个读线程负责通过HTable对象进行get操作。下面是一个多线程并发读取HBase，获取店铺一天内各分钟PV值的例子：\n\n**3.5 缓存查询结果**\n\n对于频繁查询HBase的应用场景，可以考虑在应用程序中做缓存，当有新的查询请求时，首先在缓存中查找，如果存在则直接返回，不再查询HBase；否则对HBase发起读请求查询，然后在应用程序中将查询结果缓存起来。至于缓存的替换策略，可以考虑LRU等常用的策略。\n\n**3.6 Blockcache**\n\nHBase上Regionserver的内存分为两个部分，一部分作为Memstore，主要用来写；另外一部分作为BlockCache，主要用于读。写请求会先写入Memstore，Regionserver会给每个region提供一个Memstore，当Memstore满64MB以后，会创建一个新的MemStore，并将旧的MemStore flush刷新到磁盘。当Memstore的总大小超过限制时（heapsize * hbase.regionserver.global.memstore.upperLimit * 0.9），会强行启动flush进程，从最大的Memstore开始flush直到低于限制。读请求先到Memstore中查数据，查不到就到BlockCache中查，再查不到就会到磁盘上读，并把读的结果放入BlockCache。由于 BlockCache采用的是LRU策略，因此BlockCache达到上限(heapsize *hfile.block.cache.size * 0.85)后，会启动淘汰机制，淘汰掉最老的一批数据。一个Regionserver上有一个BlockCache和N个Memstore，它们的大小之和不能大于等于heapsize * 0.8，否则HBase不能启动。默认BlockCache为0.2，而Memstore为0.4。对于注重读响应时间的系统，可以将 BlockCache设大些，比如设置BlockCache=0.4，Memstore=0.39，以加大缓存的命中率。","slug":"hbase/hbase的增删改查","published":1,"updated":"2018-09-12T03:03:21.816Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfngq002cwlkvguj1ujbx"},{"title":"hbase的表设计","date":"2017-09-10T13:36:01.000Z","_content":"\n# hbase的表设计\n\n[HBase Rowkey的散列与预分区设计](http://www.cnblogs.com/bdifn/p/3801737.html)\n\n## RowKey设计原则\n\n1）Rowkey长度原则，Rowkey是一个二进制码流，可以是任意字符串，最大长度64KB，实际应用中一般为10~100bytes，存为byte[]字节数组，一般设计成定长的。建议是越短越好，不要超过16个字节。原因一数据的持久化文件HFile中是按照KeyValue存储的，如果Rowkey过长比如100个字节，1000万列数据光Rowkey就要占用100*1000万=10亿个字节，将近1G数据，这会极大影响HFile的存储效率；原因二MemStore将缓存部分数据到内存，如果Rowkey字段过长内存的有效利用率会降低，系统将无法缓存更多的数据，这会降低检索效率。因此Rowkey的字节长度越短越好。原因三目前操作系统是都是64位系统，内存8字节对齐。控制在16个字节，8字节的整数倍利用操作系统的最佳特性。\n2）是Rowkey散列原则，如果Rowkey是按时间戳的方式递增，不要将时间放在二进制码的前面，建议将Rowkey的高位作为散列字段，由程序循环生成，低位放时间字段，这样将提高数据均衡分布在每个Regionserver实现负载均衡的几率。如果没有散列字段，首字段直接是时间信息将产生所有新数据都在一个RegionServer上堆积的热点现象，这样在做数据检索的时候负载将会集中在个别RegionServer，降低查询效率。\n3）Rowkey唯一原则，必须在设计上保证其唯一性。\nrow key是按照字典序存储，因此，设计row key时，要充分利用这个排序特点，将经常一起读取的数据存储到一块，将最近可能会被访问的数据放在一块。\n举个例子：如果最近写入HBase表中的数据是最可能被访问的，可以考虑将时间戳作为row key的一部分，由于是字典序排序，所以可以使用Long.MAX_VALUE – timestamp作为row key，这样能保证新写入的数据在读取时可以被快速命中。\n\n## 列族设计原则\n\n同一Column Family的Columns会群聚在一个存储文件上，并依Column key排序，因此设计时：读写相关性较高的数据，存在同一列族中。\n\n由于Hbase是一个面向列族的存储器，调优和存储都是在列族这个层次上进行的，最好使列族成员都有相同的\"访问模式(access pattern)\"和大小特征；\n在一张表里不要定义太多的column family。目前Hbase并不能很好的处理超过2~3个column family的表。因为某个column family在flush的时候，它邻近的column family也会因关联效应被触发flush，最终导致系统产生更多的I/O。\n\n\n\n在一张表里不要定义太多的column family。目前Hbase并不能很好的处理超过2~3个column family的表。因为某个column family在flush的时候，它邻近的column family也会因关联效应被触发flush，最终导致系统产生更多的I/O。\n\n- family越多，那么获取每一个cell数据的优势越明显，因为io和网络都减少了，而如果只有一个family，那么每一次读都会读取当前rowkey的所有数据，网络和io上会有一些损失。\n  ​    当然如果要获取的是固定的几列数据，那么把这几列写到一个family中比分别设置family要更好，因为只需一次请求就能拿回所有数据。\n\n  首先，不同的family是在同一个region下面。而每一个family都会分配一个memstore，所以更多的family会消耗更多的内存。\n  其次,目前版本的hbase，在flush和compaction都是以region为单位的，也就是说当一个family达到flush条件时，该region的所有family所属的memstore都会flush一次，即使memstore中只有很少的数据也会触发flush而生成小文件。这样就增加了compaction发生的机率，而compaction也是以region为单位的，这样就很容易发生compaction风暴从而降低系统的整体吞吐量。\n  第三，由于hfile是以family为单位的，因此对于多个family来说，数据被分散到了更多的hfile中，减小了split发生的机率。这是把双刃剑。更少的split会导致该region的体积比较大，由于balance是以region的数目而不是大小为单位来进行的，因此可能会导致balance失效。而从好的方面来说，更少的split会让系统提供更加稳定的在线服务。\n\n  上述第三点的好处对于在线应用来说是明显的，而坏处我们可以通过在请求的低谷时间进行人工的split和balance来避免掉。\n\n## 表结构\n\n```shell\ncreate 'NewsClickFeedback',{NAME=>'Toutiao',VERSIONS=>1,BLOCKCACHE=>true,BLOOMFILTER=>'ROW',COMPRESSION=>'SNAPPY',TTL => ' 259200 '},{SPLITS => ['1','2','3','4','5','6','7','8','9','a','b','c','d','e','f']}\n```\n\n- versions \n\n  数据版本数，HBase数据模型允许一个cell的数据为带有不同时间戳的多版本数据集，versions参数指定了最多保存几个版本数据，默认为1。如果想保存两个历史版本数据，可以将versions参数设置为2\n\n- 布隆过滤器BloomFilter\n\n  布隆过滤器，优化HBase的**随机**读取性能，可选值NONE|ROW|ROWCOL，默认为NONE，该参数可以单独对某个列簇启用。启用过滤器，对于get操作以及部分scan操作可以剔除掉不会用到的存储文件，减少实际IO次数，提高随机读性能。Row类型适用于只根据Row进行查找，而RowCol类型适用于根据Row+Col联合查找，如下：\n\n  Row类型适用于：get ‘NewsClickFeedback’,’row1′\n\n  RowCol类型适用于：get ‘NewsClickFeedback’,’row1′,{COLUMN => ‘Toutiao’}\n\n  对于有随机读的业务，建议开启Row类型的过滤器，使用空间换时间，提高随机读性能。\n\n- compression \n\n  数据压缩方式，HBase支持多种形式的数据压缩，一方面减少数据存储空间，一方面降低数据网络传输量进而提升读取效率。目前HBase支持的压缩算法主要包括三种：GZip | LZO | Snappy\n\n  Snappy的压缩率最低，但是编解码速率最高，对CPU的消耗也最小，目前一般建议使用Snappy\n\n- 过期时间 TTL\n\n  数据过期时间，单位为秒，默认为永久保存。如果设置了过期时间，HBase在Compact时会通过一定机制检查数据是否过期，过期数据会被删除。用户可以根据具体业务场景设置为一个月或者三个月。示例中TTL => ‘ 259200’设置数据过期时间为三天\n\n- in_memory\n\n  数据是否常驻内存，默认为false。HBase为频繁访问的数据提供了一个缓存区域，缓存区域一般存储数据量小、访问频繁的数据，常见场景为元数据存储。默认情况，该缓存区域大小等于Jvm Heapsize * 0.2 * 0.25 ，假如Jvm Heapsize = 70G，存储区域的大小约等于3.2G。需要注意的是HBase Meta元数据信息存储在这块区域，如果业务数据设置为true而且太大会导致Meta数据被置换出去，导致整个集群性能降低，所以在设置该参数时需要格外小心\n\n- blockCache\n\n  是否开启block cache缓存，默认开启。\n\n- splits\n\n  region预分配策略。通过region预分配，数据会被均衡到多台机器上，这样可以一定程度上解决热点应用数据量剧增导致系统自动split引起的性能问题","source":"_posts/hbase/hbase的表设计.md","raw":"---\ntitle: hbase的表设计\ndate: 2017-09-10 21:36:01\ntags:\n- hbase\ncategories:\n- 大数据\n---\n\n# hbase的表设计\n\n[HBase Rowkey的散列与预分区设计](http://www.cnblogs.com/bdifn/p/3801737.html)\n\n## RowKey设计原则\n\n1）Rowkey长度原则，Rowkey是一个二进制码流，可以是任意字符串，最大长度64KB，实际应用中一般为10~100bytes，存为byte[]字节数组，一般设计成定长的。建议是越短越好，不要超过16个字节。原因一数据的持久化文件HFile中是按照KeyValue存储的，如果Rowkey过长比如100个字节，1000万列数据光Rowkey就要占用100*1000万=10亿个字节，将近1G数据，这会极大影响HFile的存储效率；原因二MemStore将缓存部分数据到内存，如果Rowkey字段过长内存的有效利用率会降低，系统将无法缓存更多的数据，这会降低检索效率。因此Rowkey的字节长度越短越好。原因三目前操作系统是都是64位系统，内存8字节对齐。控制在16个字节，8字节的整数倍利用操作系统的最佳特性。\n2）是Rowkey散列原则，如果Rowkey是按时间戳的方式递增，不要将时间放在二进制码的前面，建议将Rowkey的高位作为散列字段，由程序循环生成，低位放时间字段，这样将提高数据均衡分布在每个Regionserver实现负载均衡的几率。如果没有散列字段，首字段直接是时间信息将产生所有新数据都在一个RegionServer上堆积的热点现象，这样在做数据检索的时候负载将会集中在个别RegionServer，降低查询效率。\n3）Rowkey唯一原则，必须在设计上保证其唯一性。\nrow key是按照字典序存储，因此，设计row key时，要充分利用这个排序特点，将经常一起读取的数据存储到一块，将最近可能会被访问的数据放在一块。\n举个例子：如果最近写入HBase表中的数据是最可能被访问的，可以考虑将时间戳作为row key的一部分，由于是字典序排序，所以可以使用Long.MAX_VALUE – timestamp作为row key，这样能保证新写入的数据在读取时可以被快速命中。\n\n## 列族设计原则\n\n同一Column Family的Columns会群聚在一个存储文件上，并依Column key排序，因此设计时：读写相关性较高的数据，存在同一列族中。\n\n由于Hbase是一个面向列族的存储器，调优和存储都是在列族这个层次上进行的，最好使列族成员都有相同的\"访问模式(access pattern)\"和大小特征；\n在一张表里不要定义太多的column family。目前Hbase并不能很好的处理超过2~3个column family的表。因为某个column family在flush的时候，它邻近的column family也会因关联效应被触发flush，最终导致系统产生更多的I/O。\n\n\n\n在一张表里不要定义太多的column family。目前Hbase并不能很好的处理超过2~3个column family的表。因为某个column family在flush的时候，它邻近的column family也会因关联效应被触发flush，最终导致系统产生更多的I/O。\n\n- family越多，那么获取每一个cell数据的优势越明显，因为io和网络都减少了，而如果只有一个family，那么每一次读都会读取当前rowkey的所有数据，网络和io上会有一些损失。\n  ​    当然如果要获取的是固定的几列数据，那么把这几列写到一个family中比分别设置family要更好，因为只需一次请求就能拿回所有数据。\n\n  首先，不同的family是在同一个region下面。而每一个family都会分配一个memstore，所以更多的family会消耗更多的内存。\n  其次,目前版本的hbase，在flush和compaction都是以region为单位的，也就是说当一个family达到flush条件时，该region的所有family所属的memstore都会flush一次，即使memstore中只有很少的数据也会触发flush而生成小文件。这样就增加了compaction发生的机率，而compaction也是以region为单位的，这样就很容易发生compaction风暴从而降低系统的整体吞吐量。\n  第三，由于hfile是以family为单位的，因此对于多个family来说，数据被分散到了更多的hfile中，减小了split发生的机率。这是把双刃剑。更少的split会导致该region的体积比较大，由于balance是以region的数目而不是大小为单位来进行的，因此可能会导致balance失效。而从好的方面来说，更少的split会让系统提供更加稳定的在线服务。\n\n  上述第三点的好处对于在线应用来说是明显的，而坏处我们可以通过在请求的低谷时间进行人工的split和balance来避免掉。\n\n## 表结构\n\n```shell\ncreate 'NewsClickFeedback',{NAME=>'Toutiao',VERSIONS=>1,BLOCKCACHE=>true,BLOOMFILTER=>'ROW',COMPRESSION=>'SNAPPY',TTL => ' 259200 '},{SPLITS => ['1','2','3','4','5','6','7','8','9','a','b','c','d','e','f']}\n```\n\n- versions \n\n  数据版本数，HBase数据模型允许一个cell的数据为带有不同时间戳的多版本数据集，versions参数指定了最多保存几个版本数据，默认为1。如果想保存两个历史版本数据，可以将versions参数设置为2\n\n- 布隆过滤器BloomFilter\n\n  布隆过滤器，优化HBase的**随机**读取性能，可选值NONE|ROW|ROWCOL，默认为NONE，该参数可以单独对某个列簇启用。启用过滤器，对于get操作以及部分scan操作可以剔除掉不会用到的存储文件，减少实际IO次数，提高随机读性能。Row类型适用于只根据Row进行查找，而RowCol类型适用于根据Row+Col联合查找，如下：\n\n  Row类型适用于：get ‘NewsClickFeedback’,’row1′\n\n  RowCol类型适用于：get ‘NewsClickFeedback’,’row1′,{COLUMN => ‘Toutiao’}\n\n  对于有随机读的业务，建议开启Row类型的过滤器，使用空间换时间，提高随机读性能。\n\n- compression \n\n  数据压缩方式，HBase支持多种形式的数据压缩，一方面减少数据存储空间，一方面降低数据网络传输量进而提升读取效率。目前HBase支持的压缩算法主要包括三种：GZip | LZO | Snappy\n\n  Snappy的压缩率最低，但是编解码速率最高，对CPU的消耗也最小，目前一般建议使用Snappy\n\n- 过期时间 TTL\n\n  数据过期时间，单位为秒，默认为永久保存。如果设置了过期时间，HBase在Compact时会通过一定机制检查数据是否过期，过期数据会被删除。用户可以根据具体业务场景设置为一个月或者三个月。示例中TTL => ‘ 259200’设置数据过期时间为三天\n\n- in_memory\n\n  数据是否常驻内存，默认为false。HBase为频繁访问的数据提供了一个缓存区域，缓存区域一般存储数据量小、访问频繁的数据，常见场景为元数据存储。默认情况，该缓存区域大小等于Jvm Heapsize * 0.2 * 0.25 ，假如Jvm Heapsize = 70G，存储区域的大小约等于3.2G。需要注意的是HBase Meta元数据信息存储在这块区域，如果业务数据设置为true而且太大会导致Meta数据被置换出去，导致整个集群性能降低，所以在设置该参数时需要格外小心\n\n- blockCache\n\n  是否开启block cache缓存，默认开启。\n\n- splits\n\n  region预分配策略。通过region预分配，数据会被均衡到多台机器上，这样可以一定程度上解决热点应用数据量剧增导致系统自动split引起的性能问题","slug":"hbase/hbase的表设计","published":1,"updated":"2018-09-12T03:03:21.817Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfngs002fwlkvtrfyfvhy"},{"title":"hbase的读写优化","date":"2017-09-27T14:39:33.000Z","_content":"\n任何系统都会有各种各样的问题，有些是系统本身设计问题，有些却是使用姿势问题。HBase也一样，在真实生产线上大家或多或少都会遇到很多问题，有些是HBase还需要完善的，有些是我们确实对它了解太少。总结起来，大家遇到的主要问题无非是Full GC异常导致宕机问题、RIT问题、写吞吐量太低以及读延迟较大。\n\nFull GC问题之前在一些文章里面已经讲过它的来龙去脉，主要的解决方案目前主要有两方面需要注意，一方面需要查看GC日志确认是哪种Full GC，根据Full GC类型对JVM参数进行调优，另一方面需要确认是否开启了BucketCache的offheap模式，建议使用LRUBlockCache的童鞋尽快转移到BucketCache来。当然我们还是很期待官方2.0.0版本发布的更多offheap模块。\n\nRIT问题，我相信更多是因为我们对其不了解，具体原理可以戳[这里](http://hbasefly.com/2016/09/08/hbase-rit/)，解决方案目前有两个，优先是使用官方提供的HBCK进行修复（HBCK本人一直想拿出来分享，但是目前案例还不多，等后面有更多案例的话再拿出来说），使用之后还是解决不了的话就需要手动修复文件或者元数据表。\n\n而对于写吞吐量太低以及读延迟太大的优化问题，笔者也和很多朋友进行过探讨，这篇文章就以读延迟优化为核心内容展开，具体分析HBase进行读延迟优化的那些套路，以及这些套路之后的具体原理。希望大家在看完之后能够结合这些套路剖析自己的系统。\n\n一般情况下，读请求延迟较大通常存在三种场景，分别为：\n\n\\1. 仅有某业务延迟较大，集群其他业务都正常\n\n\\2. 整个集群所有业务都反映延迟较大\n\n\\3. 某个业务起来之后集群其他部分业务延迟较大\n\n这三种场景是表象，通常某业务反应延迟异常，首先需要明确具体是哪种场景，然后针对性解决问题。下图是对读优化思路的一点总结，主要分为四个方面：客户端优化、服务器端优化、列族设计优化以及HDFS相关优化，下面每一个小点都会按照场景分类，文章最后进行归纳总结。下面分别进行详细讲解：\n\n![hbase1](http://hbasefly.com/wp-content/uploads/2016/11/hbase1.png)\n\n### **HBase客户端优化**\n\n和大多数系统一样，客户端作为业务读写的入口，姿势使用不正确通常会导致本业务读延迟较高实际上存在一些使用姿势的推荐用法，这里一般需要关注四个问题：\n\n#### **1. scan缓存是否设置合理？**\n\n优化原理：在解释这个问题之前，首先需要解释什么是scan缓存，通常来讲一次scan会返回大量数据，因此客户端发起一次scan请求，实际并不会一次就将所有数据加载到本地，而是分成多次RPC请求进行加载，这样设计一方面是因为大量数据请求可能会导致网络带宽严重消耗进而影响其他业务，另一方面也有可能因为数据量太大导致本地客户端发生OOM。在这样的设计体系下用户会首先加载一部分数据到本地，然后遍历处理，再加载下一部分数据到本地处理，如此往复，直至所有数据都加载完成。数据加载到本地就存放在scan缓存中，默认100条数据大小。\n\n通常情况下，默认的scan缓存设置就可以正常工作的。但是在一些大scan（一次scan可能需要查询几万甚至几十万行数据）来说，每次请求100条数据意味着一次scan需要几百甚至几千次RPC请求，这种交互的代价无疑是很大的。因此可以考虑将scan缓存设置增大，比如设为500或者1000就可能更加合适。笔者之前做过一次试验，在一次scan扫描10w+条数据量的条件下，将scan缓存从100增加到1000，可以有效降低scan请求的总体延迟，延迟基本降低了25%左右。\n\n优化建议：大scan场景下将scan缓存从100增大到500或者1000，用以减少RPC次数\n\n#### **2. get请求是否可以使用批量请求？**\n\n****\n\n优化原理：HBase分别提供了单条get以及批量get的API接口，使用批量get接口可以减少客户端到RegionServer之间的RPC连接数，提高读取性能。另外需要注意的是，批量get请求要么成功返回所有请求数据，要么抛出异常。\n\n优化建议：使用批量get进行读取请求\n\n#### **3. 请求是否可以显示指定列族或者列？**\n\n优化原理：HBase是典型的列族数据库，意味着同一列族的数据存储在一起，不同列族的数据分开存储在不同的目录下。如果一个表有多个列族，只是根据Rowkey而不指定列族进行检索的话不同列族的数据需要独立进行检索，性能必然会比指定列族的查询差很多，很多情况下甚至会有2倍～3倍的性能损失。\n\n****\n\n优化建议：可以指定列族或者列进行精确查找的尽量指定查找\n\n****\n\n#### **4. 离线批量读取请求是否设置禁止缓存？**\n\n优化原理：通常离线批量读取数据会进行一次性全表扫描，一方面数据量很大，另一方面请求只会执行一次。这种场景下如果使用scan默认设置，就会将数据从HDFS加载出来之后放到缓存。可想而知，大量数据进入缓存必将其他实时业务热点数据挤出，其他业务不得不从HDFS加载，进而会造成明显的读延迟毛刺\n\n优化建议：离线批量读取请求设置禁用缓存，scan.setBlockCache(false)\n\n### **HBase服务器端优化**\n\n一般服务端端问题一旦导致业务读请求延迟较大的话，通常是集群级别的，即整个集群的业务都会反映读延迟较大。可以从4个方面入手：\n\n#### **5. 读请求是否均衡？**\n\n优化原理：极端情况下假如所有的读请求都落在一台RegionServer的某几个Region上，这一方面不能发挥整个集群的并发处理能力，另一方面势必造成此台RegionServer资源严重消耗（比如IO耗尽、handler耗尽等），落在该台RegionServer上的其他业务会因此受到很大的波及。可见，读请求不均衡不仅会造成本身业务性能很差，还会严重影响其他业务。当然，写请求不均衡也会造成类似的问题，可见负载不均衡是HBase的大忌。\n\n观察确认：观察所有RegionServer的读请求QPS曲线，确认是否存在读请求不均衡现象\n\n优化建议：RowKey必须进行散列化处理（比如MD5散列），同时建表必须进行预分区处理\n\n#### **6. BlockCache是否设置合理？**\n\n优化原理：BlockCache作为读缓存，对于读性能来说至关重要。默认情况下BlockCache和Memstore的配置相对比较均衡（各占40%），可以根据集群业务进行修正，比如读多写少业务可以将BlockCache占比调大。另一方面，BlockCache的策略选择也很重要，不同策略对读性能来说影响并不是很大，但是对GC的影响却相当显著，尤其BucketCache的offheap模式下GC表现很优越。另外，HBase 2.0对offheap的改造（HBASE-11425）将会使HBase的读性能得到2～4倍的提升，同时GC表现会更好！\n\n观察确认：观察所有RegionServer的缓存未命中率、配置文件相关配置项一级GC日志，确认BlockCache是否可以优化\n\n优化建议：JVM内存配置量 < 20G，BlockCache策略选择LRUBlockCache；否则选择BucketCache策略的offheap模式；期待HBase 2.0的到来！\n\n#### **7. HFile文件是否太多？**\n\n****\n\n优化原理：HBase读取数据通常首先会到Memstore和BlockCache中检索（读取最近写入数据&热点数据），如果查找不到就会到文件中检索。HBase的类LSM结构会导致每个store包含多数HFile文件，文件越多，检索所需的IO次数必然越多，读取延迟也就越高。文件数量通常取决于Compaction的执行策略，一般和两个配置参数有关：hbase.hstore.compactionThreshold和hbase.hstore.compaction.max.size，前者表示一个store中的文件数超过多少就应该进行合并，后者表示参数合并的文件大小最大是多少，超过此大小的文件不能参与合并。这两个参数不能设置太’松’（前者不能设置太大，后者不能设置太小），导致Compaction合并文件的实际效果不明显，进而很多文件得不到合并。这样就会导致HFile文件数变多。\n\n观察确认：观察RegionServer级别以及Region级别的storefile数，确认HFile文件是否过多\n\n优化建议：hbase.hstore.compactionThreshold设置不能太大，默认是3个；设置需要根据Region大小确定，通常可以简单的认为hbase.hstore.compaction.max.size = RegionSize / hbase.hstore.compactionThreshold\n\n****\n\n#### **8. Compaction是否消耗系统资源过多？**\n\n****\n\n优化原理：Compaction是将小文件合并为大文件，提高后续业务随机读性能，但是也会带来IO放大以及带宽消耗问题（数据远程读取以及三副本写入都会消耗系统带宽）。正常配置情况下Minor Compaction并不会带来很大的系统资源消耗，除非因为配置不合理导致Minor Compaction太过频繁，或者Region设置太大情况下发生Major Compaction。\n\n****\n\n观察确认：观察系统IO资源以及带宽资源使用情况，再观察Compaction队列长度，确认是否由于Compaction导致系统资源消耗过多\n\n****\n\n优化建议：\n\n（1）Minor Compaction设置：hbase.hstore.compactionThreshold设置不能太小，又不能设置太大，因此建议设置为5～6；hbase.hstore.compaction.max.size = RegionSize / hbase.hstore.compactionThreshold\n\n（2）Major Compaction设置：大Region读延迟敏感业务（ 100G以上）通常不建议开启自动Major Compaction，手动低峰期触发。小Region或者延迟不敏感业务可以开启Major Compaction，但建议限制流量；\n\n（3）期待更多的优秀Compaction策略，类似于stripe-compaction尽早提供稳定服务\n\n### **HBase列族设计优化**\n\nHBase列族设计对读性能影响也至关重要，其特点是只影响单个业务，并不会对整个集群产生太大影响。列族设计主要从两个方面检查：\n\n#### **9. Bloomfilter是否设置？是否设置合理？**\n\n****\n\n优化原理：Bloomfilter主要用来过滤不存在待检索RowKey或者Row-Col的HFile文件，避免无用的IO操作。它会告诉你在这个HFile文件中是否可能存在待检索的KV，如果不存在，就可以不用消耗IO打开文件进行seek。很显然，通过设置Bloomfilter可以提升随机读写的性能。\n\nBloomfilter取值有两个，row以及rowcol，需要根据业务来确定具体使用哪种。如果业务大多数随机查询仅仅使用row作为查询条件，Bloomfilter一定要设置为row，否则如果大多数随机查询使用row+cf作为查询条件，Bloomfilter需要设置为rowcol。如果不确定业务查询类型，设置为row。\n\n优化建议：任何业务都应该设置Bloomfilter，通常设置为row就可以，除非确认业务随机查询类型为row+cf，可以设置为rowcol\n\n### **HDFS相关优化**\n\nHDFS作为HBase最终数据存储系统，通常会使用三副本策略存储HBase数据文件以及日志文件。从HDFS的角度望上层看，HBase即是它的客户端，HBase通过调用它的客户端进行数据读写操作，因此HDFS的相关优化也会影响HBase的读写性能。这里主要关注如下三个方面：\n\n#### **10. Short-Circuit Local Read功能是否开启？**\n\n优化原理：当前HDFS读取数据都需要经过DataNode，客户端会向DataNode发送读取数据的请求，DataNode接受到请求之后从硬盘中将文件读出来，再通过TPC发送给客户端。Short Circuit策略允许客户端绕过DataNode直接读取本地数据。（具体原理参考[此处](http://blog.cloudera.com/blog/2013/08/how-improved-short-circuit-local-reads-bring-better-performance-and-security-to-hadoop/)）\n\n优化建议：开启Short Circuit Local Read功能，具体配置戳[这里](https://hadoop.apache.org/docs/r2.7.2/hadoop-project-dist/hadoop-hdfs/ShortCircuitLocalReads.html)\n\n#### **11. Hedged Read功能是否开启？**\n\n优化原理：HBase数据在HDFS中一般都会存储三份，而且优先会通过Short-Circuit Local Read功能尝试本地读。但是在某些特殊情况下，有可能会出现因为磁盘问题或者网络问题引起的短时间本地读取失败，为了应对这类问题，社区开发者提出了补偿重试机制 – Hedged Read。该机制基本工作原理为：客户端发起一个本地读，一旦一段时间之后还没有返回，客户端将会向其他DataNode发送相同数据的请求。哪一个请求先返回，另一个就会被丢弃。 \n\n优化建议：开启Hedged Read功能，具体配置参考[这里](https://issues.apache.org/jira/browse/HDFS-5776)\n\n#### **12. 数据本地率是否太低？**\n\n数据本地率：HDFS数据通常存储三份，假如当前RegionA处于Node1上，数据a写入的时候三副本为(Node1,Node2,Node3)，数据b写入三副本是(Node1,Node4,Node5)，数据c写入三副本(Node1,Node3,Node5)，可以看出来所有数据写入本地Node1肯定会写一份，数据都在本地可以读到，因此数据本地率是100%。现在假设RegionA被迁移到了Node2上，只有数据a在该节点上，其他数据（b和c）读取只能远程跨节点读，本地率就为33%（假设a，b和c的数据大小相同）。\n\n优化原理：数据本地率太低很显然会产生大量的跨网络IO请求，必然会导致读请求延迟较高，因此提高数据本地率可以有效优化随机读性能。数据本地率低的原因一般是因为Region迁移（自动balance开启、RegionServer宕机迁移、手动迁移等）,因此一方面可以通过避免Region无故迁移来保持数据本地率，另一方面如果数据本地率很低，也可以通过执行major_compact提升数据本地率到100%。\n\n优化建议：避免Region无故迁移，比如关闭自动balance、RS宕机及时拉起并迁回飘走的Region等；在业务低峰期执行major_compact提升数据本地率\n\n### **HBase读性能优化归纳**\n\n在本文开始的时候提到读延迟较大无非三种常见的表象，单个业务慢、集群随机读慢以及某个业务随机读之后其他业务受到影响导致随机读延迟很大。了解完常见的可能导致读延迟较大的一些问题之后，我们将这些问题进行如下归类，读者可以在看到现象之后在对应的问题列表中进行具体定位：\n\n![hbase2](http://hbasefly.com/wp-content/uploads/2016/11/hbase2.png)\n\n![hbase3](http://hbasefly.com/wp-content/uploads/2016/11/hbase3.png)\n\n![hbase4](http://hbasefly.com/wp-content/uploads/2016/11/hbase4.png)\n\n\n\n\n\n\n\n上一篇文章主要介绍了HBase读性能优化的基本套路，本篇文章来说道说道如何诊断HBase写数据的异常问题以及优化写性能。和读相比，HBase写数据流程倒是显得很简单：数据先顺序写入HLog，再写入对应的缓存Memstore，当Memstore中数据大小达到一定阈值（128M）之后，系统会异步将Memstore中数据flush到HDFS形成小文件。\n\nHBase数据写入通常会遇到两类问题，一类是写性能较差，另一类是数据根本写不进去。这两类问题的切入点也不尽相同，如下图所示：\n\n![70](http://hbasefly.com/wp-content/uploads/2016/12/70.png)\n\n### **写性能优化切入点**\n\n****\n\n#### **1. 是否需要写WAL？WAL是否需要同步写入？**\n\n优化原理：数据写入流程可以理解为一次顺序写WAL+一次写缓存，通常情况下写缓存延迟很低，因此提升写性能就只能从WAL入手。WAL机制一方面是为了确保数据即使写入缓存丢失也可以恢复，另一方面是为了集群之间异步复制。默认WAL机制开启且使用同步机制写入WAL。首先考虑业务是否需要写WAL，通常情况下大多数业务都会开启WAL机制（默认），但是对于部分业务可能并不特别关心异常情况下部分数据的丢失，而更关心数据写入吞吐量，比如某些推荐业务，这类业务即使丢失一部分用户行为数据可能对推荐结果并不构成很大影响，但是对于写入吞吐量要求很高，不能造成数据队列阻塞。这种场景下可以考虑关闭WAL写入，写入吞吐量可以提升2x~3x。退而求其次，有些业务不能接受不写WAL，但可以接受WAL异步写入，也是可以考虑优化的，通常也会带来1x～2x的性能提升。\n\n优化推荐：根据业务关注点在WAL机制与写入吞吐量之间做出选择\n\n其他注意点：对于使用Increment操作的业务，WAL可以设置关闭，也可以设置异步写入，方法同Put类似。相信大多数Increment操作业务对WAL可能都不是那么敏感～\n\n#### **2. Put是否可以同步批量提交？**\n\n优化原理：HBase分别提供了单条put以及批量put的API接口，使用批量put接口可以减少客户端到RegionServer之间的RPC连接数，提高写入性能。另外需要注意的是，批量put请求要么全部成功返回，要么抛出异常。\n\n优化建议：使用批量put进行写入请求\n\n#### **3. Put是否可以异步批量提交？**\n\n优化原理：业务如果可以接受异常情况下少量数据丢失的话，还可以使用异步批量提交的方式提交请求。提交分为两阶段执行：用户提交写请求之后，数据会写入客户端缓存，并返回用户写入成功；当客户端缓存达到阈值（默认2M）之后批量提交给RegionServer。需要注意的是，在某些情况下客户端异常的情况下缓存数据有可能丢失。\n\n****\n\n优化建议：在业务可以接受的情况下开启异步批量提交\n\n使用方式：setAutoFlush(false)\n\n#### **4. Region是否太少？**\n\n优化原理：当前集群中表的Region个数如果小于RegionServer个数，即Num(Region of Table) < Num(RegionServer)，可以考虑切分Region并尽可能分布到不同RegionServer来提高系统请求并发度，如果Num(Region of Table) > Num(RegionServer)，再增加Region个数效果并不明显。\n\n优化建议：在Num(Region of Table) < Num(RegionServer)的场景下切分部分请求负载高的Region并迁移到其他RegionServer；\n\n#### **5. 写入请求是否不均衡？**\n\n优化原理：另一个需要考虑的问题是写入请求是否均衡，如果不均衡，一方面会导致系统并发度较低，另一方面也有可能造成部分节点负载很高，进而影响其他业务。分布式系统中特别害怕一个节点负载很高的情况，一个节点负载很高可能会拖慢整个集群，这是因为很多业务会使用Mutli批量提交读写请求，一旦其中一部分请求落到该节点无法得到及时响应，就会导致整个批量请求超时。因此不怕节点宕掉，就怕节点奄奄一息！\n\n优化建议：检查RowKey设计以及预分区策略，保证写入请求均衡。\n\n#### **6. 写入KeyValue数据是否太大？**\n\nKeyValue大小对写入性能的影响巨大，一旦遇到写入性能比较差的情况，需要考虑是否由于写入KeyValue数据太大导致。KeyValue大小对写入性能影响曲线图如下：\n\n![72](http://hbasefly.com/wp-content/uploads/2016/12/72.png)\n\n图中横坐标是写入的一行数据（每行数据10列）大小，左纵坐标是写入吞吐量，右坐标是写入平均延迟（ms）。可以看出随着单行数据大小不断变大，写入吞吐量急剧下降，写入延迟在100K之后急剧增大。\n\n说到这里，有必要和大家分享两起在生产线环境因为业务KeyValue较大导致的严重问题，一起是因为大字段业务写入导致其他业务吞吐量急剧下降，另一起是因为大字段业务scan导致RegionServer宕机。\n\n**案件一：大字段写入导致其他业务吞吐量急剧下降**\n\n部分业务反馈集群写入忽然变慢、数据开始堆积的情况，查看集群表级别的数据读写QPS监控，发现问题的第一个关键点：业务A开始写入之后整个集群其他部分业务写入QPS都几乎断崖式下跌，初步怀疑黑手就是业务A。\n\n下图是当时业务A的写入QPS（事后发现脑残忘了截取其他表QPS断崖式下跌的惨象），但是第一感觉是QPS并不高啊，凭什么去影响别人！\n\n![73](http://hbasefly.com/wp-content/uploads/2016/12/73.png)\n\n于是就继续查看其他监控信息，首先确认系统资源（主要是IO）并没有到达瓶颈，其次确认了写入的均衡性，直至看到下图，才追踪到影响其他业务写入的第二个关键点：RegionServer的handler（配置150）被残暴耗尽：\n\n![74](http://hbasefly.com/wp-content/uploads/2016/12/74.jpg)\n\n对比上面两张图，是不是发现出奇的一致，那就可以基本确认是由于该业务写入导致这台RegionServer的handler被耗尽，进而其他业务拿不到handler，自然写不进去。那问题来了，为什么会这样？正常情况下handler在处理完客户端请求之后会立马释放，唯一的解释是这些请求的延迟实在太大。\n\n试想，我们去汉堡店排队买汉堡，有150个窗口服务，正常情况下大家买一个很快，这样150个窗口可能只需要50个服务。假设忽然来了一批大汉，要定制超大汉堡，好了，所有的窗口都工作起来，而且因为大汉堡不好制作导致服务很慢，这样必然会导致其他排队的用户长时间等待，直至超时。\n\n可回头一想这可是写请求啊，怎么会有这么大的请求延迟！和业务方沟通之后确认该表主要存储语料库文档信息，都是平均100K左右的数据，是不是已经猜到了结果，没错，就是因为这个业务KeyValue太大导致。KeyValue太大会导致HLog文件写入频繁切换、flush以及compaction频繁触发，写入性能急剧下降。\n\n目前针对这种较大KeyValue写入性能较差的问题还没有直接的解决方案，好在社区已经意识到这个问题，在接下来即将发布的下一个大版本HBase 2.0.0版本会针对该问题进行深入优化，详见[HBase MOB](https://issues.apache.org/jira/browse/HBASE-11339)，优化后用户使用HBase存储文档、图片等二进制数据都会有极佳的性能体验。\n\n**案件二：大字段scan导致RegionServer宕机**\n\n案件现场：有段时间有个0.98集群的RegionServer经常频繁宕机，查看日志是由于”java.lang.OutOfMemoryError: Requested array size exceeds VM limit”，如下图所示：\n\n![76](http://hbasefly.com/wp-content/uploads/2016/12/76.jpg)\n\n原因分析：通过查看源码以及相关文档，确认该异常发生在scan结果数据回传给客户端时由于数据量太大导致申请的array大小超过JVM规定的最大值（ Interge.Max_Value-2）。造成该异常的两种最常见原因分别是：\n\n- 表列太宽（几十万列或者上百万列），并且scan返回没有对列数量做任何限制，导致一行数据就可能因为包含大量列而数据超过array大小阈值\n- KeyValue太大，并且scan返回没有对返回结果大小做任何限制，导致返回数据结果大小超过array大小阈值\n\n有的童鞋就要提问啦，说如果已经对返回结果大小做了限制，在表列太宽的情况下是不是就可以不对列数量做限制呢。这里需要澄清一下，如果不对列数据做限制，数据总是一行一行返回的，即使一行数据大小大于设置的返回结果限制大小，也会返回完整的一行数据。在这种情况下，如果这一行数据已经超过array大小阈值，也会触发OOM异常。\n\n解决方案：目前针对该异常有两种解决方案，其一是升级集群到1.0，问题都解决了。其二是要求客户端访问的时候对返回结果大小做限制(scan.setMaxResultSize(2*1024*1024))、并且对列数量做限制(scan.setBatch(100))，当然，0.98.13版本以后也可以对返回结果大小在服务器端进行限制，设置参数hbase.server.scanner.max.result.size即可\n\n### **写异常问题检查点**\n\n上述几点主要针对写性能优化进行了介绍，除此之外，在一些情况下还会出现写异常，一旦发生需要考虑下面两种情况（GC引起的不做介绍）：\n\n#### **Memstore设置是否会触发Region级别或者RegionServer级别flush操作？**\n\n****\n\n问题解析：以RegionServer级别flush进行解析，HBase设定一旦整个RegionServer上所有Memstore占用内存大小总和大于配置文件中upperlimit时，系统就会执行RegionServer级别flush，flush算法会首先按照Region大小进行排序，再按照该顺序依次进行flush，直至总Memstore大小低至lowerlimit。这种flush通常会block较长时间，在日志中会发现“Memstore is above high water mark and block 7452 ms”，表示这次flush将会阻塞7s左右。\n\n问题检查点：\n\n- Region规模与Memstore总大小设置是否合理？如果RegionServer上Region较多，而Memstore总大小设置的很小（JVM设置较小或者upper.limit设置较小），就会触发RegionServer级别flush。集群规划相关内容可以参考文章《》\n- 列族是否设置过多，通常情况下表列族建议设置在1～3个之间，最好一个。如果设置过多，会导致一个Region中包含很多Memstore，导致更容易触到高水位upperlimit\n\n****\n\n#### **Store中HFile数量是否大于配置参数blockingStoreFile?**\n\n****\n\n问题解析：对于数据写入很快的集群，还需要特别关注一个参数：hbase.hstore.blockingStoreFiles，此参数表示如果当前hstore中文件数大于该值，系统将会强制执行compaction操作进行文件合并，合并的过程会阻塞整个hstore的写入。通常情况下该场景发生在数据写入很快的情况下，在日志中可以发现”Waited 3722ms on a compaction to clean up ‘too many store  files“\n\n****\n\n问题检查点：\n\n- 参数设置是否合理？hbase.hstore.compactionThreshold表示启动compaction的最低阈值，该值不能太大，否则会积累太多文件，一般建议设置为5～8左右。hbase.hstore.blockingStoreFiles默认设置为7，可以适当调大一些。\n\n****\n\n### **写性能还能再提高么？**\n\n****\n\n上文已经从写性能优化以及写异常诊断两个方面对HBase中数据写入可能的问题进行了详细的解释，相信在0.98版本的基础上对写入来说已经是最好的解决方案了。但是有些业务可能依然觉得不够快，毕竟”更快”是所有存储系统活着的动力，那还有提高空间吗？当然，接下来简单介绍HBase之后版本对写性能优化的两点核心改进：\n\n#### **Utilize Flash storage for WAL(HBASE-12848)**\n\n这个特性意味着可以将WAL单独置于SSD上，这样即使在默认情况下（WALSync），写性能也会有很大的提升。需要注意的是，该特性建立在HDFS 2.6.0+的基础上，HDFS以前版本不支持该特性。具体可以参考官方jira：[https://issues.apache.org/jira/browse/HBASE-12848](https://issues.apache.org/jira/browse/HBASE-12848)\n\n#### **Multiple WALs(HBASE-14457)**\n\n该特性也是对WAL进行改造，当前WAL设计为一个RegionServer上所有Region共享一个WAL，可以想象在写入吞吐量较高的时候必然存在资源竞争，降低整体性能。针对这个问题，社区小伙伴（阿里巴巴大神）提出Multiple WALs机制，管理员可以为每个Namespace下的所有表设置一个共享WAL，通过这种方式，写性能大约可以提升20%～40%左右。具体可以参考官方jira：[https://issues.apache.org/jira/browse/HBASE-14457](https://issues.apache.org/jira/browse/HBASE-14457)","source":"_posts/hbase/hbase的读写优化.md","raw":"---\ntitle: hbase的读写优化\ndate: 2017-09-27 22:39:33\ntags:\n- hbase\ncategories:\n- 大数据\n---\n\n任何系统都会有各种各样的问题，有些是系统本身设计问题，有些却是使用姿势问题。HBase也一样，在真实生产线上大家或多或少都会遇到很多问题，有些是HBase还需要完善的，有些是我们确实对它了解太少。总结起来，大家遇到的主要问题无非是Full GC异常导致宕机问题、RIT问题、写吞吐量太低以及读延迟较大。\n\nFull GC问题之前在一些文章里面已经讲过它的来龙去脉，主要的解决方案目前主要有两方面需要注意，一方面需要查看GC日志确认是哪种Full GC，根据Full GC类型对JVM参数进行调优，另一方面需要确认是否开启了BucketCache的offheap模式，建议使用LRUBlockCache的童鞋尽快转移到BucketCache来。当然我们还是很期待官方2.0.0版本发布的更多offheap模块。\n\nRIT问题，我相信更多是因为我们对其不了解，具体原理可以戳[这里](http://hbasefly.com/2016/09/08/hbase-rit/)，解决方案目前有两个，优先是使用官方提供的HBCK进行修复（HBCK本人一直想拿出来分享，但是目前案例还不多，等后面有更多案例的话再拿出来说），使用之后还是解决不了的话就需要手动修复文件或者元数据表。\n\n而对于写吞吐量太低以及读延迟太大的优化问题，笔者也和很多朋友进行过探讨，这篇文章就以读延迟优化为核心内容展开，具体分析HBase进行读延迟优化的那些套路，以及这些套路之后的具体原理。希望大家在看完之后能够结合这些套路剖析自己的系统。\n\n一般情况下，读请求延迟较大通常存在三种场景，分别为：\n\n\\1. 仅有某业务延迟较大，集群其他业务都正常\n\n\\2. 整个集群所有业务都反映延迟较大\n\n\\3. 某个业务起来之后集群其他部分业务延迟较大\n\n这三种场景是表象，通常某业务反应延迟异常，首先需要明确具体是哪种场景，然后针对性解决问题。下图是对读优化思路的一点总结，主要分为四个方面：客户端优化、服务器端优化、列族设计优化以及HDFS相关优化，下面每一个小点都会按照场景分类，文章最后进行归纳总结。下面分别进行详细讲解：\n\n![hbase1](http://hbasefly.com/wp-content/uploads/2016/11/hbase1.png)\n\n### **HBase客户端优化**\n\n和大多数系统一样，客户端作为业务读写的入口，姿势使用不正确通常会导致本业务读延迟较高实际上存在一些使用姿势的推荐用法，这里一般需要关注四个问题：\n\n#### **1. scan缓存是否设置合理？**\n\n优化原理：在解释这个问题之前，首先需要解释什么是scan缓存，通常来讲一次scan会返回大量数据，因此客户端发起一次scan请求，实际并不会一次就将所有数据加载到本地，而是分成多次RPC请求进行加载，这样设计一方面是因为大量数据请求可能会导致网络带宽严重消耗进而影响其他业务，另一方面也有可能因为数据量太大导致本地客户端发生OOM。在这样的设计体系下用户会首先加载一部分数据到本地，然后遍历处理，再加载下一部分数据到本地处理，如此往复，直至所有数据都加载完成。数据加载到本地就存放在scan缓存中，默认100条数据大小。\n\n通常情况下，默认的scan缓存设置就可以正常工作的。但是在一些大scan（一次scan可能需要查询几万甚至几十万行数据）来说，每次请求100条数据意味着一次scan需要几百甚至几千次RPC请求，这种交互的代价无疑是很大的。因此可以考虑将scan缓存设置增大，比如设为500或者1000就可能更加合适。笔者之前做过一次试验，在一次scan扫描10w+条数据量的条件下，将scan缓存从100增加到1000，可以有效降低scan请求的总体延迟，延迟基本降低了25%左右。\n\n优化建议：大scan场景下将scan缓存从100增大到500或者1000，用以减少RPC次数\n\n#### **2. get请求是否可以使用批量请求？**\n\n****\n\n优化原理：HBase分别提供了单条get以及批量get的API接口，使用批量get接口可以减少客户端到RegionServer之间的RPC连接数，提高读取性能。另外需要注意的是，批量get请求要么成功返回所有请求数据，要么抛出异常。\n\n优化建议：使用批量get进行读取请求\n\n#### **3. 请求是否可以显示指定列族或者列？**\n\n优化原理：HBase是典型的列族数据库，意味着同一列族的数据存储在一起，不同列族的数据分开存储在不同的目录下。如果一个表有多个列族，只是根据Rowkey而不指定列族进行检索的话不同列族的数据需要独立进行检索，性能必然会比指定列族的查询差很多，很多情况下甚至会有2倍～3倍的性能损失。\n\n****\n\n优化建议：可以指定列族或者列进行精确查找的尽量指定查找\n\n****\n\n#### **4. 离线批量读取请求是否设置禁止缓存？**\n\n优化原理：通常离线批量读取数据会进行一次性全表扫描，一方面数据量很大，另一方面请求只会执行一次。这种场景下如果使用scan默认设置，就会将数据从HDFS加载出来之后放到缓存。可想而知，大量数据进入缓存必将其他实时业务热点数据挤出，其他业务不得不从HDFS加载，进而会造成明显的读延迟毛刺\n\n优化建议：离线批量读取请求设置禁用缓存，scan.setBlockCache(false)\n\n### **HBase服务器端优化**\n\n一般服务端端问题一旦导致业务读请求延迟较大的话，通常是集群级别的，即整个集群的业务都会反映读延迟较大。可以从4个方面入手：\n\n#### **5. 读请求是否均衡？**\n\n优化原理：极端情况下假如所有的读请求都落在一台RegionServer的某几个Region上，这一方面不能发挥整个集群的并发处理能力，另一方面势必造成此台RegionServer资源严重消耗（比如IO耗尽、handler耗尽等），落在该台RegionServer上的其他业务会因此受到很大的波及。可见，读请求不均衡不仅会造成本身业务性能很差，还会严重影响其他业务。当然，写请求不均衡也会造成类似的问题，可见负载不均衡是HBase的大忌。\n\n观察确认：观察所有RegionServer的读请求QPS曲线，确认是否存在读请求不均衡现象\n\n优化建议：RowKey必须进行散列化处理（比如MD5散列），同时建表必须进行预分区处理\n\n#### **6. BlockCache是否设置合理？**\n\n优化原理：BlockCache作为读缓存，对于读性能来说至关重要。默认情况下BlockCache和Memstore的配置相对比较均衡（各占40%），可以根据集群业务进行修正，比如读多写少业务可以将BlockCache占比调大。另一方面，BlockCache的策略选择也很重要，不同策略对读性能来说影响并不是很大，但是对GC的影响却相当显著，尤其BucketCache的offheap模式下GC表现很优越。另外，HBase 2.0对offheap的改造（HBASE-11425）将会使HBase的读性能得到2～4倍的提升，同时GC表现会更好！\n\n观察确认：观察所有RegionServer的缓存未命中率、配置文件相关配置项一级GC日志，确认BlockCache是否可以优化\n\n优化建议：JVM内存配置量 < 20G，BlockCache策略选择LRUBlockCache；否则选择BucketCache策略的offheap模式；期待HBase 2.0的到来！\n\n#### **7. HFile文件是否太多？**\n\n****\n\n优化原理：HBase读取数据通常首先会到Memstore和BlockCache中检索（读取最近写入数据&热点数据），如果查找不到就会到文件中检索。HBase的类LSM结构会导致每个store包含多数HFile文件，文件越多，检索所需的IO次数必然越多，读取延迟也就越高。文件数量通常取决于Compaction的执行策略，一般和两个配置参数有关：hbase.hstore.compactionThreshold和hbase.hstore.compaction.max.size，前者表示一个store中的文件数超过多少就应该进行合并，后者表示参数合并的文件大小最大是多少，超过此大小的文件不能参与合并。这两个参数不能设置太’松’（前者不能设置太大，后者不能设置太小），导致Compaction合并文件的实际效果不明显，进而很多文件得不到合并。这样就会导致HFile文件数变多。\n\n观察确认：观察RegionServer级别以及Region级别的storefile数，确认HFile文件是否过多\n\n优化建议：hbase.hstore.compactionThreshold设置不能太大，默认是3个；设置需要根据Region大小确定，通常可以简单的认为hbase.hstore.compaction.max.size = RegionSize / hbase.hstore.compactionThreshold\n\n****\n\n#### **8. Compaction是否消耗系统资源过多？**\n\n****\n\n优化原理：Compaction是将小文件合并为大文件，提高后续业务随机读性能，但是也会带来IO放大以及带宽消耗问题（数据远程读取以及三副本写入都会消耗系统带宽）。正常配置情况下Minor Compaction并不会带来很大的系统资源消耗，除非因为配置不合理导致Minor Compaction太过频繁，或者Region设置太大情况下发生Major Compaction。\n\n****\n\n观察确认：观察系统IO资源以及带宽资源使用情况，再观察Compaction队列长度，确认是否由于Compaction导致系统资源消耗过多\n\n****\n\n优化建议：\n\n（1）Minor Compaction设置：hbase.hstore.compactionThreshold设置不能太小，又不能设置太大，因此建议设置为5～6；hbase.hstore.compaction.max.size = RegionSize / hbase.hstore.compactionThreshold\n\n（2）Major Compaction设置：大Region读延迟敏感业务（ 100G以上）通常不建议开启自动Major Compaction，手动低峰期触发。小Region或者延迟不敏感业务可以开启Major Compaction，但建议限制流量；\n\n（3）期待更多的优秀Compaction策略，类似于stripe-compaction尽早提供稳定服务\n\n### **HBase列族设计优化**\n\nHBase列族设计对读性能影响也至关重要，其特点是只影响单个业务，并不会对整个集群产生太大影响。列族设计主要从两个方面检查：\n\n#### **9. Bloomfilter是否设置？是否设置合理？**\n\n****\n\n优化原理：Bloomfilter主要用来过滤不存在待检索RowKey或者Row-Col的HFile文件，避免无用的IO操作。它会告诉你在这个HFile文件中是否可能存在待检索的KV，如果不存在，就可以不用消耗IO打开文件进行seek。很显然，通过设置Bloomfilter可以提升随机读写的性能。\n\nBloomfilter取值有两个，row以及rowcol，需要根据业务来确定具体使用哪种。如果业务大多数随机查询仅仅使用row作为查询条件，Bloomfilter一定要设置为row，否则如果大多数随机查询使用row+cf作为查询条件，Bloomfilter需要设置为rowcol。如果不确定业务查询类型，设置为row。\n\n优化建议：任何业务都应该设置Bloomfilter，通常设置为row就可以，除非确认业务随机查询类型为row+cf，可以设置为rowcol\n\n### **HDFS相关优化**\n\nHDFS作为HBase最终数据存储系统，通常会使用三副本策略存储HBase数据文件以及日志文件。从HDFS的角度望上层看，HBase即是它的客户端，HBase通过调用它的客户端进行数据读写操作，因此HDFS的相关优化也会影响HBase的读写性能。这里主要关注如下三个方面：\n\n#### **10. Short-Circuit Local Read功能是否开启？**\n\n优化原理：当前HDFS读取数据都需要经过DataNode，客户端会向DataNode发送读取数据的请求，DataNode接受到请求之后从硬盘中将文件读出来，再通过TPC发送给客户端。Short Circuit策略允许客户端绕过DataNode直接读取本地数据。（具体原理参考[此处](http://blog.cloudera.com/blog/2013/08/how-improved-short-circuit-local-reads-bring-better-performance-and-security-to-hadoop/)）\n\n优化建议：开启Short Circuit Local Read功能，具体配置戳[这里](https://hadoop.apache.org/docs/r2.7.2/hadoop-project-dist/hadoop-hdfs/ShortCircuitLocalReads.html)\n\n#### **11. Hedged Read功能是否开启？**\n\n优化原理：HBase数据在HDFS中一般都会存储三份，而且优先会通过Short-Circuit Local Read功能尝试本地读。但是在某些特殊情况下，有可能会出现因为磁盘问题或者网络问题引起的短时间本地读取失败，为了应对这类问题，社区开发者提出了补偿重试机制 – Hedged Read。该机制基本工作原理为：客户端发起一个本地读，一旦一段时间之后还没有返回，客户端将会向其他DataNode发送相同数据的请求。哪一个请求先返回，另一个就会被丢弃。 \n\n优化建议：开启Hedged Read功能，具体配置参考[这里](https://issues.apache.org/jira/browse/HDFS-5776)\n\n#### **12. 数据本地率是否太低？**\n\n数据本地率：HDFS数据通常存储三份，假如当前RegionA处于Node1上，数据a写入的时候三副本为(Node1,Node2,Node3)，数据b写入三副本是(Node1,Node4,Node5)，数据c写入三副本(Node1,Node3,Node5)，可以看出来所有数据写入本地Node1肯定会写一份，数据都在本地可以读到，因此数据本地率是100%。现在假设RegionA被迁移到了Node2上，只有数据a在该节点上，其他数据（b和c）读取只能远程跨节点读，本地率就为33%（假设a，b和c的数据大小相同）。\n\n优化原理：数据本地率太低很显然会产生大量的跨网络IO请求，必然会导致读请求延迟较高，因此提高数据本地率可以有效优化随机读性能。数据本地率低的原因一般是因为Region迁移（自动balance开启、RegionServer宕机迁移、手动迁移等）,因此一方面可以通过避免Region无故迁移来保持数据本地率，另一方面如果数据本地率很低，也可以通过执行major_compact提升数据本地率到100%。\n\n优化建议：避免Region无故迁移，比如关闭自动balance、RS宕机及时拉起并迁回飘走的Region等；在业务低峰期执行major_compact提升数据本地率\n\n### **HBase读性能优化归纳**\n\n在本文开始的时候提到读延迟较大无非三种常见的表象，单个业务慢、集群随机读慢以及某个业务随机读之后其他业务受到影响导致随机读延迟很大。了解完常见的可能导致读延迟较大的一些问题之后，我们将这些问题进行如下归类，读者可以在看到现象之后在对应的问题列表中进行具体定位：\n\n![hbase2](http://hbasefly.com/wp-content/uploads/2016/11/hbase2.png)\n\n![hbase3](http://hbasefly.com/wp-content/uploads/2016/11/hbase3.png)\n\n![hbase4](http://hbasefly.com/wp-content/uploads/2016/11/hbase4.png)\n\n\n\n\n\n\n\n上一篇文章主要介绍了HBase读性能优化的基本套路，本篇文章来说道说道如何诊断HBase写数据的异常问题以及优化写性能。和读相比，HBase写数据流程倒是显得很简单：数据先顺序写入HLog，再写入对应的缓存Memstore，当Memstore中数据大小达到一定阈值（128M）之后，系统会异步将Memstore中数据flush到HDFS形成小文件。\n\nHBase数据写入通常会遇到两类问题，一类是写性能较差，另一类是数据根本写不进去。这两类问题的切入点也不尽相同，如下图所示：\n\n![70](http://hbasefly.com/wp-content/uploads/2016/12/70.png)\n\n### **写性能优化切入点**\n\n****\n\n#### **1. 是否需要写WAL？WAL是否需要同步写入？**\n\n优化原理：数据写入流程可以理解为一次顺序写WAL+一次写缓存，通常情况下写缓存延迟很低，因此提升写性能就只能从WAL入手。WAL机制一方面是为了确保数据即使写入缓存丢失也可以恢复，另一方面是为了集群之间异步复制。默认WAL机制开启且使用同步机制写入WAL。首先考虑业务是否需要写WAL，通常情况下大多数业务都会开启WAL机制（默认），但是对于部分业务可能并不特别关心异常情况下部分数据的丢失，而更关心数据写入吞吐量，比如某些推荐业务，这类业务即使丢失一部分用户行为数据可能对推荐结果并不构成很大影响，但是对于写入吞吐量要求很高，不能造成数据队列阻塞。这种场景下可以考虑关闭WAL写入，写入吞吐量可以提升2x~3x。退而求其次，有些业务不能接受不写WAL，但可以接受WAL异步写入，也是可以考虑优化的，通常也会带来1x～2x的性能提升。\n\n优化推荐：根据业务关注点在WAL机制与写入吞吐量之间做出选择\n\n其他注意点：对于使用Increment操作的业务，WAL可以设置关闭，也可以设置异步写入，方法同Put类似。相信大多数Increment操作业务对WAL可能都不是那么敏感～\n\n#### **2. Put是否可以同步批量提交？**\n\n优化原理：HBase分别提供了单条put以及批量put的API接口，使用批量put接口可以减少客户端到RegionServer之间的RPC连接数，提高写入性能。另外需要注意的是，批量put请求要么全部成功返回，要么抛出异常。\n\n优化建议：使用批量put进行写入请求\n\n#### **3. Put是否可以异步批量提交？**\n\n优化原理：业务如果可以接受异常情况下少量数据丢失的话，还可以使用异步批量提交的方式提交请求。提交分为两阶段执行：用户提交写请求之后，数据会写入客户端缓存，并返回用户写入成功；当客户端缓存达到阈值（默认2M）之后批量提交给RegionServer。需要注意的是，在某些情况下客户端异常的情况下缓存数据有可能丢失。\n\n****\n\n优化建议：在业务可以接受的情况下开启异步批量提交\n\n使用方式：setAutoFlush(false)\n\n#### **4. Region是否太少？**\n\n优化原理：当前集群中表的Region个数如果小于RegionServer个数，即Num(Region of Table) < Num(RegionServer)，可以考虑切分Region并尽可能分布到不同RegionServer来提高系统请求并发度，如果Num(Region of Table) > Num(RegionServer)，再增加Region个数效果并不明显。\n\n优化建议：在Num(Region of Table) < Num(RegionServer)的场景下切分部分请求负载高的Region并迁移到其他RegionServer；\n\n#### **5. 写入请求是否不均衡？**\n\n优化原理：另一个需要考虑的问题是写入请求是否均衡，如果不均衡，一方面会导致系统并发度较低，另一方面也有可能造成部分节点负载很高，进而影响其他业务。分布式系统中特别害怕一个节点负载很高的情况，一个节点负载很高可能会拖慢整个集群，这是因为很多业务会使用Mutli批量提交读写请求，一旦其中一部分请求落到该节点无法得到及时响应，就会导致整个批量请求超时。因此不怕节点宕掉，就怕节点奄奄一息！\n\n优化建议：检查RowKey设计以及预分区策略，保证写入请求均衡。\n\n#### **6. 写入KeyValue数据是否太大？**\n\nKeyValue大小对写入性能的影响巨大，一旦遇到写入性能比较差的情况，需要考虑是否由于写入KeyValue数据太大导致。KeyValue大小对写入性能影响曲线图如下：\n\n![72](http://hbasefly.com/wp-content/uploads/2016/12/72.png)\n\n图中横坐标是写入的一行数据（每行数据10列）大小，左纵坐标是写入吞吐量，右坐标是写入平均延迟（ms）。可以看出随着单行数据大小不断变大，写入吞吐量急剧下降，写入延迟在100K之后急剧增大。\n\n说到这里，有必要和大家分享两起在生产线环境因为业务KeyValue较大导致的严重问题，一起是因为大字段业务写入导致其他业务吞吐量急剧下降，另一起是因为大字段业务scan导致RegionServer宕机。\n\n**案件一：大字段写入导致其他业务吞吐量急剧下降**\n\n部分业务反馈集群写入忽然变慢、数据开始堆积的情况，查看集群表级别的数据读写QPS监控，发现问题的第一个关键点：业务A开始写入之后整个集群其他部分业务写入QPS都几乎断崖式下跌，初步怀疑黑手就是业务A。\n\n下图是当时业务A的写入QPS（事后发现脑残忘了截取其他表QPS断崖式下跌的惨象），但是第一感觉是QPS并不高啊，凭什么去影响别人！\n\n![73](http://hbasefly.com/wp-content/uploads/2016/12/73.png)\n\n于是就继续查看其他监控信息，首先确认系统资源（主要是IO）并没有到达瓶颈，其次确认了写入的均衡性，直至看到下图，才追踪到影响其他业务写入的第二个关键点：RegionServer的handler（配置150）被残暴耗尽：\n\n![74](http://hbasefly.com/wp-content/uploads/2016/12/74.jpg)\n\n对比上面两张图，是不是发现出奇的一致，那就可以基本确认是由于该业务写入导致这台RegionServer的handler被耗尽，进而其他业务拿不到handler，自然写不进去。那问题来了，为什么会这样？正常情况下handler在处理完客户端请求之后会立马释放，唯一的解释是这些请求的延迟实在太大。\n\n试想，我们去汉堡店排队买汉堡，有150个窗口服务，正常情况下大家买一个很快，这样150个窗口可能只需要50个服务。假设忽然来了一批大汉，要定制超大汉堡，好了，所有的窗口都工作起来，而且因为大汉堡不好制作导致服务很慢，这样必然会导致其他排队的用户长时间等待，直至超时。\n\n可回头一想这可是写请求啊，怎么会有这么大的请求延迟！和业务方沟通之后确认该表主要存储语料库文档信息，都是平均100K左右的数据，是不是已经猜到了结果，没错，就是因为这个业务KeyValue太大导致。KeyValue太大会导致HLog文件写入频繁切换、flush以及compaction频繁触发，写入性能急剧下降。\n\n目前针对这种较大KeyValue写入性能较差的问题还没有直接的解决方案，好在社区已经意识到这个问题，在接下来即将发布的下一个大版本HBase 2.0.0版本会针对该问题进行深入优化，详见[HBase MOB](https://issues.apache.org/jira/browse/HBASE-11339)，优化后用户使用HBase存储文档、图片等二进制数据都会有极佳的性能体验。\n\n**案件二：大字段scan导致RegionServer宕机**\n\n案件现场：有段时间有个0.98集群的RegionServer经常频繁宕机，查看日志是由于”java.lang.OutOfMemoryError: Requested array size exceeds VM limit”，如下图所示：\n\n![76](http://hbasefly.com/wp-content/uploads/2016/12/76.jpg)\n\n原因分析：通过查看源码以及相关文档，确认该异常发生在scan结果数据回传给客户端时由于数据量太大导致申请的array大小超过JVM规定的最大值（ Interge.Max_Value-2）。造成该异常的两种最常见原因分别是：\n\n- 表列太宽（几十万列或者上百万列），并且scan返回没有对列数量做任何限制，导致一行数据就可能因为包含大量列而数据超过array大小阈值\n- KeyValue太大，并且scan返回没有对返回结果大小做任何限制，导致返回数据结果大小超过array大小阈值\n\n有的童鞋就要提问啦，说如果已经对返回结果大小做了限制，在表列太宽的情况下是不是就可以不对列数量做限制呢。这里需要澄清一下，如果不对列数据做限制，数据总是一行一行返回的，即使一行数据大小大于设置的返回结果限制大小，也会返回完整的一行数据。在这种情况下，如果这一行数据已经超过array大小阈值，也会触发OOM异常。\n\n解决方案：目前针对该异常有两种解决方案，其一是升级集群到1.0，问题都解决了。其二是要求客户端访问的时候对返回结果大小做限制(scan.setMaxResultSize(2*1024*1024))、并且对列数量做限制(scan.setBatch(100))，当然，0.98.13版本以后也可以对返回结果大小在服务器端进行限制，设置参数hbase.server.scanner.max.result.size即可\n\n### **写异常问题检查点**\n\n上述几点主要针对写性能优化进行了介绍，除此之外，在一些情况下还会出现写异常，一旦发生需要考虑下面两种情况（GC引起的不做介绍）：\n\n#### **Memstore设置是否会触发Region级别或者RegionServer级别flush操作？**\n\n****\n\n问题解析：以RegionServer级别flush进行解析，HBase设定一旦整个RegionServer上所有Memstore占用内存大小总和大于配置文件中upperlimit时，系统就会执行RegionServer级别flush，flush算法会首先按照Region大小进行排序，再按照该顺序依次进行flush，直至总Memstore大小低至lowerlimit。这种flush通常会block较长时间，在日志中会发现“Memstore is above high water mark and block 7452 ms”，表示这次flush将会阻塞7s左右。\n\n问题检查点：\n\n- Region规模与Memstore总大小设置是否合理？如果RegionServer上Region较多，而Memstore总大小设置的很小（JVM设置较小或者upper.limit设置较小），就会触发RegionServer级别flush。集群规划相关内容可以参考文章《》\n- 列族是否设置过多，通常情况下表列族建议设置在1～3个之间，最好一个。如果设置过多，会导致一个Region中包含很多Memstore，导致更容易触到高水位upperlimit\n\n****\n\n#### **Store中HFile数量是否大于配置参数blockingStoreFile?**\n\n****\n\n问题解析：对于数据写入很快的集群，还需要特别关注一个参数：hbase.hstore.blockingStoreFiles，此参数表示如果当前hstore中文件数大于该值，系统将会强制执行compaction操作进行文件合并，合并的过程会阻塞整个hstore的写入。通常情况下该场景发生在数据写入很快的情况下，在日志中可以发现”Waited 3722ms on a compaction to clean up ‘too many store  files“\n\n****\n\n问题检查点：\n\n- 参数设置是否合理？hbase.hstore.compactionThreshold表示启动compaction的最低阈值，该值不能太大，否则会积累太多文件，一般建议设置为5～8左右。hbase.hstore.blockingStoreFiles默认设置为7，可以适当调大一些。\n\n****\n\n### **写性能还能再提高么？**\n\n****\n\n上文已经从写性能优化以及写异常诊断两个方面对HBase中数据写入可能的问题进行了详细的解释，相信在0.98版本的基础上对写入来说已经是最好的解决方案了。但是有些业务可能依然觉得不够快，毕竟”更快”是所有存储系统活着的动力，那还有提高空间吗？当然，接下来简单介绍HBase之后版本对写性能优化的两点核心改进：\n\n#### **Utilize Flash storage for WAL(HBASE-12848)**\n\n这个特性意味着可以将WAL单独置于SSD上，这样即使在默认情况下（WALSync），写性能也会有很大的提升。需要注意的是，该特性建立在HDFS 2.6.0+的基础上，HDFS以前版本不支持该特性。具体可以参考官方jira：[https://issues.apache.org/jira/browse/HBASE-12848](https://issues.apache.org/jira/browse/HBASE-12848)\n\n#### **Multiple WALs(HBASE-14457)**\n\n该特性也是对WAL进行改造，当前WAL设计为一个RegionServer上所有Region共享一个WAL，可以想象在写入吞吐量较高的时候必然存在资源竞争，降低整体性能。针对这个问题，社区小伙伴（阿里巴巴大神）提出Multiple WALs机制，管理员可以为每个Namespace下的所有表设置一个共享WAL，通过这种方式，写性能大约可以提升20%～40%左右。具体可以参考官方jira：[https://issues.apache.org/jira/browse/HBASE-14457](https://issues.apache.org/jira/browse/HBASE-14457)","slug":"hbase/hbase的读写优化","published":1,"updated":"2018-09-12T03:03:21.818Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfngu002iwlkv70jfn52w"},{"title":"hbase的读流程","date":"2017-09-27T14:49:55.000Z","_content":"\n和写流程相比，HBase读数据是一个更加复杂的操作流程，这主要基于两个方面的原因：其一是因为整个HBase存储引擎基于LSM-Like树实现，因此一次范围查询可能会涉及多个分片、多块缓存甚至多个数据存储文件；其二是因为HBase中更新操作以及删除操作实现都很简单，更新操作并没有更新原有数据，而是使用时间戳属性实现了多版本。删除操作也并没有真正删除原有数据，只是插入了一条打上”deleted”标签的数据，而真正的数据删除发生在系统异步执行Major_Compact的时候。很显然，这种实现套路大大简化了数据更新、删除流程，但是对于数据读取来说却意味着套上了层层枷锁，读取过程需要根据版本进行过滤，同时对已经标记删除的数据也要进行过滤。\n\n总之，把这么复杂的事情讲明白并不是一件简单的事情，为了更加条理化地分析整个查询过程，接下来笔者会用两篇文章来讲解整个过程，首篇文章主要会从框架的角度粗粒度地分析scan的整体流程，并不会涉及太多的细节实现。大多数看客通过首篇文章基本就可以初步了解scan的工作思路；为了能够从细节理清楚整个scan流程，接着第二篇文章将会在第一篇的基础上引入更多的实现细节以及HBase对于scan所做的基础优化。因为理解问题可能会有纰漏，希望可以一起探讨交流，欢迎拍砖~\n\n### **Client-Server交互逻辑**\n\n运维开发了很长一段时间HBase，经常有业务同学咨询为什么客户端配置文件中没有配置RegionServer的地址信息，这里针对这种疑问简单的做下解释，客户端与HBase系统的交互阶段主要有如下几个步骤：\n\n![795841](http://hbasefly.com/wp-content/uploads/2016/12/795841.png)\n\n****\n\n1. 客户端首先会根据配置文件中zookeeper地址连接zookeeper，并读取/<hbase-rootdir>/meta-region-server节点信息，该节点信息存储HBase元数据（hbase:meta）表所在的RegionServer地址以及访问端口等信息。用户可以通过zookeeper命令(get /<hbase-rootdir>/meta-region-server)查看该节点信息。\n2. 根据hbase:meta所在RegionServer的访问信息，客户端会将该元数据表加载到本地并进行缓存。然后在表中确定待检索rowkey所在的RegionServer信息。\n3. 根据数据所在RegionServer的访问信息，客户端会向该RegionServer发送真正的数据读取请求。服务器端接收到该请求之后需要进行复杂的处理，具体的处理流程将会是这个专题的重点。\n\n通过上述对客户端以及HBase系统的交互分析，可以基本明确两点：\n\n1. 客户端只需要配置zookeeper的访问地址以及根目录，就可以进行正常的读写请求。不需要配置集群的RegionServer地址列表。\n2. 客户端会将hbase:meta元数据表缓存在本地，因此上述步骤中前两步只会在客户端第一次请求的时候发生，之后所有请求都直接从缓存中加载元数据。如果集群发生某些变化导致hbase:meta元数据更改，客户端再根据本地元数据表请求的时候就会发生异常，此时客户端需要重新加载一份最新的元数据表到本地。\n\n－－－－－－－－－－－－－－－－－此处应有华丽丽的分隔线－－－－－－－－－－－－－－－－\n\nRegionServer接收到客户端的get/scan请求之后，先后做了两件事情：构建scanner体系（实际上就是做一些scan前的准备工作），在此体系基础上一行一行检索。举个不太合适但易于理解的例子，scan数据就和开发商盖房一样，也是分成两步：组建施工队体系，明确每个工人的职责；一层一层盖楼。\n\n### **构建scanner体系－组建施工队**\n\nscanner体系的核心在于三层scanner：RegionScanner、StoreScanner以及StoreFileScanner。三者是层级的关系，一个RegionScanner由多个StoreScanner构成，一张表由多个列族组成，就有多少个StoreScanner负责该列族的数据扫描。一个StoreScanner又是由多个StoreFileScanner组成。每个Store的数据由内存中的MemStore和磁盘上的StoreFile文件组成，相对应的，StoreScanner对象会雇佣一个MemStoreScanner和N个StoreFileScanner来进行实际的数据读取，每个StoreFile文件对应一个StoreFileScanner，注意：StoreFileScanner和MemstoreScanner是整个scan的最终执行者。\n\n对应于建楼项目，一栋楼通常由好几个单元楼构成（每个单元楼对应于一个Store），每个单元楼会请一个监工（StoreScanner）负责该单元楼的建造。而监工一般不做具体的事情，他负责招募很多工人（StoreFileScanner），这些工人才是建楼的主体。下图是整个构建流程图：\n\n![818160](http://hbasefly.com/wp-content/uploads/2016/12/818160.png)\n\n****\n\n1.  RegionScanner会根据列族构建StoreScanner，有多少列族就构建多少StoreScanner，用于负责该列族的数据检索\n\n​       1.1 构建StoreFileScanner：每个StoreScanner会为当前该Store中每个HFile构造一个StoreFileScanner，用于实际执行对应文件的检索。同时会为对应Memstore构造一个MemstoreScanner，用于执行该Store中Memstore的数据检索。该步骤对应于监工在人才市场招募建楼所需的各种类型工匠。\n\n​       1.2  过滤淘汰StoreFileScanner：根据Time Range以及RowKey Range对StoreFileScanner以及MemstoreScanner进行过滤，淘汰肯定不存在待检索结果的Scanner。上图中StoreFile3因为检查RowKeyRange不存在待检索Rowkey所以被淘汰。该步骤针对具体的建楼方案，裁撤掉部分不需要的工匠，比如这栋楼不需要地暖安装，对应的工匠就可以撤掉。\n\n​       1.3  Seek rowkey：所有StoreFileScanner开始做准备工作，在负责的HFile中定位到满足条件的起始Row。工匠也开始准备自己的建造工具，建造材料，找到自己的工作地点，等待一声命下。就像所有重要项目的准备工作都很核心一样，Seek过程（此处略过Lazy Seek优化）也是一个很核心的步骤，它主要包含下面三步：\n\n- 定位Block Offset：在Blockcache中读取该HFile的索引树结构，根据索引树检索对应RowKey所在的Block Offset和Block Size\n- Load Block：根据BlockOffset首先在BlockCache中查找Data Block，如果不在缓存，再在HFile中加载\n- Seek Key：在Data Block内部通过二分查找的方式定位具体的RowKey\n\n整体流程细节参见[《HBase原理-探索HFile索引机制》](http://hbasefly.com/2016/04/03/hbase_hfile_index/)，文中详细说明了HFile索引结构以及如何通过索引结构定位具体的Block以及RowKey\n\n​       1.4  StoreFileScanner合并构建最小堆：将该Store中所有StoreFileScanner和MemstoreScanner合并形成一个heap（最小堆），所谓heap是一个优先级队列，队列中元素是所有scanner，排序规则按照scanner seek到的keyvalue大小由小到大进行排序。这里需要重点关注三个问题，首先为什么这些Scanner需要由小到大排序，其次keyvalue是什么样的结构，最后，keyvalue谁大谁小是如何确定的：\n\n- 为什么这些Scanner需要由小到大排序？\n\n最直接的解释是scan的结果需要由小到大输出给用户，当然，这并不全面，最合理的解释是只有由小到大排序才能使得scan效率最高。举个简单的例子，HBase支持数据多版本，假设用户只想获取最新版本，那只需要将这些数据由最新到最旧进行排序，然后取队首元素返回就可以。那么，如果不排序，就只能遍历所有元素，查看符不符合用户查询条件。这就是排队的意义。\n\n工匠们也需要排序，先做地板的排前面，做墙体的次之，最后是做门窗户的。做墙体的内部还需要再排序，做内墙的排前面，做外墙的排后面，这样，假如设计师临时决定不做外墙的话，就可以直接跳过外墙部分工作。很显然，如果不排序的话，是没办法临时做决定的，因为这部分工作已经可能做掉了。\n\n- HBase中KeyValue是什么样的结构？\n\n​          HBase中KeyValue并不是简单的KV数据对，而是一个具有复杂元素的结构体，其中Key由RowKey，ColumnFamily，Qualifier ，TimeStamp，KeyType等多部分组成，Value是一个简单的二进制数据。Key中元素KeyType表示该KeyValue的类型，取值分别为Put/Delete/Delete Column/Delete Family等。KeyValue可以表示为如下图所示：\n\n![99091](http://hbasefly.com/wp-content/uploads/2016/12/99091.png)\n\n​        了解了KeyValue的逻辑结构后，我们不妨再进一步从原理的角度想想HBase的开发者们为什么如此对其设计。这个就得从HBase所支持的数据操作说起了，HBase支持四种主要的数据操作，分别是Get/Scan/Put/Delete，其中Get和Scan代表数据查询，Put操作代表数据插入或更新（如果Put的RowKey不存在则为插入操作、否则为更新操作），特别需要注意的是HBase中更新操作并不是直接覆盖修改原数据，而是生成新的数据，新数据和原数据具有不同的版本（时间戳）；Delete操作执行数据删除，和数据更新操作相同，HBase执行数据删除并不会马上将数据从数据库中永久删除，而只是生成一条删除记录，最后在系统执行文件合并的时候再统一删除。\n\n​        HBase中更新删除操作并不直接操作原数据，而是生成一个新纪录，那问题来了，如何知道一条记录到底是插入操作还是更新操作亦或是删除操作呢？这正是KeyType和Timestamp的用武之地。上文中提到KeyType取值为分别为Put/Delete/Delete Column/Delete Family四种，如果KeyType取值为Put，表示该条记录为插入或者更新操作，而无论是插入或者更新，都可以使用版本号（Timestamp）对记录进行选择；如果KeyType为Delete，表示该条记录为整行删除操作；相应的KeyType为Delete Column和Delete Family分别表示删除某行某列以及某行某列族操作；\n\n- 不同KeyValue之间如何进行大小比较？\n\n​        上文提到KeyValue中Key由RowKey，ColumnFamily，Qualifier ，TimeStamp，KeyType等5部分组成，HBase设定Key大小首先比较RowKey，RowKey越小Key就越小；RowKey如果相同就看CF，CF越小Key越小；CF如果相同看Qualifier，Qualifier越小Key越小；Qualifier如果相同再看Timestamp，Timestamp越大表示时间越新，对应的Key越小。如果Timestamp还相同，就看KeyType，KeyType按照DeleteFamily -> DeleteColumn -> Delete -> Put 顺序依次对应的Key越来越大。\n\n\\2. StoreScanner合并构建最小堆：上文讨论的是一个监工如何构建自己的工匠师团队以及工匠师如何做准备工作、排序工作。实际上，监工也需要进行排序，比如一单元的监工排前面，二单元的监工排之后… StoreScanner一样，列族小的StoreScanner排前面，列族大的StoreScanner排后面。\n\n****\n\n### **scan查询－层层建楼**\n\n构建Scanner体系是为了更好地执行scan查询，就像组建工匠师团队就是为了盖房子一样。scan查询总是一行一行查询的，先查第一行的所有数据，再查第二行的所有数据，但每一行的查询流程却没有什么本质区别。盖房子也一样，无论是盖8层还是盖18层，都需要一层一层往上盖，而且每一层的盖法并没有什么区别。所以实际上我们只需要关注其中一行数据是如何查询的就可以。\n\n对于一行数据的查询，又可以分解为多个列族的查询，比如RowKey=row1的一行数据查询，首先查询列族1上该行的数据集合，再查询列族2里该行的数据集合。同样是盖第一层房子，先盖一单元的一层，再改二单元的一层，盖完之后才算一层盖完，接着开始盖第二层。所以我们也只需要关注某一行某个列族的数据是如何查询的就可以。\n\n还记得Scanner体系构建的最终结果是一个由StoreFileScanner和MemstoreScanner组成的heap（最小堆）么，这里就派上用场了。下图是一张表的逻辑视图，该表有两个列族cf1和cf2（我们只关注cf1），cf1只有一个列name，表中有5行数据，其中每个cell基本都有多个版本。cf1的数据假如实际存储在三个区域，memstore中有r2和r4的最新数据，hfile1中是最早的数据。现在需要查询RowKey=r2的数据，按照上文的理论对应的Scanner指向就如图所示：\n\n![544501](http://hbasefly.com/wp-content/uploads/2016/12/544501.png)\n\n这三个Scanner组成的heap为<MemstoreScanner，StoreFileScanner2, StoreFileScanner1>，Scanner由小到大排列。查询的时候首先pop出heap的堆顶元素，即MemstoreScanner，得到keyvalue = r2:cf1:name:v3:name23的数据，拿到这个keyvalue之后，需要进行如下判定：\n\n1. 检查该KeyValue的KeyType是否是Deleted/DeletedCol等，如果是就直接忽略该列所有其他版本，跳到下列（列族）\n2. 检查该KeyValue的Timestamp是否在用户设定的Timestamp Range范围，如果不在该范围，忽略\n3. 检查该KeyValue是否满足用户设置的各种filter过滤器，如果不满足，忽略\n4. 检查该KeyValue是否满足用户查询中设定的版本数，比如用户只查询最新版本，则忽略该cell的其他版本；反正如果用户查询所有版本，则还需要查询该cell的其他版本。\n\n现在假设用户查询所有版本而且该keyvalue检查通过，此时当前的堆顶元素需要执行next方法去检索下一个值，并重新组织最小堆。即图中MemstoreScanner将会指向r4，重新组织最小堆之后最小堆将会变为<StoreFileScanner2, StoreFileScanner1, MemstoreScanner>，堆顶元素变为StoreFileScanner2，得到keyvalue＝r2:cf1:name:v2:name22，进行一系列判定，再next，再重新组织最小堆…\n\n不断重复这个过程，直至一行数据全部被检索得到。继续下一行…\n\n－－－－－－－－－－－－－－－－此处应有华丽丽的分隔符－－－－－－－－－－－－－－－－\n\n本文从框架层面对HBase读取流程进行了详细的解析，文中并没有针对细节进行深入分析，一方面是担心个人能力有限，引入太多细节会让文章难于理解，另一方面是大多数看官可能对细节并不关心，下篇文章笔者会揪出来一些比较重要的细节和大家一起交流～\n\n文章最后，贴出来一个一些朋友咨询的问题：Memstore在flush的时候会不会将Blockcache中的数据update？如果不update的话不就会产生脏读，读到以前的老数据？\n\n\n\n回顾一下scan的整个流程，如下图所示：\n\n![55](http://hbasefly.com/wp-content/uploads/2017/06/55.png)\n\n上图是一个简单的示意图，用户如果对整个流程比较感兴趣，可以阅读之前的文章，本文将会关注于隐藏在这个示意图中的核心细节。这里笔者挑出了其中五个比较重要的问题来说明，这些问题都是本人之前或早或晚比较困惑的问题，拿出来与大家分享。当然，如果大家有反馈想了解的其他细节，也可以单独交流探讨。\n\n\\1. 常说HBase数据读取要读Memstore、HFile和Blockcache，为什么上面Scanner只有StoreFileScanner和MemstoreScanner两种？没有BlockcacheScanner?\n\nHBase中数据仅仅独立地存在于Memstore和StoreFile中，Blockcache中的数据只是StoreFile中的部分数据（热点数据），即所有存在于Blockcache的数据必然存在于StoreFile中。因此MemstoreScanner和StoreFileScanner就可以覆盖到所有数据。实际读取时StoreFileScanner通过索引定位到待查找key所在的block之后，首先检查该block是否存在于Blockcache中，如果存在直接取出，如果不存在再到对应的StoreFile中读取。\n\n\\2.  数据更新操作先将数据写入Memstore，再落盘。落盘之后需不需要更新Blockcache中对应的kv？如果不更新，会不会读到脏数据？\n\n如果理清楚了第一个问题，相信很容易得出这个答案：不需要更新Blockcache中对应的kv，而且不会读到脏数据。数据写入Memstore落盘会形成新的文件，和Blockcache里面的数据是相互独立的，以多版本的方式存在。\n\n\\3. 读取流程中如何使用BloomFilter(简称BF)对StoreFile进行过滤？\n\n过滤StoreFile发生在上图中第三步，过滤手段主要有三种：根据KeyRange过滤、根据TimeRange过滤、根据BF过滤。下面分别进行介绍：\n\n（1）根据KeyRange过滤：因为StoreFile是中所有KV数据都是有序排列的，所以如果待检索row范围［startrow，stoprow］与文件起始key范围［firstkey，lastkey］没有交集，比如stoprow < firstkey 或者 startrow > lastkey，就可以过滤掉该StoreFile。 \n\n（2）根据TimeRange过滤：StoreFile中元数据有一个关于该File的TimeRange属性［minimumTimestamp, maxmumTimestamp］，因此待检索的TimeRange如果与该文件时间范围没有交集，就可以过滤掉该StoreFile；另外，如果该文件所有数据已经过期，也可以过滤淘汰。\n\n（3）根据BF过滤：BF在几乎所有的LSM模型存储领域都会用到，可说是标配，比如HBase、Kudu、RocksDB等等，用法也是如出一辙，和HBase一样，主要用来读取数据时过滤部分文件；除此之外，BF在大数据计算（分布式Join实现）中也扮演重要的角色，参考Impala中Hash Join的实现（戳[这里](http://hbasefly.com/2017/04/10/bigdata-join-2/)）。BF的具体工作原理笔者假设童鞋都了解（不了解的童鞋可以参考上述链接文章）。\n\n现在来看看HBase中如何利用BF对StoreFile进行过滤(注：接下来所有关于HBase BF的说明都按照Row类型来，Row-Column类型类似)，原理其实很简单：首先把BF数据加载到内存；然后使用hash函数对待检索row进行hash，根据hash后的结果在BF数据中进行寻址查看即可确定是否存在该HFile。第二步就是BF的原理，并没有什么好讲的，主要来看看HBase是如何将BF数据加载到内存的。\n\n看过笔者之前文章的童鞋都知道，BF数据实际上是和用户KV数据一样存储在HFile中的，那就需要先看看BF信息是如何存储在HFile中的，查看[官方文档](http://hbase.apache.org/book.html#_hfile_format_2)中HFile(v2)组织结构图如下：\n\n![56](http://hbasefly.com/wp-content/uploads/2017/06/56.png)\n\nHFile组织结构中关于BF有两个非常重要的结构－Bloom Block与Bloom Index。Bloom Block主要存储BF的实际数据，可能这会大家要问为什么Bloom Block要分布在整个HFile？分布的具体位置如何确定？其实很简单，HBase在写数据的时候就会根据row生成对应的BF信息并写到一个Block中，随着用户数据的不断写入，这个BF Block就会不断增大，当增大到一定阈值之后系统就会重新生成一个新Block，旧Block就会顺序加载到Data Block之后。这里隐含了一个关键的信息，随着单个文件的增大，BF信息会逐渐变的很大，并不适合一次性全部加载到内存，更适合的使用方式是使用哪块加载哪块！\n\n这些Bloom Block分散在HFile中的各个角落，就会带来一个问题：如何有效快速定位到这些BF Block？这就是Bloom Index的核心作用，与Data Index相同，Bloom Index也是一颗B+树，Bloom Index Block结构如下图所示：\n\n![57](http://hbasefly.com/wp-content/uploads/2017/06/57.png)\n\n上图需要重点关注Bloom Block的Block Key：Block中第一个原始KV的RowKey。这样给定一个待检索的 rowkey，就可以很容易地通过Bloom Index定位到具体的Bloom Block，将Block加载到内存进行过滤。通常情况下，热点Bloom Block会常驻内存的！\n\n到此为止，笔者已经解释清楚了HBase是如何利用BF在读取数据时根据rowkey过滤StoreFile的，相信Kudu、RocksDB中BF的原理基本相同。\n\n再回到出发的地方，我们说在实际scan之前就要使用BF对StoreFile进行过滤，那仔细想下，到底用哪个rowkey过滤？实际实现中系统使用scan的startrow作为过滤条件进行过滤，这是不是有问题？举个简单的例子，假设小明检索的数据为［row1, row4］，如果此文件不包含row1，而包含row2，这样在scan前你利用row1就把该文件淘汰掉了，row2这条数据怎么办？不是会被遗漏？\n\n这里系统实现有个隐藏点，scan之前使用BF进行过滤只针对get查询以及scan单条数据的场景，scan多条数据并不会执行实际的BF过滤，而是在实际seek到新一行的时候才会启用BF根据新一行rowkey对所有StoreFile过滤。\n\n\\4. 最小堆中弹出cell之后如何对该cell进行检查过滤，确保满足用户设置条件？检查过滤之后是继续弹出下一个cell，还是跳过部分cell重新seek到下一列或者下一行？\n\nscan之所以复杂，很大程度上是因为scan可以设置的条件非常之多，下面所示代码为比较常规的一些设置：\n\n```\nScan scan = new Scan();\nscan.withStartRow(startRow) //设置检索起始row\n        .withStopRow(stopRow) //设置检索结束row\n        .setFamilyMap(Map<byte[], Set<byte[]> familyMap>) //设置检索的列族和对应列族下的列集合\n        .setTimeRange(minStamp, maxStamp) // 设置检索TimeRange\n        .setMaxVersions(maxVersions) //设置检索的最大版本号\n        .setFilter(filter) //设置检索过滤器\n        …\n```\n\n在整个Scan流程的第6步，将堆顶kv元素出堆进行检查，实际上主要检查两个方面，其一是非用户条件检查，比如kv是否已经过期（列族设置TTL）、kv是否已经被删除，这些检查和用户设置查询条件没有任何关系；其二就是检查该kv是否满足用户设置的这些查询条件，代码逻辑还是比较清晰的，在此不再赘述。核心代码主要参考ScanQueryMatcher.match(cell)方法。\n\n相比堆顶元素检查流程，笔者更想探讨堆顶元素kv检查之后的返回值－MatchCode，这个Code可不简单，它会告诉scanner是继续seek下一个cell，还是直接跳过部分cell直接seek到下一列（对应INCLUDE_AND_SEEK_NEXT_COL或SEEK_NEXT_COL），抑或是直接seek到下一行(对应INCLUDE_AND_SEEK_NEXT_ROW或SEEK_NEXT_ROW)。还是举一个简单的例子：\n\n![58](http://hbasefly.com/wp-content/uploads/2017/06/58.png)\n\n上图是待查表，含有一个列族cf，列族下有四个列[c1, c2, c3, c4]，列族设置MaxVersions为2，即允许最多存在2个版本。现在简单构造一个查询语句如下：\n\n```\nScan scan = new Scan(r1, r4); // 表示检索范围为［r1, r4］\nscan.setFamilyMap(Map<cf, Set<c1,c2>>) //仅检索列族cf下的c1列和c2列\n        .setMaxVersions(1) //设置检索的最大版本号为1\n```\n\n下面分别模拟直接跳过部分纪录seek到下一列（INCLUDE_AND_SEEK_NEXT_COL）的场景以及跳过部分列直接seek到下一行（INCLUDE_AND_SEEK_NEXT_ROW）的场景：\n\n（1）假设当前检索r1行，堆顶元素为cf:c1下的kv1(版本为v1)，按照设置条件中检索的最大版本号为1，其他条件都满足的情况下就可以直接跳过kv2直接seek到下一列－c2列。这种场景下就会返回INCLUDE_AND_SEEK_NEXT_COL。\n\n（2）假设当前检索r1行，堆顶元素为cf:c2下的kv3(仅有1个版本)，满足设置的版本条件，系统检测到c2是检索的最后一列之后（c3、c4并不需要检索），就会返回指示－略过c3、c4直接seek到下一行。这种场景下就会返回INCLUDE_AND_SEEK_NEXT_ROW。\n\n至此，笔者针对scan流程中的第6步进行了比较详细的解读，对认为比较重要的点进行了简单演示。其实还是有很多内容，但大多都大同小异，原理类似。有兴趣读HBase源码的同学可以参考这里的解读，相信会有所帮助。\n\n\\5. 每次seek（key）命令是不是都需要所有scanner真正seek到指定key？延迟seek是如何优化读性能的？\n\n这是本文探讨的最后一个话题，严格来说，这个话题并不涉及scan的流程，而仅仅是对scan的一项优化。但是个人认为理解这项优化对scan的流程理解有着相当重要的意义，同时也是阅读HBase-Scan模块源码必须要迈过的一道坎。\n\n先回到scan的流程，根据之前的理解，如果堆顶元素出堆检查之后指示scanner需要跳过部分cell直接seek到下一列或者下一行，此时所有scanner都需要按照指示执行seek命令定位指定位置，这本身没有毛病。然而这可能并不高效，试想这么一种场景：\n\n（1）当前有3个StoreFile文件，因此对应3个StoreFileScanner，现在接到指示需要seek 到(rowk, cf:c1)位置，刚好这三个文件中都存在这样的KV，差别在于时间戳不同\n\n（2）于是这3个Scanner很顺从地在文件中找到指定位置，然后等待最小KV出堆接受检查\n\n（3）最小KV出堆接受检查之后满足用户条件，而且用户只需要检索最新版本。因此检查之后告诉所有scanner直接seek到下一行。\n\n有没有发现一些小小的问题？没错，3个scanner只有1个scanner做了’有用功’，其他两个scanner都做了’无用seek’。这很显然一定程度上会影响scan性能。\n\nHBase提出了一个很巧妙的应对方案－延迟seek，就是3个scanner接到seek指示的时候，实际上并没有真正去做，而只是将scanner的指针指向指定位置。那童鞋就会问了，那什么时候真正去seek呢？只需要在堆顶元素弹出来的时候真正去执行就可以。这样，就可以有效避免大量’无用seek’。\n\n好了，本文核心内容就基本介绍完了，接下来扯点闲篇。任何存储系统的核心模块无非读写模块，但不同类型的数据库侧重不同。MySQL类系统（Oracle、SQLServer等）侧重于写，写就是它的灵魂！为了实现事务原子性，数据更新之前要先写undo log，为了实现数据持久性，又引入redo log，为了实现事务隔离性，还需要实现各种锁，还有类似double write等一系列机制…… ，个人认为，搞懂了数据更新写入流程基本就搞懂了MySQL存储引擎。与MySQL相对，HBase类系统（RocksDB、Kudu ）更侧重读，读是它的灵魂！HBase将所有更新操作、删除操作都简单的当作写入操作来处理，对于更新删除来说确实简单了，但却给数据读取带来了极大的负担，数据读取的时候需要额外过滤删除数据、处理多版本数据，除此之外，LSM所特有的多文件存储、BloomFilter过滤特性支持等等无不增加了数据读取的难度。个人认为，只有搞懂了数据读取才可能真正理解HBase内核。","source":"_posts/hbase/hbase的读流程.md","raw":"---\ntitle: hbase的读流程\ndate: 2017-09-27 22:49:55\ntags:\n---\n\n和写流程相比，HBase读数据是一个更加复杂的操作流程，这主要基于两个方面的原因：其一是因为整个HBase存储引擎基于LSM-Like树实现，因此一次范围查询可能会涉及多个分片、多块缓存甚至多个数据存储文件；其二是因为HBase中更新操作以及删除操作实现都很简单，更新操作并没有更新原有数据，而是使用时间戳属性实现了多版本。删除操作也并没有真正删除原有数据，只是插入了一条打上”deleted”标签的数据，而真正的数据删除发生在系统异步执行Major_Compact的时候。很显然，这种实现套路大大简化了数据更新、删除流程，但是对于数据读取来说却意味着套上了层层枷锁，读取过程需要根据版本进行过滤，同时对已经标记删除的数据也要进行过滤。\n\n总之，把这么复杂的事情讲明白并不是一件简单的事情，为了更加条理化地分析整个查询过程，接下来笔者会用两篇文章来讲解整个过程，首篇文章主要会从框架的角度粗粒度地分析scan的整体流程，并不会涉及太多的细节实现。大多数看客通过首篇文章基本就可以初步了解scan的工作思路；为了能够从细节理清楚整个scan流程，接着第二篇文章将会在第一篇的基础上引入更多的实现细节以及HBase对于scan所做的基础优化。因为理解问题可能会有纰漏，希望可以一起探讨交流，欢迎拍砖~\n\n### **Client-Server交互逻辑**\n\n运维开发了很长一段时间HBase，经常有业务同学咨询为什么客户端配置文件中没有配置RegionServer的地址信息，这里针对这种疑问简单的做下解释，客户端与HBase系统的交互阶段主要有如下几个步骤：\n\n![795841](http://hbasefly.com/wp-content/uploads/2016/12/795841.png)\n\n****\n\n1. 客户端首先会根据配置文件中zookeeper地址连接zookeeper，并读取/<hbase-rootdir>/meta-region-server节点信息，该节点信息存储HBase元数据（hbase:meta）表所在的RegionServer地址以及访问端口等信息。用户可以通过zookeeper命令(get /<hbase-rootdir>/meta-region-server)查看该节点信息。\n2. 根据hbase:meta所在RegionServer的访问信息，客户端会将该元数据表加载到本地并进行缓存。然后在表中确定待检索rowkey所在的RegionServer信息。\n3. 根据数据所在RegionServer的访问信息，客户端会向该RegionServer发送真正的数据读取请求。服务器端接收到该请求之后需要进行复杂的处理，具体的处理流程将会是这个专题的重点。\n\n通过上述对客户端以及HBase系统的交互分析，可以基本明确两点：\n\n1. 客户端只需要配置zookeeper的访问地址以及根目录，就可以进行正常的读写请求。不需要配置集群的RegionServer地址列表。\n2. 客户端会将hbase:meta元数据表缓存在本地，因此上述步骤中前两步只会在客户端第一次请求的时候发生，之后所有请求都直接从缓存中加载元数据。如果集群发生某些变化导致hbase:meta元数据更改，客户端再根据本地元数据表请求的时候就会发生异常，此时客户端需要重新加载一份最新的元数据表到本地。\n\n－－－－－－－－－－－－－－－－－此处应有华丽丽的分隔线－－－－－－－－－－－－－－－－\n\nRegionServer接收到客户端的get/scan请求之后，先后做了两件事情：构建scanner体系（实际上就是做一些scan前的准备工作），在此体系基础上一行一行检索。举个不太合适但易于理解的例子，scan数据就和开发商盖房一样，也是分成两步：组建施工队体系，明确每个工人的职责；一层一层盖楼。\n\n### **构建scanner体系－组建施工队**\n\nscanner体系的核心在于三层scanner：RegionScanner、StoreScanner以及StoreFileScanner。三者是层级的关系，一个RegionScanner由多个StoreScanner构成，一张表由多个列族组成，就有多少个StoreScanner负责该列族的数据扫描。一个StoreScanner又是由多个StoreFileScanner组成。每个Store的数据由内存中的MemStore和磁盘上的StoreFile文件组成，相对应的，StoreScanner对象会雇佣一个MemStoreScanner和N个StoreFileScanner来进行实际的数据读取，每个StoreFile文件对应一个StoreFileScanner，注意：StoreFileScanner和MemstoreScanner是整个scan的最终执行者。\n\n对应于建楼项目，一栋楼通常由好几个单元楼构成（每个单元楼对应于一个Store），每个单元楼会请一个监工（StoreScanner）负责该单元楼的建造。而监工一般不做具体的事情，他负责招募很多工人（StoreFileScanner），这些工人才是建楼的主体。下图是整个构建流程图：\n\n![818160](http://hbasefly.com/wp-content/uploads/2016/12/818160.png)\n\n****\n\n1.  RegionScanner会根据列族构建StoreScanner，有多少列族就构建多少StoreScanner，用于负责该列族的数据检索\n\n​       1.1 构建StoreFileScanner：每个StoreScanner会为当前该Store中每个HFile构造一个StoreFileScanner，用于实际执行对应文件的检索。同时会为对应Memstore构造一个MemstoreScanner，用于执行该Store中Memstore的数据检索。该步骤对应于监工在人才市场招募建楼所需的各种类型工匠。\n\n​       1.2  过滤淘汰StoreFileScanner：根据Time Range以及RowKey Range对StoreFileScanner以及MemstoreScanner进行过滤，淘汰肯定不存在待检索结果的Scanner。上图中StoreFile3因为检查RowKeyRange不存在待检索Rowkey所以被淘汰。该步骤针对具体的建楼方案，裁撤掉部分不需要的工匠，比如这栋楼不需要地暖安装，对应的工匠就可以撤掉。\n\n​       1.3  Seek rowkey：所有StoreFileScanner开始做准备工作，在负责的HFile中定位到满足条件的起始Row。工匠也开始准备自己的建造工具，建造材料，找到自己的工作地点，等待一声命下。就像所有重要项目的准备工作都很核心一样，Seek过程（此处略过Lazy Seek优化）也是一个很核心的步骤，它主要包含下面三步：\n\n- 定位Block Offset：在Blockcache中读取该HFile的索引树结构，根据索引树检索对应RowKey所在的Block Offset和Block Size\n- Load Block：根据BlockOffset首先在BlockCache中查找Data Block，如果不在缓存，再在HFile中加载\n- Seek Key：在Data Block内部通过二分查找的方式定位具体的RowKey\n\n整体流程细节参见[《HBase原理-探索HFile索引机制》](http://hbasefly.com/2016/04/03/hbase_hfile_index/)，文中详细说明了HFile索引结构以及如何通过索引结构定位具体的Block以及RowKey\n\n​       1.4  StoreFileScanner合并构建最小堆：将该Store中所有StoreFileScanner和MemstoreScanner合并形成一个heap（最小堆），所谓heap是一个优先级队列，队列中元素是所有scanner，排序规则按照scanner seek到的keyvalue大小由小到大进行排序。这里需要重点关注三个问题，首先为什么这些Scanner需要由小到大排序，其次keyvalue是什么样的结构，最后，keyvalue谁大谁小是如何确定的：\n\n- 为什么这些Scanner需要由小到大排序？\n\n最直接的解释是scan的结果需要由小到大输出给用户，当然，这并不全面，最合理的解释是只有由小到大排序才能使得scan效率最高。举个简单的例子，HBase支持数据多版本，假设用户只想获取最新版本，那只需要将这些数据由最新到最旧进行排序，然后取队首元素返回就可以。那么，如果不排序，就只能遍历所有元素，查看符不符合用户查询条件。这就是排队的意义。\n\n工匠们也需要排序，先做地板的排前面，做墙体的次之，最后是做门窗户的。做墙体的内部还需要再排序，做内墙的排前面，做外墙的排后面，这样，假如设计师临时决定不做外墙的话，就可以直接跳过外墙部分工作。很显然，如果不排序的话，是没办法临时做决定的，因为这部分工作已经可能做掉了。\n\n- HBase中KeyValue是什么样的结构？\n\n​          HBase中KeyValue并不是简单的KV数据对，而是一个具有复杂元素的结构体，其中Key由RowKey，ColumnFamily，Qualifier ，TimeStamp，KeyType等多部分组成，Value是一个简单的二进制数据。Key中元素KeyType表示该KeyValue的类型，取值分别为Put/Delete/Delete Column/Delete Family等。KeyValue可以表示为如下图所示：\n\n![99091](http://hbasefly.com/wp-content/uploads/2016/12/99091.png)\n\n​        了解了KeyValue的逻辑结构后，我们不妨再进一步从原理的角度想想HBase的开发者们为什么如此对其设计。这个就得从HBase所支持的数据操作说起了，HBase支持四种主要的数据操作，分别是Get/Scan/Put/Delete，其中Get和Scan代表数据查询，Put操作代表数据插入或更新（如果Put的RowKey不存在则为插入操作、否则为更新操作），特别需要注意的是HBase中更新操作并不是直接覆盖修改原数据，而是生成新的数据，新数据和原数据具有不同的版本（时间戳）；Delete操作执行数据删除，和数据更新操作相同，HBase执行数据删除并不会马上将数据从数据库中永久删除，而只是生成一条删除记录，最后在系统执行文件合并的时候再统一删除。\n\n​        HBase中更新删除操作并不直接操作原数据，而是生成一个新纪录，那问题来了，如何知道一条记录到底是插入操作还是更新操作亦或是删除操作呢？这正是KeyType和Timestamp的用武之地。上文中提到KeyType取值为分别为Put/Delete/Delete Column/Delete Family四种，如果KeyType取值为Put，表示该条记录为插入或者更新操作，而无论是插入或者更新，都可以使用版本号（Timestamp）对记录进行选择；如果KeyType为Delete，表示该条记录为整行删除操作；相应的KeyType为Delete Column和Delete Family分别表示删除某行某列以及某行某列族操作；\n\n- 不同KeyValue之间如何进行大小比较？\n\n​        上文提到KeyValue中Key由RowKey，ColumnFamily，Qualifier ，TimeStamp，KeyType等5部分组成，HBase设定Key大小首先比较RowKey，RowKey越小Key就越小；RowKey如果相同就看CF，CF越小Key越小；CF如果相同看Qualifier，Qualifier越小Key越小；Qualifier如果相同再看Timestamp，Timestamp越大表示时间越新，对应的Key越小。如果Timestamp还相同，就看KeyType，KeyType按照DeleteFamily -> DeleteColumn -> Delete -> Put 顺序依次对应的Key越来越大。\n\n\\2. StoreScanner合并构建最小堆：上文讨论的是一个监工如何构建自己的工匠师团队以及工匠师如何做准备工作、排序工作。实际上，监工也需要进行排序，比如一单元的监工排前面，二单元的监工排之后… StoreScanner一样，列族小的StoreScanner排前面，列族大的StoreScanner排后面。\n\n****\n\n### **scan查询－层层建楼**\n\n构建Scanner体系是为了更好地执行scan查询，就像组建工匠师团队就是为了盖房子一样。scan查询总是一行一行查询的，先查第一行的所有数据，再查第二行的所有数据，但每一行的查询流程却没有什么本质区别。盖房子也一样，无论是盖8层还是盖18层，都需要一层一层往上盖，而且每一层的盖法并没有什么区别。所以实际上我们只需要关注其中一行数据是如何查询的就可以。\n\n对于一行数据的查询，又可以分解为多个列族的查询，比如RowKey=row1的一行数据查询，首先查询列族1上该行的数据集合，再查询列族2里该行的数据集合。同样是盖第一层房子，先盖一单元的一层，再改二单元的一层，盖完之后才算一层盖完，接着开始盖第二层。所以我们也只需要关注某一行某个列族的数据是如何查询的就可以。\n\n还记得Scanner体系构建的最终结果是一个由StoreFileScanner和MemstoreScanner组成的heap（最小堆）么，这里就派上用场了。下图是一张表的逻辑视图，该表有两个列族cf1和cf2（我们只关注cf1），cf1只有一个列name，表中有5行数据，其中每个cell基本都有多个版本。cf1的数据假如实际存储在三个区域，memstore中有r2和r4的最新数据，hfile1中是最早的数据。现在需要查询RowKey=r2的数据，按照上文的理论对应的Scanner指向就如图所示：\n\n![544501](http://hbasefly.com/wp-content/uploads/2016/12/544501.png)\n\n这三个Scanner组成的heap为<MemstoreScanner，StoreFileScanner2, StoreFileScanner1>，Scanner由小到大排列。查询的时候首先pop出heap的堆顶元素，即MemstoreScanner，得到keyvalue = r2:cf1:name:v3:name23的数据，拿到这个keyvalue之后，需要进行如下判定：\n\n1. 检查该KeyValue的KeyType是否是Deleted/DeletedCol等，如果是就直接忽略该列所有其他版本，跳到下列（列族）\n2. 检查该KeyValue的Timestamp是否在用户设定的Timestamp Range范围，如果不在该范围，忽略\n3. 检查该KeyValue是否满足用户设置的各种filter过滤器，如果不满足，忽略\n4. 检查该KeyValue是否满足用户查询中设定的版本数，比如用户只查询最新版本，则忽略该cell的其他版本；反正如果用户查询所有版本，则还需要查询该cell的其他版本。\n\n现在假设用户查询所有版本而且该keyvalue检查通过，此时当前的堆顶元素需要执行next方法去检索下一个值，并重新组织最小堆。即图中MemstoreScanner将会指向r4，重新组织最小堆之后最小堆将会变为<StoreFileScanner2, StoreFileScanner1, MemstoreScanner>，堆顶元素变为StoreFileScanner2，得到keyvalue＝r2:cf1:name:v2:name22，进行一系列判定，再next，再重新组织最小堆…\n\n不断重复这个过程，直至一行数据全部被检索得到。继续下一行…\n\n－－－－－－－－－－－－－－－－此处应有华丽丽的分隔符－－－－－－－－－－－－－－－－\n\n本文从框架层面对HBase读取流程进行了详细的解析，文中并没有针对细节进行深入分析，一方面是担心个人能力有限，引入太多细节会让文章难于理解，另一方面是大多数看官可能对细节并不关心，下篇文章笔者会揪出来一些比较重要的细节和大家一起交流～\n\n文章最后，贴出来一个一些朋友咨询的问题：Memstore在flush的时候会不会将Blockcache中的数据update？如果不update的话不就会产生脏读，读到以前的老数据？\n\n\n\n回顾一下scan的整个流程，如下图所示：\n\n![55](http://hbasefly.com/wp-content/uploads/2017/06/55.png)\n\n上图是一个简单的示意图，用户如果对整个流程比较感兴趣，可以阅读之前的文章，本文将会关注于隐藏在这个示意图中的核心细节。这里笔者挑出了其中五个比较重要的问题来说明，这些问题都是本人之前或早或晚比较困惑的问题，拿出来与大家分享。当然，如果大家有反馈想了解的其他细节，也可以单独交流探讨。\n\n\\1. 常说HBase数据读取要读Memstore、HFile和Blockcache，为什么上面Scanner只有StoreFileScanner和MemstoreScanner两种？没有BlockcacheScanner?\n\nHBase中数据仅仅独立地存在于Memstore和StoreFile中，Blockcache中的数据只是StoreFile中的部分数据（热点数据），即所有存在于Blockcache的数据必然存在于StoreFile中。因此MemstoreScanner和StoreFileScanner就可以覆盖到所有数据。实际读取时StoreFileScanner通过索引定位到待查找key所在的block之后，首先检查该block是否存在于Blockcache中，如果存在直接取出，如果不存在再到对应的StoreFile中读取。\n\n\\2.  数据更新操作先将数据写入Memstore，再落盘。落盘之后需不需要更新Blockcache中对应的kv？如果不更新，会不会读到脏数据？\n\n如果理清楚了第一个问题，相信很容易得出这个答案：不需要更新Blockcache中对应的kv，而且不会读到脏数据。数据写入Memstore落盘会形成新的文件，和Blockcache里面的数据是相互独立的，以多版本的方式存在。\n\n\\3. 读取流程中如何使用BloomFilter(简称BF)对StoreFile进行过滤？\n\n过滤StoreFile发生在上图中第三步，过滤手段主要有三种：根据KeyRange过滤、根据TimeRange过滤、根据BF过滤。下面分别进行介绍：\n\n（1）根据KeyRange过滤：因为StoreFile是中所有KV数据都是有序排列的，所以如果待检索row范围［startrow，stoprow］与文件起始key范围［firstkey，lastkey］没有交集，比如stoprow < firstkey 或者 startrow > lastkey，就可以过滤掉该StoreFile。 \n\n（2）根据TimeRange过滤：StoreFile中元数据有一个关于该File的TimeRange属性［minimumTimestamp, maxmumTimestamp］，因此待检索的TimeRange如果与该文件时间范围没有交集，就可以过滤掉该StoreFile；另外，如果该文件所有数据已经过期，也可以过滤淘汰。\n\n（3）根据BF过滤：BF在几乎所有的LSM模型存储领域都会用到，可说是标配，比如HBase、Kudu、RocksDB等等，用法也是如出一辙，和HBase一样，主要用来读取数据时过滤部分文件；除此之外，BF在大数据计算（分布式Join实现）中也扮演重要的角色，参考Impala中Hash Join的实现（戳[这里](http://hbasefly.com/2017/04/10/bigdata-join-2/)）。BF的具体工作原理笔者假设童鞋都了解（不了解的童鞋可以参考上述链接文章）。\n\n现在来看看HBase中如何利用BF对StoreFile进行过滤(注：接下来所有关于HBase BF的说明都按照Row类型来，Row-Column类型类似)，原理其实很简单：首先把BF数据加载到内存；然后使用hash函数对待检索row进行hash，根据hash后的结果在BF数据中进行寻址查看即可确定是否存在该HFile。第二步就是BF的原理，并没有什么好讲的，主要来看看HBase是如何将BF数据加载到内存的。\n\n看过笔者之前文章的童鞋都知道，BF数据实际上是和用户KV数据一样存储在HFile中的，那就需要先看看BF信息是如何存储在HFile中的，查看[官方文档](http://hbase.apache.org/book.html#_hfile_format_2)中HFile(v2)组织结构图如下：\n\n![56](http://hbasefly.com/wp-content/uploads/2017/06/56.png)\n\nHFile组织结构中关于BF有两个非常重要的结构－Bloom Block与Bloom Index。Bloom Block主要存储BF的实际数据，可能这会大家要问为什么Bloom Block要分布在整个HFile？分布的具体位置如何确定？其实很简单，HBase在写数据的时候就会根据row生成对应的BF信息并写到一个Block中，随着用户数据的不断写入，这个BF Block就会不断增大，当增大到一定阈值之后系统就会重新生成一个新Block，旧Block就会顺序加载到Data Block之后。这里隐含了一个关键的信息，随着单个文件的增大，BF信息会逐渐变的很大，并不适合一次性全部加载到内存，更适合的使用方式是使用哪块加载哪块！\n\n这些Bloom Block分散在HFile中的各个角落，就会带来一个问题：如何有效快速定位到这些BF Block？这就是Bloom Index的核心作用，与Data Index相同，Bloom Index也是一颗B+树，Bloom Index Block结构如下图所示：\n\n![57](http://hbasefly.com/wp-content/uploads/2017/06/57.png)\n\n上图需要重点关注Bloom Block的Block Key：Block中第一个原始KV的RowKey。这样给定一个待检索的 rowkey，就可以很容易地通过Bloom Index定位到具体的Bloom Block，将Block加载到内存进行过滤。通常情况下，热点Bloom Block会常驻内存的！\n\n到此为止，笔者已经解释清楚了HBase是如何利用BF在读取数据时根据rowkey过滤StoreFile的，相信Kudu、RocksDB中BF的原理基本相同。\n\n再回到出发的地方，我们说在实际scan之前就要使用BF对StoreFile进行过滤，那仔细想下，到底用哪个rowkey过滤？实际实现中系统使用scan的startrow作为过滤条件进行过滤，这是不是有问题？举个简单的例子，假设小明检索的数据为［row1, row4］，如果此文件不包含row1，而包含row2，这样在scan前你利用row1就把该文件淘汰掉了，row2这条数据怎么办？不是会被遗漏？\n\n这里系统实现有个隐藏点，scan之前使用BF进行过滤只针对get查询以及scan单条数据的场景，scan多条数据并不会执行实际的BF过滤，而是在实际seek到新一行的时候才会启用BF根据新一行rowkey对所有StoreFile过滤。\n\n\\4. 最小堆中弹出cell之后如何对该cell进行检查过滤，确保满足用户设置条件？检查过滤之后是继续弹出下一个cell，还是跳过部分cell重新seek到下一列或者下一行？\n\nscan之所以复杂，很大程度上是因为scan可以设置的条件非常之多，下面所示代码为比较常规的一些设置：\n\n```\nScan scan = new Scan();\nscan.withStartRow(startRow) //设置检索起始row\n        .withStopRow(stopRow) //设置检索结束row\n        .setFamilyMap(Map<byte[], Set<byte[]> familyMap>) //设置检索的列族和对应列族下的列集合\n        .setTimeRange(minStamp, maxStamp) // 设置检索TimeRange\n        .setMaxVersions(maxVersions) //设置检索的最大版本号\n        .setFilter(filter) //设置检索过滤器\n        …\n```\n\n在整个Scan流程的第6步，将堆顶kv元素出堆进行检查，实际上主要检查两个方面，其一是非用户条件检查，比如kv是否已经过期（列族设置TTL）、kv是否已经被删除，这些检查和用户设置查询条件没有任何关系；其二就是检查该kv是否满足用户设置的这些查询条件，代码逻辑还是比较清晰的，在此不再赘述。核心代码主要参考ScanQueryMatcher.match(cell)方法。\n\n相比堆顶元素检查流程，笔者更想探讨堆顶元素kv检查之后的返回值－MatchCode，这个Code可不简单，它会告诉scanner是继续seek下一个cell，还是直接跳过部分cell直接seek到下一列（对应INCLUDE_AND_SEEK_NEXT_COL或SEEK_NEXT_COL），抑或是直接seek到下一行(对应INCLUDE_AND_SEEK_NEXT_ROW或SEEK_NEXT_ROW)。还是举一个简单的例子：\n\n![58](http://hbasefly.com/wp-content/uploads/2017/06/58.png)\n\n上图是待查表，含有一个列族cf，列族下有四个列[c1, c2, c3, c4]，列族设置MaxVersions为2，即允许最多存在2个版本。现在简单构造一个查询语句如下：\n\n```\nScan scan = new Scan(r1, r4); // 表示检索范围为［r1, r4］\nscan.setFamilyMap(Map<cf, Set<c1,c2>>) //仅检索列族cf下的c1列和c2列\n        .setMaxVersions(1) //设置检索的最大版本号为1\n```\n\n下面分别模拟直接跳过部分纪录seek到下一列（INCLUDE_AND_SEEK_NEXT_COL）的场景以及跳过部分列直接seek到下一行（INCLUDE_AND_SEEK_NEXT_ROW）的场景：\n\n（1）假设当前检索r1行，堆顶元素为cf:c1下的kv1(版本为v1)，按照设置条件中检索的最大版本号为1，其他条件都满足的情况下就可以直接跳过kv2直接seek到下一列－c2列。这种场景下就会返回INCLUDE_AND_SEEK_NEXT_COL。\n\n（2）假设当前检索r1行，堆顶元素为cf:c2下的kv3(仅有1个版本)，满足设置的版本条件，系统检测到c2是检索的最后一列之后（c3、c4并不需要检索），就会返回指示－略过c3、c4直接seek到下一行。这种场景下就会返回INCLUDE_AND_SEEK_NEXT_ROW。\n\n至此，笔者针对scan流程中的第6步进行了比较详细的解读，对认为比较重要的点进行了简单演示。其实还是有很多内容，但大多都大同小异，原理类似。有兴趣读HBase源码的同学可以参考这里的解读，相信会有所帮助。\n\n\\5. 每次seek（key）命令是不是都需要所有scanner真正seek到指定key？延迟seek是如何优化读性能的？\n\n这是本文探讨的最后一个话题，严格来说，这个话题并不涉及scan的流程，而仅仅是对scan的一项优化。但是个人认为理解这项优化对scan的流程理解有着相当重要的意义，同时也是阅读HBase-Scan模块源码必须要迈过的一道坎。\n\n先回到scan的流程，根据之前的理解，如果堆顶元素出堆检查之后指示scanner需要跳过部分cell直接seek到下一列或者下一行，此时所有scanner都需要按照指示执行seek命令定位指定位置，这本身没有毛病。然而这可能并不高效，试想这么一种场景：\n\n（1）当前有3个StoreFile文件，因此对应3个StoreFileScanner，现在接到指示需要seek 到(rowk, cf:c1)位置，刚好这三个文件中都存在这样的KV，差别在于时间戳不同\n\n（2）于是这3个Scanner很顺从地在文件中找到指定位置，然后等待最小KV出堆接受检查\n\n（3）最小KV出堆接受检查之后满足用户条件，而且用户只需要检索最新版本。因此检查之后告诉所有scanner直接seek到下一行。\n\n有没有发现一些小小的问题？没错，3个scanner只有1个scanner做了’有用功’，其他两个scanner都做了’无用seek’。这很显然一定程度上会影响scan性能。\n\nHBase提出了一个很巧妙的应对方案－延迟seek，就是3个scanner接到seek指示的时候，实际上并没有真正去做，而只是将scanner的指针指向指定位置。那童鞋就会问了，那什么时候真正去seek呢？只需要在堆顶元素弹出来的时候真正去执行就可以。这样，就可以有效避免大量’无用seek’。\n\n好了，本文核心内容就基本介绍完了，接下来扯点闲篇。任何存储系统的核心模块无非读写模块，但不同类型的数据库侧重不同。MySQL类系统（Oracle、SQLServer等）侧重于写，写就是它的灵魂！为了实现事务原子性，数据更新之前要先写undo log，为了实现数据持久性，又引入redo log，为了实现事务隔离性，还需要实现各种锁，还有类似double write等一系列机制…… ，个人认为，搞懂了数据更新写入流程基本就搞懂了MySQL存储引擎。与MySQL相对，HBase类系统（RocksDB、Kudu ）更侧重读，读是它的灵魂！HBase将所有更新操作、删除操作都简单的当作写入操作来处理，对于更新删除来说确实简单了，但却给数据读取带来了极大的负担，数据读取的时候需要额外过滤删除数据、处理多版本数据，除此之外，LSM所特有的多文件存储、BloomFilter过滤特性支持等等无不增加了数据读取的难度。个人认为，只有搞懂了数据读取才可能真正理解HBase内核。","slug":"hbase/hbase的读流程","published":1,"updated":"2018-09-12T03:03:21.818Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfngw002lwlkv5r53jrqm"},{"title":"hbase认识与安装配置","date":"2017-09-05T23:20:10.000Z","_content":"# hbase认识与安装配置\n\n## 认识\n\nHBase是一种构建在HDFS之上提供高可靠性、高性能、列存储、分布式、可伸缩、实时读写的存储系统。在需要实时读写、随机访问超海量数据时，可以使用HBase。与hadoop一样，通过不断增加廉价的服务器，可以对HBase进行横向扩展，增加HBase的计算和存储能力。\n\nHBase位于结构化存储层，Hadoop HDFS为HBase提供了高可靠性的底层存储支持，Hadoop MapReduce为HBase提供了高性能的计算能力，Zookeeper为HBase提供了稳定服务和failover机制。\n\n<!--more-->\n\n ### HBase中表的特点：\n\n1. 大：一个表可以有上亿行，上百万列\n2. 面向列：面向列表（簇）的存储和权限控制，列（簇）独立检索\n3. 稀疏：不存储为空的列，所有可以节约存储空间，表可以设计的非常稀疏\n4. 非结构化：每一行都有一个可以排序的主键和任意多的列，列可以根据需要动态增加，每行可以存储不同的列\n5. 数据多版本：每个单元中的数据可以有多个版本，默认情况下，版本号自动分配，版本号就是单元格插入时的时间戳\n6. 数据类型单一：HBase中的数据都是字节\n7. 查询单一，只支持根据rowKey的精确get查询和范围scan查询\n\n### 什么时候选择HBase \n\n1. 超大数据量上高并发操作，高速插入，大量读取\n2. 存储非结构化数据\n3. 记录非常稀疏\n4. 需要保存多个版本数据\n\n### 与传统数据库区别\n\n- 传统数据库\n\n  - 传统数据库都是面向行进行数据存储，当字段过多或者条数上百万条的时候，查询性能会特别差，如果使用分库、分表来对数据库进行扩展，又会遇到分布式事务、跨数据库分页查询、负载均衡等问题。\n  - 传统数据库支持复杂的sql查询\n\n\n- hbase\n\n  - hbase抛弃关系数据的面向行存储模式，而是采用基于列进行存储，将字段映射为hbase的一个列，查询中选择要查询的列，而不需要创建索引\n  - hbase支持动态调整列，实现了字段的动态扩展。对应为空的列数据，hbase不会存储，节省了存储空间。\n  - hbase将按照列族在磁盘上存储数据文件，实现了存储文件的拆分和合并，同时可以动态扩展regionServer来支持海量数据的存储和高并发的读写操作，\n  - hbase可以存储一份数据的多个版本，对于数据的存储，hbase自动维护了一个时间戳，最新的数据版本排在最前面，通过rowKey+column+时间戳唯一确定一个shell。\n  - 只可以通过rowKey进行查询，查询比较单一\n\n### 与hadoop关系\n\nHadoop hdfs适合于存储非结构化数据，但是受限于hadoop MapReduce编程框架的高延迟数据处理机制，使得hadoop无法满足**大规模数据的实时处理**需求。\n\nHBase是可以提供实时计算的分布式数据库，数据被保存在HDFS分布式文件系统上，由HDFS保证期高容错性。HBase上的数据是以StoreFile(HFile)二进制流的形式存储在HDFS上block块儿中；\n\nHBase HRegion servers集群中的所有的region的数据在服务器启动时都是被打开的，并且在内冲初始化一些memstore，相应的这就在一定程度上加快系统响 应；而Hadoop中的block中的数据文件默认是关闭的，只有在需要的时候才打开，处理完数据后就关闭，这在一定程度上就增加了响应时间。\n\nHBase能提供实时计算服务主要原因是由其架构和底层的数据结构决定的，即由LSM-Tree + HTable(region分区) + Cache决定，客户端可以直接定位到要查数据所在的HRegion server服务器，然后直接在服务器的一个region上查找要匹配的数据，客户端也可以缓存查询region位置的信息。\n\n### 和Hive的区别\n\n1. Hive是建立在Hadoop之上为了减少MapReduce jobs编写工作的批处理系统。HBase是为了支持弥补Hadoop对实时操作的缺陷的项目。\n2. hive是高延迟、结构化和面向分析的，hbase是低延迟、非结构化和面向编程\n3. Hive的表是**逻辑表**，它本身不存储和计算数据，它完全依赖于HDFS和MapReduce，高延迟的特点。HBase的表是**物理表**，hdfs作为底层存储，而HBase负责组织文件。 提供一个超大的内存hash表，搜索引擎通过它来存储索引，方便查询操作。\n\n## 单机安装\n\n- 解压hbase安装包\n\n  ```shell\n  tar -xzvf hbase-1.1.10-bin.tar.gz\n  ```\n\n- 配置hbase-env.sh\n\n  ```xml\n  export JAVA_HOME=/usr/java/jdk1.7.0_27 //Java 安装路径\n  export HBASE_CLASSPATH=/hadoop/hbase-0.96.2 //HBase 类路径\n  export HBASE_MANAGES_ZK=true //由 HBase 自己负责启动和关闭 Zookeeper\n  ```\n\n- 配置hbase-site.xml\n\n  ```xml\n  <?xml version=\"1.0\"?>  \n  <?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?>  \n  <configuration>  \n    <property>  \n      <!--指定storefile存储磁盘位置-->\n      <name>hbase.rootdir</name>  \n      <value>file:///DIRECTORY/hbase</value>  \n      <!--hbase 中数据存放的HDFS根路径-->\n      <!--<value>hdfs://hadoop01:9000/hbase</value>-->\n    </property>  \n    <property>\n      <name>hbase.cluster.distributed</name>\n      //hbase 是否安装在分布式环境中\n      <value>true</value>\n  </property>\n  <property>\n      //指定 Hbase 的 ZK 节点位置，由于上述已指定 Hbase 自己管理 ZK\n      <name>hbase.zookeeper.quorum</name>\n      <value>hadoop01</value>\n  </property>\n  <property>\n      <name>dfs.replication</name>\n      //伪分布环境，副本数为 1\n      <value>1</value>\n  </property>\n  </configuration>  \n  ```\n\n- 启动hbase\n\n  ```shell\n  ./bin/start-hbase.sh\n  ```\n\n## 简单shell操作\n\n- 连接本地hbase\n\n  ```shell\n  ./bin/hbase shell\n  ```\n\n- 指令 **help**，查看hbase用法\n\n- 创建表\n\n  ```shell\n  #查看都有哪些表\n  list\n  #判断一个表是否存在\n  exists '表名'\n  #创建表\n  Create '表名','列族1','列族2','列族N'\n  #查看表信息\n  describe \"表名\"\n  #废弃表\n  disable '表名'\n  #删除表，只能删除disable后的表\n  drop '表名'\n  #清空表 disable-drop-create\n  trancat '表名'\n  #修改表结构，可以修改是否加入缓存、保留版本\n  alter '表名'\n  ```\n\n- 操作表\n\n  hdfs只支持写入和追加操作，所以hbase修改数据只能进行覆盖，用时间戳，获取时间戳最大的一行数据\n\n  ```shell\n  #保存数据，hbase的列由列族名和列名字组成，中间用:隔开，多个put可以连写，不要写;就可以\n  Put '表名','行键rowKey','列族:列','列值'\n  #删除一行数据\n  deleteall '表名','rowkey'\n  #删除该行的一列数据\n  delete '表名','rowkey','列族:列名'\n  #统计总行数\n  count '表名'\n  ```\n\n- 查询\n\n  ```shell\n  #全表扫描\n  scan '表名'\n  #查询表中列族为info，RowKey范围是[lz0001, lz0003)的数据\n  scan '表名', {COLUMNS => 'info', STARTROW => 'lz0001', ENDROW => 'lz0003'\n  #查询表中RowKey以lz字符开头的\n  scan '表名',{FILTER=>\"PrefixFilter('lz')\"}\n  #根据rowkey获取\n  get '表名','rowkey'\n  #查询一行中一个列族所有信息\n  get '表名','rowkey','列族名'\n  #查询一行中一个列族中一列\n  get '表名','rowkey','列族名','列名'  \n  get '表名','rowkey','列族名:列名'\n  #同时查询多个列族\n  get '表名','rowkey','列族名:列名','列族名:列名'\n  get '表名','rowkey',{COLUMN>=['列族名:列名','列族名:列名'],TIMESTAMP=>23232323}\n  #查询列名包含a的cell\n  get '表名', 'rowkey', {FILTER => \"(QualifierFilter(=,'substring:a'))\"}\n  #获取二进制binary的值为“立志”的cell\n  get '表名', 'rowkey', {FILTER => \"ValueFilter(=, 'binary:立志')\"}\n  ```\n\n\n## 配置\n\n","source":"_posts/hbase/hbase认识与安装配置.md","raw":"---\ntitle: hbase认识与安装配置\ndate: 2017-09-06 07:20:10\ntags:\n- hbase\ncategories:\n- 大数据\n---\n# hbase认识与安装配置\n\n## 认识\n\nHBase是一种构建在HDFS之上提供高可靠性、高性能、列存储、分布式、可伸缩、实时读写的存储系统。在需要实时读写、随机访问超海量数据时，可以使用HBase。与hadoop一样，通过不断增加廉价的服务器，可以对HBase进行横向扩展，增加HBase的计算和存储能力。\n\nHBase位于结构化存储层，Hadoop HDFS为HBase提供了高可靠性的底层存储支持，Hadoop MapReduce为HBase提供了高性能的计算能力，Zookeeper为HBase提供了稳定服务和failover机制。\n\n<!--more-->\n\n ### HBase中表的特点：\n\n1. 大：一个表可以有上亿行，上百万列\n2. 面向列：面向列表（簇）的存储和权限控制，列（簇）独立检索\n3. 稀疏：不存储为空的列，所有可以节约存储空间，表可以设计的非常稀疏\n4. 非结构化：每一行都有一个可以排序的主键和任意多的列，列可以根据需要动态增加，每行可以存储不同的列\n5. 数据多版本：每个单元中的数据可以有多个版本，默认情况下，版本号自动分配，版本号就是单元格插入时的时间戳\n6. 数据类型单一：HBase中的数据都是字节\n7. 查询单一，只支持根据rowKey的精确get查询和范围scan查询\n\n### 什么时候选择HBase \n\n1. 超大数据量上高并发操作，高速插入，大量读取\n2. 存储非结构化数据\n3. 记录非常稀疏\n4. 需要保存多个版本数据\n\n### 与传统数据库区别\n\n- 传统数据库\n\n  - 传统数据库都是面向行进行数据存储，当字段过多或者条数上百万条的时候，查询性能会特别差，如果使用分库、分表来对数据库进行扩展，又会遇到分布式事务、跨数据库分页查询、负载均衡等问题。\n  - 传统数据库支持复杂的sql查询\n\n\n- hbase\n\n  - hbase抛弃关系数据的面向行存储模式，而是采用基于列进行存储，将字段映射为hbase的一个列，查询中选择要查询的列，而不需要创建索引\n  - hbase支持动态调整列，实现了字段的动态扩展。对应为空的列数据，hbase不会存储，节省了存储空间。\n  - hbase将按照列族在磁盘上存储数据文件，实现了存储文件的拆分和合并，同时可以动态扩展regionServer来支持海量数据的存储和高并发的读写操作，\n  - hbase可以存储一份数据的多个版本，对于数据的存储，hbase自动维护了一个时间戳，最新的数据版本排在最前面，通过rowKey+column+时间戳唯一确定一个shell。\n  - 只可以通过rowKey进行查询，查询比较单一\n\n### 与hadoop关系\n\nHadoop hdfs适合于存储非结构化数据，但是受限于hadoop MapReduce编程框架的高延迟数据处理机制，使得hadoop无法满足**大规模数据的实时处理**需求。\n\nHBase是可以提供实时计算的分布式数据库，数据被保存在HDFS分布式文件系统上，由HDFS保证期高容错性。HBase上的数据是以StoreFile(HFile)二进制流的形式存储在HDFS上block块儿中；\n\nHBase HRegion servers集群中的所有的region的数据在服务器启动时都是被打开的，并且在内冲初始化一些memstore，相应的这就在一定程度上加快系统响 应；而Hadoop中的block中的数据文件默认是关闭的，只有在需要的时候才打开，处理完数据后就关闭，这在一定程度上就增加了响应时间。\n\nHBase能提供实时计算服务主要原因是由其架构和底层的数据结构决定的，即由LSM-Tree + HTable(region分区) + Cache决定，客户端可以直接定位到要查数据所在的HRegion server服务器，然后直接在服务器的一个region上查找要匹配的数据，客户端也可以缓存查询region位置的信息。\n\n### 和Hive的区别\n\n1. Hive是建立在Hadoop之上为了减少MapReduce jobs编写工作的批处理系统。HBase是为了支持弥补Hadoop对实时操作的缺陷的项目。\n2. hive是高延迟、结构化和面向分析的，hbase是低延迟、非结构化和面向编程\n3. Hive的表是**逻辑表**，它本身不存储和计算数据，它完全依赖于HDFS和MapReduce，高延迟的特点。HBase的表是**物理表**，hdfs作为底层存储，而HBase负责组织文件。 提供一个超大的内存hash表，搜索引擎通过它来存储索引，方便查询操作。\n\n## 单机安装\n\n- 解压hbase安装包\n\n  ```shell\n  tar -xzvf hbase-1.1.10-bin.tar.gz\n  ```\n\n- 配置hbase-env.sh\n\n  ```xml\n  export JAVA_HOME=/usr/java/jdk1.7.0_27 //Java 安装路径\n  export HBASE_CLASSPATH=/hadoop/hbase-0.96.2 //HBase 类路径\n  export HBASE_MANAGES_ZK=true //由 HBase 自己负责启动和关闭 Zookeeper\n  ```\n\n- 配置hbase-site.xml\n\n  ```xml\n  <?xml version=\"1.0\"?>  \n  <?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?>  \n  <configuration>  \n    <property>  \n      <!--指定storefile存储磁盘位置-->\n      <name>hbase.rootdir</name>  \n      <value>file:///DIRECTORY/hbase</value>  \n      <!--hbase 中数据存放的HDFS根路径-->\n      <!--<value>hdfs://hadoop01:9000/hbase</value>-->\n    </property>  \n    <property>\n      <name>hbase.cluster.distributed</name>\n      //hbase 是否安装在分布式环境中\n      <value>true</value>\n  </property>\n  <property>\n      //指定 Hbase 的 ZK 节点位置，由于上述已指定 Hbase 自己管理 ZK\n      <name>hbase.zookeeper.quorum</name>\n      <value>hadoop01</value>\n  </property>\n  <property>\n      <name>dfs.replication</name>\n      //伪分布环境，副本数为 1\n      <value>1</value>\n  </property>\n  </configuration>  \n  ```\n\n- 启动hbase\n\n  ```shell\n  ./bin/start-hbase.sh\n  ```\n\n## 简单shell操作\n\n- 连接本地hbase\n\n  ```shell\n  ./bin/hbase shell\n  ```\n\n- 指令 **help**，查看hbase用法\n\n- 创建表\n\n  ```shell\n  #查看都有哪些表\n  list\n  #判断一个表是否存在\n  exists '表名'\n  #创建表\n  Create '表名','列族1','列族2','列族N'\n  #查看表信息\n  describe \"表名\"\n  #废弃表\n  disable '表名'\n  #删除表，只能删除disable后的表\n  drop '表名'\n  #清空表 disable-drop-create\n  trancat '表名'\n  #修改表结构，可以修改是否加入缓存、保留版本\n  alter '表名'\n  ```\n\n- 操作表\n\n  hdfs只支持写入和追加操作，所以hbase修改数据只能进行覆盖，用时间戳，获取时间戳最大的一行数据\n\n  ```shell\n  #保存数据，hbase的列由列族名和列名字组成，中间用:隔开，多个put可以连写，不要写;就可以\n  Put '表名','行键rowKey','列族:列','列值'\n  #删除一行数据\n  deleteall '表名','rowkey'\n  #删除该行的一列数据\n  delete '表名','rowkey','列族:列名'\n  #统计总行数\n  count '表名'\n  ```\n\n- 查询\n\n  ```shell\n  #全表扫描\n  scan '表名'\n  #查询表中列族为info，RowKey范围是[lz0001, lz0003)的数据\n  scan '表名', {COLUMNS => 'info', STARTROW => 'lz0001', ENDROW => 'lz0003'\n  #查询表中RowKey以lz字符开头的\n  scan '表名',{FILTER=>\"PrefixFilter('lz')\"}\n  #根据rowkey获取\n  get '表名','rowkey'\n  #查询一行中一个列族所有信息\n  get '表名','rowkey','列族名'\n  #查询一行中一个列族中一列\n  get '表名','rowkey','列族名','列名'  \n  get '表名','rowkey','列族名:列名'\n  #同时查询多个列族\n  get '表名','rowkey','列族名:列名','列族名:列名'\n  get '表名','rowkey',{COLUMN>=['列族名:列名','列族名:列名'],TIMESTAMP=>23232323}\n  #查询列名包含a的cell\n  get '表名', 'rowkey', {FILTER => \"(QualifierFilter(=,'substring:a'))\"}\n  #获取二进制binary的值为“立志”的cell\n  get '表名', 'rowkey', {FILTER => \"ValueFilter(=, 'binary:立志')\"}\n  ```\n\n\n## 配置\n\n","slug":"hbase/hbase认识与安装配置","published":1,"updated":"2018-09-12T03:03:21.819Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfngx002owlkvg80a48x8"},{"title":"hbase过滤器","date":"2017-09-09T02:58:13.000Z","_content":"\n# hbase过滤器\n\n\n\n\n\n\n\n​","source":"_posts/hbase/hbase过滤器.md","raw":"---\ntitle: hbase过滤器\ndate: 2017-09-09 10:58:13\ntags:\n- hbase\ncategories:\n- 大数据\n---\n\n# hbase过滤器\n\n\n\n\n\n\n\n​","slug":"hbase/hbase过滤器","published":1,"updated":"2018-09-12T03:03:21.819Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfngy002rwlkvbq2gt7ut"},{"title":"hbase数据模型","date":"2017-09-07T13:58:46.000Z","_content":"\n# Hbase设计模型\n\n## HBase基本组件\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-8-6/72109526.jpg)\n\n- Client\n\n  - 使用HBase RPC机制与HMaster和HRegionServer进行通信\n  - Client与HMaster进行通信进行管理类操作\n  - Client与HRegionServer进行数据读写类操作\n  - Client访问ZK获取_ROOT_表位置，获取集群的属性\n  - 缓存Region的位置信息来加快对HBase的访问\n\n\n- HMaster\n\n  HBase中可以启动多个HMaster，通过Zookeeper保证总有一个Active Master运行。主要负责Table和Region的管理工作：\n\n  - 管理用户对Table的增删改操作\n  - 负责Region Split后新Region的分布,管理HRS的负载均衡\n  - 发现失效的HRS重新分配其上的HR\n  - Client对HBase数据的操作并不需要HMaster参与，仅仅维护者Table和HR的元数据信息，负载很低\n\n- HRegion Server\n\n  ![image](http://omdq6di7v.bkt.clouddn.com/17-8-6/22930446.jpg)\n\n  - 负责响应client的I\\O请求，存储hbase的数据文件，查询并返回数据\n  - HRS上存储多个Region\n  - HRS负责切分Region，当一个Region中的文件大小超过某个阈值(hbase.hregion.max.filesize)时，开始分裂成两个新Region，并由HMaster实现负载均衡，将新的分配到其他的HRS，同时删除旧Region\n  - 不要给RegionServer太大堆内存，堆内存在使用过程中会产生大量碎片，一旦full gc时间过长，master会判定slave进程已经死掉，并将其从slave工作列表中移除\n\n- ZooKeeper\n\n  - 通过选举，保证任何时候，集群中只有一个HMaster。ZK的引入使得HMaster不再是单点故障。\n  - HBase依赖ZooKeeper提供消息通信机制，避免了master和region服务器之间的心跳信息的传递。HMaster与HRS启动时会向ZK注册，并定时向ZK发送心跳。实时监控HRS的状态，将HRS上线和下线信息实时通知给HMaster。\n  - **Zookeeper存储了-ROOT-表地址(所有Region的寻址入口)、HMaster地址**。\n  - 存储Hbase的schema,包括有哪些table，每个table有哪些column family\n\n\n## 存储模型\n\n- Namespace\n  - 命名空间是对表的逻辑分组，同一个空间下的表有类似的用途\n  - 配额管理：制一个namespace可以使用的资源，资源包括region和table等\n  - 命名空间安全管理：提供了另一个层面的多租户安全管理\n  - Region服务器组：一个命名空间或一张表，可以被固定到一组regionservers上，从而保证了数据隔离性\n  - hbase内部有两个预定义的命名空间 hbase(系统表命名空间)和default(未指定命名空间的表自动归类)\n  - create_namespace 'ns'              create 'ns:tableName','f1'\n- Table\n  - 在hbase中，每张表在hbase的根目录下都有自己的目录，在表目录下有一个.tableinfo的文件存储表的结构信息\n  - 一张表初始时只有一个Region，向Region插入数据时，会检查region的大小，确保其不会超过配置的最大值，如果超过了限制，系统会在`中间键`(midlle key)处将这个region拆分成两个大致相等的region，通过HMaster负责均衡分布到其他ReginServer上\n  - 一个Region只会存储一张表的数据\n\n\n- Region\n\n  - 在表目录下存在每个Region的目录，Region目录下有个.regininfo文件存储region的信息\n\n  - Region中的数据**按照Row Key字典顺序排列**\n\n  - HBase自动把表水平（按Row）划分成多个区域(region)，每个region会保存一个表里面某段连续的数据\n\n  - 每个表一开始只有一个region，随着数据不断插入表，region不断增大，当增大到一个阀值的时候，region就会等分会两个新的region；当table中的行不断增多，就会有越来越多的region。这样一张完整的表被保存在多个Region 上。拆分的同时会更新.META.表。\n\n  - Region是HBase中分布式存储和负载均衡的最小单元（默认256M）。最小单元表示不同的Region可以分布在不同的HRegionServer上。但一个Region不会拆分到多个server上。\n\n  - 一个Region有多个Store，一个Store包含一个MemStore(内存数据)和多个StoreFile(磁盘数据)， 每个StoreFile保存一个ColumnFamily，其中StoreFile存储在HDFS上，对应为HFile文件。\n\n    ![image](http://omdq6di7v.bkt.clouddn.com/17-8-6/28630158.jpg)\n\n    ​\n\n- Store\n\n  - 一个Region包含多个Stroe，每个Store保存一个Column Family的所有数据\n  - 一个列族可以有多个StoreFile，但一个StoreFile只能存储一个列族的数据\n\n  - 一个Store包含一个位于内存中的MemStore和多个位于硬盘的StoreFile\n\n- MemStore\n\n  - MemStore处于内存中，默认64MB，用于内存级别接收client端的操作\n  - 一旦KeyValue的写入WAL中，数据就会放到MemStore中，如果MemStore写满会刷写到磁盘，生成一个新的StoreFile\n  - 客户端检索数据时，先在MemStore找，找不到再找StoreFile。\n\n- HLog(WAL)日志\n\n     由于MemStore中的数据是存储在内存中的，一旦系统出错或者宕机，一旦HRS意外退出，**MemStore**中的内存数据就会丢失，为防止这种情况，引入WAL，写MemStore之前先写入日志，Memstore刷写成一个StoreFile后再删除日志。\n\n- StoreFile\n\n  - 对HFile的简单封装，实际的物理存储文件\n\n\n## 数据模型\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-8-14/25315218.jpg)\n\n- Rowkey\n\n  - Row key按照字典序存储，要充分考虑排序存储这个特性，将经常一起读取的行存储放到一起(位置相关性)。\n\n  - 字典序对int排序的结果是1,10,100,11,2,20,21,…,9。要保持整形的自然序，行键必须用0作左填充。\n\n  - 行的一次读写是原子操作 (不论一次读写多少列)，使得多用户不能并发对同一个行进行更新操作。\n\n- Column Family(列族)\n\n  - 建表时手动指定，包含一个或者多个列\n\n  - 列族中的数据都是以二进制的形式保存在hdfs上，没有数据类型\n\n  - 不能重命名列族，通常做是法先创建新的列族，然后将数据复制过去，最后再删除旧的列族。\n\n  - 每个列族存储在HDFS上的一个单独文件中\n\n  - 访问控制、磁盘和内存的使用统计都是在列族层面进行的\n\n- Column\n\n  - 列族下可以添加任意多个列\n  - 列名在添加数据时动态添加，无需在建表时指定。没有具体的数据类型\n\n- TimeStamp\n\n  - 默认值使用系统时间戳，如果应用程序要避免数据时间戳冲突，就必须自己生成具有唯一性的时间戳。\n  - 为了避免数据存在过多版本造成的的管理 (包括存贮和索引)负担，HBase提供了两种数据版本回收方式。一是保存数据的最后n个版本，二是保存最近一段时间内的版本（即设置HColumnDescriptor.setTimeToLive(); 比如最近七天）。用户可以针对每个列族单独进行设置。\n\n- Cell\n\n  - HBase中通过\" tableName + RowKey + ColumnKey \"确定的唯一存贮单元称为Cell。\n  - 每个Cell都保存着同一份数据的多个版本，每个版本通过时间戳Time Stamp来索引。\n  - 每个cell中，不同版本的数据按照时间倒序排列，即最新的数据排在最前面。\n  - Cell的每个值通过4个键tableName + RowKey + ColumnKey + Timestamp => value唯一确定一个KeyValue\n\n- KeyValue\n\n  ![image](http://omdq6di7v.bkt.clouddn.com/17-9-12/53822290.jpg)\n\n  - KeyValue就是一个简单的byte数组，以两个分别表示键长度和值长度的定长数字开始。通过这两个值可以忽略键直接访问值\n  - 每一个KeyValue实例包含了行键、列键和时间戳索引和值 (Table,RowKey,Family,Column,Timestamp)—>value，(Timestamp是一个 64 位Java的long型)，数据按照一个四维坐标系统来组织：行键、列族、列限定符和时间版本\n  - 多个KeyValue之间的存储是有序的\n  - KeyValue所有可能存在的形式 Put、Delete、DeleteColumn、DeleteFamily\n\n\n\n\n","source":"_posts/hbase/hbase设计模型.md","raw":"---\ntitle: hbase数据模型\ndate: 2017-09-07 21:58:46\ntags:\n- hbase\ncategories:\n- 大数据\n---\n\n# Hbase设计模型\n\n## HBase基本组件\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-8-6/72109526.jpg)\n\n- Client\n\n  - 使用HBase RPC机制与HMaster和HRegionServer进行通信\n  - Client与HMaster进行通信进行管理类操作\n  - Client与HRegionServer进行数据读写类操作\n  - Client访问ZK获取_ROOT_表位置，获取集群的属性\n  - 缓存Region的位置信息来加快对HBase的访问\n\n\n- HMaster\n\n  HBase中可以启动多个HMaster，通过Zookeeper保证总有一个Active Master运行。主要负责Table和Region的管理工作：\n\n  - 管理用户对Table的增删改操作\n  - 负责Region Split后新Region的分布,管理HRS的负载均衡\n  - 发现失效的HRS重新分配其上的HR\n  - Client对HBase数据的操作并不需要HMaster参与，仅仅维护者Table和HR的元数据信息，负载很低\n\n- HRegion Server\n\n  ![image](http://omdq6di7v.bkt.clouddn.com/17-8-6/22930446.jpg)\n\n  - 负责响应client的I\\O请求，存储hbase的数据文件，查询并返回数据\n  - HRS上存储多个Region\n  - HRS负责切分Region，当一个Region中的文件大小超过某个阈值(hbase.hregion.max.filesize)时，开始分裂成两个新Region，并由HMaster实现负载均衡，将新的分配到其他的HRS，同时删除旧Region\n  - 不要给RegionServer太大堆内存，堆内存在使用过程中会产生大量碎片，一旦full gc时间过长，master会判定slave进程已经死掉，并将其从slave工作列表中移除\n\n- ZooKeeper\n\n  - 通过选举，保证任何时候，集群中只有一个HMaster。ZK的引入使得HMaster不再是单点故障。\n  - HBase依赖ZooKeeper提供消息通信机制，避免了master和region服务器之间的心跳信息的传递。HMaster与HRS启动时会向ZK注册，并定时向ZK发送心跳。实时监控HRS的状态，将HRS上线和下线信息实时通知给HMaster。\n  - **Zookeeper存储了-ROOT-表地址(所有Region的寻址入口)、HMaster地址**。\n  - 存储Hbase的schema,包括有哪些table，每个table有哪些column family\n\n\n## 存储模型\n\n- Namespace\n  - 命名空间是对表的逻辑分组，同一个空间下的表有类似的用途\n  - 配额管理：制一个namespace可以使用的资源，资源包括region和table等\n  - 命名空间安全管理：提供了另一个层面的多租户安全管理\n  - Region服务器组：一个命名空间或一张表，可以被固定到一组regionservers上，从而保证了数据隔离性\n  - hbase内部有两个预定义的命名空间 hbase(系统表命名空间)和default(未指定命名空间的表自动归类)\n  - create_namespace 'ns'              create 'ns:tableName','f1'\n- Table\n  - 在hbase中，每张表在hbase的根目录下都有自己的目录，在表目录下有一个.tableinfo的文件存储表的结构信息\n  - 一张表初始时只有一个Region，向Region插入数据时，会检查region的大小，确保其不会超过配置的最大值，如果超过了限制，系统会在`中间键`(midlle key)处将这个region拆分成两个大致相等的region，通过HMaster负责均衡分布到其他ReginServer上\n  - 一个Region只会存储一张表的数据\n\n\n- Region\n\n  - 在表目录下存在每个Region的目录，Region目录下有个.regininfo文件存储region的信息\n\n  - Region中的数据**按照Row Key字典顺序排列**\n\n  - HBase自动把表水平（按Row）划分成多个区域(region)，每个region会保存一个表里面某段连续的数据\n\n  - 每个表一开始只有一个region，随着数据不断插入表，region不断增大，当增大到一个阀值的时候，region就会等分会两个新的region；当table中的行不断增多，就会有越来越多的region。这样一张完整的表被保存在多个Region 上。拆分的同时会更新.META.表。\n\n  - Region是HBase中分布式存储和负载均衡的最小单元（默认256M）。最小单元表示不同的Region可以分布在不同的HRegionServer上。但一个Region不会拆分到多个server上。\n\n  - 一个Region有多个Store，一个Store包含一个MemStore(内存数据)和多个StoreFile(磁盘数据)， 每个StoreFile保存一个ColumnFamily，其中StoreFile存储在HDFS上，对应为HFile文件。\n\n    ![image](http://omdq6di7v.bkt.clouddn.com/17-8-6/28630158.jpg)\n\n    ​\n\n- Store\n\n  - 一个Region包含多个Stroe，每个Store保存一个Column Family的所有数据\n  - 一个列族可以有多个StoreFile，但一个StoreFile只能存储一个列族的数据\n\n  - 一个Store包含一个位于内存中的MemStore和多个位于硬盘的StoreFile\n\n- MemStore\n\n  - MemStore处于内存中，默认64MB，用于内存级别接收client端的操作\n  - 一旦KeyValue的写入WAL中，数据就会放到MemStore中，如果MemStore写满会刷写到磁盘，生成一个新的StoreFile\n  - 客户端检索数据时，先在MemStore找，找不到再找StoreFile。\n\n- HLog(WAL)日志\n\n     由于MemStore中的数据是存储在内存中的，一旦系统出错或者宕机，一旦HRS意外退出，**MemStore**中的内存数据就会丢失，为防止这种情况，引入WAL，写MemStore之前先写入日志，Memstore刷写成一个StoreFile后再删除日志。\n\n- StoreFile\n\n  - 对HFile的简单封装，实际的物理存储文件\n\n\n## 数据模型\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-8-14/25315218.jpg)\n\n- Rowkey\n\n  - Row key按照字典序存储，要充分考虑排序存储这个特性，将经常一起读取的行存储放到一起(位置相关性)。\n\n  - 字典序对int排序的结果是1,10,100,11,2,20,21,…,9。要保持整形的自然序，行键必须用0作左填充。\n\n  - 行的一次读写是原子操作 (不论一次读写多少列)，使得多用户不能并发对同一个行进行更新操作。\n\n- Column Family(列族)\n\n  - 建表时手动指定，包含一个或者多个列\n\n  - 列族中的数据都是以二进制的形式保存在hdfs上，没有数据类型\n\n  - 不能重命名列族，通常做是法先创建新的列族，然后将数据复制过去，最后再删除旧的列族。\n\n  - 每个列族存储在HDFS上的一个单独文件中\n\n  - 访问控制、磁盘和内存的使用统计都是在列族层面进行的\n\n- Column\n\n  - 列族下可以添加任意多个列\n  - 列名在添加数据时动态添加，无需在建表时指定。没有具体的数据类型\n\n- TimeStamp\n\n  - 默认值使用系统时间戳，如果应用程序要避免数据时间戳冲突，就必须自己生成具有唯一性的时间戳。\n  - 为了避免数据存在过多版本造成的的管理 (包括存贮和索引)负担，HBase提供了两种数据版本回收方式。一是保存数据的最后n个版本，二是保存最近一段时间内的版本（即设置HColumnDescriptor.setTimeToLive(); 比如最近七天）。用户可以针对每个列族单独进行设置。\n\n- Cell\n\n  - HBase中通过\" tableName + RowKey + ColumnKey \"确定的唯一存贮单元称为Cell。\n  - 每个Cell都保存着同一份数据的多个版本，每个版本通过时间戳Time Stamp来索引。\n  - 每个cell中，不同版本的数据按照时间倒序排列，即最新的数据排在最前面。\n  - Cell的每个值通过4个键tableName + RowKey + ColumnKey + Timestamp => value唯一确定一个KeyValue\n\n- KeyValue\n\n  ![image](http://omdq6di7v.bkt.clouddn.com/17-9-12/53822290.jpg)\n\n  - KeyValue就是一个简单的byte数组，以两个分别表示键长度和值长度的定长数字开始。通过这两个值可以忽略键直接访问值\n  - 每一个KeyValue实例包含了行键、列键和时间戳索引和值 (Table,RowKey,Family,Column,Timestamp)—>value，(Timestamp是一个 64 位Java的long型)，数据按照一个四维坐标系统来组织：行键、列族、列限定符和时间版本\n  - 多个KeyValue之间的存储是有序的\n  - KeyValue所有可能存在的形式 Put、Delete、DeleteColumn、DeleteFamily\n\n\n\n\n","slug":"hbase/hbase设计模型","published":1,"updated":"2018-09-12T03:03:21.819Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfngz002uwlkvfo6l3hys"},{"title":"java之动态代理","date":"2017-11-14T03:43:51.000Z","_content":"\n# java之动态代理\n\n\n\n<!--more-->\n\n什么是AOP**\n​    AOP（Aspect Orient Programming），也就是面向切面编程\n​    面向对象编程（OOP）是从静态角度考虑程序结构， 面向切面编程（AOP）是从动态角度考虑程序运行过程 \n**AOP的作用**\n​    处理一些具有横切性质的系统性服务，如事务管理、安全检查、缓存、对象池管理等\n**AOP的实现原理**\n​    AOP 实际上是由目标类的代理类实现的。AOP 代理其实是由AOP 框架动态生成的一个对象，该对象可为目标对象使用\n​    AOP 代理包含了目标对象的全部方法，但AOP 代理中的方法与目标对象的方法存在差异，AOP 方法在特定切入点添加了增强处理，并回调了目标对象的方法\n**AOP实现**\n**1.静态AOP**\n机制：静态织入\n原理：在编译期，切面直接以字节码的形式编译到目标字节码文件中\n优点：对系统无性能影响\n缺点：灵活性不够\n**2.动态AOP**\n机制：动态代理\n原理：在运行期，目标类加载后，为接口动态生成代理类，将切面植入到代理类中\n优点：相对于静态AOP更加灵活\n缺点：切入的关注点需要实现接口。对系统有一点性能影响\n代表：JDK动态代理\n接口 + InvocationHandler + 目标对象 = 代理\n**3.动态字节码生成**\n机制：在运行期，目标类加载后，动态构建字节码文件生成目标类的子类，将切面逻辑加入到子类中\n原理：没有接口也可以织入\n优点：扩展类的实例方法为final时，则无法进行织入\n代表：Cglib动态代理（依赖ASM）\n接口或类 + MethodInterceptor + 目标对象 = 代理\n**4.自定义加载器**\n机制：在运行期，目标加载前，将切面逻辑加到目标字节码里\n原理：可以对绝大部分类进行织入\n优点：代码中如果使用了其他类加载器，则这些类将不会被织入\n代表：Javassist\n**5.字节码转换**\n机制：在运行期，所有类加载器加载字节码前，前进行拦截\n原理：可以对所有类进行织入\n代表：Javassit + Instrumentation","source":"_posts/java基础/java之动态代理.md","raw":"---\ntitle: java之动态代理\ndate: 2017-11-14 11:43:51\ntags:\n- spring\ncategories:\n- java基础\n---\n\n# java之动态代理\n\n\n\n<!--more-->\n\n什么是AOP**\n​    AOP（Aspect Orient Programming），也就是面向切面编程\n​    面向对象编程（OOP）是从静态角度考虑程序结构， 面向切面编程（AOP）是从动态角度考虑程序运行过程 \n**AOP的作用**\n​    处理一些具有横切性质的系统性服务，如事务管理、安全检查、缓存、对象池管理等\n**AOP的实现原理**\n​    AOP 实际上是由目标类的代理类实现的。AOP 代理其实是由AOP 框架动态生成的一个对象，该对象可为目标对象使用\n​    AOP 代理包含了目标对象的全部方法，但AOP 代理中的方法与目标对象的方法存在差异，AOP 方法在特定切入点添加了增强处理，并回调了目标对象的方法\n**AOP实现**\n**1.静态AOP**\n机制：静态织入\n原理：在编译期，切面直接以字节码的形式编译到目标字节码文件中\n优点：对系统无性能影响\n缺点：灵活性不够\n**2.动态AOP**\n机制：动态代理\n原理：在运行期，目标类加载后，为接口动态生成代理类，将切面植入到代理类中\n优点：相对于静态AOP更加灵活\n缺点：切入的关注点需要实现接口。对系统有一点性能影响\n代表：JDK动态代理\n接口 + InvocationHandler + 目标对象 = 代理\n**3.动态字节码生成**\n机制：在运行期，目标类加载后，动态构建字节码文件生成目标类的子类，将切面逻辑加入到子类中\n原理：没有接口也可以织入\n优点：扩展类的实例方法为final时，则无法进行织入\n代表：Cglib动态代理（依赖ASM）\n接口或类 + MethodInterceptor + 目标对象 = 代理\n**4.自定义加载器**\n机制：在运行期，目标加载前，将切面逻辑加到目标字节码里\n原理：可以对绝大部分类进行织入\n优点：代码中如果使用了其他类加载器，则这些类将不会被织入\n代表：Javassist\n**5.字节码转换**\n机制：在运行期，所有类加载器加载字节码前，前进行拦截\n原理：可以对所有类进行织入\n代表：Javassit + Instrumentation","slug":"java基础/java之动态代理","published":1,"updated":"2018-09-12T03:03:21.823Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnh0002wwlkvaxitq9os"},{"title":"对象的创建","date":"2017-10-16T06:16:23.000Z","_content":"\n# 对象的创建\n\n#### java创建对象的方式\n\n-  1、直接new\n-  2、通过反射clazz的newInstance调用无参构造函数创建对象\n-  3、通过反射获取构造函数直接newInstance创建对象\n-  4、实现Serializable接口，通过反系列化创建对象\n-  5、实现Cloneable接口，覆盖clone方法，通过克隆创建对象\n\n<!--more-->\n\n```\npackage cn.zlz.createobj;\n\nimport java.io.FileInputStream;\nimport java.io.FileOutputStream;\nimport java.io.ObjectInputStream;\nimport java.io.ObjectOutputStream;\nimport java.lang.reflect.Constructor;\n\n/**\n * 创建对象的方式\n * 1、直接new\n * 2、通过反射clazz的newInstance调用无参构造函数创建对象\n * 3、通过反射获取构造函数直接newInstance创建对象\n * 4、实现Serializable接口，通过反系列化创建对象\n * 5、实现Cloneable接口，覆盖clone方法，通过克隆创建对象\n *\n */\npublic class Main {\n\n\tpublic static void main(String[] args) {\n\t\t// 通过构造函数直接new\n\t\tPerson person = new Person();\n\t\tSystem.out.println(person);\n\t\t// 通过反射创建对象\n\t\tcreateByReflect();\n\t\t// 通过构造器反射创建对象\n\t\tcreateByConstructor();\n\t\t// 通过序列化创建对象\n\t\tcreateBySerialize();\n\t\t//通过克隆创建对象\n\t\tcreateByClone();\n\t\t\n\t}\n\n\tprivate static void createByClone() {\n\t\tPerson person = new Person(\"wangwu\",5);\n\t\tPerson clone = person.clone();\n\t\tSystem.out.println(clone);\n\t}\n\tprivate static void createBySerialize() {\n\t\ttry {\n\t\t\t\n\t\t\tString filePath = \"person.dat\";\n\t\t\tPerson instance = new Person(\"lizi\",4);\n\t\t\tObjectOutputStream objectOutputStream = new ObjectOutputStream(new FileOutputStream(  \n\t\t\t\t\tfilePath));  \n            objectOutputStream.writeObject(instance);  \n            \n\t\t\tObjectInputStream objectInputStream = new ObjectInputStream(new FileInputStream(filePath));\n\t\t\tPerson person = (Person) objectInputStream.readObject();\n\t\t\tSystem.out.println(person);\n\t\t} catch (Exception e) {\n\t\t\t// TODO Auto-generated catch block\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n\n\tprivate static void createByConstructor() {\n\t\ttry {\n\t\t\tClass<?> clazz = Class.forName(\"cn.zlz.createobj.Person\");\n\t\t\tConstructor<?> constructor = clazz.getDeclaredConstructor(String.class, int.class);\n\t\t\tPerson person = (Person) constructor.newInstance(\"zhangsan\", 2);\n\t\t\tSystem.out.println(person);\n\t\t} catch (Exception e) {\n\t\t\t// TODO Auto-generated catch block\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n\n\tprivate static void createByReflect() {\n\t\ttry {\n\t\t\tClass<?> clazz = Class.forName(\"cn.zlz.createobj.Person\");\n\t\t\tPerson person = (Person) clazz.newInstance();\n\t\t\tSystem.out.println(person);\n\t\t} catch (Exception e) {\n\t\t\t// TODO Auto-generated catch block\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n\n}\npackage cn.zlz.createobj;\n\nimport java.io.Serializable;\n\npublic class Person implements Serializable, Cloneable {\n\n\t/**\n\t * \n\t */\n\tprivate static final long serialVersionUID = 1L;\n\tprivate String name;\n\tprivate int age;\n\n\tpublic Person(String name, int age) {\n\t\tsuper();\n\t\tthis.name = name;\n\t\tthis.age = age;\n\t}\n\n\tpublic Person() {\n\t\tsuper();\n\t}\n\n\t@Override\n\tpublic String toString() {\n\t\treturn \"Person [name=\" + name + \", age=\" + age + \"]\";\n\t}\n\n\t@Override\n\tpublic Person clone() {\n\t\tPerson person = null;\n\t\ttry {\n\t\t\treturn (Person) super.clone();\n\t\t} catch (CloneNotSupportedException e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t\treturn person;\n\t}\n}\n```\n## 参考\n\n​\t","source":"_posts/java基础/java反射之对象创建.md","raw":"---\ntitle: 对象的创建\ndate: 2017-10-16 14:16:23\ntags:\n- 反射\ncategories:\n- java\n---\n\n# 对象的创建\n\n#### java创建对象的方式\n\n-  1、直接new\n-  2、通过反射clazz的newInstance调用无参构造函数创建对象\n-  3、通过反射获取构造函数直接newInstance创建对象\n-  4、实现Serializable接口，通过反系列化创建对象\n-  5、实现Cloneable接口，覆盖clone方法，通过克隆创建对象\n\n<!--more-->\n\n```\npackage cn.zlz.createobj;\n\nimport java.io.FileInputStream;\nimport java.io.FileOutputStream;\nimport java.io.ObjectInputStream;\nimport java.io.ObjectOutputStream;\nimport java.lang.reflect.Constructor;\n\n/**\n * 创建对象的方式\n * 1、直接new\n * 2、通过反射clazz的newInstance调用无参构造函数创建对象\n * 3、通过反射获取构造函数直接newInstance创建对象\n * 4、实现Serializable接口，通过反系列化创建对象\n * 5、实现Cloneable接口，覆盖clone方法，通过克隆创建对象\n *\n */\npublic class Main {\n\n\tpublic static void main(String[] args) {\n\t\t// 通过构造函数直接new\n\t\tPerson person = new Person();\n\t\tSystem.out.println(person);\n\t\t// 通过反射创建对象\n\t\tcreateByReflect();\n\t\t// 通过构造器反射创建对象\n\t\tcreateByConstructor();\n\t\t// 通过序列化创建对象\n\t\tcreateBySerialize();\n\t\t//通过克隆创建对象\n\t\tcreateByClone();\n\t\t\n\t}\n\n\tprivate static void createByClone() {\n\t\tPerson person = new Person(\"wangwu\",5);\n\t\tPerson clone = person.clone();\n\t\tSystem.out.println(clone);\n\t}\n\tprivate static void createBySerialize() {\n\t\ttry {\n\t\t\t\n\t\t\tString filePath = \"person.dat\";\n\t\t\tPerson instance = new Person(\"lizi\",4);\n\t\t\tObjectOutputStream objectOutputStream = new ObjectOutputStream(new FileOutputStream(  \n\t\t\t\t\tfilePath));  \n            objectOutputStream.writeObject(instance);  \n            \n\t\t\tObjectInputStream objectInputStream = new ObjectInputStream(new FileInputStream(filePath));\n\t\t\tPerson person = (Person) objectInputStream.readObject();\n\t\t\tSystem.out.println(person);\n\t\t} catch (Exception e) {\n\t\t\t// TODO Auto-generated catch block\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n\n\tprivate static void createByConstructor() {\n\t\ttry {\n\t\t\tClass<?> clazz = Class.forName(\"cn.zlz.createobj.Person\");\n\t\t\tConstructor<?> constructor = clazz.getDeclaredConstructor(String.class, int.class);\n\t\t\tPerson person = (Person) constructor.newInstance(\"zhangsan\", 2);\n\t\t\tSystem.out.println(person);\n\t\t} catch (Exception e) {\n\t\t\t// TODO Auto-generated catch block\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n\n\tprivate static void createByReflect() {\n\t\ttry {\n\t\t\tClass<?> clazz = Class.forName(\"cn.zlz.createobj.Person\");\n\t\t\tPerson person = (Person) clazz.newInstance();\n\t\t\tSystem.out.println(person);\n\t\t} catch (Exception e) {\n\t\t\t// TODO Auto-generated catch block\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n\n}\npackage cn.zlz.createobj;\n\nimport java.io.Serializable;\n\npublic class Person implements Serializable, Cloneable {\n\n\t/**\n\t * \n\t */\n\tprivate static final long serialVersionUID = 1L;\n\tprivate String name;\n\tprivate int age;\n\n\tpublic Person(String name, int age) {\n\t\tsuper();\n\t\tthis.name = name;\n\t\tthis.age = age;\n\t}\n\n\tpublic Person() {\n\t\tsuper();\n\t}\n\n\t@Override\n\tpublic String toString() {\n\t\treturn \"Person [name=\" + name + \", age=\" + age + \"]\";\n\t}\n\n\t@Override\n\tpublic Person clone() {\n\t\tPerson person = null;\n\t\ttry {\n\t\t\treturn (Person) super.clone();\n\t\t} catch (CloneNotSupportedException e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t\treturn person;\n\t}\n}\n```\n## 参考\n\n​\t","slug":"java基础/java反射之对象创建","published":1,"updated":"2018-09-12T03:03:21.823Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnh1002zwlkvo4olhpt6"},{"title":"泛型","date":"2017-10-16T02:02:24.000Z","_content":"\n# 泛型\n\n### Java 泛型中? super T和? extends T的区别\n\n​\t经常有List<? super T>、Set<? extends T>的声明，是什么意思呢？<? super T>表示包括T在内的任何T的父类，<? extends T>表示包括T在内的任何T的子类。\n\n<!--more-->\n\n####  super\n\n​\tList<? super Integer> foo3的通配符声明，意味着以下赋值是合法的，所以对List的操作必须要满足下面三个语法检查通过才行。\n\n```java\n// Integer is a \"superclass\" of Integer (in this context)\nList<? super Integer> foo3 = new ArrayList<Integer>();\n// Number is a superclass of Integer\nList<? super Integer> foo3 = new ArrayList<Number>();\n// Object is a superclass of Integer\nList<? super Integer> foo3 = new ArrayList<Object>();\n```\n\n- 读取List<? super Integer> foo3，可能读取到Integer、Number、Object\n- 向List<? super Integer> foo3 add元素的时候只能添加Integer\n\n####  extends\n\n​\tList<? extends Number> foo3的通配符声明，意味着以下的赋值是合法的,以对List的操作必须要满足下面三个语法检查通过才行。\n\n```java\n// Number \"extends\" Number (in this context)\nList<? extends Number> foo3 = new ArrayList<Number>(); \n// Integer extends Number\nList<? extends Number> foo3 = new ArrayList<Integer>();\n// Double extends Number\nList<? extends Number> foo3 = new ArrayList<Double>();\n```\n\n- 读取List<? extends Number> foo3 可能读取到Number、Integer、Double等，所以只能使用父类(Number)来接收返回值\n- 向List<? extendsInteger> foo3 add元素的时候既不能添加Number也不能添加Number的子类，存任何一种都可能冲突，只能存入NULL值\n\n#### 总结\n\nPECS原则：生产者（Producer）使用extends，消费者（Consumer）使用super。\n\n- **生产者使用extends**\n\n  如果你需要一个列表提供T类型的元素（即你想从列表中读取T类型的元素），你需要把这个列表声明成<? extends T>，比如List<? extends Integer>，因此你不能往该列表中添加任何元素。\n\n- **消费者使用super**  \n\n  如果需要一个列表使用T类型的元素（即你想把T类型的元素加入到列表中），你需要把这个列表声明成<? super T>，比如List<? super Integer>，因此你不能保证从中读取到的元素的类型。\n\n- **即是生产者，也是消费者**\n\n  如果一个列表即要生产，又要消费，你不能使用泛型通配符声明列表，比如List<Integer>。\n\n- **例子**\n\n```java\npublic static <T> void copy(List<? super T> dest, List<? extends T> src) {\n  int srcSize = src.size();\n  if (srcSize > dest.size())\n    throw new IndexOutOfBoundsException(\"Source does not fit in dest\");\n\n  if (srcSize < COPY_THRESHOLD ||\n      (src instanceof RandomAccess && dest instanceof RandomAccess)) {\n    for (int i=0; i<srcSize; i++)\n      dest.set(i, src.get(i));\n  } else {\n    ListIterator<? super T> di=dest.listIterator();\n    ListIterator<? extends T> si=src.listIterator();\n    for (int i=0; i<srcSize; i++) {\n      di.next();\n      di.set(si.next());\n    }\n  }\n}\n```\n\n## 参考\n\n[Java 泛型中? super T和? extends T的区别](http://www.codeceo.com/article/java-super-t-extends-t.html)\t","source":"_posts/java基础/java反射之泛型.md","raw":"---\ntitle: 泛型\ndate: 2017-10-16 10:02:24\ntags:\n- 反射\ncategories:\n- java\n---\n\n# 泛型\n\n### Java 泛型中? super T和? extends T的区别\n\n​\t经常有List<? super T>、Set<? extends T>的声明，是什么意思呢？<? super T>表示包括T在内的任何T的父类，<? extends T>表示包括T在内的任何T的子类。\n\n<!--more-->\n\n####  super\n\n​\tList<? super Integer> foo3的通配符声明，意味着以下赋值是合法的，所以对List的操作必须要满足下面三个语法检查通过才行。\n\n```java\n// Integer is a \"superclass\" of Integer (in this context)\nList<? super Integer> foo3 = new ArrayList<Integer>();\n// Number is a superclass of Integer\nList<? super Integer> foo3 = new ArrayList<Number>();\n// Object is a superclass of Integer\nList<? super Integer> foo3 = new ArrayList<Object>();\n```\n\n- 读取List<? super Integer> foo3，可能读取到Integer、Number、Object\n- 向List<? super Integer> foo3 add元素的时候只能添加Integer\n\n####  extends\n\n​\tList<? extends Number> foo3的通配符声明，意味着以下的赋值是合法的,以对List的操作必须要满足下面三个语法检查通过才行。\n\n```java\n// Number \"extends\" Number (in this context)\nList<? extends Number> foo3 = new ArrayList<Number>(); \n// Integer extends Number\nList<? extends Number> foo3 = new ArrayList<Integer>();\n// Double extends Number\nList<? extends Number> foo3 = new ArrayList<Double>();\n```\n\n- 读取List<? extends Number> foo3 可能读取到Number、Integer、Double等，所以只能使用父类(Number)来接收返回值\n- 向List<? extendsInteger> foo3 add元素的时候既不能添加Number也不能添加Number的子类，存任何一种都可能冲突，只能存入NULL值\n\n#### 总结\n\nPECS原则：生产者（Producer）使用extends，消费者（Consumer）使用super。\n\n- **生产者使用extends**\n\n  如果你需要一个列表提供T类型的元素（即你想从列表中读取T类型的元素），你需要把这个列表声明成<? extends T>，比如List<? extends Integer>，因此你不能往该列表中添加任何元素。\n\n- **消费者使用super**  \n\n  如果需要一个列表使用T类型的元素（即你想把T类型的元素加入到列表中），你需要把这个列表声明成<? super T>，比如List<? super Integer>，因此你不能保证从中读取到的元素的类型。\n\n- **即是生产者，也是消费者**\n\n  如果一个列表即要生产，又要消费，你不能使用泛型通配符声明列表，比如List<Integer>。\n\n- **例子**\n\n```java\npublic static <T> void copy(List<? super T> dest, List<? extends T> src) {\n  int srcSize = src.size();\n  if (srcSize > dest.size())\n    throw new IndexOutOfBoundsException(\"Source does not fit in dest\");\n\n  if (srcSize < COPY_THRESHOLD ||\n      (src instanceof RandomAccess && dest instanceof RandomAccess)) {\n    for (int i=0; i<srcSize; i++)\n      dest.set(i, src.get(i));\n  } else {\n    ListIterator<? super T> di=dest.listIterator();\n    ListIterator<? extends T> si=src.listIterator();\n    for (int i=0; i<srcSize; i++) {\n      di.next();\n      di.set(si.next());\n    }\n  }\n}\n```\n\n## 参考\n\n[Java 泛型中? super T和? extends T的区别](http://www.codeceo.com/article/java-super-t-extends-t.html)\t","slug":"java基础/java反射之泛型","published":1,"updated":"2018-09-12T03:03:21.823Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnh20033wlkvo4vbhv8h"},{"title":"动态代理","date":"2017-10-15T14:23:36.000Z","_content":"\n# 动态代理\n\n> 代理的实质是在运行期间手动创建class类，对被代理对象的方法进行代理，调用被代理对象的方法，动态代理就是动态的创建Proxy对象，用完之后销毁class类，避免冗杂，动态代理的实现方式主要有以下两种。\n> CGLIB代理主要是对指定的类生成一个子类，覆盖其中的所有方法，所以该类或方法不能声明称final的。\n\n<!--more-->\n\n##### 一、通过jdk实现InvocationHandler实现动态代理\n###### 1、定义接口\n```\npackage cn.zlz.proxy.jdk;\n\npublic interface IComputorService {\n\t\n\t/**\n\t * 卖电脑\n\t * @param brand\n\t */\n\tpublic void sellComputor(String brand);\n\t/**\n\t * 修电脑\n\t */\n\tpublic void repairComputor(String brand);\n\n}\n```\n###### 2、定义接口实现类\n```\npackage cn.zlz.proxy.jdk;\n\npublic class ThinkPadSeller implements IComputorService{\n\n\tpublic void sellComputor(String brand) {\n\t\tSystem.out.println(\"sell the thinkPad computor\");\n\t\t\n\t}\n\n\tpublic void repairComputor(String brand) {\n\t\tSystem.out.println(\"repair the thinkPad computor\");\n\t}\n\n}\n```\n###### 3、定义生成代理对象\n```\npackage cn.zlz.proxy.jdk;\n\nimport java.lang.reflect.InvocationHandler;\nimport java.lang.reflect.Method;\nimport java.lang.reflect.Proxy;\n\npublic class SimpleProxyImpl implements InvocationHandler {\n\n\t// 被代理对象\n\tprivate ThinkPadSeller thinkPadSeller;\n\n\tpublic SimpleProxyImpl(ThinkPadSeller thinkPadSeller) {\n\t\tsuper();\n\t\tthis.thinkPadSeller = thinkPadSeller;\n\t}\n\n\tpublic Object invoke(Object proxy, Method method, Object[] args) throws Throwable {\n\t\tSystem.out.println(\"代理开始\");\n\t\t// 调用被代理对象\n\t\tmethod.invoke(thinkPadSeller, args);\n\t\tSystem.out.println(\"代理结束\");\n\t\treturn null;\n\t}\n    //提供方法获取代理对象  \n    public IComputorService newProxy(){  \n          \n        //使用Proxy类创建代理对象  \n    \tIComputorService proxyInstance = (IComputorService) Proxy.newProxyInstance(thinkPadSeller.getClass().getClassLoader(), //使用被代理对象的加载器  \n    \t\t\tthinkPadSeller.getClass().getInterfaces(), //使用被代理对象的接口  \n                this );//匿名内部类比较坑，所以我们找一个类实现并覆写方法，直接用本类，现成的..  \n        return proxyInstance;  \n    }  \n}\n```\n###### 4、main函数测试\n```\npackage cn.zlz.proxy.jdk;\n\nimport java.lang.reflect.Proxy;\n\n/**\n *  通过jdk的实现invocationHandler接口只能代理实现接口的对象\n *  为了解决这个问题，就有了动态地创建Proxy的想法：在运行状态中，需要代理的地方，根据接口 和被代理对象，\n *  动态地创建一个Proxy，用完之后，就会销毁，这样就可以避免了Proxy 角色的class在系统中冗杂的问题了。\n *\n */\npublic class Main {\n\n\tpublic static void main(String[] args) {\n\t\t/**\n\t\t * 使用Proxy创建代理对象\n\t\t * 1、被代理对象\n\t\t * 2、被代理对象实现的接口s\n\t\t * 3、Invocation实现对象\n\t\t */\n\t\t//使用Proxy类创建代理对象\n\t\tClass beProxyClazz = ThinkPadSeller.class;\n\t\tThinkPadSeller thinkPadSeller = new ThinkPadSeller();\n\t\tClassLoader classLoader = beProxyClazz.getClassLoader();\n\t\tClass[] interfaces = beProxyClazz.getInterfaces();\n\t\tSimpleProxyImpl simpleProxyImpl = new SimpleProxyImpl(thinkPadSeller);\n\t\t// 根据上面提供的信息，创建代理对象 在这个过程中，JDK会通过根据传入的参数信息动态地在内存中创建和.class 文件等同的字节码 ,然后根据相应的字节码转换成对应的class,然后调用newInstance()创建实例 \n\t\tIComputorService proxy = (IComputorService) Proxy.newProxyInstance(classLoader, interfaces, simpleProxyImpl);\n\t\t/*\n\t\t * 生成的代理对象编译后的代码为 public final repairComputor(){this.h.invoke(this, m3, null);m3 = Class.forName(\"cn.zlz.proxy.jdk.ThinkPadSeller\").getMethod(\"repairComputor\", [String.class]); }\n\t\t * this指的是invocation的实现类，调用invoke方法，并将被代理对象的方法作为参数传递\n\t\t */\n\t\tproxy.repairComputor(\"thinkPad\");\n\t}\n}\n```\n##### 而、通过cglib实现动态代理\n###### 1、定义被代理对象\n```\npackage cn.zlz.proxy.cglib;\n\npublic class ThinkPadSeller {\n\n\tpublic void sellComputor(String brand) {\n\t\tSystem.out.println(\"sell the thinkPad computor\");\n\n\t}\n\n\tpublic void repairComputor(String brand) {\n\t\tSystem.out.println(\"repair the thinkPad computor\");\n\t}\n\n}\n```\n###### 2、实现cglib的MethodInterceptor\n```\npackage cn.zlz.proxy.cglib;\n\nimport java.lang.reflect.Method;\n\nimport net.sf.cglib.proxy.MethodInterceptor;\nimport net.sf.cglib.proxy.MethodProxy;\n\n/*\n * cglib代理，实现MethodInterceptor\n */\npublic class CglibProxy implements MethodInterceptor {\n\n\tpublic Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable {\n\t\tSystem.out.println(\"开始代理\");\n\t\t//代理类是继承的被代理类，调用父类的原方法\n\t\tproxy.invokeSuper(obj, args);  \n\t\t\n\t\tSystem.out.println(\"结束代理\");\n\t\treturn null;\n\t}\n\n}\n```\n###### 3、main函数调试\n```\npackage cn.zlz.proxy.cglib;\n\nimport net.sf.cglib.proxy.Enhancer;\n\n/*\n * 代理对象继承被代理对象\n  1.查找被代理类的所有非final 的public类型的方法定义；\n  2.将这些方法的定义转换成字节码；\n  3.将组成的字节码转换成相应的代理的class对象；\n  4.实现 MethodInterceptor接口，用来处理 对代理类上所有方法的请求（这个接口和JDK动态代理InvocationHandler的功能和角色是一样的）\n */\npublic class Main {\n\tpublic static void main(String[] args) {\n\t\tCglibProxy cglibProxy = new CglibProxy();\n\t\t// cglib 中加强器，用来创建动态代理\n\t\tEnhancer enhancer = new Enhancer();\n\t\t// 设置要创建动态代理的类,即父类\n\t\tenhancer.setSuperclass(ThinkPadSeller.class);\n\t\t// 设置回调，这里相当于是对于代理类上所有方法的调用，都会调用CallBack，而Callback则需要实行intercept()方法进行拦截\n\t\tenhancer.setCallback(cglibProxy);\n\t\tThinkPadSeller proxy = (ThinkPadSeller) enhancer.create();\n\t\tproxy.repairComputor(\"thinkpad\");\n\t}\n}\n```\n## 参考\n\n[Java动态代理机制详解（JDK 和CGLIB，Javassist，ASM）](http://blog.csdn.net/luanlouis/article/details/24589193)\n\n\n\n​\t","source":"_posts/java基础/动态代理.md","raw":"---\ntitle: 动态代理\ndate: 2017-10-15 22:23:36\ntags:\n- spring\ncategories:\n- java基础\n---\n\n# 动态代理\n\n> 代理的实质是在运行期间手动创建class类，对被代理对象的方法进行代理，调用被代理对象的方法，动态代理就是动态的创建Proxy对象，用完之后销毁class类，避免冗杂，动态代理的实现方式主要有以下两种。\n> CGLIB代理主要是对指定的类生成一个子类，覆盖其中的所有方法，所以该类或方法不能声明称final的。\n\n<!--more-->\n\n##### 一、通过jdk实现InvocationHandler实现动态代理\n###### 1、定义接口\n```\npackage cn.zlz.proxy.jdk;\n\npublic interface IComputorService {\n\t\n\t/**\n\t * 卖电脑\n\t * @param brand\n\t */\n\tpublic void sellComputor(String brand);\n\t/**\n\t * 修电脑\n\t */\n\tpublic void repairComputor(String brand);\n\n}\n```\n###### 2、定义接口实现类\n```\npackage cn.zlz.proxy.jdk;\n\npublic class ThinkPadSeller implements IComputorService{\n\n\tpublic void sellComputor(String brand) {\n\t\tSystem.out.println(\"sell the thinkPad computor\");\n\t\t\n\t}\n\n\tpublic void repairComputor(String brand) {\n\t\tSystem.out.println(\"repair the thinkPad computor\");\n\t}\n\n}\n```\n###### 3、定义生成代理对象\n```\npackage cn.zlz.proxy.jdk;\n\nimport java.lang.reflect.InvocationHandler;\nimport java.lang.reflect.Method;\nimport java.lang.reflect.Proxy;\n\npublic class SimpleProxyImpl implements InvocationHandler {\n\n\t// 被代理对象\n\tprivate ThinkPadSeller thinkPadSeller;\n\n\tpublic SimpleProxyImpl(ThinkPadSeller thinkPadSeller) {\n\t\tsuper();\n\t\tthis.thinkPadSeller = thinkPadSeller;\n\t}\n\n\tpublic Object invoke(Object proxy, Method method, Object[] args) throws Throwable {\n\t\tSystem.out.println(\"代理开始\");\n\t\t// 调用被代理对象\n\t\tmethod.invoke(thinkPadSeller, args);\n\t\tSystem.out.println(\"代理结束\");\n\t\treturn null;\n\t}\n    //提供方法获取代理对象  \n    public IComputorService newProxy(){  \n          \n        //使用Proxy类创建代理对象  \n    \tIComputorService proxyInstance = (IComputorService) Proxy.newProxyInstance(thinkPadSeller.getClass().getClassLoader(), //使用被代理对象的加载器  \n    \t\t\tthinkPadSeller.getClass().getInterfaces(), //使用被代理对象的接口  \n                this );//匿名内部类比较坑，所以我们找一个类实现并覆写方法，直接用本类，现成的..  \n        return proxyInstance;  \n    }  \n}\n```\n###### 4、main函数测试\n```\npackage cn.zlz.proxy.jdk;\n\nimport java.lang.reflect.Proxy;\n\n/**\n *  通过jdk的实现invocationHandler接口只能代理实现接口的对象\n *  为了解决这个问题，就有了动态地创建Proxy的想法：在运行状态中，需要代理的地方，根据接口 和被代理对象，\n *  动态地创建一个Proxy，用完之后，就会销毁，这样就可以避免了Proxy 角色的class在系统中冗杂的问题了。\n *\n */\npublic class Main {\n\n\tpublic static void main(String[] args) {\n\t\t/**\n\t\t * 使用Proxy创建代理对象\n\t\t * 1、被代理对象\n\t\t * 2、被代理对象实现的接口s\n\t\t * 3、Invocation实现对象\n\t\t */\n\t\t//使用Proxy类创建代理对象\n\t\tClass beProxyClazz = ThinkPadSeller.class;\n\t\tThinkPadSeller thinkPadSeller = new ThinkPadSeller();\n\t\tClassLoader classLoader = beProxyClazz.getClassLoader();\n\t\tClass[] interfaces = beProxyClazz.getInterfaces();\n\t\tSimpleProxyImpl simpleProxyImpl = new SimpleProxyImpl(thinkPadSeller);\n\t\t// 根据上面提供的信息，创建代理对象 在这个过程中，JDK会通过根据传入的参数信息动态地在内存中创建和.class 文件等同的字节码 ,然后根据相应的字节码转换成对应的class,然后调用newInstance()创建实例 \n\t\tIComputorService proxy = (IComputorService) Proxy.newProxyInstance(classLoader, interfaces, simpleProxyImpl);\n\t\t/*\n\t\t * 生成的代理对象编译后的代码为 public final repairComputor(){this.h.invoke(this, m3, null);m3 = Class.forName(\"cn.zlz.proxy.jdk.ThinkPadSeller\").getMethod(\"repairComputor\", [String.class]); }\n\t\t * this指的是invocation的实现类，调用invoke方法，并将被代理对象的方法作为参数传递\n\t\t */\n\t\tproxy.repairComputor(\"thinkPad\");\n\t}\n}\n```\n##### 而、通过cglib实现动态代理\n###### 1、定义被代理对象\n```\npackage cn.zlz.proxy.cglib;\n\npublic class ThinkPadSeller {\n\n\tpublic void sellComputor(String brand) {\n\t\tSystem.out.println(\"sell the thinkPad computor\");\n\n\t}\n\n\tpublic void repairComputor(String brand) {\n\t\tSystem.out.println(\"repair the thinkPad computor\");\n\t}\n\n}\n```\n###### 2、实现cglib的MethodInterceptor\n```\npackage cn.zlz.proxy.cglib;\n\nimport java.lang.reflect.Method;\n\nimport net.sf.cglib.proxy.MethodInterceptor;\nimport net.sf.cglib.proxy.MethodProxy;\n\n/*\n * cglib代理，实现MethodInterceptor\n */\npublic class CglibProxy implements MethodInterceptor {\n\n\tpublic Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable {\n\t\tSystem.out.println(\"开始代理\");\n\t\t//代理类是继承的被代理类，调用父类的原方法\n\t\tproxy.invokeSuper(obj, args);  \n\t\t\n\t\tSystem.out.println(\"结束代理\");\n\t\treturn null;\n\t}\n\n}\n```\n###### 3、main函数调试\n```\npackage cn.zlz.proxy.cglib;\n\nimport net.sf.cglib.proxy.Enhancer;\n\n/*\n * 代理对象继承被代理对象\n  1.查找被代理类的所有非final 的public类型的方法定义；\n  2.将这些方法的定义转换成字节码；\n  3.将组成的字节码转换成相应的代理的class对象；\n  4.实现 MethodInterceptor接口，用来处理 对代理类上所有方法的请求（这个接口和JDK动态代理InvocationHandler的功能和角色是一样的）\n */\npublic class Main {\n\tpublic static void main(String[] args) {\n\t\tCglibProxy cglibProxy = new CglibProxy();\n\t\t// cglib 中加强器，用来创建动态代理\n\t\tEnhancer enhancer = new Enhancer();\n\t\t// 设置要创建动态代理的类,即父类\n\t\tenhancer.setSuperclass(ThinkPadSeller.class);\n\t\t// 设置回调，这里相当于是对于代理类上所有方法的调用，都会调用CallBack，而Callback则需要实行intercept()方法进行拦截\n\t\tenhancer.setCallback(cglibProxy);\n\t\tThinkPadSeller proxy = (ThinkPadSeller) enhancer.create();\n\t\tproxy.repairComputor(\"thinkpad\");\n\t}\n}\n```\n## 参考\n\n[Java动态代理机制详解（JDK 和CGLIB，Javassist，ASM）](http://blog.csdn.net/luanlouis/article/details/24589193)\n\n\n\n​\t","slug":"java基础/动态代理","published":1,"updated":"2018-09-12T03:03:21.824Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnh40036wlkvreoa2v50"},{"title":"java8之Comparator","date":"2017-08-05T02:58:46.000Z","_content":"\n# java8之Comparator\n\njava8新提供了一个Comparator方法接口，通过实现Comparator接口可以实现对象的排序。Comparator接口中提供了一些默认方法来更加方便使用排序，通过静态方法提供了一些java8内部实现Comparator的实现类对象，比如正序Comparator，逆序Comparator，处理Null的NullComparator。\n\n<!--more-->\n\n## Comparator的使用\n\n- 首先创建一个Person的list\n\n  ```java\n  Person p1 = new Person(1, \"zhangsan\", 1, 12);\n  Person p2 = new Person(2, \"lisi\", 1, 10);\n  Person p3 = new Person(3, \"xiaohong\", 2, 18);\n  Person p4 = new Person(4, null, 2, 8);\n  List<Person> list = Lists.newArrayList(p1,p2,p3,p4);\n  ```\n\n- 通过lambda表达式创建一个Comparator\n\n  ```java\n  List<Person> list1 = list.stream().sorted((s1, s2) -> s1.getAge() - s2.getAge()).collect(Collectors.toList());\n  System.out.println(list1);\n  ```\n\n- Comparator提供了静态方法创建Comparator的实现类\n\n  ```java\n  List<Person> list2 = list.stream().sorted(Comparator.comparingInt(Person::getAge)).collect(Collectors.toList());\n  System.out.println(list2);\n  ```\n\n- 可以通过reversed方法实现反序\n\n  ```java\n  List<Person> list3 = list.stream().sorted(Comparator.comparingInt(Person::getAge).reversed()).collect(Collectors.toList());\n  System.out.println(list3);\n  ```\n\n- Comparator提供了静态方法 reverseOrder 和natureOrder用于创建比较器，创建的时候需要制定泛型\n\n  ```java\n  Comparator<Integer> tComparator = Comparator.reverseOrder();\n  List<Integer> list4 = list.stream().map(Person::getAge).sorted(tComparator).collect(Collectors.toList());\n  System.out.println(list4);\n  ```\n\n- 通过thenComparing 实现优先根据a排序，然后根据b排序\n\n  ```java\n  List<Person> list5 = list.stream().sorted(Comparator.comparingInt(Person::getAge).thenComparingInt(Person::getId).reversed()).collect(Collectors.toList());\n  System.out.println(list5);\n  ```\n\n- 通过 nullsFirst 和 nullsLast 对空对象进行排序\n\n  ```java\n  List<String> list6 = list.stream().map(Person::getName).sorted(Comparator.nullsFirst(Comparator.comparing(s -> {return s;}))).collect(Collectors.toList());\n  System.out.println(list6);\n  ```\n\n## 源码简析\n\n- Comparator是个方法接口，只有一个compare方法是抽象的需要实现类去实现的,compare方法通过返回1、0、-1实现排序\n\n  ```java\n  @FunctionalInterface\n  public interface Comparator<T> {\n      int compare(T o1, T o2);\n  }\n  ```\n\n- Comparator中有些默认方法**thenComparing**，接收一个Comparator对象，对排序后的集合再次排序。先用调用方Comparator进行排序，如果排序结果为0，即两个对象相等，就再用下一个比较器再次比较，如果前一个比较器已经分出大小，不再使用下一个比较器进行比较。\n\n  ```java\n  default Comparator<T> thenComparing(Comparator<? super T> other) {\n      Objects.requireNonNull(other);\n      return (Comparator<T> & Serializable) (c1, c2) -> {\n          //先用前面一个Comparator排序\n          int res = compare(c1, c2);\n          //再用参数的Comparator排序\n          return (res != 0) ? res : other.compare(c1, c2);\n      };\n  }\n  ```\n\n- thenComparing的重构方法，可以传递一个处理对象的function，然后针对处理后的结果进行排序\n\n  ```java\n  default <U> Comparator<T> thenComparing(Function<? super T, ? extends U> keyExtractor,\n              Comparator<? super U> keyComparator)\n  {\n      return thenComparing(comparing(keyExtractor, keyComparator));\n  }\n  ```\n\n- Comparator接口中静态方法创建Comparator对象。接受一个比较对象的处理器和Comparator比较器作为参数。\n\n  ```java\n  public static <T, U> Comparator<T> comparing(\n              Function<? super T, ? extends U> keyExtractor,\n              Comparator<? super U> keyComparator)\n  {\n      Objects.requireNonNull(keyExtractor);\n      Objects.requireNonNull(keyComparator);\n      return (Comparator<T> & Serializable)\n          (c1, c2) -> keyComparator.compare(keyExtractor.apply(c1),\n                                            keyExtractor.apply(c2));\n  }\n  ```\n\n- 上面方法的重构方法，要求要比较的对象必须实现了**Comparable**接口，这样就不用传递比较器了，直接使用对象的**compareTo**方法进行比较\n\n  ```java\n  public static <T, U extends Comparable<? super U>> Comparator<T> comparing(\n              Function<? super T, ? extends U> keyExtractor)\n  {\n      Objects.requireNonNull(keyExtractor);\n      return (Comparator<T> & Serializable)\n          (c1, c2) -> keyExtractor.apply(c1).compareTo(keyExtractor.apply(c2));\n  }\n  ```\n\n- 针对基本类型，提供了单独处理基本类型的方法,内部其实就是指定将比较对象转换为对应的基本类型，然后调用compare方法进行实现的\n\n  ```java\n  public static <T> Comparator<T> comparingInt(ToIntFunction<? super T> keyExtractor) {\n          Objects.requireNonNull(keyExtractor);\n          return (Comparator<T> & Serializable)\n              (c1, c2) -> Integer.compare(keyExtractor.applyAsInt(c1), keyExtractor.applyAsInt(c2));\n      }\n  ```\n\n## jdk Comparator实现\n\n- 正序的Comparator\n\n  ```java\n  public static <T extends Comparable<? super T>> Comparator<T> naturalOrder() {\n      return (Comparator<T>) Comparators.NaturalOrderComparator.INSTANCE;\n  }\n  ```\n\n  Comparators的内部枚举类，实现了Comparator接口\n\n  ```java\n  enum NaturalOrderComparator implements Comparator<Comparable<Object>> {\n      //枚举实现饿汉式\n      INSTANCE;\n      @Override\n      public int compare(Comparable<Object> c1, Comparable<Object> c2) {\n          return c1.compareTo(c2);\n      }\n      @Override\n      public Comparator<Comparable<Object>> reversed() {\n          return Comparator.reverseOrder();\n      }\n  }\n  ```\n\n- 反序的Comparator，实现接口的 **compare**方法，覆写了接口的**reversed**方法\n\n  ```java\n  private static class ReverseComparator\n      implements Comparator<Comparable<Object>>, Serializable {\n      //饿汉式实现\n      static final ReverseComparator REVERSE_ORDER = new ReverseComparator();\n      public int compare(Comparable<Object> c1, Comparable<Object> c2) {\n          //c2在前实现逆序\n          return c2.compareTo(c1);\n      }\n      private Object readResolve() { return Collections.reverseOrder(); }\n      @Override\n      public Comparator<Comparable<Object>> reversed() {\n          //返回正序\n          return Comparator.naturalOrder();\n      }\n  }\n  ```\n\n- 空对象比较器NullComparator,通过一个变量**nullFirst**来决定空对象放在首部还是尾部。包装一个比较器，在创建NullComparator的时候需要传入一个比较器和空对象的位置\n\n  ```java\n  final static class NullComparator<T> implements Comparator<T>, Serializable {\n      private final boolean nullFirst;\n      // if null, non-null Ts are considered equal\n      private final Comparator<T> real;\n      @SuppressWarnings(\"unchecked\")\n      //创建的时候必须要决定空对象的位置，传入一个比较器\n      NullComparator(boolean nullFirst, Comparator<? super T> real) {\n          this.nullFirst = nullFirst;\n          this.real = (Comparator<T>) real;\n      }\n      //处理空对象的比较，非空对象之间的比较依赖传入的比较器进行处理\n      @Override\n      public int compare(T a, T b) {\n          //对null进行比大小\n          if (a == null) {\n              return (b == null) ? 0 : (nullFirst ? -1 : 1);\n          } else if (b == null) {\n              return nullFirst ? 1: -1;\n          } else {\n              return (real == null) ? 0 : real.compare(a, b);\n          }\n      }\n      @Override\n      public Comparator<T> thenComparing(Comparator<? super T> other) {\n          Objects.requireNonNull(other);\n          return new NullComparator<>(nullFirst, real == null ? other : real.thenComparing(other));\n      }\n  \n      @Override\n      public Comparator<T> reversed() {\n          //覆写 reversed的方法，创建一个NullComparator 单独处理下空对象\n          return new NullComparator<>(!nullFirst, real == null ? null : real.reversed());\n      }\n  }\n  ```\n\n","source":"_posts/java8/java8之Comparator.md","raw":"---\ntitle: java8之Comparator\ndate: 2017-08-05 10:58:46\ntags:\n- java8\ncategories:\n- java基础\n---\n\n# java8之Comparator\n\njava8新提供了一个Comparator方法接口，通过实现Comparator接口可以实现对象的排序。Comparator接口中提供了一些默认方法来更加方便使用排序，通过静态方法提供了一些java8内部实现Comparator的实现类对象，比如正序Comparator，逆序Comparator，处理Null的NullComparator。\n\n<!--more-->\n\n## Comparator的使用\n\n- 首先创建一个Person的list\n\n  ```java\n  Person p1 = new Person(1, \"zhangsan\", 1, 12);\n  Person p2 = new Person(2, \"lisi\", 1, 10);\n  Person p3 = new Person(3, \"xiaohong\", 2, 18);\n  Person p4 = new Person(4, null, 2, 8);\n  List<Person> list = Lists.newArrayList(p1,p2,p3,p4);\n  ```\n\n- 通过lambda表达式创建一个Comparator\n\n  ```java\n  List<Person> list1 = list.stream().sorted((s1, s2) -> s1.getAge() - s2.getAge()).collect(Collectors.toList());\n  System.out.println(list1);\n  ```\n\n- Comparator提供了静态方法创建Comparator的实现类\n\n  ```java\n  List<Person> list2 = list.stream().sorted(Comparator.comparingInt(Person::getAge)).collect(Collectors.toList());\n  System.out.println(list2);\n  ```\n\n- 可以通过reversed方法实现反序\n\n  ```java\n  List<Person> list3 = list.stream().sorted(Comparator.comparingInt(Person::getAge).reversed()).collect(Collectors.toList());\n  System.out.println(list3);\n  ```\n\n- Comparator提供了静态方法 reverseOrder 和natureOrder用于创建比较器，创建的时候需要制定泛型\n\n  ```java\n  Comparator<Integer> tComparator = Comparator.reverseOrder();\n  List<Integer> list4 = list.stream().map(Person::getAge).sorted(tComparator).collect(Collectors.toList());\n  System.out.println(list4);\n  ```\n\n- 通过thenComparing 实现优先根据a排序，然后根据b排序\n\n  ```java\n  List<Person> list5 = list.stream().sorted(Comparator.comparingInt(Person::getAge).thenComparingInt(Person::getId).reversed()).collect(Collectors.toList());\n  System.out.println(list5);\n  ```\n\n- 通过 nullsFirst 和 nullsLast 对空对象进行排序\n\n  ```java\n  List<String> list6 = list.stream().map(Person::getName).sorted(Comparator.nullsFirst(Comparator.comparing(s -> {return s;}))).collect(Collectors.toList());\n  System.out.println(list6);\n  ```\n\n## 源码简析\n\n- Comparator是个方法接口，只有一个compare方法是抽象的需要实现类去实现的,compare方法通过返回1、0、-1实现排序\n\n  ```java\n  @FunctionalInterface\n  public interface Comparator<T> {\n      int compare(T o1, T o2);\n  }\n  ```\n\n- Comparator中有些默认方法**thenComparing**，接收一个Comparator对象，对排序后的集合再次排序。先用调用方Comparator进行排序，如果排序结果为0，即两个对象相等，就再用下一个比较器再次比较，如果前一个比较器已经分出大小，不再使用下一个比较器进行比较。\n\n  ```java\n  default Comparator<T> thenComparing(Comparator<? super T> other) {\n      Objects.requireNonNull(other);\n      return (Comparator<T> & Serializable) (c1, c2) -> {\n          //先用前面一个Comparator排序\n          int res = compare(c1, c2);\n          //再用参数的Comparator排序\n          return (res != 0) ? res : other.compare(c1, c2);\n      };\n  }\n  ```\n\n- thenComparing的重构方法，可以传递一个处理对象的function，然后针对处理后的结果进行排序\n\n  ```java\n  default <U> Comparator<T> thenComparing(Function<? super T, ? extends U> keyExtractor,\n              Comparator<? super U> keyComparator)\n  {\n      return thenComparing(comparing(keyExtractor, keyComparator));\n  }\n  ```\n\n- Comparator接口中静态方法创建Comparator对象。接受一个比较对象的处理器和Comparator比较器作为参数。\n\n  ```java\n  public static <T, U> Comparator<T> comparing(\n              Function<? super T, ? extends U> keyExtractor,\n              Comparator<? super U> keyComparator)\n  {\n      Objects.requireNonNull(keyExtractor);\n      Objects.requireNonNull(keyComparator);\n      return (Comparator<T> & Serializable)\n          (c1, c2) -> keyComparator.compare(keyExtractor.apply(c1),\n                                            keyExtractor.apply(c2));\n  }\n  ```\n\n- 上面方法的重构方法，要求要比较的对象必须实现了**Comparable**接口，这样就不用传递比较器了，直接使用对象的**compareTo**方法进行比较\n\n  ```java\n  public static <T, U extends Comparable<? super U>> Comparator<T> comparing(\n              Function<? super T, ? extends U> keyExtractor)\n  {\n      Objects.requireNonNull(keyExtractor);\n      return (Comparator<T> & Serializable)\n          (c1, c2) -> keyExtractor.apply(c1).compareTo(keyExtractor.apply(c2));\n  }\n  ```\n\n- 针对基本类型，提供了单独处理基本类型的方法,内部其实就是指定将比较对象转换为对应的基本类型，然后调用compare方法进行实现的\n\n  ```java\n  public static <T> Comparator<T> comparingInt(ToIntFunction<? super T> keyExtractor) {\n          Objects.requireNonNull(keyExtractor);\n          return (Comparator<T> & Serializable)\n              (c1, c2) -> Integer.compare(keyExtractor.applyAsInt(c1), keyExtractor.applyAsInt(c2));\n      }\n  ```\n\n## jdk Comparator实现\n\n- 正序的Comparator\n\n  ```java\n  public static <T extends Comparable<? super T>> Comparator<T> naturalOrder() {\n      return (Comparator<T>) Comparators.NaturalOrderComparator.INSTANCE;\n  }\n  ```\n\n  Comparators的内部枚举类，实现了Comparator接口\n\n  ```java\n  enum NaturalOrderComparator implements Comparator<Comparable<Object>> {\n      //枚举实现饿汉式\n      INSTANCE;\n      @Override\n      public int compare(Comparable<Object> c1, Comparable<Object> c2) {\n          return c1.compareTo(c2);\n      }\n      @Override\n      public Comparator<Comparable<Object>> reversed() {\n          return Comparator.reverseOrder();\n      }\n  }\n  ```\n\n- 反序的Comparator，实现接口的 **compare**方法，覆写了接口的**reversed**方法\n\n  ```java\n  private static class ReverseComparator\n      implements Comparator<Comparable<Object>>, Serializable {\n      //饿汉式实现\n      static final ReverseComparator REVERSE_ORDER = new ReverseComparator();\n      public int compare(Comparable<Object> c1, Comparable<Object> c2) {\n          //c2在前实现逆序\n          return c2.compareTo(c1);\n      }\n      private Object readResolve() { return Collections.reverseOrder(); }\n      @Override\n      public Comparator<Comparable<Object>> reversed() {\n          //返回正序\n          return Comparator.naturalOrder();\n      }\n  }\n  ```\n\n- 空对象比较器NullComparator,通过一个变量**nullFirst**来决定空对象放在首部还是尾部。包装一个比较器，在创建NullComparator的时候需要传入一个比较器和空对象的位置\n\n  ```java\n  final static class NullComparator<T> implements Comparator<T>, Serializable {\n      private final boolean nullFirst;\n      // if null, non-null Ts are considered equal\n      private final Comparator<T> real;\n      @SuppressWarnings(\"unchecked\")\n      //创建的时候必须要决定空对象的位置，传入一个比较器\n      NullComparator(boolean nullFirst, Comparator<? super T> real) {\n          this.nullFirst = nullFirst;\n          this.real = (Comparator<T>) real;\n      }\n      //处理空对象的比较，非空对象之间的比较依赖传入的比较器进行处理\n      @Override\n      public int compare(T a, T b) {\n          //对null进行比大小\n          if (a == null) {\n              return (b == null) ? 0 : (nullFirst ? -1 : 1);\n          } else if (b == null) {\n              return nullFirst ? 1: -1;\n          } else {\n              return (real == null) ? 0 : real.compare(a, b);\n          }\n      }\n      @Override\n      public Comparator<T> thenComparing(Comparator<? super T> other) {\n          Objects.requireNonNull(other);\n          return new NullComparator<>(nullFirst, real == null ? other : real.thenComparing(other));\n      }\n  \n      @Override\n      public Comparator<T> reversed() {\n          //覆写 reversed的方法，创建一个NullComparator 单独处理下空对象\n          return new NullComparator<>(!nullFirst, real == null ? null : real.reversed());\n      }\n  }\n  ```\n\n","slug":"java8/java8之Comparator","published":1,"updated":"2018-09-12T03:03:21.821Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnh50038wlkv8chkpg1i"},{"title":"java8之Collector","date":"2017-08-05T05:58:46.000Z","_content":"\n# java8之Collector\n\nStream流的终端操作常常需要聚合，Collector就是对Stream流进行聚合的实现。jdk提供了Collectors工具类封装了一些常用的聚合操作。\n\n<!--more-->\n\n## Collector接口\n\nCollector是一个接口，它是一个可变的汇聚操作，通过累加器将输入元素汇集到一个**可伸展**的结果容器中；如果是并行流会产生多个结果容器，还需将结果容器合并为一个，最后将累积的结果容器转换为一个最终想要的容器返回（这是一个可选操作）\n\n```java\npublic interface Collector<T, A, R> {\n    //用于提供一个可伸展结构的容器\n    Supplier<A> supplier();   //容器\n  \t//用于将元素添加到提供的容器中\n    BiConsumer<A, T> accumulator();//累加器\n  \t//把并行流产生的多个容易合并为一个\n    BinaryOperator<A> combiner(); //合并器\n\t//将combiner返回的结果类型转换为其他类型，当characteristics选择IDENTITY_FINISH时，不需要转换类型，\t   所以该方法不会被调用，其他情况下会被调用\n    Function<A, R> finisher();\n    //Collector约束属性set,不可变Collections.unmodifiableSet\n    Set<Characteristics> characteristics();\n}\n```\nCharacteristics是Collector内的一个枚举类，用来约束Collector的属性。\n\n- CONCURRENT：表示此收集器支持并发，意味着允许在多个线程中，累加器可以调用结果容器\n- UNORDERED：表示收集器并不按照Stream中的元素输入顺序执行\n- IDENTITY_FINISH：表示不需要转换结果类型，直接返回supplier创建的数据类型，finisher方法不执行。\n\n\n如下就是一个简单的Collector的实现，将结果聚合到一个list当中\n\n```java\nList result = Stream.of(1, 2,3, 4,5).collect(\n  () -> new ArrayList(), //创建一个可变容器\n  (list, item) -> list.add(item),//将stream中元素添加到可变容器中\n  (list1, list2) -> list1.addAll(list2)//合并多个可变容器\n);\n```\n\n## Collectors工具类\n\nCollectors本身提供了关于Collector的常见汇聚实现，Collectors的内部类CollectorImpl实现了Collector接口，Collectors本身就是一堆创建CollectorImpl对象的工具类。\n\n### CollectorImpl\n\nCollectorImpl是Collectors工具类中的内部类，实现了Collector接口，提供了构造器，方便构造Collector的具体实现类，Collector接口中可以设置一个Characteristics的集合，Collectors针对可能出现的组合定义好了几个类型集合。\n\n```java\nstatic final Set<Collector.Characteristics> CH_CONCURRENT_ID                                   \n        = Collections.unmodifiableSet(EnumSet.of(Collector.Characteristics.CONCURRENT,         \n                                                 Collector.Characteristics.UNORDERED,          \n                                                 Collector.Characteristics.IDENTITY_FINISH));  \nstatic final Set<Collector.Characteristics> CH_CONCURRENT_NOID                                 \n        = Collections.unmodifiableSet(EnumSet.of(Collector.Characteristics.CONCURRENT,         \n                                                 Collector.Characteristics.UNORDERED));        \nstatic final Set<Collector.Characteristics> CH_ID                                              \n        = Collections.unmodifiableSet(EnumSet.of(Collector.Characteristics.IDENTITY_FINISH));  \nstatic final Set<Collector.Characteristics> CH_UNORDERED_ID                                    \n        = Collections.unmodifiableSet(EnumSet.of(Collector.Characteristics.UNORDERED,          \n                                                 Collector.Characteristics.IDENTITY_FINISH));  \nstatic final Set<Collector.Characteristics> CH_NOID = Collections.emptySet();    \n\nstatic class CollectorImpl<T, A, R> implements Collector<T, A, R> { \n     //构造函数，创建Collector的实现类对象\n     CollectorImpl(Supplier<A> supplier,                             \n                   BiConsumer<A, T> accumulator,                     \n                   BinaryOperator<A> combiner,                       \n                   Function<A,R> finisher,                           \n                   Set<Characteristics> characteristics) {           \n         this.supplier = supplier;                                   \n         this.accumulator = accumulator;                             \n         this.combiner = combiner;                                   \n         this.finisher = finisher;                                   \n         this.characteristics = characteristics;                     \n     }                  \n }\n```\n\n### Collectors工具类型\n\n#### 链接\n\nmapping是在将元素添加到容器前进行一次映射处理、collectingAndThen是处理Collector的最终返回值问题，是额外给Collector添加一个Finisher方法\n\n```java\npublic static <T, U, A, R>                                                                \nCollector<T, ?, R> mapping(Function<? super T, ? extends U> mapper,                       \n                           Collector<? super U, A, R> downstream) {                       \n    BiConsumer<A, ? super U> downstreamAccumulator = downstream.accumulator();            \n    return new CollectorImpl<>(downstream.supplier(),                                     \n                               (r, t) -> downstreamAccumulator.accept(r, mapper.apply(t)),\n                               downstream.combiner(), downstream.finisher(),              \n                               downstream.characteristics());                             \n}                                                                                         \n```\n\n```java\npublic static<T,A,R,RR> Collector<T,A,RR> collectingAndThen(Collector<T,A,R> downstream,  \n                                                            Function<R,RR> finisher) {    \n    Set<Collector.Characteristics> characteristics = downstream.characteristics();        \n    if (characteristics.contains(Collector.Characteristics.IDENTITY_FINISH)) {            \n        if (characteristics.size() == 1)                                                  \n            characteristics = Collectors.CH_NOID;                                         \n        else {                                                                            \n            characteristics = EnumSet.copyOf(characteristics);                            \n            characteristics.remove(Collector.Characteristics.IDENTITY_FINISH);            \n            characteristics = Collections.unmodifiableSet(characteristics);               \n        }                                                                                 \n    }                                                                                     \n    return new CollectorImpl<>(downstream.supplier(),                                     \n                               downstream.accumulator(),                                  \n                               downstream.combiner(),                                     \n                               downstream.finisher().andThen(finisher),                   \n                               characteristics);                                          \n}                                                                                                                                                                                  \n```\n\n\n\n#### 构建集合类\n\ntoCollection、toList、toSet：创建集合-->将元素添加到集合-->合并集合—>返回集合类型。构建set的时候需要注意设置characteristics类型为无序的，不需要按照Stream顺序添加到集合中。\n\n```java\npublic static <T> Collector<T, ?, Set<T>> toSet() {                                                    \n    return new CollectorImpl<>((Supplier<Set<T>>) HashSet::new, Set::add,            \n                               (left, right) -> { left.addAll(right); return left; },\n                               CH_UNORDERED_ID);                                     \n}                                                                                    \n```\n\n#### 聚合为字符串\n\n提供了一个可变的字符存储容器StringJoiner，然后就是将Stream中的元素添加到StringJoiner，合并多个StringJoiner，最后toString返回字符串。\n\n```java\npublic static Collector<CharSequence, ?, String> joining(CharSequence delimiter, \n                                                         CharSequence prefix,    \n                                                         CharSequence suffix) {  \n    return new CollectorImpl<>(                                                  \n            () -> new StringJoiner(delimiter, prefix, suffix),                   \n            StringJoiner::add, StringJoiner::merge,                              \n            StringJoiner::toString, CH_NOID);                                    \n}                                                                                \n```\n\n#### 聚合reduce\n\n- 接受一个默认值和一个BinaryOperator参数，通过BinaryOperator将元素集合合并为一个元素\n```java\npublic static <T> Collector<T, ?, T>                             \nreducing(T identity, BinaryOperator<T> op) {                     \n    return new CollectorImpl<>(                                  \n            boxSupplier(identity),                               \n            (a, t) -> { a[0] = op.apply(a[0], t); },             \n            (a, b) -> { a[0] = op.apply(a[0], b[0]); return a; },\n            a -> a[0],                                           \n            CH_NOID);                                            \n}  \n//为了实现容器，使用数组来当存储对象的容器\nprivate static <T> Supplier<T[]> boxSupplier(T identity) {\n\treturn () -> (T[]) new Object[] { identity };\n}\n```\n- 同上一样，只是多个一个mapper参数用于处理向容器添加前的映射处理\n```java\npublic static <T, U>  Collector<T, ?, U> reducing(U identity,\n                            Function<? super T, ? extends U> mapper,\n                            BinaryOperator<U> op) {                 \n    return new CollectorImpl<>(   \n      \t\t// boxSupplier == return () -> (T[]) new Object[] { identity }; \n            boxSupplier(identity), //转换为可伸缩数据结构，存储数据                            \n            (a, t) -> { a[0] = op.apply(a[0], mapper.apply(t)); },  \n            (a, b) -> { a[0] = op.apply(a[0], b[0]); return a; },   \n            a -> a[0], CH_NOID);                                    \n}    \n```\n\n- 接受一个BinaryOperator参数，通过BinaryOperator将元素集合合并为一个元素\n```java\npublic static <T> Collector<T, ?, Optional<T>>                        \nreducing(BinaryOperator<T> op) {         \n\t//匿名内部类提供一个容器\n    class OptionalBox implements Consumer<T> {                        \n        T value = null;                                               \n        boolean present = false;                                      \n                                                                      \n        @Override                                                     \n        public void accept(T t) {//容器添加元素，这里其实就是通过参数 BinaryOperator来决定是否用新的元素替代原有的元素                                 \n            if (present) {                                            \n                value = op.apply(value, t);                           \n            }                                                         \n            else {                                                    \n                value = t;                                            \n                present = true;                                       \n            }                                                         \n        }                                                             \n    }                                                                 \n                                                                      \n    return new CollectorImpl<T, OptionalBox, Optional<T>>(            \n            OptionalBox::new, OptionalBox::accept,                    \n            (a, b) -> { if (b.present) a.accept(b.value); return a; },\n            a -> Optional.ofNullable(a.value), CH_NOID);              \n}   \n\n//给出每个城市最高的人\nComparator<Person> byHeight = Comparator.comparing(Person::getHeight);\nMap<City, Person> tallestByCity = people.stream().collect(groupingBy(Person::getCity,reducing(BinaryOperator.maxBy(byHeight))));\n```\n\n#### 聚合为值(reduce)\n\ncounting、minBy、maxBy：通过reduce将数据聚合为一个值\n\n```java\npublic static <T> Collector<T, ?, Long> counting() {                                       \n    return reducing(0L, e -> 1L, Long::sum);   //一个元素代表1，通过Long::sum 累加    \n}                 \npublic static <T> Collector<T, ?, Optional<T>>        \nminBy(Comparator<? super T> comparator) {             \n    return reducing(BinaryOperator.minBy(comparator));\n}                                                     \n```\n\n#### 累积求值\n\nsummingInt、averagingInt、summarizingInt等:返回总值、平均值、统计数据(和、平均值、最大值、最小值),注意到在针对基本数据类型创建可伸展数据结构的时候都选择了基本数据类型的数组类型。\n\n```java\npublic static <T> Collector<T, ?, Integer> summingInt(ToIntFunction<? super T> mapper) {           \n    return new CollectorImpl<>(                         \n            () -> new int[1],                           \n            (a, t) -> { a[0] += mapper.applyAsInt(t); },\n            (a, b) -> { a[0] += b[0]; return a; },      \n            a -> a[0], CH_NOID);                        \n}      \n\npublic static <T> Collector<T, ?, Double> averagingInt(ToIntFunction<? super T> mapper) {                      \n    return new CollectorImpl<>(                                      \n            () -> new long[2],  //一个存储总值，一个存储总数                                    \n            (a, t) -> { a[0] += mapper.applyAsInt(t); a[1]++; },     \n            (a, b) -> { a[0] += b[0]; a[1] += b[1]; return a; },     \n            a -> (a[1] == 0) ? 0.0d : (double) a[0] / a[1], CH_NOID);\n}                                                                    \n```\n\n#### 转换为Map\n\ntoMap、toConcurrentMap：将Stream流转换为map或者concurrentMap\n\n```java\npublic static <T, K, U>                                                      \nCollector<T, ?, Map<K,U>> toMap(Function<? super T, ? extends K> keyMapper,  \n                                Function<? super T, ? extends U> valueMapper,\n                                BinaryOperator<U> mergeFunction) {           \n    return toMap(keyMapper, valueMapper, mergeFunction, HashMap::new);       \n}                                                                            \npublic static <T, K, U, M extends Map<K, U>>                                                \nCollector<T, ?, M> toMap(Function<? super T, ? extends K> keyMapper,                        \n                            Function<? super T, ? extends U> valueMapper,                   \n                            BinaryOperator<U> mergeFunction,                                \n                            Supplier<M> mapSupplier) { \n    //map提供的merge方法，用于合并两个map\n    BiConsumer<M, T> accumulator                                                            \n            = (map, element) -> map.merge(keyMapper.apply(element),                         \n                                          valueMapper.apply(element), mergeFunction);       \n    return new CollectorImpl<>(mapSupplier, accumulator, mapMerger(mergeFunction), CH_ID);  \n}        \n//用法 \nMap<String, Student> studentIdToStudent = students.stream().collect(toMap(Student::getId,Function.identity());\n```\n\n#### 分组聚合\n\ngroupingBy、partitioningBy：默认会将value聚合为list，可以传递一个Collector对value进行聚合\n\n- partitioningBy\n\n```java\npublic static <T, D, A>                                                                              \nCollector<T, ?, Map<Boolean, D>> partitioningBy(Predicate<? super T> predicate,                      \n                                                Collector<? super T, A, D> downstream) {             \n    BiConsumer<A, ? super T> downstreamAccumulator = downstream.accumulator();\n    //将元素根据true和false分别添加到包装后的Partition容器中\n    BiConsumer<Partition<A>, T> accumulator = (result, t) ->                                         \n            downstreamAccumulator.accept(predicate.test(t) ? result.forTrue : result.forFalse, t);   \n    BinaryOperator<A> op = downstream.combiner();                                                    \n    BinaryOperator<Partition<A>> merger = (left, right) ->                                           \n            new Partition<>(op.apply(left.forTrue, right.forTrue),                                   \n                            op.apply(left.forFalse, right.forFalse));  \n    //元素容器，使用Partition，包装原有的Collector的容器\n    Supplier<Partition<A>> supplier = () ->                                                          \n            new Partition<>(downstream.supplier().get(),                                             \n                            downstream.supplier().get());                                            \n    if (downstream.characteristics().contains(Collector.Characteristics.IDENTITY_FINISH)) {          \n        return new CollectorImpl<>(supplier, accumulator, merger, CH_ID);                            \n    }                                                                                                \n    else {                                                                                           \n        Function<Partition<A>, Map<Boolean, D>> finisher = par ->                                    \n                new Partition<>(downstream.finisher().apply(par.forTrue),                            \n                                downstream.finisher().apply(par.forFalse));                          \n        return new CollectorImpl<>(supplier, accumulator, merger, finisher, CH_NOID);                \n    }                                                                                                \n}    \n\n//私有类提供容器\nprivate static final class Partition<T> extends AbstractMap<Boolean, T> implements Map<Boolean, T> {\n    final T forTrue;\n    final T forFalse;\n\t//包装两个被包装容器 一个用于存储true的情况，一种存储false的情况\n    Partition(T forTrue, T forFalse) {//使用被包装的Collector的容器类型\n        this.forTrue = forTrue;\n        this.forFalse = forFalse;\n    }\n\n    @Override\n    public Set<Map.Entry<Boolean, T>> entrySet() {\n        return new AbstractSet<Map.Entry<Boolean, T>>() {\n            @Override\n            public Iterator<Map.Entry<Boolean, T>> iterator() {\n                Map.Entry<Boolean, T> falseEntry = new SimpleImmutableEntry<>(false, forFalse);\n                Map.Entry<Boolean, T> trueEntry = new SimpleImmutableEntry<>(true, forTrue);\n                return Arrays.asList(falseEntry, trueEntry).iterator();\n            }\n\n            @Override\n            public int size() {\n                return 2;\n            }\n        };\n    }\n}\n```\n- groupingBy  要求容器是一个Map的实现类型。\n```java\n//classifier   mapFactory \npublic static <T, K, D, A, M extends Map<K, D>>                                                            \nCollector<T, ?, M> groupingBy(Function<? super T, ? extends K> classifier, //提供map的key值函数                                    \n                              Supplier<M> mapFactory,//提供容器                                                          \n                              Collector<? super T, A, D> downstream) {                                         \n    Supplier<A> downstreamSupplier = downstream.supplier();                                                    \n    BiConsumer<A, ? super T> downstreamAccumulator = downstream.accumulator();                                 \n    BiConsumer<Map<K, A>, T> accumulator = (m, t) -> { //m为容器，即Map\n    \t//获取key值\n        K key = Objects.requireNonNull(classifier.apply(t), \"element cannot be mapped to a null key\");\n        //以Collectors.toList为例，这里将被包装Collector的容器放入map中，并返回被包装Collector的容器\n        A container = m.computeIfAbsent(key, k -> downstreamSupplier.get());   \n        //再使用被包装Collector的类加器向被包装Collector的容器中添加元素\n        downstreamAccumulator.accept(container, t);                                                            \n    };                                                                                                         \n    BinaryOperator<Map<K, A>> merger = Collectors.<K, A, Map<K, A>>mapMerger(downstream.combiner());     \n    //容器 ，一般使用 HashMap\n    @SuppressWarnings(\"unchecked\")                                                                             \n    Supplier<Map<K, A>> mangledFactory = (Supplier<Map<K, A>>) mapFactory;                                     \n                                                                                                               \n    if (downstream.characteristics().contains(Collector.Characteristics.IDENTITY_FINISH)) {                    \n        return new CollectorImpl<>(mangledFactory, accumulator, merger, CH_ID);                                \n    }                                                                                                          \n    else {                                                                                                     \n        @SuppressWarnings(\"unchecked\")                                                                         \n        Function<A, A> downstreamFinisher = (Function<A, A>) downstream.finisher();                            \n        Function<Map<K, A>, M> finisher = intermediate -> {                                                    \n            intermediate.replaceAll((k, v) -> downstreamFinisher.apply(v));                                    \n            @SuppressWarnings(\"unchecked\")                                                                     \n            M castResult = (M) intermediate;                                                                   \n            return castResult;                                                                                 \n        };                                                                                                     \n        return new CollectorImpl<>(mangledFactory, accumulator, merger, finisher, CH_NOID);                    \n    }                                                                                                          \n}                                                                                                              \n\ngroupingBy(classifier, HashMap::new, toList());\n```\n\n\n","source":"_posts/java8/java8之Collector.md","raw":"---\ntitle: java8之Collector\ndate: 2017-08-05 13:58:46\ntags:\n- java8\ncategories:\n- java基础\n---\n\n# java8之Collector\n\nStream流的终端操作常常需要聚合，Collector就是对Stream流进行聚合的实现。jdk提供了Collectors工具类封装了一些常用的聚合操作。\n\n<!--more-->\n\n## Collector接口\n\nCollector是一个接口，它是一个可变的汇聚操作，通过累加器将输入元素汇集到一个**可伸展**的结果容器中；如果是并行流会产生多个结果容器，还需将结果容器合并为一个，最后将累积的结果容器转换为一个最终想要的容器返回（这是一个可选操作）\n\n```java\npublic interface Collector<T, A, R> {\n    //用于提供一个可伸展结构的容器\n    Supplier<A> supplier();   //容器\n  \t//用于将元素添加到提供的容器中\n    BiConsumer<A, T> accumulator();//累加器\n  \t//把并行流产生的多个容易合并为一个\n    BinaryOperator<A> combiner(); //合并器\n\t//将combiner返回的结果类型转换为其他类型，当characteristics选择IDENTITY_FINISH时，不需要转换类型，\t   所以该方法不会被调用，其他情况下会被调用\n    Function<A, R> finisher();\n    //Collector约束属性set,不可变Collections.unmodifiableSet\n    Set<Characteristics> characteristics();\n}\n```\nCharacteristics是Collector内的一个枚举类，用来约束Collector的属性。\n\n- CONCURRENT：表示此收集器支持并发，意味着允许在多个线程中，累加器可以调用结果容器\n- UNORDERED：表示收集器并不按照Stream中的元素输入顺序执行\n- IDENTITY_FINISH：表示不需要转换结果类型，直接返回supplier创建的数据类型，finisher方法不执行。\n\n\n如下就是一个简单的Collector的实现，将结果聚合到一个list当中\n\n```java\nList result = Stream.of(1, 2,3, 4,5).collect(\n  () -> new ArrayList(), //创建一个可变容器\n  (list, item) -> list.add(item),//将stream中元素添加到可变容器中\n  (list1, list2) -> list1.addAll(list2)//合并多个可变容器\n);\n```\n\n## Collectors工具类\n\nCollectors本身提供了关于Collector的常见汇聚实现，Collectors的内部类CollectorImpl实现了Collector接口，Collectors本身就是一堆创建CollectorImpl对象的工具类。\n\n### CollectorImpl\n\nCollectorImpl是Collectors工具类中的内部类，实现了Collector接口，提供了构造器，方便构造Collector的具体实现类，Collector接口中可以设置一个Characteristics的集合，Collectors针对可能出现的组合定义好了几个类型集合。\n\n```java\nstatic final Set<Collector.Characteristics> CH_CONCURRENT_ID                                   \n        = Collections.unmodifiableSet(EnumSet.of(Collector.Characteristics.CONCURRENT,         \n                                                 Collector.Characteristics.UNORDERED,          \n                                                 Collector.Characteristics.IDENTITY_FINISH));  \nstatic final Set<Collector.Characteristics> CH_CONCURRENT_NOID                                 \n        = Collections.unmodifiableSet(EnumSet.of(Collector.Characteristics.CONCURRENT,         \n                                                 Collector.Characteristics.UNORDERED));        \nstatic final Set<Collector.Characteristics> CH_ID                                              \n        = Collections.unmodifiableSet(EnumSet.of(Collector.Characteristics.IDENTITY_FINISH));  \nstatic final Set<Collector.Characteristics> CH_UNORDERED_ID                                    \n        = Collections.unmodifiableSet(EnumSet.of(Collector.Characteristics.UNORDERED,          \n                                                 Collector.Characteristics.IDENTITY_FINISH));  \nstatic final Set<Collector.Characteristics> CH_NOID = Collections.emptySet();    \n\nstatic class CollectorImpl<T, A, R> implements Collector<T, A, R> { \n     //构造函数，创建Collector的实现类对象\n     CollectorImpl(Supplier<A> supplier,                             \n                   BiConsumer<A, T> accumulator,                     \n                   BinaryOperator<A> combiner,                       \n                   Function<A,R> finisher,                           \n                   Set<Characteristics> characteristics) {           \n         this.supplier = supplier;                                   \n         this.accumulator = accumulator;                             \n         this.combiner = combiner;                                   \n         this.finisher = finisher;                                   \n         this.characteristics = characteristics;                     \n     }                  \n }\n```\n\n### Collectors工具类型\n\n#### 链接\n\nmapping是在将元素添加到容器前进行一次映射处理、collectingAndThen是处理Collector的最终返回值问题，是额外给Collector添加一个Finisher方法\n\n```java\npublic static <T, U, A, R>                                                                \nCollector<T, ?, R> mapping(Function<? super T, ? extends U> mapper,                       \n                           Collector<? super U, A, R> downstream) {                       \n    BiConsumer<A, ? super U> downstreamAccumulator = downstream.accumulator();            \n    return new CollectorImpl<>(downstream.supplier(),                                     \n                               (r, t) -> downstreamAccumulator.accept(r, mapper.apply(t)),\n                               downstream.combiner(), downstream.finisher(),              \n                               downstream.characteristics());                             \n}                                                                                         \n```\n\n```java\npublic static<T,A,R,RR> Collector<T,A,RR> collectingAndThen(Collector<T,A,R> downstream,  \n                                                            Function<R,RR> finisher) {    \n    Set<Collector.Characteristics> characteristics = downstream.characteristics();        \n    if (characteristics.contains(Collector.Characteristics.IDENTITY_FINISH)) {            \n        if (characteristics.size() == 1)                                                  \n            characteristics = Collectors.CH_NOID;                                         \n        else {                                                                            \n            characteristics = EnumSet.copyOf(characteristics);                            \n            characteristics.remove(Collector.Characteristics.IDENTITY_FINISH);            \n            characteristics = Collections.unmodifiableSet(characteristics);               \n        }                                                                                 \n    }                                                                                     \n    return new CollectorImpl<>(downstream.supplier(),                                     \n                               downstream.accumulator(),                                  \n                               downstream.combiner(),                                     \n                               downstream.finisher().andThen(finisher),                   \n                               characteristics);                                          \n}                                                                                                                                                                                  \n```\n\n\n\n#### 构建集合类\n\ntoCollection、toList、toSet：创建集合-->将元素添加到集合-->合并集合—>返回集合类型。构建set的时候需要注意设置characteristics类型为无序的，不需要按照Stream顺序添加到集合中。\n\n```java\npublic static <T> Collector<T, ?, Set<T>> toSet() {                                                    \n    return new CollectorImpl<>((Supplier<Set<T>>) HashSet::new, Set::add,            \n                               (left, right) -> { left.addAll(right); return left; },\n                               CH_UNORDERED_ID);                                     \n}                                                                                    \n```\n\n#### 聚合为字符串\n\n提供了一个可变的字符存储容器StringJoiner，然后就是将Stream中的元素添加到StringJoiner，合并多个StringJoiner，最后toString返回字符串。\n\n```java\npublic static Collector<CharSequence, ?, String> joining(CharSequence delimiter, \n                                                         CharSequence prefix,    \n                                                         CharSequence suffix) {  \n    return new CollectorImpl<>(                                                  \n            () -> new StringJoiner(delimiter, prefix, suffix),                   \n            StringJoiner::add, StringJoiner::merge,                              \n            StringJoiner::toString, CH_NOID);                                    \n}                                                                                \n```\n\n#### 聚合reduce\n\n- 接受一个默认值和一个BinaryOperator参数，通过BinaryOperator将元素集合合并为一个元素\n```java\npublic static <T> Collector<T, ?, T>                             \nreducing(T identity, BinaryOperator<T> op) {                     \n    return new CollectorImpl<>(                                  \n            boxSupplier(identity),                               \n            (a, t) -> { a[0] = op.apply(a[0], t); },             \n            (a, b) -> { a[0] = op.apply(a[0], b[0]); return a; },\n            a -> a[0],                                           \n            CH_NOID);                                            \n}  \n//为了实现容器，使用数组来当存储对象的容器\nprivate static <T> Supplier<T[]> boxSupplier(T identity) {\n\treturn () -> (T[]) new Object[] { identity };\n}\n```\n- 同上一样，只是多个一个mapper参数用于处理向容器添加前的映射处理\n```java\npublic static <T, U>  Collector<T, ?, U> reducing(U identity,\n                            Function<? super T, ? extends U> mapper,\n                            BinaryOperator<U> op) {                 \n    return new CollectorImpl<>(   \n      \t\t// boxSupplier == return () -> (T[]) new Object[] { identity }; \n            boxSupplier(identity), //转换为可伸缩数据结构，存储数据                            \n            (a, t) -> { a[0] = op.apply(a[0], mapper.apply(t)); },  \n            (a, b) -> { a[0] = op.apply(a[0], b[0]); return a; },   \n            a -> a[0], CH_NOID);                                    \n}    \n```\n\n- 接受一个BinaryOperator参数，通过BinaryOperator将元素集合合并为一个元素\n```java\npublic static <T> Collector<T, ?, Optional<T>>                        \nreducing(BinaryOperator<T> op) {         \n\t//匿名内部类提供一个容器\n    class OptionalBox implements Consumer<T> {                        \n        T value = null;                                               \n        boolean present = false;                                      \n                                                                      \n        @Override                                                     \n        public void accept(T t) {//容器添加元素，这里其实就是通过参数 BinaryOperator来决定是否用新的元素替代原有的元素                                 \n            if (present) {                                            \n                value = op.apply(value, t);                           \n            }                                                         \n            else {                                                    \n                value = t;                                            \n                present = true;                                       \n            }                                                         \n        }                                                             \n    }                                                                 \n                                                                      \n    return new CollectorImpl<T, OptionalBox, Optional<T>>(            \n            OptionalBox::new, OptionalBox::accept,                    \n            (a, b) -> { if (b.present) a.accept(b.value); return a; },\n            a -> Optional.ofNullable(a.value), CH_NOID);              \n}   \n\n//给出每个城市最高的人\nComparator<Person> byHeight = Comparator.comparing(Person::getHeight);\nMap<City, Person> tallestByCity = people.stream().collect(groupingBy(Person::getCity,reducing(BinaryOperator.maxBy(byHeight))));\n```\n\n#### 聚合为值(reduce)\n\ncounting、minBy、maxBy：通过reduce将数据聚合为一个值\n\n```java\npublic static <T> Collector<T, ?, Long> counting() {                                       \n    return reducing(0L, e -> 1L, Long::sum);   //一个元素代表1，通过Long::sum 累加    \n}                 \npublic static <T> Collector<T, ?, Optional<T>>        \nminBy(Comparator<? super T> comparator) {             \n    return reducing(BinaryOperator.minBy(comparator));\n}                                                     \n```\n\n#### 累积求值\n\nsummingInt、averagingInt、summarizingInt等:返回总值、平均值、统计数据(和、平均值、最大值、最小值),注意到在针对基本数据类型创建可伸展数据结构的时候都选择了基本数据类型的数组类型。\n\n```java\npublic static <T> Collector<T, ?, Integer> summingInt(ToIntFunction<? super T> mapper) {           \n    return new CollectorImpl<>(                         \n            () -> new int[1],                           \n            (a, t) -> { a[0] += mapper.applyAsInt(t); },\n            (a, b) -> { a[0] += b[0]; return a; },      \n            a -> a[0], CH_NOID);                        \n}      \n\npublic static <T> Collector<T, ?, Double> averagingInt(ToIntFunction<? super T> mapper) {                      \n    return new CollectorImpl<>(                                      \n            () -> new long[2],  //一个存储总值，一个存储总数                                    \n            (a, t) -> { a[0] += mapper.applyAsInt(t); a[1]++; },     \n            (a, b) -> { a[0] += b[0]; a[1] += b[1]; return a; },     \n            a -> (a[1] == 0) ? 0.0d : (double) a[0] / a[1], CH_NOID);\n}                                                                    \n```\n\n#### 转换为Map\n\ntoMap、toConcurrentMap：将Stream流转换为map或者concurrentMap\n\n```java\npublic static <T, K, U>                                                      \nCollector<T, ?, Map<K,U>> toMap(Function<? super T, ? extends K> keyMapper,  \n                                Function<? super T, ? extends U> valueMapper,\n                                BinaryOperator<U> mergeFunction) {           \n    return toMap(keyMapper, valueMapper, mergeFunction, HashMap::new);       \n}                                                                            \npublic static <T, K, U, M extends Map<K, U>>                                                \nCollector<T, ?, M> toMap(Function<? super T, ? extends K> keyMapper,                        \n                            Function<? super T, ? extends U> valueMapper,                   \n                            BinaryOperator<U> mergeFunction,                                \n                            Supplier<M> mapSupplier) { \n    //map提供的merge方法，用于合并两个map\n    BiConsumer<M, T> accumulator                                                            \n            = (map, element) -> map.merge(keyMapper.apply(element),                         \n                                          valueMapper.apply(element), mergeFunction);       \n    return new CollectorImpl<>(mapSupplier, accumulator, mapMerger(mergeFunction), CH_ID);  \n}        \n//用法 \nMap<String, Student> studentIdToStudent = students.stream().collect(toMap(Student::getId,Function.identity());\n```\n\n#### 分组聚合\n\ngroupingBy、partitioningBy：默认会将value聚合为list，可以传递一个Collector对value进行聚合\n\n- partitioningBy\n\n```java\npublic static <T, D, A>                                                                              \nCollector<T, ?, Map<Boolean, D>> partitioningBy(Predicate<? super T> predicate,                      \n                                                Collector<? super T, A, D> downstream) {             \n    BiConsumer<A, ? super T> downstreamAccumulator = downstream.accumulator();\n    //将元素根据true和false分别添加到包装后的Partition容器中\n    BiConsumer<Partition<A>, T> accumulator = (result, t) ->                                         \n            downstreamAccumulator.accept(predicate.test(t) ? result.forTrue : result.forFalse, t);   \n    BinaryOperator<A> op = downstream.combiner();                                                    \n    BinaryOperator<Partition<A>> merger = (left, right) ->                                           \n            new Partition<>(op.apply(left.forTrue, right.forTrue),                                   \n                            op.apply(left.forFalse, right.forFalse));  \n    //元素容器，使用Partition，包装原有的Collector的容器\n    Supplier<Partition<A>> supplier = () ->                                                          \n            new Partition<>(downstream.supplier().get(),                                             \n                            downstream.supplier().get());                                            \n    if (downstream.characteristics().contains(Collector.Characteristics.IDENTITY_FINISH)) {          \n        return new CollectorImpl<>(supplier, accumulator, merger, CH_ID);                            \n    }                                                                                                \n    else {                                                                                           \n        Function<Partition<A>, Map<Boolean, D>> finisher = par ->                                    \n                new Partition<>(downstream.finisher().apply(par.forTrue),                            \n                                downstream.finisher().apply(par.forFalse));                          \n        return new CollectorImpl<>(supplier, accumulator, merger, finisher, CH_NOID);                \n    }                                                                                                \n}    \n\n//私有类提供容器\nprivate static final class Partition<T> extends AbstractMap<Boolean, T> implements Map<Boolean, T> {\n    final T forTrue;\n    final T forFalse;\n\t//包装两个被包装容器 一个用于存储true的情况，一种存储false的情况\n    Partition(T forTrue, T forFalse) {//使用被包装的Collector的容器类型\n        this.forTrue = forTrue;\n        this.forFalse = forFalse;\n    }\n\n    @Override\n    public Set<Map.Entry<Boolean, T>> entrySet() {\n        return new AbstractSet<Map.Entry<Boolean, T>>() {\n            @Override\n            public Iterator<Map.Entry<Boolean, T>> iterator() {\n                Map.Entry<Boolean, T> falseEntry = new SimpleImmutableEntry<>(false, forFalse);\n                Map.Entry<Boolean, T> trueEntry = new SimpleImmutableEntry<>(true, forTrue);\n                return Arrays.asList(falseEntry, trueEntry).iterator();\n            }\n\n            @Override\n            public int size() {\n                return 2;\n            }\n        };\n    }\n}\n```\n- groupingBy  要求容器是一个Map的实现类型。\n```java\n//classifier   mapFactory \npublic static <T, K, D, A, M extends Map<K, D>>                                                            \nCollector<T, ?, M> groupingBy(Function<? super T, ? extends K> classifier, //提供map的key值函数                                    \n                              Supplier<M> mapFactory,//提供容器                                                          \n                              Collector<? super T, A, D> downstream) {                                         \n    Supplier<A> downstreamSupplier = downstream.supplier();                                                    \n    BiConsumer<A, ? super T> downstreamAccumulator = downstream.accumulator();                                 \n    BiConsumer<Map<K, A>, T> accumulator = (m, t) -> { //m为容器，即Map\n    \t//获取key值\n        K key = Objects.requireNonNull(classifier.apply(t), \"element cannot be mapped to a null key\");\n        //以Collectors.toList为例，这里将被包装Collector的容器放入map中，并返回被包装Collector的容器\n        A container = m.computeIfAbsent(key, k -> downstreamSupplier.get());   \n        //再使用被包装Collector的类加器向被包装Collector的容器中添加元素\n        downstreamAccumulator.accept(container, t);                                                            \n    };                                                                                                         \n    BinaryOperator<Map<K, A>> merger = Collectors.<K, A, Map<K, A>>mapMerger(downstream.combiner());     \n    //容器 ，一般使用 HashMap\n    @SuppressWarnings(\"unchecked\")                                                                             \n    Supplier<Map<K, A>> mangledFactory = (Supplier<Map<K, A>>) mapFactory;                                     \n                                                                                                               \n    if (downstream.characteristics().contains(Collector.Characteristics.IDENTITY_FINISH)) {                    \n        return new CollectorImpl<>(mangledFactory, accumulator, merger, CH_ID);                                \n    }                                                                                                          \n    else {                                                                                                     \n        @SuppressWarnings(\"unchecked\")                                                                         \n        Function<A, A> downstreamFinisher = (Function<A, A>) downstream.finisher();                            \n        Function<Map<K, A>, M> finisher = intermediate -> {                                                    \n            intermediate.replaceAll((k, v) -> downstreamFinisher.apply(v));                                    \n            @SuppressWarnings(\"unchecked\")                                                                     \n            M castResult = (M) intermediate;                                                                   \n            return castResult;                                                                                 \n        };                                                                                                     \n        return new CollectorImpl<>(mangledFactory, accumulator, merger, finisher, CH_NOID);                    \n    }                                                                                                          \n}                                                                                                              \n\ngroupingBy(classifier, HashMap::new, toList());\n```\n\n\n","slug":"java8/java8之Collector","published":1,"updated":"2018-09-12T03:03:21.820Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnh7003cwlkvrtoip116"},{"title":"java8之CompletableFuture","date":"2017-08-05T04:58:46.000Z","_content":"\n# java8之CompletableFuture\n\nCompletableFuture实现了Future接口，是jdk8新添加的对与并发编程的扩展支持。通过CompletableFuture可以方便的操作多个异步任务、执行结果的回调等操作。\n\n<!--more-->\n\n## CompletableFuture优点\n\njdk8之前的Future接口也可以构建异步任务，并且通过get()阻塞获取异步任务的结果。但是依然存在一些局限性，只能阻塞或者轮询去监控获取异步任务的结果，jdb8中的CompletableFuture实现了Future接口，同时扩展了异步编程中更多的需求\n\n- 可以再异步任务异常或者完成的时候回调通知监听者\n- 异步任务完成之后直接参与下个流程\n- 将两个异步任务合并为一个异步任务，其中的两个异步任务可以依次依赖执行，也可以同时执行\n- 仅获取多个异步任务中最快结束的任务返回结果\n- parallelStream使用默认的ForkJoinPool无法修改线程数，而CompletableFuture可以指定线程池，默认跟parallelStream用的是一样的线程池\n\n\n## 用法\n\njdk8之前使用futureTask创建一个有返回值的异步线程\n\n```java\nCallable callable = () -> 0d;\nFutureTask<Double> future = new FutureTask<Double>(callable);\nThread thread = new Thread(future);\nthread.start();\nSystem.out.println(future.get());\n```\n\njdk8提供了CompletableFuture，同样实现了future接口，可以通过以下方式创建一个带返回结果的异步任务\n\n```java\nCompletableFuture<Double> completableFuture = new CompletableFuture();\nThread thread = new Thread(() -> {\n  try {\n    double price = getPrice(product);\n    completableFuture.complete(price);\n  } catch (Exception e) {\n    //发生异常时，工作线程会被kill，使用future将异常传递给调用线程\n    completableFuture.completeExceptionally(e);\n  }\n});\nthread.start();\nSystem.out.println(completableFuture.get());\n```\n\nCompletableFuture提供了静态方法，直接创建异步任务，同时也可以指定线程池，如果不指定，默认使用ForkJoinPool.commonPool()\n\n- 创建不带返回结果的异步任务\n\n  ```java\n  public static CompletableFuture<Void> runAsync(Runnable runnable)\n  public static CompletableFuture<Void> runAsync(Runnable runnable,Executor executor)\n  ```\n\n- 创建带返回结果的异步任务\n\n  ```java\n  public static <U> CompletableFuture<U> supplyAsync(Supplier<U> supplier) \n  public static <U> CompletableFuture<U> supplyAsync(Supplier<U> supplier,Executor executor)\n  ```\n\n### 获取值\n\nCompletableFuture提供了多种获取异步任务返回值的方法\n\n\n```java\npublic T    get()  //阻塞等待直到有返回结果,抛出检查性异常\npublic T    get(long timeout, TimeUnit unit)  //阻塞等待指定时间,抛出检查性异常抛出非检查性异常\npublic T    getNow(T valueIfAbsent)  //如果结果已经计算完则返回结果或抛异常，否则返回给定的valueIfAbsent的值。\npublic T    join()  //阻塞等待直到有返回结果，抛出非检查性异常，当任务异常后，join会抛出RuntimeException,多次调用join会抛出CompletionException异常\n```\n\n### 状态检查\n\n可以通过isDone检查异步任务是否执行完毕，isCompletedExceptionally检查异步任务是否抛出异常结束\n\n```java\npublic boolean isDone()\npublic boolean isCompletedExceptionally()\n```\n\n### 异步链式\n\nCompletableFuture的异步链式方法都提供了三个类型\n\n- 同一线程:跟调用者CompletableFuture使用同一个线程\n- Async: 使用`ForkJoinPool.commonPool()`系统级公共线程池中的线程，默认是守护线程，(jvm退出守护线程即消亡)\n- Async+指定executor: 使用指定的线程池中的线程执行\n\n```java\nstatic {\n        int threadCount = 2;\n        AtomicInteger atomicInteger = new AtomicInteger(1);\n        executorService = Executors.newFixedThreadPool(threadCount, r -> {\n            Thread t = new Thread(Thread.currentThread().getThreadGroup(), r, \"test\"+atomicInteger.getAndIncrement());\n            t.setDaemon(false);\n            return t;\n        });\n    }\n```\n\n在执行一组异步操作的时候，一定不要将join和生成CompletableFuture的map放在一个链里面，不然会阻塞\n\n```java\npublic static void main(String[] args) throws InterruptedException {\n  List<String> parameters = Lists.newArrayList(\"a\",\"b\",\"c\",\"d\");\n  List<CompletableFuture> futureList = parameters.stream().map(s -> CompletableFuture.supplyAsync(() -> {\n    try {\n      Thread.currentThread().sleep(1000L);\n    } catch (InterruptedException e) {\n      e.printStackTrace();\n    }\n    System.out.println(Thread.currentThread().getName() + \"执行完毕:\" + s);\n    return s;\n  },executorService)).collect(Collectors.toList());\n  System.out.println(\"main over\");\n  //单独放在一个map链里面\n  futureList.stream().map(s -> s.join()).forEach(System.out::println);\n}\n```\n\n#### thenApply\n\n**等待异步返回结果，将异步返回的结果作为参数，执行function转换结果**。thenApply方法会跟异步任务使用同一个线程(异步任务很快的时候测试时用的main线程),Async方法会启用ForkJoinPool中的线程来执行function。如果不想用默认的ForkJoinPool，可以指定一个线程池。\n\n```java\npublic <U> CompletionStage<U> thenApply(Function<? super T,? extends U> fn);\npublic <U> CompletionStage<U> thenApplyAsync(Function<? super T,? extends U> fn);\npublic <U> CompletionStage<U> thenApplyAsync(Function<? super T,? extends U> fn,Executor executor);\n```\n\n```java\npublic static void main(String[] args) throws InterruptedException {\n  System.out.println(\"main start\");\n  CompletableFuture<String> future = CompletableFuture.supplyAsync(() -> {\n    System.out.println(Thread.currentThread().getName() + \": before first\");\n    try {\n      Thread.currentThread().sleep(1000);\n    } catch (InterruptedException e) {\n    }\n    System.out.println(Thread.currentThread().getName() + \": after first\");\n\n    return \"first\";\n  }, executorService).thenApplyAsync((s) -> {\n    System.out.println(Thread.currentThread().getName() + \": get \" + s);\n    return \"second\";\n  },executorService);\n  System.out.println(\"main over\");\n  String join = future.join();\n  System.out.println(String.format(\"future result %s\",join));\n}\n/*\nmain start\ntest1: before first\nmain over\ntest1: after first\ntest2: get first\nfuture result second\n*/\n```\n\n#### thenAccept\n\n等待异步返回结果，将异步返回的结果作为参数，执行consumer消耗结果。同thenApply一样，唯一不同的是该方法没有返回值，直接消费异步结果，不再需要阻塞主线程获取异步结果。\n\n```java\npublic CompletionStage<Void> thenAccept(Consumer<? super T> action);\npublic CompletionStage<Void> thenAcceptAsync(Consumer<? super T> action);\npublic CompletionStage<Void> thenAcceptAsync(Consumer<? super T> action,Executor executor);\n```\n\n#### thenRun\n\n等待异步返回结果，然后执行任务。同thenApply一样，唯一不同的是该方法等待异步任务执行完毕后执行自己的任务。\n\n```java\npublic CompletionStage<Void> thenRun(Runnable action);\npublic CompletionStage<Void> thenRunAsync(Runnable action);\npublic CompletionStage<Void> thenRunAsync(Runnable action,Executor executor);\n```\n\n#### thenCompose\n\n合并两个异步操作。等待第一个异步任务执行完毕，将结果作为第二个异步任务的参数来执行第二个异步任务\n\n```java\npublic <U> CompletableFuture<U> thenCompose(Function<? super T, ? extends CompletionStage<U>> fn)\npublic <U> CompletableFuture<U> thenComposeAsync(Function<? super T, ? extends CompletionStage<U>> fn)\npublic <U> CompletableFuture<U> thenComposeAsync(Function<? super T, ? extends CompletionStage<U>> fn,public <U> CompletableFuture<U> thenComposeAsync(Function<? super T, ? extends CompletionStage<U>> fn))\n```\n\n#### thenCombine\n\n合并两个异步操作。同时执行两个异步操作，等待两个都执行完毕后将两个异步操作的结果合并转换后返回一个future，调用join方法获取结果。\n\n```java\npublic <U,V> CompletionStage<V> thenCombine(CompletionStage<? extends U> other,BiFunction<? super T,? super U,? extends V> fn);\npublic <U,V> CompletionStage<V> thenCombineAsync(CompletionStage<? extends U> other,BiFunction<? super T,? super U,? extends V> fn);\npublic <U,V> CompletionStage<V> thenCombineAsync(CompletionStage<? extends U> other,BiFunction<? super T,? super U,? extends V> fn,Executor executor);\n```\n\n```java\npublic static void main(String[] args) throws InterruptedException {\n  System.out.println(\"main start\");\n  CompletableFuture<String> future = CompletableFuture.supplyAsync(() -> {\n    System.out.println(Thread.currentThread().getName() + \": before first\");\n    try {\n      Thread.currentThread().sleep(1000);\n    } catch (InterruptedException e) {\n    }\n    System.out.println(Thread.currentThread().getName() + \": after first\");\n\n    return \"first\";\n  }, executorService).thenCombineAsync(CompletableFuture.supplyAsync(() -> {\n    System.out.println(Thread.currentThread().getName() + \": before second\");\n    try {\n      Thread.currentThread().sleep(2000);\n    } catch (InterruptedException e) {\n    }\n    System.out.println(Thread.currentThread().getName() + \": after second\");\n\n    return \"second\";\n  },executorService), (s1, s2) ->  s1 + \":\" + s2);\n  System.out.println(\"main over\");\n  String join = future.join();\n  System.out.println(String.format(\"future result %s\",join));\n}\n/*\nmain start\ntest1: before first\ntest1: after first\nmain over\ntest2: get first\nfuture result second\n*/\n```\n\n#### thenAcceptBoth\n\n合并两个异步操作,同thenCombine一样，唯一不同是该方法直接消费两个异步任务的结果，不再需要阻塞主线程获取异步结果\n\n```java\npublic <U> CompletionStage<Void> thenAcceptBoth(CompletionStage<? extends U> other,BiConsumer<? super T, ? super U> action);\npublic <U> CompletionStage<Void> thenAcceptBothAsync(CompletionStage<? extends U> other,BiConsumer<? super T, ? super U> action);\npublic <U> CompletionStage<Void> thenAcceptBothAsync(CompletionStage<? extends U> other,BiConsumer<? super T, ? super U> action,     Executor executor);\n```\n\n#### runAfterBoth\n\n合并两个异步操作,同thenCombine一样，唯一不同是该方法等待两个异步任务执行完毕后，执行自己的任务\n\n```java\npublic CompletionStage<Void> runAfterBoth(CompletionStage<?> other,Runnable action);\npublic CompletionStage<Void> runAfterBothAsync(CompletionStage<?> other,Runnable action);\npublic CompletionStage<Void> runAfterBothAsync(CompletionStage<?> other,Runnable action,Executor executor);\n```\n\n#### applyToEither\n\n两个异步操作，任意一个返回结果，再调用join的时候就返回接口，其中一个未执行完毕的任务会继续执行\n\n```java\npublic <U> CompletionStage<U> applyToEither(CompletionStage<? extends T> other,Function<? super T, U> fn);\npublic <U> CompletionStage<U> applyToEitherAsync(CompletionStage<? extends T> other,Function<? super T, U> fn);\npublic <U> CompletionStage<U> applyToEitherAsync(CompletionStage<? extends T> other,Function<? super T, U> fn,Executor executor);\n```\n\n```java\npublic static void main(String[] args) throws InterruptedException {\n  System.out.println(\"main start\");\n  CompletableFuture<String> future = CompletableFuture.supplyAsync(() -> {\n    System.out.println(Thread.currentThread().getName() + \": before first\");\n    try {\n      Thread.currentThread().sleep(1000);\n    } catch (InterruptedException e) {\n    }\n    System.out.println(Thread.currentThread().getName() + \": after first\");\n\n    return \"first\";\n  }, executorService).applyToEitherAsync(CompletableFuture.supplyAsync(() -> {\n    System.out.println(Thread.currentThread().getName() + \": before second\");\n    try {\n      Thread.currentThread().sleep(2000);\n    } catch (InterruptedException e) {\n    }\n    System.out.println(Thread.currentThread().getName() + \": after second\");\n\n    return \"second\";\n  }, executorService), (s) -> s);\n  System.out.println(\"main over\");\n  String join = future.join();\n  System.out.println(String.format(\"future result %s\",join));\n}\n/*\nmain start\ntest1: before first\ntest2: before second\nmain over\ntest1: after first\nfuture result first\ntest2: after second\n*/\n```\n\n#### acceptEither\n\n同理acceptEither\n\n```java\npublic CompletionStage<Void> acceptEither(CompletionStage<? extends T> other,Consumer<? super T> action);\npublic CompletionStage<Void> acceptEitherAsync(CompletionStage<? extends T> other,Consumer<? super T> action);\npublic CompletionStage<Void> acceptEitherAsync(CompletionStage<? extends T> other,Consumer<? super T> action,Executor executor);\n```\n\n#### runAfterEither\n\n同理runAfterEither，两个异步任务任意一个执行完毕就执行 runAfterEither 参数中的任务\n\n```java\npublic CompletionStage<Void> runAfterEither(CompletionStage<?> other,Runnable action);\npublic CompletionStage<Void> runAfterEitherAsync(CompletionStage<?> other,Runnable action);\npublic CompletionStage<Void> runAfterEitherAsync(CompletionStage<?> other,Runnable action,Executor executor);\n```\n\n#### exceptionally\n\n异常处理，当异步任务出现异常的时候处理方式,相当于 try-catch-finnaly中的catch，**可以调用程序指定的回调函数，通知外界执行异常**\n\n```java\npublic CompletionStage<T> exceptionally(Function<Throwable, ? extends T> fn);\n```\n\n#### whenComplete\n\n try-catch-finnaly中的finnaly在返回结果前执行,接收两个参数，result和exception,一种是正常执行，返回值。另外一种是遇到异常抛出造成程序的中断，**可以调用程序指定的回调函数，通知外界执行完毕**\n\n```java\npublic CompletionStage<T> whenComplete(BiConsumer<? super T, ? super Throwable> action);\npublic CompletionStage<T> whenCompleteAsync(BiConsumer<? super T, ? super Throwable> action);\npublic CompletionStage<T> whenCompleteAsync(BiConsumer<? super T, ? super Throwable> action,Executor executor);\n```\n\n```java\npublic static void main(String[] args) throws InterruptedException {\n  System.out.println(\"main start\");\n  CompletableFuture<String> future = CompletableFuture.supplyAsync(() -> {\n    System.out.println(Thread.currentThread().getName() + \": before first\");\n    try {\n      Thread.currentThread().sleep(1000);\n    } catch (InterruptedException e) {\n    }\n    if(1 == 1) {\n      throw new RuntimeException(\"fff\");\n    }\n    System.out.println(Thread.currentThread().getName() + \": after first\");\n    return \"first\";\n  }, executorService).exceptionally(e -> {\n    System.out.println(\"异常：\"+e.getMessage());\n    return \"exception\";\n  }).whenComplete((r,e) -> {\n    System.out.println(\"finnaly result:\"+(r!=null?r:\"\"));\n    System.out.println(\"finnaly exception:\"+(e!=null?e.getMessage():\"\"));\n  });\n  System.out.println(\"main over\");\n  String join = future.join();\n  System.out.println(String.format(\"future result %s\",join));\n}\n/*\nmain start\ntest1: before first\nmain over\n异常：java.lang.RuntimeException: fff\nfinnaly result:exception\nfinnaly exception:\nfuture result exception\n*/\n```\n\n#### handle\n\n运行完成时，对结果的处理，跟whenComplete一样，不过调用该方法会有返回值。\n\n```java\npublic <U> CompletionStage<U> handle(BiFunction<? super T, Throwable, ? extends U> fn);\npublic <U> CompletionStage<U> handleAsync(BiFunction<? super T, Throwable, ? extends U> fn);\npublic <U> CompletionStage<U> handleAsync(BiFunction<? super T, Throwable, ? extends U> fn,Executor executor);\n```\n\n#### allOf\n\n等待一组异步任务都执行完毕\n\n```java\npublic static void main(String[] args) throws InterruptedException {\n  List<String> parameters = Lists.newArrayList(\"a\",\"b\",\"c\",\"d\");\n  CompletableFuture[] futureList = parameters.stream().map(s -> CompletableFuture.supplyAsync(() -> {\n    try {\n      Thread.currentThread().sleep(1000L);\n    } catch (InterruptedException e) {\n      e.printStackTrace();\n    }\n    System.out.println(Thread.currentThread().getName() + \"执行完毕:\" + s);\n    return s;\n  },executorService)).toArray(CompletableFuture[]::new);\n  System.out.println(\"main over\");\n  CompletableFuture<Void> voidCompletableFuture = CompletableFuture.allOf(futureList);\n  Void join = voidCompletableFuture.join();\n  System.out.println(\"all run over\");\n}\n/*\nmain over\ntest1执行完毕:a\ntest2执行完毕:b\ntest1执行完毕:c\ntest2执行完毕:d\nall run over\n*/\n```\n\n#### anyOf\n\n等待一组任意一个异步任务执行完毕","source":"_posts/java8/java8之CompletableFuture.md","raw":"---\ntitle: java8之CompletableFuture\ndate: 2017-08-05 12:58:46\ntags:\n- java8\n- 多线程\ncategories:\n- java基础\n---\n\n# java8之CompletableFuture\n\nCompletableFuture实现了Future接口，是jdk8新添加的对与并发编程的扩展支持。通过CompletableFuture可以方便的操作多个异步任务、执行结果的回调等操作。\n\n<!--more-->\n\n## CompletableFuture优点\n\njdk8之前的Future接口也可以构建异步任务，并且通过get()阻塞获取异步任务的结果。但是依然存在一些局限性，只能阻塞或者轮询去监控获取异步任务的结果，jdb8中的CompletableFuture实现了Future接口，同时扩展了异步编程中更多的需求\n\n- 可以再异步任务异常或者完成的时候回调通知监听者\n- 异步任务完成之后直接参与下个流程\n- 将两个异步任务合并为一个异步任务，其中的两个异步任务可以依次依赖执行，也可以同时执行\n- 仅获取多个异步任务中最快结束的任务返回结果\n- parallelStream使用默认的ForkJoinPool无法修改线程数，而CompletableFuture可以指定线程池，默认跟parallelStream用的是一样的线程池\n\n\n## 用法\n\njdk8之前使用futureTask创建一个有返回值的异步线程\n\n```java\nCallable callable = () -> 0d;\nFutureTask<Double> future = new FutureTask<Double>(callable);\nThread thread = new Thread(future);\nthread.start();\nSystem.out.println(future.get());\n```\n\njdk8提供了CompletableFuture，同样实现了future接口，可以通过以下方式创建一个带返回结果的异步任务\n\n```java\nCompletableFuture<Double> completableFuture = new CompletableFuture();\nThread thread = new Thread(() -> {\n  try {\n    double price = getPrice(product);\n    completableFuture.complete(price);\n  } catch (Exception e) {\n    //发生异常时，工作线程会被kill，使用future将异常传递给调用线程\n    completableFuture.completeExceptionally(e);\n  }\n});\nthread.start();\nSystem.out.println(completableFuture.get());\n```\n\nCompletableFuture提供了静态方法，直接创建异步任务，同时也可以指定线程池，如果不指定，默认使用ForkJoinPool.commonPool()\n\n- 创建不带返回结果的异步任务\n\n  ```java\n  public static CompletableFuture<Void> runAsync(Runnable runnable)\n  public static CompletableFuture<Void> runAsync(Runnable runnable,Executor executor)\n  ```\n\n- 创建带返回结果的异步任务\n\n  ```java\n  public static <U> CompletableFuture<U> supplyAsync(Supplier<U> supplier) \n  public static <U> CompletableFuture<U> supplyAsync(Supplier<U> supplier,Executor executor)\n  ```\n\n### 获取值\n\nCompletableFuture提供了多种获取异步任务返回值的方法\n\n\n```java\npublic T    get()  //阻塞等待直到有返回结果,抛出检查性异常\npublic T    get(long timeout, TimeUnit unit)  //阻塞等待指定时间,抛出检查性异常抛出非检查性异常\npublic T    getNow(T valueIfAbsent)  //如果结果已经计算完则返回结果或抛异常，否则返回给定的valueIfAbsent的值。\npublic T    join()  //阻塞等待直到有返回结果，抛出非检查性异常，当任务异常后，join会抛出RuntimeException,多次调用join会抛出CompletionException异常\n```\n\n### 状态检查\n\n可以通过isDone检查异步任务是否执行完毕，isCompletedExceptionally检查异步任务是否抛出异常结束\n\n```java\npublic boolean isDone()\npublic boolean isCompletedExceptionally()\n```\n\n### 异步链式\n\nCompletableFuture的异步链式方法都提供了三个类型\n\n- 同一线程:跟调用者CompletableFuture使用同一个线程\n- Async: 使用`ForkJoinPool.commonPool()`系统级公共线程池中的线程，默认是守护线程，(jvm退出守护线程即消亡)\n- Async+指定executor: 使用指定的线程池中的线程执行\n\n```java\nstatic {\n        int threadCount = 2;\n        AtomicInteger atomicInteger = new AtomicInteger(1);\n        executorService = Executors.newFixedThreadPool(threadCount, r -> {\n            Thread t = new Thread(Thread.currentThread().getThreadGroup(), r, \"test\"+atomicInteger.getAndIncrement());\n            t.setDaemon(false);\n            return t;\n        });\n    }\n```\n\n在执行一组异步操作的时候，一定不要将join和生成CompletableFuture的map放在一个链里面，不然会阻塞\n\n```java\npublic static void main(String[] args) throws InterruptedException {\n  List<String> parameters = Lists.newArrayList(\"a\",\"b\",\"c\",\"d\");\n  List<CompletableFuture> futureList = parameters.stream().map(s -> CompletableFuture.supplyAsync(() -> {\n    try {\n      Thread.currentThread().sleep(1000L);\n    } catch (InterruptedException e) {\n      e.printStackTrace();\n    }\n    System.out.println(Thread.currentThread().getName() + \"执行完毕:\" + s);\n    return s;\n  },executorService)).collect(Collectors.toList());\n  System.out.println(\"main over\");\n  //单独放在一个map链里面\n  futureList.stream().map(s -> s.join()).forEach(System.out::println);\n}\n```\n\n#### thenApply\n\n**等待异步返回结果，将异步返回的结果作为参数，执行function转换结果**。thenApply方法会跟异步任务使用同一个线程(异步任务很快的时候测试时用的main线程),Async方法会启用ForkJoinPool中的线程来执行function。如果不想用默认的ForkJoinPool，可以指定一个线程池。\n\n```java\npublic <U> CompletionStage<U> thenApply(Function<? super T,? extends U> fn);\npublic <U> CompletionStage<U> thenApplyAsync(Function<? super T,? extends U> fn);\npublic <U> CompletionStage<U> thenApplyAsync(Function<? super T,? extends U> fn,Executor executor);\n```\n\n```java\npublic static void main(String[] args) throws InterruptedException {\n  System.out.println(\"main start\");\n  CompletableFuture<String> future = CompletableFuture.supplyAsync(() -> {\n    System.out.println(Thread.currentThread().getName() + \": before first\");\n    try {\n      Thread.currentThread().sleep(1000);\n    } catch (InterruptedException e) {\n    }\n    System.out.println(Thread.currentThread().getName() + \": after first\");\n\n    return \"first\";\n  }, executorService).thenApplyAsync((s) -> {\n    System.out.println(Thread.currentThread().getName() + \": get \" + s);\n    return \"second\";\n  },executorService);\n  System.out.println(\"main over\");\n  String join = future.join();\n  System.out.println(String.format(\"future result %s\",join));\n}\n/*\nmain start\ntest1: before first\nmain over\ntest1: after first\ntest2: get first\nfuture result second\n*/\n```\n\n#### thenAccept\n\n等待异步返回结果，将异步返回的结果作为参数，执行consumer消耗结果。同thenApply一样，唯一不同的是该方法没有返回值，直接消费异步结果，不再需要阻塞主线程获取异步结果。\n\n```java\npublic CompletionStage<Void> thenAccept(Consumer<? super T> action);\npublic CompletionStage<Void> thenAcceptAsync(Consumer<? super T> action);\npublic CompletionStage<Void> thenAcceptAsync(Consumer<? super T> action,Executor executor);\n```\n\n#### thenRun\n\n等待异步返回结果，然后执行任务。同thenApply一样，唯一不同的是该方法等待异步任务执行完毕后执行自己的任务。\n\n```java\npublic CompletionStage<Void> thenRun(Runnable action);\npublic CompletionStage<Void> thenRunAsync(Runnable action);\npublic CompletionStage<Void> thenRunAsync(Runnable action,Executor executor);\n```\n\n#### thenCompose\n\n合并两个异步操作。等待第一个异步任务执行完毕，将结果作为第二个异步任务的参数来执行第二个异步任务\n\n```java\npublic <U> CompletableFuture<U> thenCompose(Function<? super T, ? extends CompletionStage<U>> fn)\npublic <U> CompletableFuture<U> thenComposeAsync(Function<? super T, ? extends CompletionStage<U>> fn)\npublic <U> CompletableFuture<U> thenComposeAsync(Function<? super T, ? extends CompletionStage<U>> fn,public <U> CompletableFuture<U> thenComposeAsync(Function<? super T, ? extends CompletionStage<U>> fn))\n```\n\n#### thenCombine\n\n合并两个异步操作。同时执行两个异步操作，等待两个都执行完毕后将两个异步操作的结果合并转换后返回一个future，调用join方法获取结果。\n\n```java\npublic <U,V> CompletionStage<V> thenCombine(CompletionStage<? extends U> other,BiFunction<? super T,? super U,? extends V> fn);\npublic <U,V> CompletionStage<V> thenCombineAsync(CompletionStage<? extends U> other,BiFunction<? super T,? super U,? extends V> fn);\npublic <U,V> CompletionStage<V> thenCombineAsync(CompletionStage<? extends U> other,BiFunction<? super T,? super U,? extends V> fn,Executor executor);\n```\n\n```java\npublic static void main(String[] args) throws InterruptedException {\n  System.out.println(\"main start\");\n  CompletableFuture<String> future = CompletableFuture.supplyAsync(() -> {\n    System.out.println(Thread.currentThread().getName() + \": before first\");\n    try {\n      Thread.currentThread().sleep(1000);\n    } catch (InterruptedException e) {\n    }\n    System.out.println(Thread.currentThread().getName() + \": after first\");\n\n    return \"first\";\n  }, executorService).thenCombineAsync(CompletableFuture.supplyAsync(() -> {\n    System.out.println(Thread.currentThread().getName() + \": before second\");\n    try {\n      Thread.currentThread().sleep(2000);\n    } catch (InterruptedException e) {\n    }\n    System.out.println(Thread.currentThread().getName() + \": after second\");\n\n    return \"second\";\n  },executorService), (s1, s2) ->  s1 + \":\" + s2);\n  System.out.println(\"main over\");\n  String join = future.join();\n  System.out.println(String.format(\"future result %s\",join));\n}\n/*\nmain start\ntest1: before first\ntest1: after first\nmain over\ntest2: get first\nfuture result second\n*/\n```\n\n#### thenAcceptBoth\n\n合并两个异步操作,同thenCombine一样，唯一不同是该方法直接消费两个异步任务的结果，不再需要阻塞主线程获取异步结果\n\n```java\npublic <U> CompletionStage<Void> thenAcceptBoth(CompletionStage<? extends U> other,BiConsumer<? super T, ? super U> action);\npublic <U> CompletionStage<Void> thenAcceptBothAsync(CompletionStage<? extends U> other,BiConsumer<? super T, ? super U> action);\npublic <U> CompletionStage<Void> thenAcceptBothAsync(CompletionStage<? extends U> other,BiConsumer<? super T, ? super U> action,     Executor executor);\n```\n\n#### runAfterBoth\n\n合并两个异步操作,同thenCombine一样，唯一不同是该方法等待两个异步任务执行完毕后，执行自己的任务\n\n```java\npublic CompletionStage<Void> runAfterBoth(CompletionStage<?> other,Runnable action);\npublic CompletionStage<Void> runAfterBothAsync(CompletionStage<?> other,Runnable action);\npublic CompletionStage<Void> runAfterBothAsync(CompletionStage<?> other,Runnable action,Executor executor);\n```\n\n#### applyToEither\n\n两个异步操作，任意一个返回结果，再调用join的时候就返回接口，其中一个未执行完毕的任务会继续执行\n\n```java\npublic <U> CompletionStage<U> applyToEither(CompletionStage<? extends T> other,Function<? super T, U> fn);\npublic <U> CompletionStage<U> applyToEitherAsync(CompletionStage<? extends T> other,Function<? super T, U> fn);\npublic <U> CompletionStage<U> applyToEitherAsync(CompletionStage<? extends T> other,Function<? super T, U> fn,Executor executor);\n```\n\n```java\npublic static void main(String[] args) throws InterruptedException {\n  System.out.println(\"main start\");\n  CompletableFuture<String> future = CompletableFuture.supplyAsync(() -> {\n    System.out.println(Thread.currentThread().getName() + \": before first\");\n    try {\n      Thread.currentThread().sleep(1000);\n    } catch (InterruptedException e) {\n    }\n    System.out.println(Thread.currentThread().getName() + \": after first\");\n\n    return \"first\";\n  }, executorService).applyToEitherAsync(CompletableFuture.supplyAsync(() -> {\n    System.out.println(Thread.currentThread().getName() + \": before second\");\n    try {\n      Thread.currentThread().sleep(2000);\n    } catch (InterruptedException e) {\n    }\n    System.out.println(Thread.currentThread().getName() + \": after second\");\n\n    return \"second\";\n  }, executorService), (s) -> s);\n  System.out.println(\"main over\");\n  String join = future.join();\n  System.out.println(String.format(\"future result %s\",join));\n}\n/*\nmain start\ntest1: before first\ntest2: before second\nmain over\ntest1: after first\nfuture result first\ntest2: after second\n*/\n```\n\n#### acceptEither\n\n同理acceptEither\n\n```java\npublic CompletionStage<Void> acceptEither(CompletionStage<? extends T> other,Consumer<? super T> action);\npublic CompletionStage<Void> acceptEitherAsync(CompletionStage<? extends T> other,Consumer<? super T> action);\npublic CompletionStage<Void> acceptEitherAsync(CompletionStage<? extends T> other,Consumer<? super T> action,Executor executor);\n```\n\n#### runAfterEither\n\n同理runAfterEither，两个异步任务任意一个执行完毕就执行 runAfterEither 参数中的任务\n\n```java\npublic CompletionStage<Void> runAfterEither(CompletionStage<?> other,Runnable action);\npublic CompletionStage<Void> runAfterEitherAsync(CompletionStage<?> other,Runnable action);\npublic CompletionStage<Void> runAfterEitherAsync(CompletionStage<?> other,Runnable action,Executor executor);\n```\n\n#### exceptionally\n\n异常处理，当异步任务出现异常的时候处理方式,相当于 try-catch-finnaly中的catch，**可以调用程序指定的回调函数，通知外界执行异常**\n\n```java\npublic CompletionStage<T> exceptionally(Function<Throwable, ? extends T> fn);\n```\n\n#### whenComplete\n\n try-catch-finnaly中的finnaly在返回结果前执行,接收两个参数，result和exception,一种是正常执行，返回值。另外一种是遇到异常抛出造成程序的中断，**可以调用程序指定的回调函数，通知外界执行完毕**\n\n```java\npublic CompletionStage<T> whenComplete(BiConsumer<? super T, ? super Throwable> action);\npublic CompletionStage<T> whenCompleteAsync(BiConsumer<? super T, ? super Throwable> action);\npublic CompletionStage<T> whenCompleteAsync(BiConsumer<? super T, ? super Throwable> action,Executor executor);\n```\n\n```java\npublic static void main(String[] args) throws InterruptedException {\n  System.out.println(\"main start\");\n  CompletableFuture<String> future = CompletableFuture.supplyAsync(() -> {\n    System.out.println(Thread.currentThread().getName() + \": before first\");\n    try {\n      Thread.currentThread().sleep(1000);\n    } catch (InterruptedException e) {\n    }\n    if(1 == 1) {\n      throw new RuntimeException(\"fff\");\n    }\n    System.out.println(Thread.currentThread().getName() + \": after first\");\n    return \"first\";\n  }, executorService).exceptionally(e -> {\n    System.out.println(\"异常：\"+e.getMessage());\n    return \"exception\";\n  }).whenComplete((r,e) -> {\n    System.out.println(\"finnaly result:\"+(r!=null?r:\"\"));\n    System.out.println(\"finnaly exception:\"+(e!=null?e.getMessage():\"\"));\n  });\n  System.out.println(\"main over\");\n  String join = future.join();\n  System.out.println(String.format(\"future result %s\",join));\n}\n/*\nmain start\ntest1: before first\nmain over\n异常：java.lang.RuntimeException: fff\nfinnaly result:exception\nfinnaly exception:\nfuture result exception\n*/\n```\n\n#### handle\n\n运行完成时，对结果的处理，跟whenComplete一样，不过调用该方法会有返回值。\n\n```java\npublic <U> CompletionStage<U> handle(BiFunction<? super T, Throwable, ? extends U> fn);\npublic <U> CompletionStage<U> handleAsync(BiFunction<? super T, Throwable, ? extends U> fn);\npublic <U> CompletionStage<U> handleAsync(BiFunction<? super T, Throwable, ? extends U> fn,Executor executor);\n```\n\n#### allOf\n\n等待一组异步任务都执行完毕\n\n```java\npublic static void main(String[] args) throws InterruptedException {\n  List<String> parameters = Lists.newArrayList(\"a\",\"b\",\"c\",\"d\");\n  CompletableFuture[] futureList = parameters.stream().map(s -> CompletableFuture.supplyAsync(() -> {\n    try {\n      Thread.currentThread().sleep(1000L);\n    } catch (InterruptedException e) {\n      e.printStackTrace();\n    }\n    System.out.println(Thread.currentThread().getName() + \"执行完毕:\" + s);\n    return s;\n  },executorService)).toArray(CompletableFuture[]::new);\n  System.out.println(\"main over\");\n  CompletableFuture<Void> voidCompletableFuture = CompletableFuture.allOf(futureList);\n  Void join = voidCompletableFuture.join();\n  System.out.println(\"all run over\");\n}\n/*\nmain over\ntest1执行完毕:a\ntest2执行完毕:b\ntest1执行完毕:c\ntest2执行完毕:d\nall run over\n*/\n```\n\n#### anyOf\n\n等待一组任意一个异步任务执行完毕","slug":"java8/java8之CompletableFuture","published":1,"updated":"2018-09-12T03:03:21.821Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnh8003fwlkv1d3b46cy"},{"title":"java8之Optional","date":"2017-08-05T03:58:46.000Z","_content":"\n#  java8之Optional\n\n开发过程中最常遇到的是空指针异常，jdk8对空指针进行了再次处理，Optional类就是一个简单的容器，可以通过`isPresent()`方法判断是否为空，然后通过`get()`方法返回容器中对象，但是这样用跟判断空没什么区别，Optional提供了一些其他的方法，可以避免这种判断\n\n<!--more-->\n\n## Optional实现\n\nOptional是一个值容器。在Optional对象中维护了一个泛型类型的值\n\n```java\npublic final class Optional<T> {\n    /**\n     * Common instance for {@code empty()}.\n     */\n    private static final Optional<?> EMPTY = new Optional<>();\n\n    /**\n     * If non-null, the value; if null, indicates no value is present\n     */\n    private final T value;\n\n    private Optional() {\n        this.value = null;\n    }\n  \tprivate Optional(T value) {\n        this.value = Objects.requireNonNull(value);\n    }\n}\n\n```\n\n## Optional用法\n\n以下列出了Optional中的API用法\n\n```java\n//创建Optional实例，of方法必须不能为空\nOptional<String> name = Optional.of(\"Sanaulla\");\n\n//创建没有值的Optional实例，例如值为'null'\nOptional empty = Optional.ofNullable(null);\n//创建空的Optional\n//Optional empty = Optional.empty();\n\n//isPresent方法用来检查Optional实例是否有值。\nif (name.isPresent()) {\n  //调用get()返回Optional值。\n  System.out.println(name.get());\n}\n\ntry {\n  //在Optional实例上调用get()抛出NoSuchElementException。\n  System.out.println(empty.get());\n} catch (NoSuchElementException ex) {\n  System.out.println(ex.getMessage());\n}\n\n//ifPresent方法接受lambda表达式参数。\n//如果Optional值不为空，lambda表达式会处理并在其上执行操作。\nname.ifPresent((value) -> {\n  System.out.println(\"The length of the value is: \" + value.length());\n});\n\n//如果有值orElse方法会返回Optional实例，否则返回传入的错误信息。\nSystem.out.println(empty.orElse(\"There is no value present!\"));\nSystem.out.println(name.orElse(\"There is some value!\"));\n\n//orElseGet与orElse类似，区别在于传入的默认值。orElseGet接受lambda表达式生成默认值。只有当option中值真正为空的时候才会调用，是orElse的一种延迟实现\nSystem.out.println(empty.orElseGet(() -> \"Default Value\"));\nSystem.out.println(name.orElseGet(() -> \"Default Value\"));\n\ntry {\n  //orElseThrow与orElse方法类似，区别在于返回值。\n  //orElseThrow抛出由传入的lambda表达式/方法生成异常。\n  empty.orElseThrow(RuntimeException::new);\n} catch (Throwable ex) {\n  System.out.println(ex.getMessage());\n}\n\n//map方法通过传入的lambda表达式修改Optonal实例默认值。\n//lambda表达式返回值会包装为Optional实例。\nOptional<String> upperName = name.map((value) -> value.toUpperCase());\nSystem.out.println(upperName.orElse(\"No value found\"));\n\n//flatMap与map（Funtion）非常相似，区别在于lambda表达式的返回值。\n//map方法的lambda表达式返回值可以是任何类型，但是返回值会包装成Optional实例。\n//但是flatMap方法的lambda返回值总是Optional类型。\n//如果值存在，就对该值执行提供的 mapping 函数调用， 返回一个 Optional 类型的值 ， 则就返回一个空的 Optional 对象\nupperName = name.flatMap((value) -> Optional.of(value.toUpperCase()));\nSystem.out.println(upperName.orElse(\"No value found\"));\n\n//filter方法检查Optiona值是否满足给定条件。\n//如果满足返回Optional实例值，否则返回空Optional。\nOptional<String> longName = name.filter((value) -> value.length() > 6);\nSystem.out.println(longName.orElse(\"The name is less than 6 characters\"));\n\n//另一个示例，Optional值不满足给定条件。\nOptional<String> anotherName = Optional.of(\"Sana\");\nOptional<String> shortName = anotherName.filter((value) -> value.length() > 6);\nSystem.out.println(shortName.orElse(\"The name is less than 6 characters\"));\n\n//Optional的map方法接收一个function作为参数，修改Optional的值\nOptional<Integer> mapValue = Optional.of(-1);\nOptional<Integer> expectValue = mapValue.map(s -> Math.abs(s));\nSystem.out.println(expectValue.get());\n```\n\n\n\n","source":"_posts/java8/java8之Optional.md","raw":"---\ntitle: java8之Optional\ndate: 2017-08-05 11:58:46\ntags:\n- java8\ncategories:\n- java基础\n---\n\n#  java8之Optional\n\n开发过程中最常遇到的是空指针异常，jdk8对空指针进行了再次处理，Optional类就是一个简单的容器，可以通过`isPresent()`方法判断是否为空，然后通过`get()`方法返回容器中对象，但是这样用跟判断空没什么区别，Optional提供了一些其他的方法，可以避免这种判断\n\n<!--more-->\n\n## Optional实现\n\nOptional是一个值容器。在Optional对象中维护了一个泛型类型的值\n\n```java\npublic final class Optional<T> {\n    /**\n     * Common instance for {@code empty()}.\n     */\n    private static final Optional<?> EMPTY = new Optional<>();\n\n    /**\n     * If non-null, the value; if null, indicates no value is present\n     */\n    private final T value;\n\n    private Optional() {\n        this.value = null;\n    }\n  \tprivate Optional(T value) {\n        this.value = Objects.requireNonNull(value);\n    }\n}\n\n```\n\n## Optional用法\n\n以下列出了Optional中的API用法\n\n```java\n//创建Optional实例，of方法必须不能为空\nOptional<String> name = Optional.of(\"Sanaulla\");\n\n//创建没有值的Optional实例，例如值为'null'\nOptional empty = Optional.ofNullable(null);\n//创建空的Optional\n//Optional empty = Optional.empty();\n\n//isPresent方法用来检查Optional实例是否有值。\nif (name.isPresent()) {\n  //调用get()返回Optional值。\n  System.out.println(name.get());\n}\n\ntry {\n  //在Optional实例上调用get()抛出NoSuchElementException。\n  System.out.println(empty.get());\n} catch (NoSuchElementException ex) {\n  System.out.println(ex.getMessage());\n}\n\n//ifPresent方法接受lambda表达式参数。\n//如果Optional值不为空，lambda表达式会处理并在其上执行操作。\nname.ifPresent((value) -> {\n  System.out.println(\"The length of the value is: \" + value.length());\n});\n\n//如果有值orElse方法会返回Optional实例，否则返回传入的错误信息。\nSystem.out.println(empty.orElse(\"There is no value present!\"));\nSystem.out.println(name.orElse(\"There is some value!\"));\n\n//orElseGet与orElse类似，区别在于传入的默认值。orElseGet接受lambda表达式生成默认值。只有当option中值真正为空的时候才会调用，是orElse的一种延迟实现\nSystem.out.println(empty.orElseGet(() -> \"Default Value\"));\nSystem.out.println(name.orElseGet(() -> \"Default Value\"));\n\ntry {\n  //orElseThrow与orElse方法类似，区别在于返回值。\n  //orElseThrow抛出由传入的lambda表达式/方法生成异常。\n  empty.orElseThrow(RuntimeException::new);\n} catch (Throwable ex) {\n  System.out.println(ex.getMessage());\n}\n\n//map方法通过传入的lambda表达式修改Optonal实例默认值。\n//lambda表达式返回值会包装为Optional实例。\nOptional<String> upperName = name.map((value) -> value.toUpperCase());\nSystem.out.println(upperName.orElse(\"No value found\"));\n\n//flatMap与map（Funtion）非常相似，区别在于lambda表达式的返回值。\n//map方法的lambda表达式返回值可以是任何类型，但是返回值会包装成Optional实例。\n//但是flatMap方法的lambda返回值总是Optional类型。\n//如果值存在，就对该值执行提供的 mapping 函数调用， 返回一个 Optional 类型的值 ， 则就返回一个空的 Optional 对象\nupperName = name.flatMap((value) -> Optional.of(value.toUpperCase()));\nSystem.out.println(upperName.orElse(\"No value found\"));\n\n//filter方法检查Optiona值是否满足给定条件。\n//如果满足返回Optional实例值，否则返回空Optional。\nOptional<String> longName = name.filter((value) -> value.length() > 6);\nSystem.out.println(longName.orElse(\"The name is less than 6 characters\"));\n\n//另一个示例，Optional值不满足给定条件。\nOptional<String> anotherName = Optional.of(\"Sana\");\nOptional<String> shortName = anotherName.filter((value) -> value.length() > 6);\nSystem.out.println(shortName.orElse(\"The name is less than 6 characters\"));\n\n//Optional的map方法接收一个function作为参数，修改Optional的值\nOptional<Integer> mapValue = Optional.of(-1);\nOptional<Integer> expectValue = mapValue.map(s -> Math.abs(s));\nSystem.out.println(expectValue.get());\n```\n\n\n\n","slug":"java8/java8之Optional","published":1,"updated":"2018-09-12T03:03:21.821Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnh9003iwlkvyorqkcn9"},{"title":"java8之lambda表达式","date":"2017-08-05T00:58:46.000Z","_content":"\n# java8之lambda表达式\n\n为了使方法更加的灵活，可以将行为作为参数传递，这样就需要用到匿名内部类，为了简化匿名内部类的书写，jdk8推出了lambda表达式，lambda表达式基本上就是一个只有一个抽象方法的匿名内部类对象，通过使用lambda表达式能够使代码更加的简洁。\n\n<!--more-->\n\n## lambda语法\n\nlambda表达式格式常见的有两种 **(parameters) -> expression**，**(parameters) -> { statements; }**主要包括三个方面\n\n- 参数列表：有时可以省略参数的类型\n- 箭头：用于分隔参数列表和方法体\n- lambda主体(方法体)：当有返回值并且只有一行方法体的时候可以省略 return和{} (**必须同时省略return和{}**)\n\n例如使用lambda表达式可以简化匿名内部类\n\n```java\n//传统的使用匿名内部类\nComparator<String> cpr1 = new Comparator<String>() {\n  @Override\n  public int compare(String o1, String o2) {\n    return 0;\n  }\n};\n//使用lambada表达式,当有返回值并且只有一行方法体的时候可以省略 return和{}\nComparator<String> cpr2 = (String o1,String o2) -> o1.compareTo(o2);\n```\n\n## 方法引用\n\n方法引用语法格式有以下四种：\n\n```java\nobjectName::instanceMethod//把lambda表达式的参数直接当成instanceMethod的参数来调用。比如System.out::println等同于x->System.out.println(x)\nClassName::staticMethod//把lambda表达式的参数直接当成staticMethod的参数来调用。比如Math::max等同于(x, y)->Math.max(x,y)\nClassName::instanceMethod //把lambda表达式的第一个参数当成instanceMethod的调用对象，其他剩余参数当成该方法的参数。比如String::toLowerCase等同于x->x.toLowerCase()\nClassName::new //把lambda表达式的参数当成ClassName构造器的参数 。例如BigDecimal::new等同于x->new BigDecimal(x)\n```\n\n## lambda与匿名内部类\n\n匿名类和Lambda表达式中的this和super的含义是不同的。\n\n- 在匿名类中，this代表的是匿名类自身，匿名类可以覆盖外部类的变量，匿名内部类只能访问final修改的变量\n- 在Lambda中，this指的是声明lambda表达式的外部对象。Lambda表达式不能覆盖外部类的变量。lambda表达式隐式的将使用的外部变量定义为final。\n\n","source":"_posts/java8/java8之lambda表达式.md","raw":"---\ntitle: java8之lambda表达式\ndate: 2017-08-05 08:58:46\ntags:\n- java8\ncategories:\n- java基础\n---\n\n# java8之lambda表达式\n\n为了使方法更加的灵活，可以将行为作为参数传递，这样就需要用到匿名内部类，为了简化匿名内部类的书写，jdk8推出了lambda表达式，lambda表达式基本上就是一个只有一个抽象方法的匿名内部类对象，通过使用lambda表达式能够使代码更加的简洁。\n\n<!--more-->\n\n## lambda语法\n\nlambda表达式格式常见的有两种 **(parameters) -> expression**，**(parameters) -> { statements; }**主要包括三个方面\n\n- 参数列表：有时可以省略参数的类型\n- 箭头：用于分隔参数列表和方法体\n- lambda主体(方法体)：当有返回值并且只有一行方法体的时候可以省略 return和{} (**必须同时省略return和{}**)\n\n例如使用lambda表达式可以简化匿名内部类\n\n```java\n//传统的使用匿名内部类\nComparator<String> cpr1 = new Comparator<String>() {\n  @Override\n  public int compare(String o1, String o2) {\n    return 0;\n  }\n};\n//使用lambada表达式,当有返回值并且只有一行方法体的时候可以省略 return和{}\nComparator<String> cpr2 = (String o1,String o2) -> o1.compareTo(o2);\n```\n\n## 方法引用\n\n方法引用语法格式有以下四种：\n\n```java\nobjectName::instanceMethod//把lambda表达式的参数直接当成instanceMethod的参数来调用。比如System.out::println等同于x->System.out.println(x)\nClassName::staticMethod//把lambda表达式的参数直接当成staticMethod的参数来调用。比如Math::max等同于(x, y)->Math.max(x,y)\nClassName::instanceMethod //把lambda表达式的第一个参数当成instanceMethod的调用对象，其他剩余参数当成该方法的参数。比如String::toLowerCase等同于x->x.toLowerCase()\nClassName::new //把lambda表达式的参数当成ClassName构造器的参数 。例如BigDecimal::new等同于x->new BigDecimal(x)\n```\n\n## lambda与匿名内部类\n\n匿名类和Lambda表达式中的this和super的含义是不同的。\n\n- 在匿名类中，this代表的是匿名类自身，匿名类可以覆盖外部类的变量，匿名内部类只能访问final修改的变量\n- 在Lambda中，this指的是声明lambda表达式的外部对象。Lambda表达式不能覆盖外部类的变量。lambda表达式隐式的将使用的外部变量定义为final。\n\n","slug":"java8/java8之lambda表达式","published":1,"updated":"2018-09-12T03:03:21.822Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnha003lwlkvppmwcqfi"},{"title":"java8之Stream流","date":"2017-08-05T01:58:46.000Z","_content":"\n# java8之Stream流\n\nStream是java8的新特性之一，为了方便操作集合类数据结构，结合lambda表达式能够更好的处理集合的遍历、查询、映射、聚合等操作。\n\n<!--more-->\n\n## 原理\n\n### 流的工作过程\n\n- 一个数据源(如集合)来执行一个查询;\n- 多个中间操作链，形成一条流的流水线;\n- 一个终端操作，执行流水线，并能生成结果。\n\n### 特点\n\n- 数据源可以是无限，但是不存储任何数据\n- 流只能遍历一次，遍历完后，流就被关闭了，如果要再次遍历，需要重新获取一下\n- 支持并行，充分利用计算机多核CPU的特性\n\n### 操作类型：\n\n- **Intermediate**：一个流可以后面跟随零个或多个 intermediate 操作。其目的主要是打开流，做出某种程度的数据映射/过滤，然后返回一个新的流，交给下一个操作使用。这类操作都是**惰性化**的，就是说，仅仅调用到这类方法，并没有真正开始流的遍历。\n- **Terminal**：一个流只能有一个 terminal 操作，当这个操作执行后，流就关闭了，无法再被操作。所以这必定是流的最后一个操作。Terminal 操作的执行，才会真正开始流的遍历，并且会生成一个结果。\n\n注意:**流是从一串中间操作到一个终端操作为一个循环执行，然后再从第一个中间操作开始循环流中的元素，而不是每个中间操作遍历完后再遍历下一个中间操作。**\n\n### 并行(paralleStream)\n\n- jdk8可以充分利用多核CPU的特性，实现并行处理。在使用流的时候调用**.paralle()**就可以获取一个并行流\n- 并行流内部默认使用**ForkJoinPool**，默认的线程数量就是处理器的数量，这个值由Runtime.getRuntime().availableProcessors()得到的。**可 以 通 过 java.util.concurrent.ForkJoinPool.common. parallelism来改变线程大小**\n- 在使用并行流的时候，一定要保证操作是无状态的，不然会遇到一些不可知的问题\n- 影响并行流性能的五要素是：数据大小、源数据结构、值是否装箱、可用的 CPU 核数量，以及处理每个元素所花的时间 \n\n### 基本类型流\n\n在对包装类型操作时，存在着大量的拆箱和装箱操作，为了避免拆装箱的成本，jdk8提供了一些专门处理基本类型的流，如IntStream、DoubleStream、LongStream，可以通过Stream的**mapToInt()**、**mapToDouble()**、**mapToLong()**方法得到，再操作完基本类型后，可以调用基本类型流的 **boxed()** 方法转换为对象流\n\n## 创建流\n\n```Java\n1. 由值创建流：Stream.of(\"a\",\"b\");\n2. 由数组创建流：int[] numbers = {1,2,3};Arrays.stream(numbers);\n3. 由文件创建流：java.io.BufferedReader.lines()\n4. Stream.iterate(0, n -> n + 2).limit(10)  \n5. 通过接收一个supplier创建：Stream.generate(Math::random).limit(10)  \n6. 通过集合创建: list.stream()\n7. 基本类型范围创建：IntStream evenNumbers = IntStream.rangeClosed(1, 100)//从1到100\nIntStream evenNumbers = IntStream.range(1, 100)//从1到99\n```\n\n### 语句例子\n\n- Peek可以使用peek来进行调试\n\n  ```java\n  List<Integer> result =numbers.stream() \n       .peek(x ->System.out.println(\"from stream: \" + x))\n       .map(x -> x + 17)\n       .peek(x -> System.out.println(\"after map: \" + x))\n       .filter(x -> x % 2 == 0)\n       .peek(x -> System.out.println(\"after filter: \" + x))\n       .limit(3)\n       .peek(x -> System.out.println(\"after limit: \" + x))\n       .collect(toList());\n  ```\n\n\n- 双层for循环 (flatMap 用于将映射后的多个流合并成一个流,即扁平化流,用于处理返回值是Stream的东东)\n\n  ```java\n  List<Integer> numbers1 = Arrays.asList(1, 2);\n  List<Integer> numbers2 = Arrays.asList(3, 4);\n  List<int[]> pairs =numbers1.stream().flatMap(\n    i ->numbers2.stream().map(j -> new int[]{i, j})\n  ).collect(Collectors.toList());\n   //其结果是[(1, 3),(1, 4),(2,3),(2,4)]。\n  ```\n\n- 聚合\n\n  ```java\n  List<Integer> list = new ArrayList<Integer>();\n  List<Integer> reduce = Stream.of(1, 2, 3, 4).reduce(list, (List<Integer> a, Integer x) -> {\n    a.add(x);\n    return a;\n  }, new BinaryOperator<List<Integer>>() {\n    @Override\n    public List<Integer> apply(List<Integer> integers, List<Integer> integers2) {\n      //\t\t\t\tintegers.addAll(integers2);\n      return integers;\n    }\n  });\n  System.out.println(reduce);//[1, 2, 3, 4]\n\n  int reduce = IntStream.range(1, 10).reduce(0, (s1, s2) -> s1 + s2);//45\n  ```\n\n- 根据对象中的某个属性去重,\n\n  ```java\n  List<Person> list = Lists.newArrayList(p1,p2,p3,p4,p5);\n  List<Person> uniqueList = list.stream().collect(Collectors.collectingAndThen(\n                  Collectors.toCollection(() -> new TreeSet<>((s1,s2)->{\n                    \t//名称相同的时候 数量+1\n                      if(s1.getName().equals(s2.getName())&&s1!=s2){\n                          s2.setCount(s1.getCount()+s2.getCount());\n                      }\n                    \t//根据Person对象中的name去重\n                      return s1.getName().compareTo(s2.getName());\n                  })), ArrayList::new));\n  ```\n\n- list和array之间的互转\n\n  ```java\n  List<String> l = Lists.newArrayList(\"a\",\"b\",\"c\");\n  String[] array = l.stream().toArray(String[]::new);\n  List<String> l2 = Stream.of(array).collect(Collectors.toList());\n  ```\n\n- 排序、取最大、最小值\n\n  ```java\n  Stream<String> sortedStream = stream.sorted(String::compareTo);\n  Optional maxOptionnal = stream.min(String::compareTo);\n  IntStream.range(1,10).max();\n  ```\n\n- 过滤\n\n  ```java\n  List<String> ll = Lists.newArrayList(\"a\",\"\",\"b\");\n  ll.stream().filter(StringUtils::isNotBlank).collect(Collectors.toList());\n  ```\n\n- anyMatch、allMatch、noneMatch\n\n  ```java\n  boolean b = IntStream.of(1, 3, 5, 8, 10).anyMatch((s) -> s % 3 == 0);\n  ```\n\n\n## 参考\n\n[Java 8 中的 Streams API 详解](https://www.ibm.com/developerworks/cn/java/j-lo-java8streamapi/)","source":"_posts/java8/java8之Stream流.md","raw":"---\ntitle: java8之Stream流\ndate: 2017-08-05 09:58:46\ntags:\n- java8\ncategories:\n- java基础\n---\n\n# java8之Stream流\n\nStream是java8的新特性之一，为了方便操作集合类数据结构，结合lambda表达式能够更好的处理集合的遍历、查询、映射、聚合等操作。\n\n<!--more-->\n\n## 原理\n\n### 流的工作过程\n\n- 一个数据源(如集合)来执行一个查询;\n- 多个中间操作链，形成一条流的流水线;\n- 一个终端操作，执行流水线，并能生成结果。\n\n### 特点\n\n- 数据源可以是无限，但是不存储任何数据\n- 流只能遍历一次，遍历完后，流就被关闭了，如果要再次遍历，需要重新获取一下\n- 支持并行，充分利用计算机多核CPU的特性\n\n### 操作类型：\n\n- **Intermediate**：一个流可以后面跟随零个或多个 intermediate 操作。其目的主要是打开流，做出某种程度的数据映射/过滤，然后返回一个新的流，交给下一个操作使用。这类操作都是**惰性化**的，就是说，仅仅调用到这类方法，并没有真正开始流的遍历。\n- **Terminal**：一个流只能有一个 terminal 操作，当这个操作执行后，流就关闭了，无法再被操作。所以这必定是流的最后一个操作。Terminal 操作的执行，才会真正开始流的遍历，并且会生成一个结果。\n\n注意:**流是从一串中间操作到一个终端操作为一个循环执行，然后再从第一个中间操作开始循环流中的元素，而不是每个中间操作遍历完后再遍历下一个中间操作。**\n\n### 并行(paralleStream)\n\n- jdk8可以充分利用多核CPU的特性，实现并行处理。在使用流的时候调用**.paralle()**就可以获取一个并行流\n- 并行流内部默认使用**ForkJoinPool**，默认的线程数量就是处理器的数量，这个值由Runtime.getRuntime().availableProcessors()得到的。**可 以 通 过 java.util.concurrent.ForkJoinPool.common. parallelism来改变线程大小**\n- 在使用并行流的时候，一定要保证操作是无状态的，不然会遇到一些不可知的问题\n- 影响并行流性能的五要素是：数据大小、源数据结构、值是否装箱、可用的 CPU 核数量，以及处理每个元素所花的时间 \n\n### 基本类型流\n\n在对包装类型操作时，存在着大量的拆箱和装箱操作，为了避免拆装箱的成本，jdk8提供了一些专门处理基本类型的流，如IntStream、DoubleStream、LongStream，可以通过Stream的**mapToInt()**、**mapToDouble()**、**mapToLong()**方法得到，再操作完基本类型后，可以调用基本类型流的 **boxed()** 方法转换为对象流\n\n## 创建流\n\n```Java\n1. 由值创建流：Stream.of(\"a\",\"b\");\n2. 由数组创建流：int[] numbers = {1,2,3};Arrays.stream(numbers);\n3. 由文件创建流：java.io.BufferedReader.lines()\n4. Stream.iterate(0, n -> n + 2).limit(10)  \n5. 通过接收一个supplier创建：Stream.generate(Math::random).limit(10)  \n6. 通过集合创建: list.stream()\n7. 基本类型范围创建：IntStream evenNumbers = IntStream.rangeClosed(1, 100)//从1到100\nIntStream evenNumbers = IntStream.range(1, 100)//从1到99\n```\n\n### 语句例子\n\n- Peek可以使用peek来进行调试\n\n  ```java\n  List<Integer> result =numbers.stream() \n       .peek(x ->System.out.println(\"from stream: \" + x))\n       .map(x -> x + 17)\n       .peek(x -> System.out.println(\"after map: \" + x))\n       .filter(x -> x % 2 == 0)\n       .peek(x -> System.out.println(\"after filter: \" + x))\n       .limit(3)\n       .peek(x -> System.out.println(\"after limit: \" + x))\n       .collect(toList());\n  ```\n\n\n- 双层for循环 (flatMap 用于将映射后的多个流合并成一个流,即扁平化流,用于处理返回值是Stream的东东)\n\n  ```java\n  List<Integer> numbers1 = Arrays.asList(1, 2);\n  List<Integer> numbers2 = Arrays.asList(3, 4);\n  List<int[]> pairs =numbers1.stream().flatMap(\n    i ->numbers2.stream().map(j -> new int[]{i, j})\n  ).collect(Collectors.toList());\n   //其结果是[(1, 3),(1, 4),(2,3),(2,4)]。\n  ```\n\n- 聚合\n\n  ```java\n  List<Integer> list = new ArrayList<Integer>();\n  List<Integer> reduce = Stream.of(1, 2, 3, 4).reduce(list, (List<Integer> a, Integer x) -> {\n    a.add(x);\n    return a;\n  }, new BinaryOperator<List<Integer>>() {\n    @Override\n    public List<Integer> apply(List<Integer> integers, List<Integer> integers2) {\n      //\t\t\t\tintegers.addAll(integers2);\n      return integers;\n    }\n  });\n  System.out.println(reduce);//[1, 2, 3, 4]\n\n  int reduce = IntStream.range(1, 10).reduce(0, (s1, s2) -> s1 + s2);//45\n  ```\n\n- 根据对象中的某个属性去重,\n\n  ```java\n  List<Person> list = Lists.newArrayList(p1,p2,p3,p4,p5);\n  List<Person> uniqueList = list.stream().collect(Collectors.collectingAndThen(\n                  Collectors.toCollection(() -> new TreeSet<>((s1,s2)->{\n                    \t//名称相同的时候 数量+1\n                      if(s1.getName().equals(s2.getName())&&s1!=s2){\n                          s2.setCount(s1.getCount()+s2.getCount());\n                      }\n                    \t//根据Person对象中的name去重\n                      return s1.getName().compareTo(s2.getName());\n                  })), ArrayList::new));\n  ```\n\n- list和array之间的互转\n\n  ```java\n  List<String> l = Lists.newArrayList(\"a\",\"b\",\"c\");\n  String[] array = l.stream().toArray(String[]::new);\n  List<String> l2 = Stream.of(array).collect(Collectors.toList());\n  ```\n\n- 排序、取最大、最小值\n\n  ```java\n  Stream<String> sortedStream = stream.sorted(String::compareTo);\n  Optional maxOptionnal = stream.min(String::compareTo);\n  IntStream.range(1,10).max();\n  ```\n\n- 过滤\n\n  ```java\n  List<String> ll = Lists.newArrayList(\"a\",\"\",\"b\");\n  ll.stream().filter(StringUtils::isNotBlank).collect(Collectors.toList());\n  ```\n\n- anyMatch、allMatch、noneMatch\n\n  ```java\n  boolean b = IntStream.of(1, 3, 5, 8, 10).anyMatch((s) -> s % 3 == 0);\n  ```\n\n\n## 参考\n\n[Java 8 中的 Streams API 详解](https://www.ibm.com/developerworks/cn/java/j-lo-java8streamapi/)","slug":"java8/java8之Stream流","published":1,"updated":"2018-09-12T03:03:21.821Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnhd003owlkvfxmqri8d"},{"title":"java8之方法接口","date":"2017-08-04T23:58:46.000Z","_content":"\n# java8之方法接口\n\n## 方法接口\n\n### 定义\n\n一个只声明了一个抽象方法的接口，可以认定为一个方法接口，方法接口可以使用lambda表达式进行实现。在接口上添加**@FunctionalInterface**注解，可以显示的声明该接口为方法接口(非必须)。\n\n### 默认方法\n\njdk8之前的接口只能有抽象方法，一旦给接口添加新的方法，所有的实现类都必须进行改动，这对整个系统的影响范围太大，jdk8允许在接口中声明**默认方法**，在方法前面显示声明**default**,所有的实现类都会默认继承接口中的默认方法，通过默认方法可以很友好的扩展接口的功能，而且不会破坏方法接口。\n\n默认方法和抽象方法的区别是抽象方法必须要被实现，默认方法不需要，实现类会继承默认方法，同时可以覆盖默认方法。\n\n### 静态方法\n\n接口可以定义静态方法，一般可以通过接口中的静态方法中创建该接口的匿名实现，方便对接口的使用，jdk8之后有了lambda表达式，可以更加方便的操作接口的实现。\n\n## 内置方法接口\n\n**operation**运算符,**binary** 二元（就是数学里二元一次方程那个二元,代表2个的意思）,双重的\n\n### Function\n\n函数，接受一个参数,返回一个值\n\n### Consumer\n\n消费者，该接口对应的方法类型为接收一个参数，没有返回值\n\n### Supplier\n\n提供者,和上面的消费者相反，该接口对应的方法类型为不接受参数，但是提供一个返回值\n\n### Predicate\n\n预言，判断是否的接口，该接口对应的方法为接收一个参数，返回一个Boolean类型值，多用于判断与过滤，是一个特殊的Funcation\n\n### Operator接口\n\n一种特殊的function接口实现，参数类型和返回值类型相同。提供了UnaryOperator(一个参数)、BinaryOperator(两个参数)两个接口。\n\n```java\n@FunctionalInterface\npublic interface UnaryOperator<T> extends Function<T, T> {}\n```\n\n### 类型限制接口\n\n**参数类型**\n\n例如IntPredicate,LongPredicate, DoublePredicate，这几个接口，都是在基于Predicate接口的，不同的就是他们的泛型类型分别变成了Integer,Long,Double,IntConsumer,LongConsumer, DoubleConsumer比如这几个,对应的就是Consumer,Consumer,Consumer,其余的是一样的道理，就不再举例子了\n\n**返回值类型**\n\n和参数类型相似，通过限制返回值类型定义接口，例如IntToDoubleFunction,IntToLongFunction, 很明显就是对应的Funtion 与Fcuntion，只是命名的规则上多了一个To。参数限制与返回值限制的命名唯一不同就是To,**前面不带To的都是参数类型限制,带To的是返回值类型限制**\n\n### 数量限制接口\n\n有些接口需要接受两名参数,此类接口的所有名字前面都是附加上**Bi**,是Binary的缩写，例如BiConsumer、BiPredicate,BiFcuntion\n\n## 默认方法\n\n- 默认方法由default修饰符修饰\n- 默认方法的引入，就是为了解决当需要改动接口时，导致所有的实现类都需要改动的不足之处。有了默认方法之后，所有的实现类都会有一个默认的实现。\n- 默认方法两种情况 ：可选方法和行为的多继承\n- 可选方法：实现类在不需要remove方法时候，不再需要去实现remove方法了，在接口的remove中抛异常，接口自身实现了默认适配，避免实现类去实现自己不关心的方法。\n\n```java\ninterface Iterator<T> { \n  boolean hasNext();\n  T next();\n  default void remove() {\n    throw new UnsupportedOperationException();\n  }\n}\n```\n\n## 函数式编程\n\n函数式编程思想：\n\n- 接受0个或多个参数，返回0个或多个结果，\n- 不涉及修改其他共享变量\n- 函数不会产生副作用(幂等)\n- 函数式方法不可抛出任何异常\n- 面向对象编程是对数据进行抽象，而函数式编程是对行为进行抽象\n- 函数式编程:核心是在于思考问题时，**使用不可变值和函数，函数对一个值进行处理，映射成另一个值**\n\n","source":"_posts/java8/java8之方法接口.md","raw":"---\ntitle: java8之方法接口\ndate: 2017-08-05 07:58:46\ntags:\n- java8\ncategories:\n- java基础\n---\n\n# java8之方法接口\n\n## 方法接口\n\n### 定义\n\n一个只声明了一个抽象方法的接口，可以认定为一个方法接口，方法接口可以使用lambda表达式进行实现。在接口上添加**@FunctionalInterface**注解，可以显示的声明该接口为方法接口(非必须)。\n\n### 默认方法\n\njdk8之前的接口只能有抽象方法，一旦给接口添加新的方法，所有的实现类都必须进行改动，这对整个系统的影响范围太大，jdk8允许在接口中声明**默认方法**，在方法前面显示声明**default**,所有的实现类都会默认继承接口中的默认方法，通过默认方法可以很友好的扩展接口的功能，而且不会破坏方法接口。\n\n默认方法和抽象方法的区别是抽象方法必须要被实现，默认方法不需要，实现类会继承默认方法，同时可以覆盖默认方法。\n\n### 静态方法\n\n接口可以定义静态方法，一般可以通过接口中的静态方法中创建该接口的匿名实现，方便对接口的使用，jdk8之后有了lambda表达式，可以更加方便的操作接口的实现。\n\n## 内置方法接口\n\n**operation**运算符,**binary** 二元（就是数学里二元一次方程那个二元,代表2个的意思）,双重的\n\n### Function\n\n函数，接受一个参数,返回一个值\n\n### Consumer\n\n消费者，该接口对应的方法类型为接收一个参数，没有返回值\n\n### Supplier\n\n提供者,和上面的消费者相反，该接口对应的方法类型为不接受参数，但是提供一个返回值\n\n### Predicate\n\n预言，判断是否的接口，该接口对应的方法为接收一个参数，返回一个Boolean类型值，多用于判断与过滤，是一个特殊的Funcation\n\n### Operator接口\n\n一种特殊的function接口实现，参数类型和返回值类型相同。提供了UnaryOperator(一个参数)、BinaryOperator(两个参数)两个接口。\n\n```java\n@FunctionalInterface\npublic interface UnaryOperator<T> extends Function<T, T> {}\n```\n\n### 类型限制接口\n\n**参数类型**\n\n例如IntPredicate,LongPredicate, DoublePredicate，这几个接口，都是在基于Predicate接口的，不同的就是他们的泛型类型分别变成了Integer,Long,Double,IntConsumer,LongConsumer, DoubleConsumer比如这几个,对应的就是Consumer,Consumer,Consumer,其余的是一样的道理，就不再举例子了\n\n**返回值类型**\n\n和参数类型相似，通过限制返回值类型定义接口，例如IntToDoubleFunction,IntToLongFunction, 很明显就是对应的Funtion 与Fcuntion，只是命名的规则上多了一个To。参数限制与返回值限制的命名唯一不同就是To,**前面不带To的都是参数类型限制,带To的是返回值类型限制**\n\n### 数量限制接口\n\n有些接口需要接受两名参数,此类接口的所有名字前面都是附加上**Bi**,是Binary的缩写，例如BiConsumer、BiPredicate,BiFcuntion\n\n## 默认方法\n\n- 默认方法由default修饰符修饰\n- 默认方法的引入，就是为了解决当需要改动接口时，导致所有的实现类都需要改动的不足之处。有了默认方法之后，所有的实现类都会有一个默认的实现。\n- 默认方法两种情况 ：可选方法和行为的多继承\n- 可选方法：实现类在不需要remove方法时候，不再需要去实现remove方法了，在接口的remove中抛异常，接口自身实现了默认适配，避免实现类去实现自己不关心的方法。\n\n```java\ninterface Iterator<T> { \n  boolean hasNext();\n  T next();\n  default void remove() {\n    throw new UnsupportedOperationException();\n  }\n}\n```\n\n## 函数式编程\n\n函数式编程思想：\n\n- 接受0个或多个参数，返回0个或多个结果，\n- 不涉及修改其他共享变量\n- 函数不会产生副作用(幂等)\n- 函数式方法不可抛出任何异常\n- 面向对象编程是对数据进行抽象，而函数式编程是对行为进行抽象\n- 函数式编程:核心是在于思考问题时，**使用不可变值和函数，函数对一个值进行处理，映射成另一个值**\n\n","slug":"java8/java8之方法接口","published":1,"updated":"2018-09-12T03:03:21.822Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnhe003rwlkvqntln98w"},{"title":"java8之日期实现","date":"2017-08-05T06:58:46.000Z","_content":"\n# java8之日期实现\n\n## 历史问题\n\n- jdk api中提供了两类日期实现Date和Calendar，存在一些缺陷和不足\n  1. Date的实现是年份从1900年开始，月份是从0开始\n  2. DateForm不是线程安全的，多线程 并发时会出现不可知的问题\n  3. Date和Calendar是可变类\n  4. 日期的toString输出的格式不够人性化\n\n\n\n## JDK8 接口定义\n\n- **TemporalAccessor**:定义日期类的查询接口\n\n- **Temporal**:继承**TemporalAccessor**，扩展定义了日期的修改接口，必须是连续时间的类型实现接口\n\n  ```java\n  default Temporal with(TemporalAdjuster adjuster);//提供了默认实现\n  Temporal with(TemporalField field, long newValue);\n  default Temporal plus(TemporalAmount amount);//提供了默认实现\n  Temporal plus(long amountToAdd, TemporalUnit unit);\n  long until(Temporal endExclusive, TemporalUnit unit);\n  ```\n\n- **TemporalAdjuster** :调整时间，函数式接口，定义了adjustInto方法，让子类实现，jdk通过TemporalAdjusters提供了一些默认实现\n\n  ```java\n  Temporal adjustInto(Temporal temporal);//接口\n  //以下两种实现 使用adjust对应field\n  temporal = thisAdjuster.adjustInto(temporal);\n  temporal = temporal.with(thisAdjuster);//推荐使用with\n  ```\n\n- **TemporalAmount**：一段时间的接口，主要实现类 Period和Duration\n\n  ```java\n  long get(TemporalUnit unit);\n  List<TemporalUnit> getUnits();\n  Temporal addTo(Temporal temporal);\n  Temporal subtractFrom(Temporal temporal);\n  ```\n\n- **TemporalUnit** ：时间单位，主要实现类为ChronoUnit\n\n  ```java\n  Duration getDuration();//接口中主要是定义了单位对应的时间长度\n  <R extends Temporal> R addTo(R temporal, long amount);//访问者模式\n  ```\n\n  ChronoUnit\n\n  ```java\n  MINUTES(\"Minutes\", Duration.ofSeconds(60)),//定义枚举对象，各个枚举对应的时间长度\n  @Override\n  public <R extends Temporal> R addTo(R temporal, long amount) {  //访问者模式\n      return (R) temporal.plus(amount, this);\n  }\n  @Override\n  public long between(Temporal temporal1Inclusive, Temporal temporal2Exclusive) {\n      return temporal1Inclusive.until(temporal2Exclusive, this);\n  }\n  ```\n\n- **TemporalField** ：日期field的抽象，主要实现是ChronoField枚举\n  ```java\n  long getFrom(TemporalAccessor temporal); //访问者模式\n  <R extends Temporal> R adjustInto(R temporal, long newValue);\n  ```\n  ChronoField\n\n  ```java\n  private final String name;\n  private final TemporalUnit baseUnit;\n  private final TemporalUnit rangeUnit;\n  private final ValueRange range;\n  private final String displayNameKey;\n  \n  private ChronoField(String name, TemporalUnit baseUnit, TemporalUnit rangeUnit, ValueRange range) {\n      this.name = name;\n      this.baseUnit = baseUnit;\n      this.rangeUnit = rangeUnit;\n      this.range = range;\n      this.displayNameKey = null;\n  }\n  @Override\n  public long getFrom(TemporalAccessor temporal) {\n      return temporal.getLong(this);\n  }\n  \n  @SuppressWarnings(\"unchecked\")\n  @Override\n  public <R extends Temporal> R adjustInto(R temporal, long newValue) {\n      return (R) temporal.with(this, newValue);\n  }\n  ```\n\n- **TemporalQuery**: 函数式接口，定义了查询抽象方法，jdk通过TemporalQueries提供了一些默认实现\n\n  ```java\n  R queryFrom(TemporalAccessor temporal);\n  ```\n\n  \n\n## JDK8新增的日期类\n\n### LocalDate\n\nlocalDate.of\n\n### LocalTime\n\n它包含了时间与日期，不过没有带时区的偏移量\n\n### LocalDateTime\n\n包含了LocalDate和LocalTim\n\n###  ZonedDateTime\n\n这是一个包含时区的完整的日期时间，偏移量是以UTC/格林威治时间为基准的。\n\n### OffsetDateTime\n\n### MonthDay\n\n处理一个月，一般配合TemporalAdjusters一起使用，用于调整日期\n\n### YearMonth\n\n处理年月，一般配合TemporalAdjusters一起使用，用于调整日期\n\n### Clock\n\n时钟接口，通过内部类提供了一些实现，用于获取某个时区下当前的瞬时日期或者时间。\n可以用Clock来替代System.currentTimeInMillis()与 TimeZone.getDefault()方法\n```java\nClock.systemDefaultZone().millis()  === System.currentTimeMillis();\nInstant instant = Clock.systemDefaultZone().instant();//获取instant\n```\n\n### Instant\n\n设计初衷是为了机器使用方便，是1970年1月1日到现在的秒数,事实上Instant就是Java 8前的Date，你可以使用这两个类中的方法来在这两个类型之间进行转换，\n\n```java\nDate date = Date.from(instant);//将instant转换为Date类型\nInstant instant = date.toInstant();//将Date转换为instant类型\n```\n\n### Duration\n\n由于Duration类主要用于以秒和纳秒衡量时间的长短，你不能仅向between方法传递一个LocalDate对象做参数。\n\n### Period\n\n如果需要以年、月或者日的方式对多个时间单位建模，可以使用Period类。使用该类的工厂方法between，你可以使用得到两个LocalDate之间的时长\n\n### ValueRange\n\n一段，保存起始和结束标示\n\n### ZoneId\n\n处理时期\n\n### ZoneOffset\n\n### DateTimeFormatter","source":"_posts/java8/java8之日期实现.md","raw":"---\ntitle: java8之日期实现\ndate: 2017-08-05 14:58:46\ntags:\n- java8\ncategories:\n- java基础\n---\n\n# java8之日期实现\n\n## 历史问题\n\n- jdk api中提供了两类日期实现Date和Calendar，存在一些缺陷和不足\n  1. Date的实现是年份从1900年开始，月份是从0开始\n  2. DateForm不是线程安全的，多线程 并发时会出现不可知的问题\n  3. Date和Calendar是可变类\n  4. 日期的toString输出的格式不够人性化\n\n\n\n## JDK8 接口定义\n\n- **TemporalAccessor**:定义日期类的查询接口\n\n- **Temporal**:继承**TemporalAccessor**，扩展定义了日期的修改接口，必须是连续时间的类型实现接口\n\n  ```java\n  default Temporal with(TemporalAdjuster adjuster);//提供了默认实现\n  Temporal with(TemporalField field, long newValue);\n  default Temporal plus(TemporalAmount amount);//提供了默认实现\n  Temporal plus(long amountToAdd, TemporalUnit unit);\n  long until(Temporal endExclusive, TemporalUnit unit);\n  ```\n\n- **TemporalAdjuster** :调整时间，函数式接口，定义了adjustInto方法，让子类实现，jdk通过TemporalAdjusters提供了一些默认实现\n\n  ```java\n  Temporal adjustInto(Temporal temporal);//接口\n  //以下两种实现 使用adjust对应field\n  temporal = thisAdjuster.adjustInto(temporal);\n  temporal = temporal.with(thisAdjuster);//推荐使用with\n  ```\n\n- **TemporalAmount**：一段时间的接口，主要实现类 Period和Duration\n\n  ```java\n  long get(TemporalUnit unit);\n  List<TemporalUnit> getUnits();\n  Temporal addTo(Temporal temporal);\n  Temporal subtractFrom(Temporal temporal);\n  ```\n\n- **TemporalUnit** ：时间单位，主要实现类为ChronoUnit\n\n  ```java\n  Duration getDuration();//接口中主要是定义了单位对应的时间长度\n  <R extends Temporal> R addTo(R temporal, long amount);//访问者模式\n  ```\n\n  ChronoUnit\n\n  ```java\n  MINUTES(\"Minutes\", Duration.ofSeconds(60)),//定义枚举对象，各个枚举对应的时间长度\n  @Override\n  public <R extends Temporal> R addTo(R temporal, long amount) {  //访问者模式\n      return (R) temporal.plus(amount, this);\n  }\n  @Override\n  public long between(Temporal temporal1Inclusive, Temporal temporal2Exclusive) {\n      return temporal1Inclusive.until(temporal2Exclusive, this);\n  }\n  ```\n\n- **TemporalField** ：日期field的抽象，主要实现是ChronoField枚举\n  ```java\n  long getFrom(TemporalAccessor temporal); //访问者模式\n  <R extends Temporal> R adjustInto(R temporal, long newValue);\n  ```\n  ChronoField\n\n  ```java\n  private final String name;\n  private final TemporalUnit baseUnit;\n  private final TemporalUnit rangeUnit;\n  private final ValueRange range;\n  private final String displayNameKey;\n  \n  private ChronoField(String name, TemporalUnit baseUnit, TemporalUnit rangeUnit, ValueRange range) {\n      this.name = name;\n      this.baseUnit = baseUnit;\n      this.rangeUnit = rangeUnit;\n      this.range = range;\n      this.displayNameKey = null;\n  }\n  @Override\n  public long getFrom(TemporalAccessor temporal) {\n      return temporal.getLong(this);\n  }\n  \n  @SuppressWarnings(\"unchecked\")\n  @Override\n  public <R extends Temporal> R adjustInto(R temporal, long newValue) {\n      return (R) temporal.with(this, newValue);\n  }\n  ```\n\n- **TemporalQuery**: 函数式接口，定义了查询抽象方法，jdk通过TemporalQueries提供了一些默认实现\n\n  ```java\n  R queryFrom(TemporalAccessor temporal);\n  ```\n\n  \n\n## JDK8新增的日期类\n\n### LocalDate\n\nlocalDate.of\n\n### LocalTime\n\n它包含了时间与日期，不过没有带时区的偏移量\n\n### LocalDateTime\n\n包含了LocalDate和LocalTim\n\n###  ZonedDateTime\n\n这是一个包含时区的完整的日期时间，偏移量是以UTC/格林威治时间为基准的。\n\n### OffsetDateTime\n\n### MonthDay\n\n处理一个月，一般配合TemporalAdjusters一起使用，用于调整日期\n\n### YearMonth\n\n处理年月，一般配合TemporalAdjusters一起使用，用于调整日期\n\n### Clock\n\n时钟接口，通过内部类提供了一些实现，用于获取某个时区下当前的瞬时日期或者时间。\n可以用Clock来替代System.currentTimeInMillis()与 TimeZone.getDefault()方法\n```java\nClock.systemDefaultZone().millis()  === System.currentTimeMillis();\nInstant instant = Clock.systemDefaultZone().instant();//获取instant\n```\n\n### Instant\n\n设计初衷是为了机器使用方便，是1970年1月1日到现在的秒数,事实上Instant就是Java 8前的Date，你可以使用这两个类中的方法来在这两个类型之间进行转换，\n\n```java\nDate date = Date.from(instant);//将instant转换为Date类型\nInstant instant = date.toInstant();//将Date转换为instant类型\n```\n\n### Duration\n\n由于Duration类主要用于以秒和纳秒衡量时间的长短，你不能仅向between方法传递一个LocalDate对象做参数。\n\n### Period\n\n如果需要以年、月或者日的方式对多个时间单位建模，可以使用Period类。使用该类的工厂方法between，你可以使用得到两个LocalDate之间的时长\n\n### ValueRange\n\n一段，保存起始和结束标示\n\n### ZoneId\n\n处理时期\n\n### ZoneOffset\n\n### DateTimeFormatter","slug":"java8/java8之日期实现","published":1,"updated":"2018-09-12T03:03:21.822Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnhg003vwlkvid4c3hmk"},{"title":"vim编辑器","date":"2018-09-10T02:26:48.000Z","_content":"\n# vim编辑器\n定制vim的工作特性： 配置文件：永久有效  全局：/etc/vimrc  个人：~/.vimrc\n## 屏幕翻滚类命令\n\n```shell\nCtrl+u  #向文件首翻半屏\nCtrl+d  #向文件尾翻半屏\nCtrl+f #向文件尾翻一屏\nCtrl＋b #向文件首翻一屏\nnz  #将第n行滚至屏幕顶部，不指定n时将当前行滚至屏幕顶部\n\n```\n\n## 进入vim的命令\n\n```shell\nvim filename #打开或新建文件，并将光标置于第一行首\nvim +n filename #打开文件，并将光标置于第n行首\nvim + filename #打开文件，并将光标置于最后一行首\nvim +/pattern filename #打开文件，并将光标置于第一个与pattern匹配的串处\nvim -r filename #在上次正用vi编辑时发生系统崩溃，恢复filename\nvim -o/O filename1 filename2 ... #打开多个文件，依次进行编辑\n\n```\n\n##  vi m关闭文件\n\n```shell\n:w       #保存\n:w file.txt：在末尾将文件内容另存到 file.txt中   (将当前文件中部分内容另存为另一个文件)\n:r file.txt：将file中的内容复制到当前文件的光标处  (将另一个文件的内容填充在当前文件中) \n:q        #退出\n:q!       #强制退出\n:wq       #保存退出编辑器\n:set nu   #显示行号，:set nonu：隐藏行号\n:set mouse=a #就能够使用鼠标点击光标的位置\n:set ic   #忽略大小写\n:set autoindent #设置自动缩进  :set noai：取消自动缩进\n:syntax on #语法着色，:syntax off：关闭语法着色\n可以修改 /etc/vimrc文件修改vim的默认配置，如果只作用于某个用户，在该用户家目录下闯将.vimrc文件，并复制进去内容进行修改\n```\n\n## 插入文本类命令\n\n```shell\ni           #在光标前\nI           #在当前行首\na           #光标后\nA           #在当前行尾\no           #在当前行之下新开一行\nO           #在当前行之上新开一行\nr           #替换当前字符\nR           #替换当前字符及其后的字符，直至按ESC键\ns           #从当前光标位置处开始，以输入的文本替代指定数目的字符\nS           #删除指定数目的行，并以所输入文本代替之\nncw或nCW    #修改指定数目的字\nnCC        #修改指定数目的行\nC          #删除光标位置到行尾的内容并进入插入模式 (相当于c$) \nc<范围>     #删除光标所在位置周围某个范围的文本并进入插入模式。关于范围请看第5点，常用的组合有：caw - 删除一个单词包括它后面的空格并开始插入； ciw - 删除一个单词并开始插入； ci\" - 删除一个字符串内部文本并开始插入； c$ - 从光标位置删除到行尾并开始插入； ct字符 - 从光标位置删除本行某个字符之前（保留该字符）并开始插入。等等。 \n```\n\n```shell\n常用的范围指令有： \n空格 #光标所在位置字符。（例如 gU空格 - 将光标位置字符转为大写） \n重复某些动作命令 - 光标所在行。 （例如dd删除一行，yy复制一行，cc删除一行文本并开始插入，>> 当前行缩进一格，==自动缩进当前行） \n$ - 从光标位置到行尾 \n^ - 从光标位置到行首，不包含缩进空白 \n0 - 从光标位置到行首，包含缩进空白 \ngg - 从光标位置到文件开头 \nG - 从光标位置到文件结尾 \n% - 从光标位置到另一边匹配的括号 \nf<字符> - 从光标位置到光标右边某个字符首次出现的位置，包括该字符 \nF<字符> - 从光标位置到光标左边某个字符首次出现的位置，包括该字符 \nt<字符> - 从光标位置到光标右边某个字符首次出现的位置，包括该字符 \nF<字符> - 从光标位置到光标左边某个字符首次出现的位置，包括该字符 \n/正则表达式 - 从光标位置到下一个匹配正则表达式的位置（跨行） \n?正则表达式 - 从光标位置到上一个匹配正则表达式的位置（跨行） \naw - 一个单词加一个空格 （a可理解为“一个”，下同） \niw - 一个单词 （i可理解为in，下同） \na\" - 一个字符串包括双引号 \ni\" - 一个字符串内部文本 \na< - 一组< >包含的文本，包括< >号本身 \n同理类推： i<, a[, i[, a(, i( \n注意：真正vim中的it范围（一对xml标签内部）在ideaVim中不生效。 \n```\n\n## 复制、粘贴\n\n```shell\nggvG    #全选\nyy    #将当前行复制到缓存区\nnyy   #将当前行向下n行复制到缓冲区\nyw    #复制从光标开始到词尾的字符。\nnyw   #复制从光标开始的n个单词。\ny^    #复制从光标到行首的内容。  \ny$    #复制从光标到行尾的内容。\np     #粘贴剪切板里的内容在光标后\nP     #粘贴剪切板里的内容在光标前\n```\n\n## 文本替换\n\n```shell\n:s/old/new           #用new替换行中首次出现的old\n:s/old/new/g         #用new替换行中所有的old\n:s/old/new/gc         #用new替换行中所有的old，每次都需要询问确认\n:n,m s/old/new/g     #用new替换从n到m行里所有的old\n:%s/old/new/g        #用new替换当前文件里所有的old ,简单替换表达式  :%s/four/4/g , “%” 范围前缀表示在所有行中执行替换，最后的 “g” 标记表示替换行中的所有匹配点，如果仅仅对当前行进行操作，那么只要去掉%即可\n如果你有一个像 “thirtyfour” 这样的单词，上面的命令会出错。这种情况下，这个单词会被替换成”thirty4″。要解决这个问题，用 “<”来指定匹配单词开头： :%s/<four/4/g , 显然，这样在处理 “fourty” 的时候还是会出错。用 “>” 来解决这个问题： :%s/<four>/4/g \n```\n\n## 删除命令\n\n```shell\nndw或ndW     #删除光标处开始及其后的n-1个字 ,并复制被删除的\ndo     #删至行首,并复制被删除的\nd$     #删至行尾,并复制被删除的\nndd    #删除当前行及其后n-1行,并复制被删除的\nx或X   #删除一个字符，x删除光标后的，而X删除光标前的\nCtrl+u #删除输入方式下所输入的文本\nx      #删除当前字符,并复制被删除的\nnx     #删除从光标开始的n个字符,并复制被删除的\ndd     #删除当前行,并复制被删除的\nndd    #向下删除当前行在内的n行,并复制被删除的\nu      #撤销上一步操作\nU      #撤销对当前行的所有操作\n```\n\n## 搜索及替换命令\n\n```shell\n/pattern     #从光标开始处向文件尾搜索pattern \n?pattern     #从光标开始处向文件首搜索pattern\nn            #在同一方向重复上一次搜索命令\nN            #在反方向上重复上一次搜索命令\n：s/p1/p2/g  #将当前行中所有p1均用p2替代\n：n1,n2s/p1/p2/g   #将第n1至n2行中所有p1均用p2替代\n：g/p1/s//p2/g     #将文件中所有p1均用p2替换\n```\n\n\n\n## 打开多个文件：vim 1.txt 2.txt\n\n```shell\nvim -o 1.txt 2.txt          #水平分割显示\nvim -O 1.txt 2.txt          #垂直分割显示\nctrl+w 放开后按 s            #水平拆分窗口\nctrl+w 放开后按 v            #垂直拆分窗口\nctrl+w 放开后按 w   \t\t #放开后按上下箭头：在各个窗口中切换光标\n:next                       #切换到下一个文件\n:prev                       #切换到上一个文件\n:last                       #切换到最后一个文件\n:first                      #切换至第一个文件\n:qa                         #退出全部\n```\n\n\n\nvim编辑器\n\n\n​\t\n\t使用\n\t\tvim：模式化的编辑\n\t\n\t\t\t基本模式：\n\t\t\t\t编辑模式，命令模式\n\t\t\t\t输入模式\n\t\t\t\t末行模式：\n\t\t\t\t\t内置的命令行接口\n\t\n\t\t\t打开文件：\n\t\t\t\t# vim [OPTION]... FILE...\n\t\t\t\t\t+#: 打开文件后，直接让光标处于第#行的行首；\n\t\t\t\t\t+/PATTERN：打开文件后，直接让光标处于第一个被PATTERN匹配到的行的行首；\n\t\n\t\t\t模式转换：\n\t\t\t\t编辑模式 --> 输入模式\n\t\t\t\t\ti: insert, 在光标所在处输入；\n\t\t\t\t\ta: append, 在光标所在处后面输入；\n\t\t\t\t\to: 在当前光标所在行的下方打开一个新行；\n\t\t\t\t\tI：在当前光标所在行的行首输入；\n\t\t\t\t\tA：在当前光标所在行的行尾输入；\n\t\t\t\t\tO：在当前光标所在行的上方打开一个新行；\n\t\t\t\t\tc\n\t\t\t\t\tC\n\t\n\t\t\t\t输入模式 --> 编辑模式\n\t\t\t\t\tESC\n\t\n\t\t\t\t编辑模式 --> 末行模式\n\t\t\t\t\t:\n\t\n\t\t\t\t末行模式 --> 编辑模式\n\t\t\t\t\tESC\n\t\n\t\t\t关闭文件：\n\t\t\t\t:q 退出\n\t\t\t\t:q! 强制退出，丢弃做出的修改；\n\t\t\t\t:wq 保存退出\n\t\t\t\t:x 保存退出\n\t\t\t\t:w /PATH/TO/SOMEWHERE\n\t\n\t\t\t\tZZ: 保存退出；\n\t\n\t\t光标跳转：\n\t\t\t\n\t\t\t字符间跳转：\n\t\t\t\th, j, k, l\n\t\t\t\t\th: 左\n\t\t\t\t\tl: 右\n\t\t\t\t\tj: 下\n\t\t\t\t\tk: 上\n\t\n\t\t\t\t#COMMAND：跳转由#指定的个数的字符；\n\t\n\t\t\t单词间跳转：\n\t\t\t\tw：下一个单词的词首\n\t\t\t\te：当前或下一单词的词尾\n\t\t\t\tb：当前或前一个单词的词首\n\t\n\t\t\t\t#COMMAND：由#指定一次跳转的单词数\n\t\n\t\t\t行首行尾跳转：\n\t\t\t\t^: 跳转至行首的第一个非空白字符；\n\t\t\t\t0: 跳转至行首；\n\t\t\t\t$: 跳转至行尾；\n\t\n\t\t\t行间移动：\n\t\t\t\t#G：跳转至由#指定行；\n\t\t\t\tG：最后一行；\n\t\t\t\t1G, gg: 第一行；\n\t\n\t\t\t句间移动：\n\t\t\t\t)\n\t\t\t\t(\n\t\n\t\t\t段落间移动：\n\t\t\t\t}\n\t\t\t\t{\n\t\n\tvim的编辑命令：\n\t\n\t\t字符编辑：\n\t\t\tx: 删除光标处的字符；\n\t\t\t#x: 删除光标处起始的#个字符；\n\t\n\t\t\txp: 交换光标所在处的字符及其后面字符的位置；\n\t\n\t\t替换命令(r, replace)\n\t\t\tr: 替换光标所在处的字符\n\t\n\t\t删除命令：\n\t\t\td: 删除命令，可结合光标跳转字符，实现范围删除；\n\t\t\t\td$: \n\t\t\t\td^:\n\t\t\t\td0:\n\t\n\t\t\t\tdw\n\t\t\t\tde\n\t\t\t\tdb\n\t\n\t\t\t\t\t#COMMAND\n\t\n\t\t\t\tdd: 删除光标所在的行；\n\t\t\t\t\t#dd：多行删除；\n\t\n\t\t粘贴命令(p, put, paste)：\n\t\t\tp：缓冲区存的如果为整行，则粘贴当前光标所在行的下方；否则，则粘贴至当前光标所在处的后面；\n\t\t\tP：缓冲区存的如果为整行，则粘贴当前光标所在行的上方；否则，则粘贴至当前光标所在处的前面；\n\t\n\t\t复制命令(y, yank)：\n\t\t\ty: 复制，工作行为相似于d命令；\n\t\t\t\ty$\n\t\t\t\ty0\n\t\t\t\ty^\n\t\n\t\t\t\tye\n\t\t\t\tyw\n\t\t\t\tyb\n\t\n\t\t\t\t\t#COMMAND\n\t\n\t\t\t\tyy：复制行\n\t\t\t\t\t#yy: 复制多行；\n\t\n\t\t改变命令(c, change)\n\t\t\tc: 修改\n\t\t\t\t编辑模式 --> 输入模式\n\t\n\t\t\t\tc$\n\t\t\t\tc^\n\t\t\t\tc0\n\t\n\t\t\t\tcb\n\t\t\t\tce\n\t\t\t\tcw\n\t\t\t\t\t#COMMAND\n\t\n\t\t\t\tcc：删除并输入新内容\n\t\t\t\t#cc: \n\t\n\t\t其它编辑操作\n\t\n\t\t\t可视化模式：\n\t\t\t\tv: 按字符选定\n\t\t\t\tV：按行行定\n\t\n\t\t\t\tNote：经常结合编辑命令；\n\t\t\t\t\td, c, y\n\t\n\t\t\t撤消此前的编辑：\n\t\t\t\tu(undo)：撤消此前的操作；\n\t\t\t\t\t#u: 撤消指定次数的操作；\n\t\n\t\t\t撤消此前的撤消：\n\t\t\t\tCtrl+r\n\t\n\t\t\t重复前一个编辑操作：\n\t\t\t\t.\n\n\n​\t\n\tvim中的末行模式：\n\t\t内建的命令行接口\n\t\n\t\t(1) 地址定界\n\t\t\t:start_pos,end_pos\n\t\t\t\t#: 具体第#行，例如2表示第2行；\n\t\t\t\t#,#: 从左侧#表示行起始，到右侧#表示行结尾；\n\t\t\t\t#,+#: 从左侧#表示的行起始，加上右侧#表示的行数；\n\t\t\t\t.: 当前行\n\t\t\t\t$: 最后一行\n\t\t\t\t\t.,$-1\n\t\t\t\t%：全文, 相当于1,$\n\t\n\t\t\t\t/pat1/,/pat2/：\n\t\t\t\t\t从第一次被pat1模式匹配到的行开始，一直到第一次被pat2匹配到的行结束；\n\t\t\t\t\t#,/pat/\n\t\t\t\t\t/pat/,$\n\t\n\t\t\t使用方式：\n\t\t\t\t后跟一个编辑命令\n\t\t\t\t\td\n\t\t\t\t\ty\n\t\t\t\t\tw /PATH/TO/SOMEWHERE: 将范围内的行另存至指定文件中；\n\t\t\t\t\tr /PATH/FROM/SOMEFILE：在指定位置插入指定文件中的所有内容；\n\t\n\t\t(2) 查找\n\t\t\t/PATTERN：从当前光标所在处向文件尾部查找；\n\t\t\t?PATTERN：从当前光标所在处向文件首部查找；\n\t\t\t\tn：与命令同方向；\n\t\t\t\tN：与命令反方向；\n\t\n\t\t(3) 查找并替换\n\t\t\ts: 在末行模式下完成查找替换操作\n\t\t\t\ts/要查找的内容/替换为的内容/修饰符\n\t\t\t\t\t要查找的内容：可使用模式\n\t\t\t\t\t替换为的内容：不能使用模式，但可以使用\\1, \\2, ...等后向引用符号；还可以使用“&”引用前面查找时查找到的整个内容；\n\t\t\t\t\t修饰符：\n\t\t\t\t\t\ti: 忽略大小写\n\t\t\t\t\t\tg: 全局替换；默认情况下，每一行只替换第一次出现；\n\t\n\t\t\t\t查找替换中的分隔符/可替换为其它字符，例如\n\t\t\t\t\ts@@@\n\t\t\t\t\ts###\n\t\n\t\t\t练习：\n\t\t\t\t1、复制/etc/grub2.cfg至/tmp/目录，用查找替换命令删除/tmp/grub2.cfg文件中的行首的空白字符；\n\t\t\t\t\t%s/^[[:space:]]\\+//g\n\t\n\t\t\t\t2、复制/etc/rc.d/init.d/functions文件至/tmp目录，用查找替换命令为/tmp/functions的每行开头为空白字符的行的行首添加一个#号；\n\t\t\t\t\t:%s/^[[:space:]]/#&/\n\n\n​\t\n​\t\n​\t\n​\t","source":"_posts/linux/vim编辑器.md","raw":"---\ntitle: vim编辑器\ndate: 2018-09-10 10:26:48\ntags:\n- linux\ncategories:\n- linux\n\n\n---\n\n# vim编辑器\n定制vim的工作特性： 配置文件：永久有效  全局：/etc/vimrc  个人：~/.vimrc\n## 屏幕翻滚类命令\n\n```shell\nCtrl+u  #向文件首翻半屏\nCtrl+d  #向文件尾翻半屏\nCtrl+f #向文件尾翻一屏\nCtrl＋b #向文件首翻一屏\nnz  #将第n行滚至屏幕顶部，不指定n时将当前行滚至屏幕顶部\n\n```\n\n## 进入vim的命令\n\n```shell\nvim filename #打开或新建文件，并将光标置于第一行首\nvim +n filename #打开文件，并将光标置于第n行首\nvim + filename #打开文件，并将光标置于最后一行首\nvim +/pattern filename #打开文件，并将光标置于第一个与pattern匹配的串处\nvim -r filename #在上次正用vi编辑时发生系统崩溃，恢复filename\nvim -o/O filename1 filename2 ... #打开多个文件，依次进行编辑\n\n```\n\n##  vi m关闭文件\n\n```shell\n:w       #保存\n:w file.txt：在末尾将文件内容另存到 file.txt中   (将当前文件中部分内容另存为另一个文件)\n:r file.txt：将file中的内容复制到当前文件的光标处  (将另一个文件的内容填充在当前文件中) \n:q        #退出\n:q!       #强制退出\n:wq       #保存退出编辑器\n:set nu   #显示行号，:set nonu：隐藏行号\n:set mouse=a #就能够使用鼠标点击光标的位置\n:set ic   #忽略大小写\n:set autoindent #设置自动缩进  :set noai：取消自动缩进\n:syntax on #语法着色，:syntax off：关闭语法着色\n可以修改 /etc/vimrc文件修改vim的默认配置，如果只作用于某个用户，在该用户家目录下闯将.vimrc文件，并复制进去内容进行修改\n```\n\n## 插入文本类命令\n\n```shell\ni           #在光标前\nI           #在当前行首\na           #光标后\nA           #在当前行尾\no           #在当前行之下新开一行\nO           #在当前行之上新开一行\nr           #替换当前字符\nR           #替换当前字符及其后的字符，直至按ESC键\ns           #从当前光标位置处开始，以输入的文本替代指定数目的字符\nS           #删除指定数目的行，并以所输入文本代替之\nncw或nCW    #修改指定数目的字\nnCC        #修改指定数目的行\nC          #删除光标位置到行尾的内容并进入插入模式 (相当于c$) \nc<范围>     #删除光标所在位置周围某个范围的文本并进入插入模式。关于范围请看第5点，常用的组合有：caw - 删除一个单词包括它后面的空格并开始插入； ciw - 删除一个单词并开始插入； ci\" - 删除一个字符串内部文本并开始插入； c$ - 从光标位置删除到行尾并开始插入； ct字符 - 从光标位置删除本行某个字符之前（保留该字符）并开始插入。等等。 \n```\n\n```shell\n常用的范围指令有： \n空格 #光标所在位置字符。（例如 gU空格 - 将光标位置字符转为大写） \n重复某些动作命令 - 光标所在行。 （例如dd删除一行，yy复制一行，cc删除一行文本并开始插入，>> 当前行缩进一格，==自动缩进当前行） \n$ - 从光标位置到行尾 \n^ - 从光标位置到行首，不包含缩进空白 \n0 - 从光标位置到行首，包含缩进空白 \ngg - 从光标位置到文件开头 \nG - 从光标位置到文件结尾 \n% - 从光标位置到另一边匹配的括号 \nf<字符> - 从光标位置到光标右边某个字符首次出现的位置，包括该字符 \nF<字符> - 从光标位置到光标左边某个字符首次出现的位置，包括该字符 \nt<字符> - 从光标位置到光标右边某个字符首次出现的位置，包括该字符 \nF<字符> - 从光标位置到光标左边某个字符首次出现的位置，包括该字符 \n/正则表达式 - 从光标位置到下一个匹配正则表达式的位置（跨行） \n?正则表达式 - 从光标位置到上一个匹配正则表达式的位置（跨行） \naw - 一个单词加一个空格 （a可理解为“一个”，下同） \niw - 一个单词 （i可理解为in，下同） \na\" - 一个字符串包括双引号 \ni\" - 一个字符串内部文本 \na< - 一组< >包含的文本，包括< >号本身 \n同理类推： i<, a[, i[, a(, i( \n注意：真正vim中的it范围（一对xml标签内部）在ideaVim中不生效。 \n```\n\n## 复制、粘贴\n\n```shell\nggvG    #全选\nyy    #将当前行复制到缓存区\nnyy   #将当前行向下n行复制到缓冲区\nyw    #复制从光标开始到词尾的字符。\nnyw   #复制从光标开始的n个单词。\ny^    #复制从光标到行首的内容。  \ny$    #复制从光标到行尾的内容。\np     #粘贴剪切板里的内容在光标后\nP     #粘贴剪切板里的内容在光标前\n```\n\n## 文本替换\n\n```shell\n:s/old/new           #用new替换行中首次出现的old\n:s/old/new/g         #用new替换行中所有的old\n:s/old/new/gc         #用new替换行中所有的old，每次都需要询问确认\n:n,m s/old/new/g     #用new替换从n到m行里所有的old\n:%s/old/new/g        #用new替换当前文件里所有的old ,简单替换表达式  :%s/four/4/g , “%” 范围前缀表示在所有行中执行替换，最后的 “g” 标记表示替换行中的所有匹配点，如果仅仅对当前行进行操作，那么只要去掉%即可\n如果你有一个像 “thirtyfour” 这样的单词，上面的命令会出错。这种情况下，这个单词会被替换成”thirty4″。要解决这个问题，用 “<”来指定匹配单词开头： :%s/<four/4/g , 显然，这样在处理 “fourty” 的时候还是会出错。用 “>” 来解决这个问题： :%s/<four>/4/g \n```\n\n## 删除命令\n\n```shell\nndw或ndW     #删除光标处开始及其后的n-1个字 ,并复制被删除的\ndo     #删至行首,并复制被删除的\nd$     #删至行尾,并复制被删除的\nndd    #删除当前行及其后n-1行,并复制被删除的\nx或X   #删除一个字符，x删除光标后的，而X删除光标前的\nCtrl+u #删除输入方式下所输入的文本\nx      #删除当前字符,并复制被删除的\nnx     #删除从光标开始的n个字符,并复制被删除的\ndd     #删除当前行,并复制被删除的\nndd    #向下删除当前行在内的n行,并复制被删除的\nu      #撤销上一步操作\nU      #撤销对当前行的所有操作\n```\n\n## 搜索及替换命令\n\n```shell\n/pattern     #从光标开始处向文件尾搜索pattern \n?pattern     #从光标开始处向文件首搜索pattern\nn            #在同一方向重复上一次搜索命令\nN            #在反方向上重复上一次搜索命令\n：s/p1/p2/g  #将当前行中所有p1均用p2替代\n：n1,n2s/p1/p2/g   #将第n1至n2行中所有p1均用p2替代\n：g/p1/s//p2/g     #将文件中所有p1均用p2替换\n```\n\n\n\n## 打开多个文件：vim 1.txt 2.txt\n\n```shell\nvim -o 1.txt 2.txt          #水平分割显示\nvim -O 1.txt 2.txt          #垂直分割显示\nctrl+w 放开后按 s            #水平拆分窗口\nctrl+w 放开后按 v            #垂直拆分窗口\nctrl+w 放开后按 w   \t\t #放开后按上下箭头：在各个窗口中切换光标\n:next                       #切换到下一个文件\n:prev                       #切换到上一个文件\n:last                       #切换到最后一个文件\n:first                      #切换至第一个文件\n:qa                         #退出全部\n```\n\n\n\nvim编辑器\n\n\n​\t\n\t使用\n\t\tvim：模式化的编辑\n\t\n\t\t\t基本模式：\n\t\t\t\t编辑模式，命令模式\n\t\t\t\t输入模式\n\t\t\t\t末行模式：\n\t\t\t\t\t内置的命令行接口\n\t\n\t\t\t打开文件：\n\t\t\t\t# vim [OPTION]... FILE...\n\t\t\t\t\t+#: 打开文件后，直接让光标处于第#行的行首；\n\t\t\t\t\t+/PATTERN：打开文件后，直接让光标处于第一个被PATTERN匹配到的行的行首；\n\t\n\t\t\t模式转换：\n\t\t\t\t编辑模式 --> 输入模式\n\t\t\t\t\ti: insert, 在光标所在处输入；\n\t\t\t\t\ta: append, 在光标所在处后面输入；\n\t\t\t\t\to: 在当前光标所在行的下方打开一个新行；\n\t\t\t\t\tI：在当前光标所在行的行首输入；\n\t\t\t\t\tA：在当前光标所在行的行尾输入；\n\t\t\t\t\tO：在当前光标所在行的上方打开一个新行；\n\t\t\t\t\tc\n\t\t\t\t\tC\n\t\n\t\t\t\t输入模式 --> 编辑模式\n\t\t\t\t\tESC\n\t\n\t\t\t\t编辑模式 --> 末行模式\n\t\t\t\t\t:\n\t\n\t\t\t\t末行模式 --> 编辑模式\n\t\t\t\t\tESC\n\t\n\t\t\t关闭文件：\n\t\t\t\t:q 退出\n\t\t\t\t:q! 强制退出，丢弃做出的修改；\n\t\t\t\t:wq 保存退出\n\t\t\t\t:x 保存退出\n\t\t\t\t:w /PATH/TO/SOMEWHERE\n\t\n\t\t\t\tZZ: 保存退出；\n\t\n\t\t光标跳转：\n\t\t\t\n\t\t\t字符间跳转：\n\t\t\t\th, j, k, l\n\t\t\t\t\th: 左\n\t\t\t\t\tl: 右\n\t\t\t\t\tj: 下\n\t\t\t\t\tk: 上\n\t\n\t\t\t\t#COMMAND：跳转由#指定的个数的字符；\n\t\n\t\t\t单词间跳转：\n\t\t\t\tw：下一个单词的词首\n\t\t\t\te：当前或下一单词的词尾\n\t\t\t\tb：当前或前一个单词的词首\n\t\n\t\t\t\t#COMMAND：由#指定一次跳转的单词数\n\t\n\t\t\t行首行尾跳转：\n\t\t\t\t^: 跳转至行首的第一个非空白字符；\n\t\t\t\t0: 跳转至行首；\n\t\t\t\t$: 跳转至行尾；\n\t\n\t\t\t行间移动：\n\t\t\t\t#G：跳转至由#指定行；\n\t\t\t\tG：最后一行；\n\t\t\t\t1G, gg: 第一行；\n\t\n\t\t\t句间移动：\n\t\t\t\t)\n\t\t\t\t(\n\t\n\t\t\t段落间移动：\n\t\t\t\t}\n\t\t\t\t{\n\t\n\tvim的编辑命令：\n\t\n\t\t字符编辑：\n\t\t\tx: 删除光标处的字符；\n\t\t\t#x: 删除光标处起始的#个字符；\n\t\n\t\t\txp: 交换光标所在处的字符及其后面字符的位置；\n\t\n\t\t替换命令(r, replace)\n\t\t\tr: 替换光标所在处的字符\n\t\n\t\t删除命令：\n\t\t\td: 删除命令，可结合光标跳转字符，实现范围删除；\n\t\t\t\td$: \n\t\t\t\td^:\n\t\t\t\td0:\n\t\n\t\t\t\tdw\n\t\t\t\tde\n\t\t\t\tdb\n\t\n\t\t\t\t\t#COMMAND\n\t\n\t\t\t\tdd: 删除光标所在的行；\n\t\t\t\t\t#dd：多行删除；\n\t\n\t\t粘贴命令(p, put, paste)：\n\t\t\tp：缓冲区存的如果为整行，则粘贴当前光标所在行的下方；否则，则粘贴至当前光标所在处的后面；\n\t\t\tP：缓冲区存的如果为整行，则粘贴当前光标所在行的上方；否则，则粘贴至当前光标所在处的前面；\n\t\n\t\t复制命令(y, yank)：\n\t\t\ty: 复制，工作行为相似于d命令；\n\t\t\t\ty$\n\t\t\t\ty0\n\t\t\t\ty^\n\t\n\t\t\t\tye\n\t\t\t\tyw\n\t\t\t\tyb\n\t\n\t\t\t\t\t#COMMAND\n\t\n\t\t\t\tyy：复制行\n\t\t\t\t\t#yy: 复制多行；\n\t\n\t\t改变命令(c, change)\n\t\t\tc: 修改\n\t\t\t\t编辑模式 --> 输入模式\n\t\n\t\t\t\tc$\n\t\t\t\tc^\n\t\t\t\tc0\n\t\n\t\t\t\tcb\n\t\t\t\tce\n\t\t\t\tcw\n\t\t\t\t\t#COMMAND\n\t\n\t\t\t\tcc：删除并输入新内容\n\t\t\t\t#cc: \n\t\n\t\t其它编辑操作\n\t\n\t\t\t可视化模式：\n\t\t\t\tv: 按字符选定\n\t\t\t\tV：按行行定\n\t\n\t\t\t\tNote：经常结合编辑命令；\n\t\t\t\t\td, c, y\n\t\n\t\t\t撤消此前的编辑：\n\t\t\t\tu(undo)：撤消此前的操作；\n\t\t\t\t\t#u: 撤消指定次数的操作；\n\t\n\t\t\t撤消此前的撤消：\n\t\t\t\tCtrl+r\n\t\n\t\t\t重复前一个编辑操作：\n\t\t\t\t.\n\n\n​\t\n\tvim中的末行模式：\n\t\t内建的命令行接口\n\t\n\t\t(1) 地址定界\n\t\t\t:start_pos,end_pos\n\t\t\t\t#: 具体第#行，例如2表示第2行；\n\t\t\t\t#,#: 从左侧#表示行起始，到右侧#表示行结尾；\n\t\t\t\t#,+#: 从左侧#表示的行起始，加上右侧#表示的行数；\n\t\t\t\t.: 当前行\n\t\t\t\t$: 最后一行\n\t\t\t\t\t.,$-1\n\t\t\t\t%：全文, 相当于1,$\n\t\n\t\t\t\t/pat1/,/pat2/：\n\t\t\t\t\t从第一次被pat1模式匹配到的行开始，一直到第一次被pat2匹配到的行结束；\n\t\t\t\t\t#,/pat/\n\t\t\t\t\t/pat/,$\n\t\n\t\t\t使用方式：\n\t\t\t\t后跟一个编辑命令\n\t\t\t\t\td\n\t\t\t\t\ty\n\t\t\t\t\tw /PATH/TO/SOMEWHERE: 将范围内的行另存至指定文件中；\n\t\t\t\t\tr /PATH/FROM/SOMEFILE：在指定位置插入指定文件中的所有内容；\n\t\n\t\t(2) 查找\n\t\t\t/PATTERN：从当前光标所在处向文件尾部查找；\n\t\t\t?PATTERN：从当前光标所在处向文件首部查找；\n\t\t\t\tn：与命令同方向；\n\t\t\t\tN：与命令反方向；\n\t\n\t\t(3) 查找并替换\n\t\t\ts: 在末行模式下完成查找替换操作\n\t\t\t\ts/要查找的内容/替换为的内容/修饰符\n\t\t\t\t\t要查找的内容：可使用模式\n\t\t\t\t\t替换为的内容：不能使用模式，但可以使用\\1, \\2, ...等后向引用符号；还可以使用“&”引用前面查找时查找到的整个内容；\n\t\t\t\t\t修饰符：\n\t\t\t\t\t\ti: 忽略大小写\n\t\t\t\t\t\tg: 全局替换；默认情况下，每一行只替换第一次出现；\n\t\n\t\t\t\t查找替换中的分隔符/可替换为其它字符，例如\n\t\t\t\t\ts@@@\n\t\t\t\t\ts###\n\t\n\t\t\t练习：\n\t\t\t\t1、复制/etc/grub2.cfg至/tmp/目录，用查找替换命令删除/tmp/grub2.cfg文件中的行首的空白字符；\n\t\t\t\t\t%s/^[[:space:]]\\+//g\n\t\n\t\t\t\t2、复制/etc/rc.d/init.d/functions文件至/tmp目录，用查找替换命令为/tmp/functions的每行开头为空白字符的行的行首添加一个#号；\n\t\t\t\t\t:%s/^[[:space:]]/#&/\n\n\n​\t\n​\t\n​\t\n​\t","slug":"linux/vim编辑器","published":1,"updated":"2018-09-12T03:03:21.824Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnhh003ywlkv9me6281h"},{"title":"mysql","catalog":"保证内存可见性","date":"2017-09-01T02:51:24.000Z","subtitle":"","header-img":null,"_content":"\n# Mysql\n\nmysql\n\n<!--more-->\n\nshow variables like '%thread%';\n\n```\n| Variable_name                           | Value                     |\n+-----------------------------------------+---------------------------+\n| innodb_purge_threads                    | 1                         |\n| innodb_read_io_threads                  | 4                         |\n| innodb_thread_concurrency               | 0                         |\n| innodb_thread_sleep_delay               | 10000                     |\n| innodb_write_io_threads                 | 4                         |\n| max_delayed_threads                     | 20                        |\n| max_insert_delayed_threads              | 20                        |\n| myisam_repair_threads                   | 1                         |\n| performance_schema_max_thread_classes   | 50                        |\n| performance_schema_max_thread_instances | -1                        |\n| pseudo_thread_id                        | 2034351984                |\n| thread_cache_size                       | 18                        | //缓存多少个线程\n| thread_concurrency                      | 10                        |\n| thread_handling                         | one-thread-per-connection | //每个连接一个线程\n| thread_stack                            | 262144                    |\n+-----------------------------------------+---------------------------+\n```\n\n show variables like '%conn%';\n\n```\n+-----------------------------------------------+-----------------+\n| Variable_name                                 | Value           |\n+-----------------------------------------------+-----------------+\n| character_set_connection                      | utf8            |\n| collation_connection                          | utf8_general_ci |\n| connect_timeout                               | 10              |\n| disconnect_on_expired_password                | ON              |\n| init_connect                                  |                 |\n| max_connect_errors                            | 100             |\n| max_connections                               | 1000            | /最大连接数\n| max_user_connections                          | 0               |\n| performance_schema_session_connect_attrs_size | -1              |\n+-----------------------------------------------+-----------------+\n```\n\nshow status like '%conn%';  查看当前mysql实例连接数情况\n\n```\n+-----------------------------------------------+------------+\n| Variable_name                                 | Value      |\n+-----------------------------------------------+------------+\n| Aborted_connects                              | 1992481369 |\n| Connection_errors_accept                      | 0          |\n| Connection_errors_internal                    | 0          |\n| Connection_errors_max_connections             | 0          |\n| Connection_errors_peer_address                | 0          |\n| Connection_errors_select                      | 0          |\n| Connection_errors_tcpwrap                     | 0          |\n| Connections                                   | 2034359919 |\n| Max_used_connections                          | 968        |  //产生过的最大连接数\n| Performance_schema_session_connect_attrs_lost | 0          |\n| Ssl_client_connects                           | 0          |\n| Ssl_connect_renegotiates                      | 0          |\n| Ssl_finished_connects                         | 0          |\n| Threads_connected                             | 543        |  //当前已连接数\n+-----------------------------------------------+------------+\n```\n\nshow variables like '%slow%';\n\n```java\n+---------------------------+----------------------------------------------+\n| Variable_name             | Value                                        |\n+---------------------------+----------------------------------------------+\n| log_slow_admin_statements | OFF                                          |\n| log_slow_slave_statements | OFF                                          |\n| slow_launch_time          |\n| slow_query_log            | ON                                           |//开启慢sql收集\n| slow_query_log_file       | /rdsdbdata/log/slowquery/mysql-slowquery.log |\n+---------------------------+----------------------------------------------+\n```\n\n show variables like '%long_query%';\n\n```\n+-----------------+----------+\n| Variable_name   | Value    |\n+-----------------+----------+\n| long_query_time | 1.000000 |  //执行时间超过1秒的sql将会被收集到日志里面\n+-----------------+----------+\n```\n\nselect * from mysql.slow_log ;查询慢sql语句\n\n","source":"_posts/mysql/mysql.md","raw":"---\ntitle: mysql\ncatalog: 保证内存可见性\ndate: 2017-09-01 10:51:24\nsubtitle: \"\"\nheader-img: \ntags:\n- mysql\ncategories:\n- 数据库\n\n---\n\n# Mysql\n\nmysql\n\n<!--more-->\n\nshow variables like '%thread%';\n\n```\n| Variable_name                           | Value                     |\n+-----------------------------------------+---------------------------+\n| innodb_purge_threads                    | 1                         |\n| innodb_read_io_threads                  | 4                         |\n| innodb_thread_concurrency               | 0                         |\n| innodb_thread_sleep_delay               | 10000                     |\n| innodb_write_io_threads                 | 4                         |\n| max_delayed_threads                     | 20                        |\n| max_insert_delayed_threads              | 20                        |\n| myisam_repair_threads                   | 1                         |\n| performance_schema_max_thread_classes   | 50                        |\n| performance_schema_max_thread_instances | -1                        |\n| pseudo_thread_id                        | 2034351984                |\n| thread_cache_size                       | 18                        | //缓存多少个线程\n| thread_concurrency                      | 10                        |\n| thread_handling                         | one-thread-per-connection | //每个连接一个线程\n| thread_stack                            | 262144                    |\n+-----------------------------------------+---------------------------+\n```\n\n show variables like '%conn%';\n\n```\n+-----------------------------------------------+-----------------+\n| Variable_name                                 | Value           |\n+-----------------------------------------------+-----------------+\n| character_set_connection                      | utf8            |\n| collation_connection                          | utf8_general_ci |\n| connect_timeout                               | 10              |\n| disconnect_on_expired_password                | ON              |\n| init_connect                                  |                 |\n| max_connect_errors                            | 100             |\n| max_connections                               | 1000            | /最大连接数\n| max_user_connections                          | 0               |\n| performance_schema_session_connect_attrs_size | -1              |\n+-----------------------------------------------+-----------------+\n```\n\nshow status like '%conn%';  查看当前mysql实例连接数情况\n\n```\n+-----------------------------------------------+------------+\n| Variable_name                                 | Value      |\n+-----------------------------------------------+------------+\n| Aborted_connects                              | 1992481369 |\n| Connection_errors_accept                      | 0          |\n| Connection_errors_internal                    | 0          |\n| Connection_errors_max_connections             | 0          |\n| Connection_errors_peer_address                | 0          |\n| Connection_errors_select                      | 0          |\n| Connection_errors_tcpwrap                     | 0          |\n| Connections                                   | 2034359919 |\n| Max_used_connections                          | 968        |  //产生过的最大连接数\n| Performance_schema_session_connect_attrs_lost | 0          |\n| Ssl_client_connects                           | 0          |\n| Ssl_connect_renegotiates                      | 0          |\n| Ssl_finished_connects                         | 0          |\n| Threads_connected                             | 543        |  //当前已连接数\n+-----------------------------------------------+------------+\n```\n\nshow variables like '%slow%';\n\n```java\n+---------------------------+----------------------------------------------+\n| Variable_name             | Value                                        |\n+---------------------------+----------------------------------------------+\n| log_slow_admin_statements | OFF                                          |\n| log_slow_slave_statements | OFF                                          |\n| slow_launch_time          |\n| slow_query_log            | ON                                           |//开启慢sql收集\n| slow_query_log_file       | /rdsdbdata/log/slowquery/mysql-slowquery.log |\n+---------------------------+----------------------------------------------+\n```\n\n show variables like '%long_query%';\n\n```\n+-----------------+----------+\n| Variable_name   | Value    |\n+-----------------+----------+\n| long_query_time | 1.000000 |  //执行时间超过1秒的sql将会被收集到日志里面\n+-----------------+----------+\n```\n\nselect * from mysql.slow_log ;查询慢sql语句\n\n","slug":"mysql/mysql","published":1,"updated":"2018-09-12T03:03:21.825Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnhj0042wlkv0uwu1vje"},{"title":"spring-boot初识","date":"2017-10-20T10:18:04.000Z","_content":"\n# spring boot初识\n\n## 使用spring boot\n\n- 继承\n\n- 引入\n\n  如果不想继承spring-boot-starter-parent，可以引入spring-boot-dependencies的jar包，指定scope为import。\n\n  ```xml\n  <dependencyManagement>\n       <dependencies>\n         <!-- Override Spring Data release train provided by Spring Boot -->\n          <dependency>\n              <groupId>org.springframework.data</groupId>\n              <artifactId>spring-data-releasetrain</artifactId>\n              <version>Fowler-SR2</version>\n              <scope>import</scope>\n              <type>pom</type>\n          </dependency>\n          <dependency>\n              <!-- Import dependency management from Spring Boot -->\n              <groupId>org.springframework.boot</groupId>\n              <artifactId>spring-boot-dependencies</artifactId>\n              <version>1.5.9.RELEASE</version>\n              <type>pom</type>\n              <scope>import</scope>\n          </dependency>\n      </dependencies>\n  </dependencyManagement>\n  ```\n\n\n- Spring-boot打包\n\n  ```xml\n  <build>\n      <plugins>\n          <plugin>\n              <groupId>org.springframework.boot</groupId>\n              <artifactId>spring-boot-maven-plugin</artifactId>\n          </plugin>\n      </plugins>\n  </build>\n  ```\n\n- @EnableAutoConfiguration\n\n  - ​        这里我们只需要关心 @EnableAutoConfiguration 即可。这个注解是让Spring Boot*猜测 *你想怎么配置Spring，但实际上，它是根据你添加到classpath中的依赖来判断的。\n\n- SpringApplication.run(IndexController.class,args);\n\n- @SpringBootApplication\n\n- mvn spring-boot:run\n\n- actuator","source":"_posts/spring/spring boot初识.md","raw":"---\ntitle: spring-boot初识\ndate: 2017-10-20 18:18:04\ntags:\n- spring \n- spring-boot\ncategories:\n- spring\n\n---\n\n# spring boot初识\n\n## 使用spring boot\n\n- 继承\n\n- 引入\n\n  如果不想继承spring-boot-starter-parent，可以引入spring-boot-dependencies的jar包，指定scope为import。\n\n  ```xml\n  <dependencyManagement>\n       <dependencies>\n         <!-- Override Spring Data release train provided by Spring Boot -->\n          <dependency>\n              <groupId>org.springframework.data</groupId>\n              <artifactId>spring-data-releasetrain</artifactId>\n              <version>Fowler-SR2</version>\n              <scope>import</scope>\n              <type>pom</type>\n          </dependency>\n          <dependency>\n              <!-- Import dependency management from Spring Boot -->\n              <groupId>org.springframework.boot</groupId>\n              <artifactId>spring-boot-dependencies</artifactId>\n              <version>1.5.9.RELEASE</version>\n              <type>pom</type>\n              <scope>import</scope>\n          </dependency>\n      </dependencies>\n  </dependencyManagement>\n  ```\n\n\n- Spring-boot打包\n\n  ```xml\n  <build>\n      <plugins>\n          <plugin>\n              <groupId>org.springframework.boot</groupId>\n              <artifactId>spring-boot-maven-plugin</artifactId>\n          </plugin>\n      </plugins>\n  </build>\n  ```\n\n- @EnableAutoConfiguration\n\n  - ​        这里我们只需要关心 @EnableAutoConfiguration 即可。这个注解是让Spring Boot*猜测 *你想怎么配置Spring，但实际上，它是根据你添加到classpath中的依赖来判断的。\n\n- SpringApplication.run(IndexController.class,args);\n\n- @SpringBootApplication\n\n- mvn spring-boot:run\n\n- actuator","slug":"spring/spring boot初识","published":1,"updated":"2018-09-12T03:03:21.826Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnhk0046wlkv6hwnnvf9"},{"title":"netty","date":"2018-05-15T15:12:12.000Z","_content":"\n# Netty\n\nnetty是高性能网络编程技术\n\n<!--more-->\n\nNetty 的主要构件块: \n\n- Channel：它代表一个到实体(如一个硬件设备、一个文件、一个网络套接字或者一个能够执行一个或者多个不同的I/O操作的程序组件)的开放连接，如读操作和写操作 。 目前，可以把 Channel 看作是传入(入站)或者传出(出站)数据的载体。因此，它可以被打开或者被关闭，连接或者断开连接。\n\n-  回调：被通知回调的方法。Netty 在内部使用了回调来处理事件;当一个回调被触发时，相关的事件可以被一个 interface-ChannelHandler 的实现处理\n\n- Future：Future 提供了另一种在操作完成时通知应用程序的方式，它将在未来的某个时刻完成，并提供对其结果的访问。每个 Netty 的出站 I/O 操作都将返回一个 ChannelFuture;也就是说，它们都不会阻塞。netty中的大部分方法都是异步的，返回值都是通过回调通知的，如connect方法不会阻塞，它将会注册一个ChannelFutureListener\n\n  ```java\n  ChannelFuture future = channel.connect(\n  new InetSocketAddress(\"192.168.0.1\", 25)); future.addListener(new ChannelFutureListener() {\n  @Override\n  public void operationComplete(ChannelFuture future) {\n  if (future.isSuccess()){\n  ByteBuf buffer = Unpooled.copiedBuffer(\n  \"Hello\",Charset.defaultCharset()); ChannelFuture wf = future.channel() .....writeAndFlush(buffer);\n  } else {\n  Throwable cause = future.cause();\n                cause.printStackTrace();\n            }\n  }); \t\n  ```\n\n- 事件:Netty 使用不同的事件来通知我们状态的改变或者是操作的状态\n\n  - 连接已被激活或者连接失活\n  - 数据读取\n  - 用户事件\n  - 错误事件\n  - 打开或关闭到远程的连接\n  - 将数据写到或冲刷到套接字\n\n- ChannelHandler：负责接收和响应事件通知\n\n  - 针对不同类型的事件来调用 ChannelHandler;\n  - 将数据从一种格式转换为另一种格式\n  - 提供异常的通知\n  - 提供channel变为活动或非活动的通知\n  - 提供channel注册到eventLoop或从eventLoop注销时的通知\n  - 应用程序通过实现或者扩展 ChannelHandler 来挂钩到事件的生命周期，并且提供自定义的应用程序逻辑;\n\n  ChannelHandler的生命周期方法\n\n  - handlerAdded：handler添加到channelPipeline中调用\n  - handlerRemoved：从channelPipeline中移除handler时调用\n  - exceptionCaught：在channelPipeline有异常产生时调用\n\n在内部，将会为每个 Channel 分配一个 EventLoop，用以处理所有事件，包括:\n\n- 注册感兴趣的事件;\n- 将事件派发给 ChannelHandler;\n- 安排进一步的动作。\nEventLoop 本身只由一个线程驱动，其处理了一个 Channel 的所有 I/O 事件，并且在该EventLoop 的整个生命周期内都不会改变。\n\n\n\n@Sharable :在channalHandler上添加该注解标识该handler可以安全的被多个channel共享\n\n如果服务器发送了 5 字节，那么不能保证这 5 字节会被一次性接收。即使是对于这么少量的数据，channelRead0()方法也可能会被调用两次，第一次使用一个持有 3 字节的 ByteBuf(Netty 的字节容器)，第二次使用一个持有 2 字节的 ByteBuf。作为一个面向流的协议，TCP 保证了字节数组将会按照服务器发送它们的顺序被接收。\n\n\nexec-maven-plugin\n​\t\t\n- Channel— Socket; \n\n  基本的 I/O 操作(bind()、connect()、read()和 write())依赖于底层网络传输所提供的原语。在基于 Java 的网络编程中，其基本的构造是 class Socket。 \n\n  每个channel都会分配一个channelPileline和channelConfig\n\n  可以通过channel获取分配给channel的eventLoop、channelPileLine、channelConfig、localAddress\n\n  可以通过channel的write和fush方法实现写I/O\n\n  Netty 的 Channel 实现是线程安全的，因此你可以存储一个到 Channel 的引用，并且每当\n  你需要向远程节点写数据时，都可以使用它，即使当时许多线程都在使用它。\n\n  channel分四个状态，\n\n  - ChannelUnregistered ：channel已被创建，但未注册到EventLoop上\n\n  - ChannelRegistered ：channel已被注册到EventLoop上\n\n  - ChannelActive ：channel已经连接到远程节点，可以发送和接收数据\n\n  - ChannelInActive：channel没有连接到远程节点\n\n    ​\n    channel在声明周期的每次状态变化都会有事件通知到ChannelPipeline链中的每个ChannelHandler\n\n    在多个ChannelPipeline中安装同一个ChannelHandler的一个常见的原因是用于收集跨越多个 Channel 的统计信息。\n\n\n\n- EventLoop— 控制流、多线程处理、并发;\n\n  - 一个 EventLoopGroup 包含一个或者多个 EventLoop;  \n  - 一个 EventLoop 在它的生命周期内只和一个 Thread 绑定;  即EventLoop和Thread的关系是一对一\n  - 所有由 EventLoop 处理的 I/O 事件都将在它专有的 Thread 上被处理;  \n  - 一个 Channel 在它的生命周期内只注册于一个 EventLoop;  \n  - 一个 EventLoop 可能会被分配给一个或多个 Channel。 即EventLoop和channel的关系是一对多\n\n- ChannelFuture— 异步通知。 \n\n  Netty 中所有的 I/O 操作都是异步的。因为一个操作可能不会 立即返回，所以我们需要一种用于在之后的某个时间点确定其结果的方法。为此，Netty 提供了 ChannelFuture接口，其addListener()方法注册了一个ChannelFutureListener，以 便在某个操作完成时(无论是否成功)得到通知。 \n\n  所有属于同一个 Channel 的操作都被保证其将以它们被调用的顺序被执行。 \n\n- ChannelPipeline \n\n  ChannelPipeline 提供了 ChannelHandler 链的容器，并定义了用于在该链上传播入站 和出站事件流的 API。每一个新创建的Channel都会自动地分配一个新的 ChannelPipeline。\n\n  - 一个ChannelInitializer的实现被注册到了ServerBootstrap中 1;\n  - 当 ChannelInitializer.initChannel()方法被调用时，ChannelInitializer 将在 ChannelPipeline 中安装一组自定义的 ChannelHandler; \n  - ChannelInitializer 将它自己从 ChannelPipeline 中移除。 \n\n  这些对象接收事件、执行它们所实现的处理逻辑，并将数据传递给ChannelHandler链中的下一个 ChannelHandler。它们的执行顺序是由它们被添加的顺序所决定的。实际上ChannelPipeline 就是给这些 ChannelHandler编排顺序的。\n\n  数据的出站运动(即正在被写的数据)在概念上也是一样的。在这种情况下，数据将从 ChannelOutboundHandler 链的尾端开始流动，直到它到达链的头部为止。在这之后，出站 数据将会到达网络传输层，这里显示为 Socket。通常情况下，这将触发一个写操作。 \n\n  数据的入站运动那么它会从 ChannelPipeline 的头部开始流动，并被传递给第一个 ChannelInboundHandler。这个 ChannelHandler 不一定 会实际地修改数据，具体取决于它的具体功能，在这之后，数据将会被传递给链中的下一个 ChannelInboundHandler。最终，数据将会到达 ChannelPipeline 的尾端，届时，所有 处理就都结束了。  \n\n  当 ChannelHandler 被添加到 ChannelPipeline 时，它将会被分配一个 ChannelHandler- Context，其代表了 ChannelHandler 和 ChannelPipeline 之间的绑定。虽然这个对象可 以被用于获取底层的 Channel，但是它主要还是被用于写出站数据。 \n\n  在Netty中，有两种发送消息的方式。你可以直接写到Channel中，也可以 写到和Channel- Handler 相关联的 ChannelHandlerContext 对象中。前一种方式将会导致消息从 Channel- Pipeline 的尾端开始流动，而后者将导致消息从 ChannelPipeline 中的下一个 Channel- Handler 开始流动。 \n\n  通常 ChannelPipeline 中的每一个 ChannelHandler 都是通过它的 EventLoop(I/O 线程)来处理传递给它的事件的。所以至关重要的是不要阻塞这个线程，因为这会对整体的 I/O 处理产生负面的影响\n\n   ChannelHandler.exceptionCaught()的默认实现是简单地将当前异常转发给ChannelPipeline 中的下一个 ChannelHandler; 如果异常到达了 ChannelPipeline 的尾端，它将会被记录为未被处理; 要想定义自定义的处理逻辑，你需要重写 exceptionCaught()方法。然后你需要决定是否需要将该异常传播出去。\n\n- ChannelConfig\n\n  ChannelConfig 包含了该 Channel 的所有配置设置，并且支持热更新。由于特定的传输可能\n  具有独特的设置，所以它可能会实现一个 ChannelConfig 的子类型(\n\n- ChannelHandlerContext\n\n  ChannelHandlerContext使得ChannelHandler能够和它的ChannelPipeline以及其他的ChannelHandler 交 互 。 ChannelHandler 可 以 通 知 其 所 属 的 ChannelPipeline 中 的 下 一 个ChannelHandler，甚至可以动态修改它所属的ChannelPipeline1。\n\n  ChannelHandlerContext 具有丰富的用于处理事件和执行 I/O 操作的 API。\n\n  如果调用 Channel 或者 ChannelPipeline 上的这些方法，它们将沿着整个 ChannelPipeline 进行传播。而调用位于 ChannelHandlerContext上的相同方法，则将从当前所关联的 ChannelHandler 开始，并且只会传播给位于该ChannelPipeline 中的下一个能够处理该事件的 ChannelHandler。\n\n\n  ​\t\t\t\n  ​\t\t\n  ​\t\n\n\n选择器selector背后的基本概念是充当一个注册表，在那里你将可以请求在 Channel 的状态发生变化时得到通知。可能的状态变化有:\n\n-  新的 Channel 已被接受并且就绪;\n-  Channel 连接已经完成;\n-  Channel 有已经就绪的可供读取的数据;\n-  Channel 可用于写数据。\n\n选择器运行在一个检查状态变化并对其做出相应响应的线程上，在应用程序对状态的改变做出响应之后，选择器将会被重置，并将重复这个过程。\n\n![](http://omdq6di7v.bkt.clouddn.com/18-5-17/40931059.jpg)  \t\n\n### 编码器和解码器\n\n当你通过 Netty 发送或者接收一个消息的时候，就将会发生一次数据转换。入站消息会被解 码;也就是说，从字节转换为另一种格式，通常是一个 Java 对象。如果是出站消息，则会发生 相反方向的转换:它将从它的当前格式被编码为字节。这两种方向的转换的原因很简单:网络数 据总是一系列的字节。 \n\n### 引导 \n\nNetty 的引导类为应用程序的网络层配置提供了容器，这涉及将一个进程绑定到某个指定的 端口，或者将一个进程连接到另一个运行在某个指定主机的指定端口上的进程。 \n\n- Bootstrap \n\n  连接到远程主机和端口 \n\n  1个EventLoopGroup \n\n- ServerBootstrap\n\n  绑定到一个本地端口 \n\n  2个EventLoopGroup \n\n  ​\t因为服务器需要两组不同的 Channel。第一组将只包含一个 ServerChannel，代表服务 器自身的已绑定到某个本地端口的正在监听的套接字。而第二组将包含所有已创建的用来处理传 入客户端连接(对于每个服务器已经接受的连接都有一个)的 Channel。 与 ServerChannel 相关联的 EventLoopGroup 将分配一个负责为传入连接请求创建 Channel 的 EventLoop。一旦连接被接受，第二个 EventLoopGroup 就会给它的 Channel 分配一个 EventLoop。\n\n  ​\n\n  ​\n##ByteBuf、ByteBufHolder\n\n网络传输中的数据都是字节，java提供了ByteBuffer用来存储字节，netty对ByteBuffer进行了优化，使用ByteBuf来存储，\n\n#### ByteBuf netty的数据容器\n\n-  它可以被用户自定义的缓冲区类型扩展\n\n\n- 通过内置的复合缓冲区类型实现了透明的零拷贝\n- 容量可以按需增长(类似于 JDK 的 StringBuilder);\n- 在读和写这两种模式之间切换不需要调用 ByteBuffer 的 flip()方法;\n- 读和写使用了不同的索引;\n- 支持方法的链式调用;\n- 支持引用计数;\n- 支持池化。\n\nByteBuf 维护了两个不同的索引:一个用于读取，一个用于写入。两个索引都是从0开始，当你从 ByteBuf 读取时，\n它的 readerIndex 将会被递增已经被读取的字节数。同样地，当你写入 ByteBuf 时，它的writerIndex 也会被递增。\n\n如果指定的读取的readerIndex>writerIndex的时候，将会抛出一个越界异常\n\n名称以 read 或者 write 开头的 ByteBuf 方法，将会推进其对应的索引，而名称以 set 或者 get 开头的操作则不会。\n\n任何名称以 read 或者 skip 开头的操作都将检索或者跳过位于当前readerIndex 的数据，并且将它增加已读字节数。\n\n\n![](http://omdq6di7v.bkt.clouddn.com/18-5-17/70804660.jpg)\t\t\t\n可丢弃字节的分段包含了已经被读过的字节。通过调用 discardReadBytes()方法，可以丢弃它们并回收空间。这个分段的初始大小为 0，存储在 readerIndex 中，会随着 read 操作的执行而增加(get*操作不会移动 readerIndex)。\n\n调用discardReadBytes()方法会回收已读取的空间，同时会将可读取字节向前copy移动，调用该方法一方面最大化可写空间，当也需要copy移动可读字节\n\n![](http://omdq6di7v.bkt.clouddn.com/18-5-17/22320572.jpg)\t\t\t\n​\t\t\t\t\n通过调用 markReaderIndex()、markWriterIndex()、resetWriterIndex()和 resetReaderIndex()来标记和重置 ByteBuf 的 readerIndex 和 writerIndex。\n\n可以通过调用 clear()方法来将 readerIndex 和 writerIndex 都设置为 0。注意这并不会清除内存中的内容。只移动索引。调用 clear()比调用 discardReadBytes()轻量得多，因为它将只是重置索引而不会复制任何的内存\n\n可以同 indexOf和buf.forEachByte(ByteBufProcessor.FIND_NUL) 进行查找\n\nduplicat和slice、unmodifiableBuffer是对byteBuf的浅拷贝，对象内容还是一个，调用copy方法是深拷贝\n\nhasArray()？？？？byteBuf的存储类型？？？\tByteBufHolder ？？？\n\nByteBuf 分配 \t\tByteBufAllocator？？？\n\n可以通过 Channel(每个都可以有一个不同的 ByteBufAllocator 实例)或者绑定到\nChannelHandler 的 ChannelHandlerContext 获取一个到 ByteBufAllocator 的引用。\tByteBufAllocator allocator = channel.alloc();\t从 Channel 获取一个到ByteBufAllocator 的引用\n\nNetty提供了两种ByteBufAllocator的实现:PooledByteBufAllocator和Unpooled-\nByteBufAllocator。前者池化了ByteBuf的实例以提高性能并最大限度地减少内存碎片。此实\n现 使 用 了 一 种 称 为 j e m a l l o c 2 的 已 被 大 量 现 代 操 作 系 统 所 采 用 的 高 效 方 法 来 分 配 内 存 。后 者 的 实 现 不池化ByteBuf实例，并且在每次它被调用时都会返回一个新的实例。虽然Netty默认 1 使用了PooledByteBufAllocator，但这可以很容易地通过ChannelConfig API或者在引导你的应用程序时指定一个不同的分配器来更改。\n\n你未能获取一个到 ByteBufAllocator 的引用。对于这种情况，Netty 提供了一个简单的称为 Unpooled 的工具类，它提供了静态的辅助方法来创建未池化的 ByteBuf实例\n\nByteBufUtil.hexdump() \t 它以十六进制的表示形式打印 ByteBuf 的内容\n\n\nReferenceCountUtil.release(msg) ：丢弃已经接收到的消息\n\n​\t\t\t\n\n根据配置和可用核心的不同，可能会创建多个 EventLoop 实例用以优化资源的使用，并且单个EventLoop 可能会被指派用于服务多个 Channel。\n\n事件/任务的执行顺序 事件和任务是以先进先出(FIFO)的顺序执行的。这样可以通过保证字节内容总是按正确的顺序被处理，消除潜在的数据损坏的可能性。\n\n每个 EventLoop 都有它自已的任务队列，独立于任何其他的 EventLoop\n\n\n![](http://omdq6di7v.bkt.clouddn.com/18-5-21/1077564.jpg)\t\n永远不要将一个长时间运行的任务放入到执行队列中，因为它将阻塞需要在同一线程上执行的任何其他任务。”如果必须要进行阻塞调用或者执行长时间运行的任务，我们建议使用一个专门的EventExecutor\n\n​\t\t\t\n![](http://omdq6di7v.bkt.clouddn.com/18-5-21/29017964.jpg)\t\t\n异步传输实现只使用了少量的 EventLoop(以及和它们相关联的 Thread)，而且在当前的线程模型中，它们可能会被多个 Channel 所共享。这使得可以通过尽可能少量的 Thread 来支撑大量的 Channel，而不是每个 Channel 分配一个 Thread\n\nEventLoopGroup 负责为每个新创建的 Channel 分配一个 EventLoop。在当前实现中，使用顺序循环(round-robin)的方式进行分配以获取一个均衡的分布，并且相同的 EventLoop可能会被分配给多个 Channel\n\n一旦一个 Channel 被分配给一个 EventLoop，它将在它的整个生命周期中都使用这个EventLoop(以及相关联的 Thread)\n\n\n![](http://omdq6di7v.bkt.clouddn.com/18-5-21/22826427.jpg)\t\t\t\n​\t\t\t\t\nBootstrap 类负责为客户端和使用无连接协议的应用程序创建 Channel\t\n\n```\n<T> Bootstrap option(\n    ChannelOption<T> option,\n    T value)\n设置 ChannelOption，其将被应用到每个新创建的Channel 的 ChannelConfig。这些选项将会通过bind()或者 connect()方法设置到 Channel，不管哪个先被调用。这个方法在 Channel 已经被创建后再调用将不会有任何的效果。支持的 ChannelOption 取决于使用的 Channel 类型。\n```\n\n\n​\t\t\t\n​\t\t\n​\t\n\n\n​\t\t\t\t\n​\t\t\t\n​\t\t\n​\t\n\n​\t\n\n\n​\t\t\t\n​\t\t\n​\t\t\t\n\n​\t\t\t\t\n​\t\t\n​\t\n\n\n​\t\t\t\n​\t\t\n​\t\n\n\n​\t\t\t\n​\t\t\n​\t\n\n\n​\t\t\t\n​\t\t\n​\t\n\n\n​\t\t\t\n​\t\t\n​\t\n\n\n​\t\t\t\n​\t\t\n​\t\n\n\n​\t\t\t\n​\t\t\n​\t\n\n\n​\t\t\t\n​\t\t\n​\t\n\n\n​\t\t\t\n​\t\t\n​\t\n\n\n​\t\t\t\t\n​\t\t\t\n​\t\t\n​\t\n\n\n​\t\t\t\n​\t\t\n​\t\t\t\t\t\n\n​\t\t\t\n​\t\t\n​\t\t\t\t\n​\t\t\n​\t\t\t\t\n​\t\t\n​\t\t\n\n\n​\t\t\t\n​\t\t\n​\t","source":"_posts/netty/netty.md","raw":"---\ntitle: netty\ndate: 2018-05-15 23:12:12\ntags:\n- netty\ncategories:\n- java基础\n---\n\n# Netty\n\nnetty是高性能网络编程技术\n\n<!--more-->\n\nNetty 的主要构件块: \n\n- Channel：它代表一个到实体(如一个硬件设备、一个文件、一个网络套接字或者一个能够执行一个或者多个不同的I/O操作的程序组件)的开放连接，如读操作和写操作 。 目前，可以把 Channel 看作是传入(入站)或者传出(出站)数据的载体。因此，它可以被打开或者被关闭，连接或者断开连接。\n\n-  回调：被通知回调的方法。Netty 在内部使用了回调来处理事件;当一个回调被触发时，相关的事件可以被一个 interface-ChannelHandler 的实现处理\n\n- Future：Future 提供了另一种在操作完成时通知应用程序的方式，它将在未来的某个时刻完成，并提供对其结果的访问。每个 Netty 的出站 I/O 操作都将返回一个 ChannelFuture;也就是说，它们都不会阻塞。netty中的大部分方法都是异步的，返回值都是通过回调通知的，如connect方法不会阻塞，它将会注册一个ChannelFutureListener\n\n  ```java\n  ChannelFuture future = channel.connect(\n  new InetSocketAddress(\"192.168.0.1\", 25)); future.addListener(new ChannelFutureListener() {\n  @Override\n  public void operationComplete(ChannelFuture future) {\n  if (future.isSuccess()){\n  ByteBuf buffer = Unpooled.copiedBuffer(\n  \"Hello\",Charset.defaultCharset()); ChannelFuture wf = future.channel() .....writeAndFlush(buffer);\n  } else {\n  Throwable cause = future.cause();\n                cause.printStackTrace();\n            }\n  }); \t\n  ```\n\n- 事件:Netty 使用不同的事件来通知我们状态的改变或者是操作的状态\n\n  - 连接已被激活或者连接失活\n  - 数据读取\n  - 用户事件\n  - 错误事件\n  - 打开或关闭到远程的连接\n  - 将数据写到或冲刷到套接字\n\n- ChannelHandler：负责接收和响应事件通知\n\n  - 针对不同类型的事件来调用 ChannelHandler;\n  - 将数据从一种格式转换为另一种格式\n  - 提供异常的通知\n  - 提供channel变为活动或非活动的通知\n  - 提供channel注册到eventLoop或从eventLoop注销时的通知\n  - 应用程序通过实现或者扩展 ChannelHandler 来挂钩到事件的生命周期，并且提供自定义的应用程序逻辑;\n\n  ChannelHandler的生命周期方法\n\n  - handlerAdded：handler添加到channelPipeline中调用\n  - handlerRemoved：从channelPipeline中移除handler时调用\n  - exceptionCaught：在channelPipeline有异常产生时调用\n\n在内部，将会为每个 Channel 分配一个 EventLoop，用以处理所有事件，包括:\n\n- 注册感兴趣的事件;\n- 将事件派发给 ChannelHandler;\n- 安排进一步的动作。\nEventLoop 本身只由一个线程驱动，其处理了一个 Channel 的所有 I/O 事件，并且在该EventLoop 的整个生命周期内都不会改变。\n\n\n\n@Sharable :在channalHandler上添加该注解标识该handler可以安全的被多个channel共享\n\n如果服务器发送了 5 字节，那么不能保证这 5 字节会被一次性接收。即使是对于这么少量的数据，channelRead0()方法也可能会被调用两次，第一次使用一个持有 3 字节的 ByteBuf(Netty 的字节容器)，第二次使用一个持有 2 字节的 ByteBuf。作为一个面向流的协议，TCP 保证了字节数组将会按照服务器发送它们的顺序被接收。\n\n\nexec-maven-plugin\n​\t\t\n- Channel— Socket; \n\n  基本的 I/O 操作(bind()、connect()、read()和 write())依赖于底层网络传输所提供的原语。在基于 Java 的网络编程中，其基本的构造是 class Socket。 \n\n  每个channel都会分配一个channelPileline和channelConfig\n\n  可以通过channel获取分配给channel的eventLoop、channelPileLine、channelConfig、localAddress\n\n  可以通过channel的write和fush方法实现写I/O\n\n  Netty 的 Channel 实现是线程安全的，因此你可以存储一个到 Channel 的引用，并且每当\n  你需要向远程节点写数据时，都可以使用它，即使当时许多线程都在使用它。\n\n  channel分四个状态，\n\n  - ChannelUnregistered ：channel已被创建，但未注册到EventLoop上\n\n  - ChannelRegistered ：channel已被注册到EventLoop上\n\n  - ChannelActive ：channel已经连接到远程节点，可以发送和接收数据\n\n  - ChannelInActive：channel没有连接到远程节点\n\n    ​\n    channel在声明周期的每次状态变化都会有事件通知到ChannelPipeline链中的每个ChannelHandler\n\n    在多个ChannelPipeline中安装同一个ChannelHandler的一个常见的原因是用于收集跨越多个 Channel 的统计信息。\n\n\n\n- EventLoop— 控制流、多线程处理、并发;\n\n  - 一个 EventLoopGroup 包含一个或者多个 EventLoop;  \n  - 一个 EventLoop 在它的生命周期内只和一个 Thread 绑定;  即EventLoop和Thread的关系是一对一\n  - 所有由 EventLoop 处理的 I/O 事件都将在它专有的 Thread 上被处理;  \n  - 一个 Channel 在它的生命周期内只注册于一个 EventLoop;  \n  - 一个 EventLoop 可能会被分配给一个或多个 Channel。 即EventLoop和channel的关系是一对多\n\n- ChannelFuture— 异步通知。 \n\n  Netty 中所有的 I/O 操作都是异步的。因为一个操作可能不会 立即返回，所以我们需要一种用于在之后的某个时间点确定其结果的方法。为此，Netty 提供了 ChannelFuture接口，其addListener()方法注册了一个ChannelFutureListener，以 便在某个操作完成时(无论是否成功)得到通知。 \n\n  所有属于同一个 Channel 的操作都被保证其将以它们被调用的顺序被执行。 \n\n- ChannelPipeline \n\n  ChannelPipeline 提供了 ChannelHandler 链的容器，并定义了用于在该链上传播入站 和出站事件流的 API。每一个新创建的Channel都会自动地分配一个新的 ChannelPipeline。\n\n  - 一个ChannelInitializer的实现被注册到了ServerBootstrap中 1;\n  - 当 ChannelInitializer.initChannel()方法被调用时，ChannelInitializer 将在 ChannelPipeline 中安装一组自定义的 ChannelHandler; \n  - ChannelInitializer 将它自己从 ChannelPipeline 中移除。 \n\n  这些对象接收事件、执行它们所实现的处理逻辑，并将数据传递给ChannelHandler链中的下一个 ChannelHandler。它们的执行顺序是由它们被添加的顺序所决定的。实际上ChannelPipeline 就是给这些 ChannelHandler编排顺序的。\n\n  数据的出站运动(即正在被写的数据)在概念上也是一样的。在这种情况下，数据将从 ChannelOutboundHandler 链的尾端开始流动，直到它到达链的头部为止。在这之后，出站 数据将会到达网络传输层，这里显示为 Socket。通常情况下，这将触发一个写操作。 \n\n  数据的入站运动那么它会从 ChannelPipeline 的头部开始流动，并被传递给第一个 ChannelInboundHandler。这个 ChannelHandler 不一定 会实际地修改数据，具体取决于它的具体功能，在这之后，数据将会被传递给链中的下一个 ChannelInboundHandler。最终，数据将会到达 ChannelPipeline 的尾端，届时，所有 处理就都结束了。  \n\n  当 ChannelHandler 被添加到 ChannelPipeline 时，它将会被分配一个 ChannelHandler- Context，其代表了 ChannelHandler 和 ChannelPipeline 之间的绑定。虽然这个对象可 以被用于获取底层的 Channel，但是它主要还是被用于写出站数据。 \n\n  在Netty中，有两种发送消息的方式。你可以直接写到Channel中，也可以 写到和Channel- Handler 相关联的 ChannelHandlerContext 对象中。前一种方式将会导致消息从 Channel- Pipeline 的尾端开始流动，而后者将导致消息从 ChannelPipeline 中的下一个 Channel- Handler 开始流动。 \n\n  通常 ChannelPipeline 中的每一个 ChannelHandler 都是通过它的 EventLoop(I/O 线程)来处理传递给它的事件的。所以至关重要的是不要阻塞这个线程，因为这会对整体的 I/O 处理产生负面的影响\n\n   ChannelHandler.exceptionCaught()的默认实现是简单地将当前异常转发给ChannelPipeline 中的下一个 ChannelHandler; 如果异常到达了 ChannelPipeline 的尾端，它将会被记录为未被处理; 要想定义自定义的处理逻辑，你需要重写 exceptionCaught()方法。然后你需要决定是否需要将该异常传播出去。\n\n- ChannelConfig\n\n  ChannelConfig 包含了该 Channel 的所有配置设置，并且支持热更新。由于特定的传输可能\n  具有独特的设置，所以它可能会实现一个 ChannelConfig 的子类型(\n\n- ChannelHandlerContext\n\n  ChannelHandlerContext使得ChannelHandler能够和它的ChannelPipeline以及其他的ChannelHandler 交 互 。 ChannelHandler 可 以 通 知 其 所 属 的 ChannelPipeline 中 的 下 一 个ChannelHandler，甚至可以动态修改它所属的ChannelPipeline1。\n\n  ChannelHandlerContext 具有丰富的用于处理事件和执行 I/O 操作的 API。\n\n  如果调用 Channel 或者 ChannelPipeline 上的这些方法，它们将沿着整个 ChannelPipeline 进行传播。而调用位于 ChannelHandlerContext上的相同方法，则将从当前所关联的 ChannelHandler 开始，并且只会传播给位于该ChannelPipeline 中的下一个能够处理该事件的 ChannelHandler。\n\n\n  ​\t\t\t\n  ​\t\t\n  ​\t\n\n\n选择器selector背后的基本概念是充当一个注册表，在那里你将可以请求在 Channel 的状态发生变化时得到通知。可能的状态变化有:\n\n-  新的 Channel 已被接受并且就绪;\n-  Channel 连接已经完成;\n-  Channel 有已经就绪的可供读取的数据;\n-  Channel 可用于写数据。\n\n选择器运行在一个检查状态变化并对其做出相应响应的线程上，在应用程序对状态的改变做出响应之后，选择器将会被重置，并将重复这个过程。\n\n![](http://omdq6di7v.bkt.clouddn.com/18-5-17/40931059.jpg)  \t\n\n### 编码器和解码器\n\n当你通过 Netty 发送或者接收一个消息的时候，就将会发生一次数据转换。入站消息会被解 码;也就是说，从字节转换为另一种格式，通常是一个 Java 对象。如果是出站消息，则会发生 相反方向的转换:它将从它的当前格式被编码为字节。这两种方向的转换的原因很简单:网络数 据总是一系列的字节。 \n\n### 引导 \n\nNetty 的引导类为应用程序的网络层配置提供了容器，这涉及将一个进程绑定到某个指定的 端口，或者将一个进程连接到另一个运行在某个指定主机的指定端口上的进程。 \n\n- Bootstrap \n\n  连接到远程主机和端口 \n\n  1个EventLoopGroup \n\n- ServerBootstrap\n\n  绑定到一个本地端口 \n\n  2个EventLoopGroup \n\n  ​\t因为服务器需要两组不同的 Channel。第一组将只包含一个 ServerChannel，代表服务 器自身的已绑定到某个本地端口的正在监听的套接字。而第二组将包含所有已创建的用来处理传 入客户端连接(对于每个服务器已经接受的连接都有一个)的 Channel。 与 ServerChannel 相关联的 EventLoopGroup 将分配一个负责为传入连接请求创建 Channel 的 EventLoop。一旦连接被接受，第二个 EventLoopGroup 就会给它的 Channel 分配一个 EventLoop。\n\n  ​\n\n  ​\n##ByteBuf、ByteBufHolder\n\n网络传输中的数据都是字节，java提供了ByteBuffer用来存储字节，netty对ByteBuffer进行了优化，使用ByteBuf来存储，\n\n#### ByteBuf netty的数据容器\n\n-  它可以被用户自定义的缓冲区类型扩展\n\n\n- 通过内置的复合缓冲区类型实现了透明的零拷贝\n- 容量可以按需增长(类似于 JDK 的 StringBuilder);\n- 在读和写这两种模式之间切换不需要调用 ByteBuffer 的 flip()方法;\n- 读和写使用了不同的索引;\n- 支持方法的链式调用;\n- 支持引用计数;\n- 支持池化。\n\nByteBuf 维护了两个不同的索引:一个用于读取，一个用于写入。两个索引都是从0开始，当你从 ByteBuf 读取时，\n它的 readerIndex 将会被递增已经被读取的字节数。同样地，当你写入 ByteBuf 时，它的writerIndex 也会被递增。\n\n如果指定的读取的readerIndex>writerIndex的时候，将会抛出一个越界异常\n\n名称以 read 或者 write 开头的 ByteBuf 方法，将会推进其对应的索引，而名称以 set 或者 get 开头的操作则不会。\n\n任何名称以 read 或者 skip 开头的操作都将检索或者跳过位于当前readerIndex 的数据，并且将它增加已读字节数。\n\n\n![](http://omdq6di7v.bkt.clouddn.com/18-5-17/70804660.jpg)\t\t\t\n可丢弃字节的分段包含了已经被读过的字节。通过调用 discardReadBytes()方法，可以丢弃它们并回收空间。这个分段的初始大小为 0，存储在 readerIndex 中，会随着 read 操作的执行而增加(get*操作不会移动 readerIndex)。\n\n调用discardReadBytes()方法会回收已读取的空间，同时会将可读取字节向前copy移动，调用该方法一方面最大化可写空间，当也需要copy移动可读字节\n\n![](http://omdq6di7v.bkt.clouddn.com/18-5-17/22320572.jpg)\t\t\t\n​\t\t\t\t\n通过调用 markReaderIndex()、markWriterIndex()、resetWriterIndex()和 resetReaderIndex()来标记和重置 ByteBuf 的 readerIndex 和 writerIndex。\n\n可以通过调用 clear()方法来将 readerIndex 和 writerIndex 都设置为 0。注意这并不会清除内存中的内容。只移动索引。调用 clear()比调用 discardReadBytes()轻量得多，因为它将只是重置索引而不会复制任何的内存\n\n可以同 indexOf和buf.forEachByte(ByteBufProcessor.FIND_NUL) 进行查找\n\nduplicat和slice、unmodifiableBuffer是对byteBuf的浅拷贝，对象内容还是一个，调用copy方法是深拷贝\n\nhasArray()？？？？byteBuf的存储类型？？？\tByteBufHolder ？？？\n\nByteBuf 分配 \t\tByteBufAllocator？？？\n\n可以通过 Channel(每个都可以有一个不同的 ByteBufAllocator 实例)或者绑定到\nChannelHandler 的 ChannelHandlerContext 获取一个到 ByteBufAllocator 的引用。\tByteBufAllocator allocator = channel.alloc();\t从 Channel 获取一个到ByteBufAllocator 的引用\n\nNetty提供了两种ByteBufAllocator的实现:PooledByteBufAllocator和Unpooled-\nByteBufAllocator。前者池化了ByteBuf的实例以提高性能并最大限度地减少内存碎片。此实\n现 使 用 了 一 种 称 为 j e m a l l o c 2 的 已 被 大 量 现 代 操 作 系 统 所 采 用 的 高 效 方 法 来 分 配 内 存 。后 者 的 实 现 不池化ByteBuf实例，并且在每次它被调用时都会返回一个新的实例。虽然Netty默认 1 使用了PooledByteBufAllocator，但这可以很容易地通过ChannelConfig API或者在引导你的应用程序时指定一个不同的分配器来更改。\n\n你未能获取一个到 ByteBufAllocator 的引用。对于这种情况，Netty 提供了一个简单的称为 Unpooled 的工具类，它提供了静态的辅助方法来创建未池化的 ByteBuf实例\n\nByteBufUtil.hexdump() \t 它以十六进制的表示形式打印 ByteBuf 的内容\n\n\nReferenceCountUtil.release(msg) ：丢弃已经接收到的消息\n\n​\t\t\t\n\n根据配置和可用核心的不同，可能会创建多个 EventLoop 实例用以优化资源的使用，并且单个EventLoop 可能会被指派用于服务多个 Channel。\n\n事件/任务的执行顺序 事件和任务是以先进先出(FIFO)的顺序执行的。这样可以通过保证字节内容总是按正确的顺序被处理，消除潜在的数据损坏的可能性。\n\n每个 EventLoop 都有它自已的任务队列，独立于任何其他的 EventLoop\n\n\n![](http://omdq6di7v.bkt.clouddn.com/18-5-21/1077564.jpg)\t\n永远不要将一个长时间运行的任务放入到执行队列中，因为它将阻塞需要在同一线程上执行的任何其他任务。”如果必须要进行阻塞调用或者执行长时间运行的任务，我们建议使用一个专门的EventExecutor\n\n​\t\t\t\n![](http://omdq6di7v.bkt.clouddn.com/18-5-21/29017964.jpg)\t\t\n异步传输实现只使用了少量的 EventLoop(以及和它们相关联的 Thread)，而且在当前的线程模型中，它们可能会被多个 Channel 所共享。这使得可以通过尽可能少量的 Thread 来支撑大量的 Channel，而不是每个 Channel 分配一个 Thread\n\nEventLoopGroup 负责为每个新创建的 Channel 分配一个 EventLoop。在当前实现中，使用顺序循环(round-robin)的方式进行分配以获取一个均衡的分布，并且相同的 EventLoop可能会被分配给多个 Channel\n\n一旦一个 Channel 被分配给一个 EventLoop，它将在它的整个生命周期中都使用这个EventLoop(以及相关联的 Thread)\n\n\n![](http://omdq6di7v.bkt.clouddn.com/18-5-21/22826427.jpg)\t\t\t\n​\t\t\t\t\nBootstrap 类负责为客户端和使用无连接协议的应用程序创建 Channel\t\n\n```\n<T> Bootstrap option(\n    ChannelOption<T> option,\n    T value)\n设置 ChannelOption，其将被应用到每个新创建的Channel 的 ChannelConfig。这些选项将会通过bind()或者 connect()方法设置到 Channel，不管哪个先被调用。这个方法在 Channel 已经被创建后再调用将不会有任何的效果。支持的 ChannelOption 取决于使用的 Channel 类型。\n```\n\n\n​\t\t\t\n​\t\t\n​\t\n\n\n​\t\t\t\t\n​\t\t\t\n​\t\t\n​\t\n\n​\t\n\n\n​\t\t\t\n​\t\t\n​\t\t\t\n\n​\t\t\t\t\n​\t\t\n​\t\n\n\n​\t\t\t\n​\t\t\n​\t\n\n\n​\t\t\t\n​\t\t\n​\t\n\n\n​\t\t\t\n​\t\t\n​\t\n\n\n​\t\t\t\n​\t\t\n​\t\n\n\n​\t\t\t\n​\t\t\n​\t\n\n\n​\t\t\t\n​\t\t\n​\t\n\n\n​\t\t\t\n​\t\t\n​\t\n\n\n​\t\t\t\n​\t\t\n​\t\n\n\n​\t\t\t\t\n​\t\t\t\n​\t\t\n​\t\n\n\n​\t\t\t\n​\t\t\n​\t\t\t\t\t\n\n​\t\t\t\n​\t\t\n​\t\t\t\t\n​\t\t\n​\t\t\t\t\n​\t\t\n​\t\t\n\n\n​\t\t\t\n​\t\t\n​\t","slug":"netty/netty","published":1,"updated":"2018-09-12T03:03:21.825Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnhl004awlkv1bpmi7y4"},{"title":"spring-AOP","date":"2018-10-29T08:05:10.000Z","_content":"\n# spring-AOP\n\n## 一、类\n\n- AspectJAutoProxyBeanDefinitionParser.paser()\n- AnnotationAwareAspectJAutoProxyCreator  需要注册这个类 实现了 BeanPostProcessor接口，加载bean时调用\n- AopConfigUtils\n- AbstractAutoProxyCreator.postProcessAfterInitialization().wrapIfNecessary()\n- BeanFactoryAspectJAdvisorsBuilder\n- InstantiationModelAwarePointcutAdvisorImpl\n- ReflectiveAspectJAdvisorFactory\n- AbstractAspectJAdvice","source":"_posts/spring/spring-AOP.md","raw":"---\ntitle: spring-AOP\ndate: 2018-10-29 16:05:10\ntags:\n- spring \ncategories:\n- spring\n\n---\n\n# spring-AOP\n\n## 一、类\n\n- AspectJAutoProxyBeanDefinitionParser.paser()\n- AnnotationAwareAspectJAutoProxyCreator  需要注册这个类 实现了 BeanPostProcessor接口，加载bean时调用\n- AopConfigUtils\n- AbstractAutoProxyCreator.postProcessAfterInitialization().wrapIfNecessary()\n- BeanFactoryAspectJAdvisorsBuilder\n- InstantiationModelAwarePointcutAdvisorImpl\n- ReflectiveAspectJAdvisorFactory\n- AbstractAspectJAdvice","slug":"spring/spring-AOP","published":1,"updated":"2018-10-29T14:56:23.007Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnhm004bwlkvprg5ez39"},{"title":"spring入门","date":"2018-09-20T03:11:03.000Z","_content":"\n# spring入门\n\n## 一、spring-framework组成\n\n![](http://omdq6di7v.bkt.clouddn.com/18-9-20/75505703.jpg)\n\n- spring-core、spring-beans 提供了基础的依赖注入和控制反转功能 BeanFactory。\n- spring-context 提供了ApplicationContext接口集成容器。 并提供了资源加载、国际化等功能\n- spring-context-support 提供了集成第三方jar包(guava、javaMail、quatz、freeMarker等)到context中功能.\n- spring-expression 提供了SpEL在运行期间向容器对象注入属性功能。\n- spring-aop 提供了面向切面编程功能\n- spring-aspects 集成AspectJ\n- spring-instrument 提供了字节码注入的的切面实现\n- spring-instrument-tomcat 提供了tomcat的代理\n- spring-jdbc 对jdbc代码的封装\n- spring-tx 提供spring声明式事务\n- spring-orm 集成O/R-mapping 持久化框架 如JPA、JDO、Hibernate\n- spring-oxm 提供了Object/XML mapping的抽象层，用于支持 JAXB、Castor、XMLBeans、JiBX、XStream\n- spring-web 将servlet的功能集成到IOC中\n- spring-webmvc 提供了mvc和rest web请求\n- spring-test 集成测试框架，并提供mock功能\n\n## 版本控制\n\n在使用maven添加spring依赖的时候，一般都会希望spring-framework中所有的jar包都是同一个版本，通过使用spring-framework-bom可以指定版本，这样就避免了传递依赖导致的版本不一致，同时也可以省略了在spring-framework各个模块上重复的指定版本号\n\n```xml\n<dependencyManagement>\n    <dependencies>\n        <dependency>\n            <groupId>org.springframework</groupId>\n            <artifactId>spring-framework-bom</artifactId>\n            <version>4.3.19.RELEASE</version>\n            <type>pom</type>\n            <scope>import</scope>\n        </dependency>\n    </dependencies>\n</dependencyManagement>\n```\n\n## 日志控制\n\nspring默认使用`commons-logging`记录日志。在`spring-core`中依赖了该jar包。目前比较流行的是使用 `slf4j+log4j2`或者`slf4j+logback`.\n\n```xml\n<dependency>\n   <groupId>org.springframework</groupId>\n   <artifactId>spring-core</artifactId>\n   <!--使用slf4j 排除spring默认日志实现  jcl-->\n   <exclusions>\n      <exclusion>\n         <groupId>commons-logging</groupId>\n         <artifactId>commons-logging</artifactId>\n      </exclusion>\n   </exclusions>\n</dependency>\n<!--jcl的日志重定向到slf4j 依赖slf4j-api-->\n<dependency>\n   <groupId>org.slf4j</groupId>\n   <artifactId>jcl-over-slf4j</artifactId>\n   <version>1.7.21</version>\n</dependency>\n<!--logback默认实现slf4j 依赖logback-core-->\n<dependency>\n   <groupId>ch.qos.logback</groupId>\n   <artifactId>logback-classic</artifactId>\n   <version>1.1.7</version>\n</dependency>\n```\n\n## jjjj\n\nDepend-on属性， 明确初始化先后顺序和销毁先后顺序","source":"_posts/spring/spring入门.md","raw":"---\ntitle: spring入门\ndate: 2018-09-20 11:11:03\ntags:\n- spring \ncategories:\n- spring\n\n---\n\n# spring入门\n\n## 一、spring-framework组成\n\n![](http://omdq6di7v.bkt.clouddn.com/18-9-20/75505703.jpg)\n\n- spring-core、spring-beans 提供了基础的依赖注入和控制反转功能 BeanFactory。\n- spring-context 提供了ApplicationContext接口集成容器。 并提供了资源加载、国际化等功能\n- spring-context-support 提供了集成第三方jar包(guava、javaMail、quatz、freeMarker等)到context中功能.\n- spring-expression 提供了SpEL在运行期间向容器对象注入属性功能。\n- spring-aop 提供了面向切面编程功能\n- spring-aspects 集成AspectJ\n- spring-instrument 提供了字节码注入的的切面实现\n- spring-instrument-tomcat 提供了tomcat的代理\n- spring-jdbc 对jdbc代码的封装\n- spring-tx 提供spring声明式事务\n- spring-orm 集成O/R-mapping 持久化框架 如JPA、JDO、Hibernate\n- spring-oxm 提供了Object/XML mapping的抽象层，用于支持 JAXB、Castor、XMLBeans、JiBX、XStream\n- spring-web 将servlet的功能集成到IOC中\n- spring-webmvc 提供了mvc和rest web请求\n- spring-test 集成测试框架，并提供mock功能\n\n## 版本控制\n\n在使用maven添加spring依赖的时候，一般都会希望spring-framework中所有的jar包都是同一个版本，通过使用spring-framework-bom可以指定版本，这样就避免了传递依赖导致的版本不一致，同时也可以省略了在spring-framework各个模块上重复的指定版本号\n\n```xml\n<dependencyManagement>\n    <dependencies>\n        <dependency>\n            <groupId>org.springframework</groupId>\n            <artifactId>spring-framework-bom</artifactId>\n            <version>4.3.19.RELEASE</version>\n            <type>pom</type>\n            <scope>import</scope>\n        </dependency>\n    </dependencies>\n</dependencyManagement>\n```\n\n## 日志控制\n\nspring默认使用`commons-logging`记录日志。在`spring-core`中依赖了该jar包。目前比较流行的是使用 `slf4j+log4j2`或者`slf4j+logback`.\n\n```xml\n<dependency>\n   <groupId>org.springframework</groupId>\n   <artifactId>spring-core</artifactId>\n   <!--使用slf4j 排除spring默认日志实现  jcl-->\n   <exclusions>\n      <exclusion>\n         <groupId>commons-logging</groupId>\n         <artifactId>commons-logging</artifactId>\n      </exclusion>\n   </exclusions>\n</dependency>\n<!--jcl的日志重定向到slf4j 依赖slf4j-api-->\n<dependency>\n   <groupId>org.slf4j</groupId>\n   <artifactId>jcl-over-slf4j</artifactId>\n   <version>1.7.21</version>\n</dependency>\n<!--logback默认实现slf4j 依赖logback-core-->\n<dependency>\n   <groupId>ch.qos.logback</groupId>\n   <artifactId>logback-classic</artifactId>\n   <version>1.1.7</version>\n</dependency>\n```\n\n## jjjj\n\nDepend-on属性， 明确初始化先后顺序和销毁先后顺序","slug":"spring/spring入门","published":1,"updated":"2018-10-16T13:23:51.458Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnhn004ewlkvsn2tfhv3"},{"title":"spring-IOC","date":"2018-09-20T07:27:13.000Z","_content":"\n# spring-IOC\n\n## 一、bean\n\n- bean属性\n\n  ```\n  class\n  name\n  scope\n  constructor arguments\n  properties\n  autowiring mode\n  lazy-initialization mode\n  initialization method\n  destruction method\n  ```\n\n  IdentityHashMap\n\n\n\n```java\npublic AbstractAutowireCapableBeanFactory() {\n   super();\n    //Set<Class<?>> ignoredDependencyInterfaces ,Dependency interfaces to ignore on dependency check and autowire 依赖注入的时候忽略实现以下接口的bean的初始化\n   ignoreDependencyInterface(BeanNameAware.class);\n   ignoreDependencyInterface(BeanFactoryAware.class);\n   ignoreDependencyInterface(BeanClassLoaderAware.class);\n}\n\npublic AbstractAutowireCapableBeanFactory(BeanFactory parentBeanFactory) {\n   this();\n   setParentBeanFactory(parentBeanFactory);\n}\n\n\n//AbstractBeanFactory 继承自ConfigurableBeanFactory\n@Override\npublic void setParentBeanFactory(BeanFactory parentBeanFactory) {\n\tif (this.parentBeanFactory != null && this.parentBeanFactory != parentBeanFactory) {\n    \tthrow new IllegalStateException(\"Already associated with parent BeanFactory: \" + \t\t\tthis.parentBeanFactory);\n    }\n\tthis.parentBeanFactory = parentBeanFactory;\n}\n```\n\n![](http://omdq6di7v.bkt.clouddn.com/18-9-20/54908296.jpg)\n\n```java\n//XmlBeanDefinitionReader\npublic int registerBeanDefinitions(Document doc, Resource resource) throws BeanDefinitionStoreException {\n   BeanDefinitionDocumentReader documentReader = createBeanDefinitionDocumentReader();\n   int countBefore = getRegistry().getBeanDefinitionCount();\n   documentReader.registerBeanDefinitions(doc, createReaderContext(resource));\n   return getRegistry().getBeanDefinitionCount() - countBefore;\n}\n```\n\n\n\n```java\n//DefaultBeanDefinitionDocumentReader\n@Override\npublic void registerBeanDefinitions(Document doc, XmlReaderContext readerContext) {\n    this.readerContext = readerContext;\n    logger.debug(\"Loading bean definitions\");\n    Element root = doc.getDocumentElement();\n    doRegisterBeanDefinitions(root);\n}\nprotected void doRegisterBeanDefinitions(Element root) {\n   BeanDefinitionParserDelegate parent = this.delegate;\n   this.delegate = createDelegate(getReaderContext(), root, parent);\n\n   if (this.delegate.isDefaultNamespace(root)) {\n      String profileSpec = root.getAttribute(PROFILE_ATTRIBUTE);\n      if (StringUtils.hasText(profileSpec)) {\n         String[] specifiedProfiles = StringUtils.tokenizeToStringArray(\n               profileSpec, BeanDefinitionParserDelegate.MULTI_VALUE_ATTRIBUTE_DELIMITERS);\n         if (!getReaderContext().getEnvironment().acceptsProfiles(specifiedProfiles)) {\n            if (logger.isInfoEnabled()) {\n               logger.info(\"Skipped XML bean definition file due to specified profiles [\" + profileSpec +\n                     \"] not matching: \" + getReaderContext().getResource());\n            }\n            return;\n         }\n      }\n   }\n\n   preProcessXml(root);\n   parseBeanDefinitions(root, this.delegate);\n   postProcessXml(root);\n\n   this.delegate = parent;\n}\nprotected void parseBeanDefinitions(Element root, BeanDefinitionParserDelegate delegate) {\n    if (delegate.isDefaultNamespace(root)) {\n        NodeList nl = root.getChildNodes();\n        for (int i = 0; i < nl.getLength(); i++) {\n            Node node = nl.item(i);\n            if (node instanceof Element) {\n                Element ele = (Element) node;\n                if (delegate.isDefaultNamespace(ele)) {\n                    parseDefaultElement(ele, delegate);\n                }\n                else {\n                    delegate.parseCustomElement(ele);\n                }\n            }\n        }\n    }\n    else {\n        delegate.parseCustomElement(root);\n    }\n}\nprivate void parseDefaultElement(Element ele, BeanDefinitionParserDelegate delegate) {\n    if (delegate.nodeNameEquals(ele, IMPORT_ELEMENT)) {\n        importBeanDefinitionResource(ele);\n    }\n    else if (delegate.nodeNameEquals(ele, ALIAS_ELEMENT)) {\n        processAliasRegistration(ele);\n    }\n    else if (delegate.nodeNameEquals(ele, BEAN_ELEMENT)) {\n        processBeanDefinition(ele, delegate);\n    }\n    else if (delegate.nodeNameEquals(ele, NESTED_BEANS_ELEMENT)) {\n        // recurse\n        doRegisterBeanDefinitions(ele);\n    }\n}\n\n//解析bean\nprotected void processBeanDefinition(Element ele, BeanDefinitionParserDelegate delegate) {\n    BeanDefinitionHolder bdHolder = delegate.parseBeanDefinitionElement(ele);\n    if (bdHolder != null) {\n        bdHolder = delegate.decorateBeanDefinitionIfRequired(ele, bdHolder);\n        try {\n            // Register the final decorated instance.\n            BeanDefinitionReaderUtils.registerBeanDefinition(bdHolder, getReaderContext().getRegistry());\n        }\n        catch (BeanDefinitionStoreException ex) {\n            getReaderContext().error(\"Failed to register bean definition with name '\" +\n                                     bdHolder.getBeanName() + \"'\", ele, ex);\n        }\n        // Send registration event.\n        getReaderContext().fireComponentRegistered(new BeanComponentDefinition(bdHolder));\n    }\n}\npublic AbstractBeanDefinition parseBeanDefinitionElement(\n\t\t\tElement ele, String beanName, BeanDefinition containingBean) {\n\n    this.parseState.push(new BeanEntry(beanName));\n\n    String className = null;\n    if (ele.hasAttribute(CLASS_ATTRIBUTE)) {\n        className = ele.getAttribute(CLASS_ATTRIBUTE).trim();\n    }\n\n    try {\n        String parent = null;\n        if (ele.hasAttribute(PARENT_ATTRIBUTE)) {\n            parent = ele.getAttribute(PARENT_ATTRIBUTE);\n        }\n        AbstractBeanDefinition bd = createBeanDefinition(className, parent);\n\n        parseBeanDefinitionAttributes(ele, beanName, containingBean, bd);\n        bd.setDescription(DomUtils.getChildElementValueByTagName(ele, DESCRIPTION_ELEMENT));\n\n        parseMetaElements(ele, bd);//解析子元素 <meta>\n        parseLookupOverrideSubElements(ele, bd.getMethodOverrides());//解析子元素 <look-up>\n        parseReplacedMethodSubElements(ele, bd.getMethodOverrides());//解析子元素 <replace-method>\n        parseConstructorArgElements(ele, bd);\n        parsePropertyElements(ele, bd);\n        parseQualifierElements(ele, bd);//解析子元素 <qualifier>\n\n        bd.setResource(this.readerContext.getResource());\n        bd.setSource(extractSource(ele));\n\n        return bd;\n    }\n    catch (ClassNotFoundException ex) {\n        error(\"Bean class [\" + className + \"] not found\", ele, ex);\n    }\n    catch (NoClassDefFoundError err) {\n        error(\"Class that bean class [\" + className + \"] depends on not found\", ele, err);\n    }\n    catch (Throwable ex) {\n        error(\"Unexpected failure during bean definition parsing\", ele, ex);\n    }\n    finally {\n        this.parseState.pop();\n    }\n\n    return null;\n}\n```\n\n\n\n![](http://omdq6di7v.bkt.clouddn.com/18-9-25/39838794.jpg)\n\nResourceLoader—资源加载，处理import的时候用了\n\nBeanDefinitionReader----\n\nDocumentLoader——配置文件转换为Document\n\nBeanDefinitionDocumentReader——读取Document并注册BeanDefinition\n\nBeanDefinitionParserDelegate 用来解析xml转换为BeanDefinition 用来解析 <bean>标签返回 BeanDefinitionHolder\n\nXmlReaderContext——全局变量 存储 BeanDefinitionRegistry, XmlBeanDefinitionReader\n\nBeanDefinitionReaderUtils——注册\n\nBeanDefinitionRegistry —— 注册器  DefaultListableBeanFactory 实现了注册器功能\n\nStringTokenizer 类  StringUtils.tokenizeToStringArray方法\n\nFailFastProblemReporter 用法\n\n\n\n初始化的入口在容器实现中的refresh()调用来完成 \n\n    * 对bean 定义载入IOC容器使用的方法是loadBeanDefinition,其中的大致过程如下：通过ResourceLoader来完成资源文件位置的定位，DefaultResourceLoader是默认的实现，同时上下文本身就给出了ResourceLoader的实现，可以从类路径，文件系统, URL等方式来定为资源位置。如果是XmlBeanFactory作为IOC容器，那么需要为它指定bean定义的资源，也就是说bean定义文件时通过抽象成Resource来被IOC容器处理的，容器通过BeanDefinitionReader来完成定义信息的解析和Bean信息的注册,往往使用的是XmlBeanDefinitionReader来解析bean的xml定义文件 - 实际的处理过程是委托给BeanDefinitionParserDelegate来完成的，从而得到bean的定义信息，这些信息在Spring中使用BeanDefinition对象来表示 - 这个名字可以让我们想到loadBeanDefinition,RegisterBeanDefinition这些相关的方法 - 他们都是为处理BeanDefinitin服务的，IoC容器解析得到BeanDefinition以后，需要把它在IOC容器中注册，这由IOC实现 BeanDefinitionRegistry接口来实现。注册过程就是在IOC容器内部维护的一个HashMap来保存得到的 BeanDefinition的过程。这个HashMap是IoC容器持有bean信息的场所，以后对bean的操作都是围绕这个HashMap来实现的\n\n\n\n- Resource定位 ，Resource接口，由ResourceLoader加载。\n- BeanDefinition载入， 将用户定义的bean表示为IOC容器内部的数据结构\n- BeanDefinition注册，BeanDefinitionRegistry注册到一个HashMap中\n\n![](http://omdq6di7v.bkt.clouddn.com/18-9-29/21686210.jpg)\n\n\n\nFactoryBean接口，实现该接口可以通过getObject方法创建自己想要的bean对象。在初始化bean的时候，如果bean实现类了FactoryBean接口，则是返回getObject方法返回的对象，而不是创建实现FactoryBean接口的对象\n\n因为在创建单例bean的时候会存在依赖注入的情况，而在创建依赖的时候为了避免循环依赖，spring创建bean的原则是不等bean创建完成就会将创建bean的ObjectFactory提早曝光，也就是将ObjectFactory加入到缓存中，一旦下个bean创建时间需要依赖上个bean则直接使用ObjectFactory。缓存中记录的只是最原始的bean状态，需要进行实例化\n\n只有单例模式setter注入才会解决循环依赖问题，原型模式在遇到循环依赖的情况下会直接抛出异常，因为不允许缓存原型模式的bean.\n\n解析 depend-on标签，会缓存并初始化depend-on指定的bean\n\n\n\n\n\nAbstractBeanFactory.getBean\n\nDefaultSingletonBeanRegistry.getSingleton\n\nAbstractAutowireCapableBeanFactory.createBean\n\nConstructorResolver.autowireConstructor\n\n##### 缓存类\n\n- singletonObjects：beanName和bean实例之间关系\n- earlySingletonObjects：beanName和bean实例之间关系。通singletonObjects不同的是当一个bean还在创建过程中，就可以通过getBean方法获取到，主要用来检测循环引用\n- singletonFactories：beanName和创建bean的工厂之间的关系 beanName---ObjectFactory\n- registeredSingletons：保存当前已注册的bean,包括ObjectFactory\n\n\n\nBeanWrapper\n\n\n\n\n\n```java\nprivate final Set<String> singletonsCurrentlyInCreation =\n      Collections.newSetFromMap(new ConcurrentHashMap<String, Boolean>(16));\n```","source":"_posts/spring/spring-IOC.md","raw":"---\ntitle: spring-IOC\ndate: 2018-09-20 15:27:13\ntags:\n- spring \ncategories:\n- spring\n\n---\n\n# spring-IOC\n\n## 一、bean\n\n- bean属性\n\n  ```\n  class\n  name\n  scope\n  constructor arguments\n  properties\n  autowiring mode\n  lazy-initialization mode\n  initialization method\n  destruction method\n  ```\n\n  IdentityHashMap\n\n\n\n```java\npublic AbstractAutowireCapableBeanFactory() {\n   super();\n    //Set<Class<?>> ignoredDependencyInterfaces ,Dependency interfaces to ignore on dependency check and autowire 依赖注入的时候忽略实现以下接口的bean的初始化\n   ignoreDependencyInterface(BeanNameAware.class);\n   ignoreDependencyInterface(BeanFactoryAware.class);\n   ignoreDependencyInterface(BeanClassLoaderAware.class);\n}\n\npublic AbstractAutowireCapableBeanFactory(BeanFactory parentBeanFactory) {\n   this();\n   setParentBeanFactory(parentBeanFactory);\n}\n\n\n//AbstractBeanFactory 继承自ConfigurableBeanFactory\n@Override\npublic void setParentBeanFactory(BeanFactory parentBeanFactory) {\n\tif (this.parentBeanFactory != null && this.parentBeanFactory != parentBeanFactory) {\n    \tthrow new IllegalStateException(\"Already associated with parent BeanFactory: \" + \t\t\tthis.parentBeanFactory);\n    }\n\tthis.parentBeanFactory = parentBeanFactory;\n}\n```\n\n![](http://omdq6di7v.bkt.clouddn.com/18-9-20/54908296.jpg)\n\n```java\n//XmlBeanDefinitionReader\npublic int registerBeanDefinitions(Document doc, Resource resource) throws BeanDefinitionStoreException {\n   BeanDefinitionDocumentReader documentReader = createBeanDefinitionDocumentReader();\n   int countBefore = getRegistry().getBeanDefinitionCount();\n   documentReader.registerBeanDefinitions(doc, createReaderContext(resource));\n   return getRegistry().getBeanDefinitionCount() - countBefore;\n}\n```\n\n\n\n```java\n//DefaultBeanDefinitionDocumentReader\n@Override\npublic void registerBeanDefinitions(Document doc, XmlReaderContext readerContext) {\n    this.readerContext = readerContext;\n    logger.debug(\"Loading bean definitions\");\n    Element root = doc.getDocumentElement();\n    doRegisterBeanDefinitions(root);\n}\nprotected void doRegisterBeanDefinitions(Element root) {\n   BeanDefinitionParserDelegate parent = this.delegate;\n   this.delegate = createDelegate(getReaderContext(), root, parent);\n\n   if (this.delegate.isDefaultNamespace(root)) {\n      String profileSpec = root.getAttribute(PROFILE_ATTRIBUTE);\n      if (StringUtils.hasText(profileSpec)) {\n         String[] specifiedProfiles = StringUtils.tokenizeToStringArray(\n               profileSpec, BeanDefinitionParserDelegate.MULTI_VALUE_ATTRIBUTE_DELIMITERS);\n         if (!getReaderContext().getEnvironment().acceptsProfiles(specifiedProfiles)) {\n            if (logger.isInfoEnabled()) {\n               logger.info(\"Skipped XML bean definition file due to specified profiles [\" + profileSpec +\n                     \"] not matching: \" + getReaderContext().getResource());\n            }\n            return;\n         }\n      }\n   }\n\n   preProcessXml(root);\n   parseBeanDefinitions(root, this.delegate);\n   postProcessXml(root);\n\n   this.delegate = parent;\n}\nprotected void parseBeanDefinitions(Element root, BeanDefinitionParserDelegate delegate) {\n    if (delegate.isDefaultNamespace(root)) {\n        NodeList nl = root.getChildNodes();\n        for (int i = 0; i < nl.getLength(); i++) {\n            Node node = nl.item(i);\n            if (node instanceof Element) {\n                Element ele = (Element) node;\n                if (delegate.isDefaultNamespace(ele)) {\n                    parseDefaultElement(ele, delegate);\n                }\n                else {\n                    delegate.parseCustomElement(ele);\n                }\n            }\n        }\n    }\n    else {\n        delegate.parseCustomElement(root);\n    }\n}\nprivate void parseDefaultElement(Element ele, BeanDefinitionParserDelegate delegate) {\n    if (delegate.nodeNameEquals(ele, IMPORT_ELEMENT)) {\n        importBeanDefinitionResource(ele);\n    }\n    else if (delegate.nodeNameEquals(ele, ALIAS_ELEMENT)) {\n        processAliasRegistration(ele);\n    }\n    else if (delegate.nodeNameEquals(ele, BEAN_ELEMENT)) {\n        processBeanDefinition(ele, delegate);\n    }\n    else if (delegate.nodeNameEquals(ele, NESTED_BEANS_ELEMENT)) {\n        // recurse\n        doRegisterBeanDefinitions(ele);\n    }\n}\n\n//解析bean\nprotected void processBeanDefinition(Element ele, BeanDefinitionParserDelegate delegate) {\n    BeanDefinitionHolder bdHolder = delegate.parseBeanDefinitionElement(ele);\n    if (bdHolder != null) {\n        bdHolder = delegate.decorateBeanDefinitionIfRequired(ele, bdHolder);\n        try {\n            // Register the final decorated instance.\n            BeanDefinitionReaderUtils.registerBeanDefinition(bdHolder, getReaderContext().getRegistry());\n        }\n        catch (BeanDefinitionStoreException ex) {\n            getReaderContext().error(\"Failed to register bean definition with name '\" +\n                                     bdHolder.getBeanName() + \"'\", ele, ex);\n        }\n        // Send registration event.\n        getReaderContext().fireComponentRegistered(new BeanComponentDefinition(bdHolder));\n    }\n}\npublic AbstractBeanDefinition parseBeanDefinitionElement(\n\t\t\tElement ele, String beanName, BeanDefinition containingBean) {\n\n    this.parseState.push(new BeanEntry(beanName));\n\n    String className = null;\n    if (ele.hasAttribute(CLASS_ATTRIBUTE)) {\n        className = ele.getAttribute(CLASS_ATTRIBUTE).trim();\n    }\n\n    try {\n        String parent = null;\n        if (ele.hasAttribute(PARENT_ATTRIBUTE)) {\n            parent = ele.getAttribute(PARENT_ATTRIBUTE);\n        }\n        AbstractBeanDefinition bd = createBeanDefinition(className, parent);\n\n        parseBeanDefinitionAttributes(ele, beanName, containingBean, bd);\n        bd.setDescription(DomUtils.getChildElementValueByTagName(ele, DESCRIPTION_ELEMENT));\n\n        parseMetaElements(ele, bd);//解析子元素 <meta>\n        parseLookupOverrideSubElements(ele, bd.getMethodOverrides());//解析子元素 <look-up>\n        parseReplacedMethodSubElements(ele, bd.getMethodOverrides());//解析子元素 <replace-method>\n        parseConstructorArgElements(ele, bd);\n        parsePropertyElements(ele, bd);\n        parseQualifierElements(ele, bd);//解析子元素 <qualifier>\n\n        bd.setResource(this.readerContext.getResource());\n        bd.setSource(extractSource(ele));\n\n        return bd;\n    }\n    catch (ClassNotFoundException ex) {\n        error(\"Bean class [\" + className + \"] not found\", ele, ex);\n    }\n    catch (NoClassDefFoundError err) {\n        error(\"Class that bean class [\" + className + \"] depends on not found\", ele, err);\n    }\n    catch (Throwable ex) {\n        error(\"Unexpected failure during bean definition parsing\", ele, ex);\n    }\n    finally {\n        this.parseState.pop();\n    }\n\n    return null;\n}\n```\n\n\n\n![](http://omdq6di7v.bkt.clouddn.com/18-9-25/39838794.jpg)\n\nResourceLoader—资源加载，处理import的时候用了\n\nBeanDefinitionReader----\n\nDocumentLoader——配置文件转换为Document\n\nBeanDefinitionDocumentReader——读取Document并注册BeanDefinition\n\nBeanDefinitionParserDelegate 用来解析xml转换为BeanDefinition 用来解析 <bean>标签返回 BeanDefinitionHolder\n\nXmlReaderContext——全局变量 存储 BeanDefinitionRegistry, XmlBeanDefinitionReader\n\nBeanDefinitionReaderUtils——注册\n\nBeanDefinitionRegistry —— 注册器  DefaultListableBeanFactory 实现了注册器功能\n\nStringTokenizer 类  StringUtils.tokenizeToStringArray方法\n\nFailFastProblemReporter 用法\n\n\n\n初始化的入口在容器实现中的refresh()调用来完成 \n\n    * 对bean 定义载入IOC容器使用的方法是loadBeanDefinition,其中的大致过程如下：通过ResourceLoader来完成资源文件位置的定位，DefaultResourceLoader是默认的实现，同时上下文本身就给出了ResourceLoader的实现，可以从类路径，文件系统, URL等方式来定为资源位置。如果是XmlBeanFactory作为IOC容器，那么需要为它指定bean定义的资源，也就是说bean定义文件时通过抽象成Resource来被IOC容器处理的，容器通过BeanDefinitionReader来完成定义信息的解析和Bean信息的注册,往往使用的是XmlBeanDefinitionReader来解析bean的xml定义文件 - 实际的处理过程是委托给BeanDefinitionParserDelegate来完成的，从而得到bean的定义信息，这些信息在Spring中使用BeanDefinition对象来表示 - 这个名字可以让我们想到loadBeanDefinition,RegisterBeanDefinition这些相关的方法 - 他们都是为处理BeanDefinitin服务的，IoC容器解析得到BeanDefinition以后，需要把它在IOC容器中注册，这由IOC实现 BeanDefinitionRegistry接口来实现。注册过程就是在IOC容器内部维护的一个HashMap来保存得到的 BeanDefinition的过程。这个HashMap是IoC容器持有bean信息的场所，以后对bean的操作都是围绕这个HashMap来实现的\n\n\n\n- Resource定位 ，Resource接口，由ResourceLoader加载。\n- BeanDefinition载入， 将用户定义的bean表示为IOC容器内部的数据结构\n- BeanDefinition注册，BeanDefinitionRegistry注册到一个HashMap中\n\n![](http://omdq6di7v.bkt.clouddn.com/18-9-29/21686210.jpg)\n\n\n\nFactoryBean接口，实现该接口可以通过getObject方法创建自己想要的bean对象。在初始化bean的时候，如果bean实现类了FactoryBean接口，则是返回getObject方法返回的对象，而不是创建实现FactoryBean接口的对象\n\n因为在创建单例bean的时候会存在依赖注入的情况，而在创建依赖的时候为了避免循环依赖，spring创建bean的原则是不等bean创建完成就会将创建bean的ObjectFactory提早曝光，也就是将ObjectFactory加入到缓存中，一旦下个bean创建时间需要依赖上个bean则直接使用ObjectFactory。缓存中记录的只是最原始的bean状态，需要进行实例化\n\n只有单例模式setter注入才会解决循环依赖问题，原型模式在遇到循环依赖的情况下会直接抛出异常，因为不允许缓存原型模式的bean.\n\n解析 depend-on标签，会缓存并初始化depend-on指定的bean\n\n\n\n\n\nAbstractBeanFactory.getBean\n\nDefaultSingletonBeanRegistry.getSingleton\n\nAbstractAutowireCapableBeanFactory.createBean\n\nConstructorResolver.autowireConstructor\n\n##### 缓存类\n\n- singletonObjects：beanName和bean实例之间关系\n- earlySingletonObjects：beanName和bean实例之间关系。通singletonObjects不同的是当一个bean还在创建过程中，就可以通过getBean方法获取到，主要用来检测循环引用\n- singletonFactories：beanName和创建bean的工厂之间的关系 beanName---ObjectFactory\n- registeredSingletons：保存当前已注册的bean,包括ObjectFactory\n\n\n\nBeanWrapper\n\n\n\n\n\n```java\nprivate final Set<String> singletonsCurrentlyInCreation =\n      Collections.newSetFromMap(new ConcurrentHashMap<String, Boolean>(16));\n```","slug":"spring/spring-IOC","published":1,"updated":"2018-10-30T04:10:29.309Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnho004gwlkvy3hsido6"},{"title":"JUC总览","date":"2017-10-27T08:07:18.000Z","_content":"\n# JUC总览\n\n\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-11-16/51924135.jpg)\n\n\n\n　3.1 Condition\n\n　　Condition为接口类型，它将 Object 监视器方法（wait、notify 和 notifyAll）分解成截然不同的对象，以便通过将这些对象与任意 Lock 实现组合使用，为每个对象提供多个等待 set （wait-set）。其中，Lock 替代了 synchronized 方法和语句的使用，Condition 替代了 Object 监视器方法的使用。可以通过await(),signal()来休眠/唤醒线程。\n\n　　3.2 Lock\n\n　　Lock为接口类型，Lock``实现提供了比使用synchronized``方法和语句可获得的更广泛的锁定操作。此实现允许更灵活的结构，可以具有差别很大的属性，可以支持多个相关的Condition对象。\n\n　　3.3 ReadWriteLock\n\n`　　`ReadWriteLock为接口类型， 维护了一对相关的锁，一个用于只读操作，另一个用于写入操作。只要没有 writer，读取锁可以由多个 reader 线程同时保持。写入锁是独占的。\n\n　　3.4 AbstractOwnableSynchonizer\n\n　　AbstractOwnableSynchonizer为抽象类，可以由线程以独占方式拥有的同步器。此类为创建锁和相关同步器（伴随着所有权的概念）提供了基础。AbstractOwnableSynchronizer 类本身不管理或使用此信息。但是，子类和工具可以使用适当维护的值帮助控制和监视访问以及提供诊断。\n\n　　3.5 AbstractQueuedLongSynchronizer\n\n　　AbstractQueuedLongSynchronizer为抽象类，以 long 形式维护同步状态的一个 AbstractQueuedSynchronizer 版本。此类具有的结构、属性和方法与 AbstractQueuedSynchronizer 完全相同，但所有与状态相关的参数和结果都定义为 long 而不是 int。当创建需要 64 位状态的多级别锁和屏障等同步器时，此类很有用。\n\n　　3.6 AbstractQueuedSynchonizer\n\n　　AbstractQueuedSynchonizer为抽象类，其为实现依赖于先进先出 (FIFO) 等待队列的阻塞锁和相关同步器（信号量、事件，等等）提供一个框架。此类的设计目标是成为依靠单个原子 int 值来表示状态的大多数同步器的一个有用基础。 \n\n　　3.7 LockSupport\n\n　　LockSupport为常用类，用来创建锁和其他同步类的基本线程阻塞原语。LockSupport的功能和\"Thread中的 Thread.suspend()和Thread.resume()有点类似\"，LockSupport中的park() 和 unpark() 的作用分别是阻塞线程和解除阻塞线程。但是park()和unpark()不会遇到“Thread.suspend 和 Thread.resume所可能引发的死锁”问题。\n\n　　3.8 CountDownLatch\n\n　　CountDownLatch为常用类，它是一个同步辅助类，在完成一组正在其他线程中执行的操作之前，它允许一个或多个线程一直等待。\n\n　　3.9 Semaphore\n\n　　Semaphore为常用类，其是一个计数信号量，从概念上讲，信号量维护了一个许可集。如有必要，在许可可用前会阻塞每一个 acquire()，然后再获取该许可。每个 release() 添加一个许可，从而可能释放一个正在阻塞的获取者。但是，不使用实际的许可对象，Semaphore 只对可用许可的号码进行计数，并采取相应的行动。通常用于限制可以访问某些资源（物理或逻辑的）的线程数目。\n\n　　3.10 CyclicBarrier\n\n　　CyclicBarrier为常用类，其是一个同步辅助类，它允许一组线程互相等待，直到到达某个公共屏障点 (common barrier point)。在涉及一组固定大小的线程的程序中，这些线程必须不时地互相等待，此时 CyclicBarrier 很有用。因为该 barrier 在释放等待线程后可以重用，所以称它为循环 的 barrier。\n\n　　3.11 ReentrantLock\n\n　　ReentrantLock为常用类，它是一个可重入的互斥锁 Lock，它具有与使用 synchronized 方法和语句所访问的隐式监视器锁相同的一些基本行为和语义，但功能更强大。\n\n　　3.12 ReentrantReadWriteLock\n\n　　ReentrantReadWriteLock是读写锁接口ReadWriteLock的实现类，它包括Lock子类ReadLock和WriteLock。ReadLock是共享锁，WriteLock是独占锁。","source":"_posts/多线程/JUC总览.md","raw":"---\ntitle: JUC总览\ndate: 2017-10-27 16:07:18\ntags:\n- 多线程\ncategories:\n- java基础\n---\n\n# JUC总览\n\n\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-11-16/51924135.jpg)\n\n\n\n　3.1 Condition\n\n　　Condition为接口类型，它将 Object 监视器方法（wait、notify 和 notifyAll）分解成截然不同的对象，以便通过将这些对象与任意 Lock 实现组合使用，为每个对象提供多个等待 set （wait-set）。其中，Lock 替代了 synchronized 方法和语句的使用，Condition 替代了 Object 监视器方法的使用。可以通过await(),signal()来休眠/唤醒线程。\n\n　　3.2 Lock\n\n　　Lock为接口类型，Lock``实现提供了比使用synchronized``方法和语句可获得的更广泛的锁定操作。此实现允许更灵活的结构，可以具有差别很大的属性，可以支持多个相关的Condition对象。\n\n　　3.3 ReadWriteLock\n\n`　　`ReadWriteLock为接口类型， 维护了一对相关的锁，一个用于只读操作，另一个用于写入操作。只要没有 writer，读取锁可以由多个 reader 线程同时保持。写入锁是独占的。\n\n　　3.4 AbstractOwnableSynchonizer\n\n　　AbstractOwnableSynchonizer为抽象类，可以由线程以独占方式拥有的同步器。此类为创建锁和相关同步器（伴随着所有权的概念）提供了基础。AbstractOwnableSynchronizer 类本身不管理或使用此信息。但是，子类和工具可以使用适当维护的值帮助控制和监视访问以及提供诊断。\n\n　　3.5 AbstractQueuedLongSynchronizer\n\n　　AbstractQueuedLongSynchronizer为抽象类，以 long 形式维护同步状态的一个 AbstractQueuedSynchronizer 版本。此类具有的结构、属性和方法与 AbstractQueuedSynchronizer 完全相同，但所有与状态相关的参数和结果都定义为 long 而不是 int。当创建需要 64 位状态的多级别锁和屏障等同步器时，此类很有用。\n\n　　3.6 AbstractQueuedSynchonizer\n\n　　AbstractQueuedSynchonizer为抽象类，其为实现依赖于先进先出 (FIFO) 等待队列的阻塞锁和相关同步器（信号量、事件，等等）提供一个框架。此类的设计目标是成为依靠单个原子 int 值来表示状态的大多数同步器的一个有用基础。 \n\n　　3.7 LockSupport\n\n　　LockSupport为常用类，用来创建锁和其他同步类的基本线程阻塞原语。LockSupport的功能和\"Thread中的 Thread.suspend()和Thread.resume()有点类似\"，LockSupport中的park() 和 unpark() 的作用分别是阻塞线程和解除阻塞线程。但是park()和unpark()不会遇到“Thread.suspend 和 Thread.resume所可能引发的死锁”问题。\n\n　　3.8 CountDownLatch\n\n　　CountDownLatch为常用类，它是一个同步辅助类，在完成一组正在其他线程中执行的操作之前，它允许一个或多个线程一直等待。\n\n　　3.9 Semaphore\n\n　　Semaphore为常用类，其是一个计数信号量，从概念上讲，信号量维护了一个许可集。如有必要，在许可可用前会阻塞每一个 acquire()，然后再获取该许可。每个 release() 添加一个许可，从而可能释放一个正在阻塞的获取者。但是，不使用实际的许可对象，Semaphore 只对可用许可的号码进行计数，并采取相应的行动。通常用于限制可以访问某些资源（物理或逻辑的）的线程数目。\n\n　　3.10 CyclicBarrier\n\n　　CyclicBarrier为常用类，其是一个同步辅助类，它允许一组线程互相等待，直到到达某个公共屏障点 (common barrier point)。在涉及一组固定大小的线程的程序中，这些线程必须不时地互相等待，此时 CyclicBarrier 很有用。因为该 barrier 在释放等待线程后可以重用，所以称它为循环 的 barrier。\n\n　　3.11 ReentrantLock\n\n　　ReentrantLock为常用类，它是一个可重入的互斥锁 Lock，它具有与使用 synchronized 方法和语句所访问的隐式监视器锁相同的一些基本行为和语义，但功能更强大。\n\n　　3.12 ReentrantReadWriteLock\n\n　　ReentrantReadWriteLock是读写锁接口ReadWriteLock的实现类，它包括Lock子类ReadLock和WriteLock。ReadLock是共享锁，WriteLock是独占锁。","slug":"多线程/JUC总览","published":1,"updated":"2018-09-12T03:03:21.827Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnhp004lwlkvlrnlu6eb"},{"title":"java synchronized原理","date":"2017-09-01T08:52:24.000Z","_content":"\n#  java synchronized原理\n\n在java多线程编程中，最常用的加锁方式就是使用synchronized关键字。synchronized可以加在方法上、代码块上从而使方法和代码实现线程安全，当一个线程进入synchronized代码块后，其他线程会被阻塞在代码块外面，处于对象的锁池中，这时不再消耗cpu资源，等待对象锁的释放，然后从阻塞状态切换为可运行状态，参与竞争对象锁。\n\nsynchronized在获锁的过程中是不能被中断的，意思是说如果产生了死锁，则不可能被中断\n\n<!--more-->\n\n## synchronized使用方式\n\nSynchronized本质上都是当前线程获取指定对象相关联的monitor对象，这个过程是互斥性的，也就是说同一时刻只有一个线程能够成功，其它失败的线程会被阻塞，并放入到锁池中，进入阻塞状态。\n\n- synchronized代码块：\n\n  javap查看同步块的入口位置和退出位置分别插入monitorenter和monitorexit字节码指令\n\n  ```java\n  public void test(){\n    synchronized (this) {\n      \n    }\n  }\n  public void test();\n      descriptor: ()V\n      flags: ACC_PUBLIC\n      Code:\n        stack=2, locals=3, args_size=1\n           0: aload_0\n           1: dup\n           2: astore_1\n           3: monitorenter\n           4: aload_1\n           5: monitorexit\n           6: goto          14\n           9: astore_2\n          10: aload_1\n          11: monitorexit\n          12: aload_2\n          13: athrow\n          14: return\n            \n  ```\n\n  ​\n\n- synchronized方法\n\n  javap查看synchronized方法会被编译成方法的flags加上标志ACC_SYNCHRONIZED，在Class文件的方法表中将该方法的access_flags字段中的synchronized标志位置1，表明该方法使用自身对象或者自身Class对象作为锁对象\n\n  ```java\n  public synchronized void test(){\n    System.out.println(\"test\");\n  }\n\n  public synchronized void test();\n      descriptor: ()V\n      flags: ACC_PUBLIC, ACC_SYNCHRONIZED\n      Code:\n        stack=0, locals=1, args_size=1\n           0: return\n  ```\n\n  ​\n\n## synchronized对内存空间的影响\n\n- 进入synchronized同步代码块后，JVM会把该线程对应的本地内存置为无效，从而强制线程去主内存读取共享数据。\n- 出synchronized同步代码块前，线程会将当前工作内存中的缓存写入主内存。\n\n## synchronized锁优化\n\n由于线程的阻塞和重启涉及CPU内核切换，非常耗费性能，Jdk1.6之后针对synchronized做了一些优化，主要包括如锁粗化、锁消除、轻量级锁、偏向锁、适应性自旋、重量级锁等技术来减少锁操作的开销。\n\n**锁粗化：**在已经持有该对象锁的情况下，再次调用synchronized该对象，不再判断，如StringBuilder.append().apend()\n\n```java\npublic void test() {\n  synchronized (this) {\n    System.out.println(\"a\");\n  }\n  synchronized (this) {//优化后不再阻塞\n    System.out.println(\"b\");\n  }\n}\n```\n\n**锁消除：**通过运行时JIT编译器的逃逸分析来消除一些没有操作共享变量的同步操作\n\n```java\npublic void test1() {\n  Vector vector = new Vector();\n  vector.add(\"1\");//vector本身属于线程私有的，调用add的时候会进行锁消除\n  vector.add(\"2\");\n}\n```\n\n偏向锁：**当线程访问同步方法或者同步代码块的时候，会先判断对象头存储的线程是否为当前线程，而不需要进行CAS操作进行加锁和解锁，避免轻量级锁。**用于处理只有一个线程进入同步块中的情况**\n\n**轻量级锁：**假设大部分同步代码一般都处于无锁竞争状态，在无竞争的情况下应该尽量避免使用锁，取而代之的是在monitorenter和monitorexit中只需要依靠一条CAS原子指令就可以完成锁的获取及释放。当存在锁竞争的情况下，执行CAS指令失败的线程将调用操作系统互斥锁进入到阻塞状态，当锁被释放的时候被唤醒。**用于处理多个线程交替进入同步块的情况**\n\n**适应性自旋：**当线程在获取轻量级锁的过程中执行CAS操作失败时，升级为重量级锁，当前线程会自旋，自旋一定时间再次尝试获取锁，成功则避免进入阻塞状态，减少CPU的切换消耗，如果自旋后尝试还是无法获取则进入阻塞状态，等待其他线程释放对象锁。java虚拟机内部会对自旋的次数自动调整，如果上次自旋后成功获取锁则减少下次自旋次数，如果自旋后还是无法获取到对象锁，会减少下次的自旋字数，避免在自旋长期占用CPU资源。\n\n**重量级锁**：**用于多个线程同时进入同步块的情况**\n\n## 锁优化实现原理\n\n### java 对象头\n\n在java中每个对象都可以作为一个锁，继承Object中的wait和notify方法，在hotspot虚拟机中，对象在内存的分布分为3个部分：对象头，实例数据，和对齐填充。在对象头中的Mark Word存储了对象的锁信息，Mark Word被设计成一个非固定的数据结构以便在极小的空间内存存储尽量多的数据，它会根据对象的状态复用自己的存储空间，也就是说，Mark Word会随着程序的运行发生变化，变化状态如下\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-10-28/87461048.jpg)\n\n### monitor锁对象\n\n**monitor是线程私有的数据结构，存储在栈中**，每一个线程都有一个可用monitor列表，同时还有一个全局的可用列表，当线程可用monitor列表为空的时候会请求全局可用列表补充。\n\n在 java 虚拟机中，线程一旦进入到被synchronized修饰的方法或代码块时，指定的锁对象的对象头存储指向monitor对象的指针，这个过程称为锁对象的膨胀。同时monitor 中的Owner存放拥有该对象锁的线程的唯一标识，确保一次只能有一个线程执行该部分的代码，线程在获取锁之前不允许执行该部分的代码。\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-10-28/44370183.jpg)\n\n**Owner**：初始时为NULL表示当前没有任何线程拥有该monitor record，当线程成功拥有该锁后保存持有锁的线程唯一标识，当锁被释放时又设置为NULL；\n\n**EntryQ**:关联一个系统互斥锁（semaphore），阻塞所有试图锁住monitor record失败的线程。\n\n**RcThis**:表示blocked或waiting在该monitor record上的所有线程的个数。\n\n**Nest**:用来实现重入锁的计数。\n\n**HashCode**:保存从对象头拷贝过来的HashCode值（可能还包含GC age）。\n\n**Candidate**:用来避免不必要的阻塞或等待线程唤醒，因为每一次只有一个线程能够成功拥有锁，如果每次前一个释放锁的线程唤醒所有正在阻塞或等待的线程，会引起不必要的上下文切换（从阻塞到就绪然后因为竞争锁失败又被阻塞）从而导致性能严重下降。Candidate只有两种可能的值0表示没有需要唤醒的线程1表示要唤醒一个继任线程来竞争锁。\n\nJava中锁有四种状态，**无锁状态，偏向锁状态，轻量级锁状态和重量级锁状态**，它会随着竞争情况逐渐升级。锁可以升级但不能降级，目的是为了提高获得锁和释放锁的效率。\n\n### 偏向锁\n\n**引入背景**：Hotspot 的作者经过以往的研究发现大多数情况下锁不仅不存在多线程竞争，而且总是由同一线程多次获得，为了让线程获得锁的代价更低而引入了偏向锁。当一个线程访问同步块并获取锁时，会在对象头和栈帧中的锁记录里存储锁偏向的线程 ID，以后该线程在进入和退出同步块时不需要花费CAS操作来加锁和解锁，而只需简单的测试一下对象头的Mark Word里是否存储着指向当前线程的偏向锁，如果测试成功，表示线程已经获得了锁，如果测试失败，则需要再测试下 Mark Word中偏向锁的标识是否设置成 1（表示当前是偏向锁），如果没有设置，则使用 CAS 竞争锁，如果设置了，则尝试使用 CAS 将对象头的偏向锁指向当前线程。\n\n```java\npublic static void main(String[] args) {\n  method1();\n  method2();\n}\nsynchronized static void method1() {}\nsynchronized static void method2() {}\n```\n\n**加锁**：当Thread#1进入临界区时，JVM会将lockObject的对象头Mark Word的锁标志位设为“01”，同时会用CAS操作把Thread#1的线程ID记录到Mark Word中，此时进入偏向模式。所谓“偏向”，指的是这个锁会偏向于Thread#1，若接下来没有其他线程进入临界区，则Thread#1再出入临界区无需再执行任何同步操作。也就是说，若只有Thread#1会进入临界区，实际上只有Thread#1初次进入临界区时需要执行CAS操作，以后再出入临界区都不会有同步操作带来的开销。\n\n然而情况一是一个比较理想的情况，更多时候Thread#2也会尝试进入临界区。若Thread#2尝试进入时Thread#1已退出临界区，即此时lockObject处于未锁定状态，这时说明偏向锁上发生了竞争（对应情况二），此时会撤销偏向，Mark Word中不再存放偏向线程ID，而是存放hashCode和GC分代年龄，同时锁标识位变为“01”（表示未锁定），这时Thread#2会获取lockObject的轻量级锁。因为此时Thread#1和Thread#2交替进入临界区，所以偏向锁无法满足需求，需要膨胀到轻量级锁。\n\n**解除锁**：偏向锁使用了一种等到竞争出现才释放锁的机制，所以当其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁。偏向锁的撤销，需要等待全局安全点（在这个时间点上没有字节码正在执行），它会首先暂停拥有偏向锁的线程，然后检查持有偏向锁的线程是否活着，如果线程不处于活动状态，则将对象头设置成无锁状态，如果线程仍然活着，拥有偏向锁的栈会被执行，遍历偏向对象的锁记录，栈中的锁记录和对象头的Mark Word要么重新偏向于其他线程，要么恢复到无锁或者标记对象不适合作为偏向锁，最后唤醒暂停的线程。\n\n![偏向锁](http://omdq6di7v.bkt.clouddn.com/17-10-28/40695590.jpg)\n\n### 轻量级锁\n\n**引入背景**：这种锁实现的背后基于这样一种假设，即在真实的情况下我们程序中的大部分同步代码一般都处于无锁竞争状态（即单线程执行环境），在无锁竞争的情况下完全可以避免调用操作系统层面的**重量级互斥锁**，取而代之的是在monitorenter和monitorexit中**只需要依靠一条CAS原子指令就可以完成锁的获取及释放**。当存在锁竞争的情况下，执行CAS指令失败的线程将调用操作系统互斥锁进入到阻塞状态，当锁被释放的时候被唤醒\n\n**加锁**： 线程在执行同步块之前， 线程首先从自己的可用moniter record列表中取得一个空闲的monite对象，初始Nest和Owner值分别被预先设置为1和该线程自己的标识，并将对象头中的Mark Word复制到锁记录中，官方称为Displaced Mark Word。然后线程尝试使用 CAS 将对象头中的Mark Word替换为指向monitor对象的指针。如果成功，当前线程获得锁，如果失败，表示其他线程竞争锁，当前线程便尝试使用**自旋**来获取锁。,**如果有两条以上的线程争用同一个锁，那轻量级锁就不再有效，要膨胀为重量级锁，锁标志的状态值变为”10”，Mark Word中存储的就是指向重量级（互斥量）的指针。当达到一定的次数时如果仍然没有成功获得锁，则开始准备进入阻塞状态，将rfThis的值原子性的加1**\n\n如果Mark Word中已经指向一个monitor对象，并且该monitor对象中的Owner中保存的线程标识是线程自己，这就是重入锁的情况，只需要简单的将Nest加1即可\n\n**释放锁**:首先使用原子的 CAS 操作来将Displaced Mark Word替换回到对象头，如果成功，则表示没有竞争发生。如果失败，表示当前锁存在竞争，锁就会膨胀成重量级锁。\n\n![轻量级锁](http://omdq6di7v.bkt.clouddn.com/17-10-28/21119997.jpg)\n\n\n\n### 重量级锁\n\n**加锁**：Mark Word标记为10，其他线程进入同步阻塞状态\n\n**释放锁**：\n\n1. 检查该对象是否处于膨胀状态并且该线程是这个锁的拥有者，如果发现不对则抛出异常。\n2. 检查Nest字段是否大于1，如果大于1则简单的将Nest减1并继续拥有锁，如果等于1，则进入到步骤3。\n3. 检查rfThis是否大于0，设置Owner为空然后唤醒一个正在阻塞或等待的线程再一次试图获取锁，如果等于0则进入到步骤4\n4. 将对象头的LockWord置为空，解除和monitor对象的关联，释放对象锁，同时将这个空的monitor对象再次放入线程的可用monitor列表。        \n\n\n### 总结\n\n- 偏向锁、轻量级锁都是乐观锁，重量级锁是悲观锁。 没有任何线程来访问同步块的时候，对象锁是可偏向的，这意味着当有第一个线程进入同步块的访问锁对象的时候，会获取对象的偏向锁，这个线程在修改锁对象的对象头成为偏向锁的时候使用CAS操作，并将对象头中的ThreadID改成自己的ID，之后该线程再次访问该锁对象，只需要对比ID，不需要再使用CAS在进行操作。\n\n\n- 一旦有第二个线程访问锁对象，因为偏向锁不会主动释放，所以第二个线程可以看到对象时偏向状态，这时表明在这个对象上已经存在竞争了，检查原来持有该对象锁的线程是否依然存活，如果挂了，则可以将对象变为无锁状态，然后重新偏向新的线程，如果原来的偏向的线程依然存活，则马上执行那个线程的操作栈，检查该对象的使用情况，如果仍然需要持有偏向锁，则偏向锁升级为轻量级锁，（**偏向锁就是这个时候升级为轻量级锁的**）。如果不存在使用了，则可以将对象回复成无锁状态，然后重新偏向。\n- 轻量级锁认为竞争存在，但一般两个线程对于同一个锁的操作都会错开，或者存在竞争时线程进行几次**自旋**，另一个线程就会释放锁。 但是当自旋超过一定的次数后还无法获得对象锁，轻量级锁膨胀为重量级锁，重量级锁使除了拥有锁的线程以外的线程都阻塞，防止CPU空转。\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-10-28/39811669.jpg)\n\n\n## 参考资料\n\n[深入浅出synchronized](http://www.jianshu.com/p/19f861ab749e)\n\n[Java中synchronized的实现原理与应用](http://www.infoq.com/cn/articles/java-se-16-synchronized/)","source":"_posts/多线程/java synchronized原理.md","raw":"---\ntitle: java synchronized原理\ndate: 2017-09-01 16:52:24\ntags:\n- 多线程\ncategories:\n- java基础\n\n---\n\n#  java synchronized原理\n\n在java多线程编程中，最常用的加锁方式就是使用synchronized关键字。synchronized可以加在方法上、代码块上从而使方法和代码实现线程安全，当一个线程进入synchronized代码块后，其他线程会被阻塞在代码块外面，处于对象的锁池中，这时不再消耗cpu资源，等待对象锁的释放，然后从阻塞状态切换为可运行状态，参与竞争对象锁。\n\nsynchronized在获锁的过程中是不能被中断的，意思是说如果产生了死锁，则不可能被中断\n\n<!--more-->\n\n## synchronized使用方式\n\nSynchronized本质上都是当前线程获取指定对象相关联的monitor对象，这个过程是互斥性的，也就是说同一时刻只有一个线程能够成功，其它失败的线程会被阻塞，并放入到锁池中，进入阻塞状态。\n\n- synchronized代码块：\n\n  javap查看同步块的入口位置和退出位置分别插入monitorenter和monitorexit字节码指令\n\n  ```java\n  public void test(){\n    synchronized (this) {\n      \n    }\n  }\n  public void test();\n      descriptor: ()V\n      flags: ACC_PUBLIC\n      Code:\n        stack=2, locals=3, args_size=1\n           0: aload_0\n           1: dup\n           2: astore_1\n           3: monitorenter\n           4: aload_1\n           5: monitorexit\n           6: goto          14\n           9: astore_2\n          10: aload_1\n          11: monitorexit\n          12: aload_2\n          13: athrow\n          14: return\n            \n  ```\n\n  ​\n\n- synchronized方法\n\n  javap查看synchronized方法会被编译成方法的flags加上标志ACC_SYNCHRONIZED，在Class文件的方法表中将该方法的access_flags字段中的synchronized标志位置1，表明该方法使用自身对象或者自身Class对象作为锁对象\n\n  ```java\n  public synchronized void test(){\n    System.out.println(\"test\");\n  }\n\n  public synchronized void test();\n      descriptor: ()V\n      flags: ACC_PUBLIC, ACC_SYNCHRONIZED\n      Code:\n        stack=0, locals=1, args_size=1\n           0: return\n  ```\n\n  ​\n\n## synchronized对内存空间的影响\n\n- 进入synchronized同步代码块后，JVM会把该线程对应的本地内存置为无效，从而强制线程去主内存读取共享数据。\n- 出synchronized同步代码块前，线程会将当前工作内存中的缓存写入主内存。\n\n## synchronized锁优化\n\n由于线程的阻塞和重启涉及CPU内核切换，非常耗费性能，Jdk1.6之后针对synchronized做了一些优化，主要包括如锁粗化、锁消除、轻量级锁、偏向锁、适应性自旋、重量级锁等技术来减少锁操作的开销。\n\n**锁粗化：**在已经持有该对象锁的情况下，再次调用synchronized该对象，不再判断，如StringBuilder.append().apend()\n\n```java\npublic void test() {\n  synchronized (this) {\n    System.out.println(\"a\");\n  }\n  synchronized (this) {//优化后不再阻塞\n    System.out.println(\"b\");\n  }\n}\n```\n\n**锁消除：**通过运行时JIT编译器的逃逸分析来消除一些没有操作共享变量的同步操作\n\n```java\npublic void test1() {\n  Vector vector = new Vector();\n  vector.add(\"1\");//vector本身属于线程私有的，调用add的时候会进行锁消除\n  vector.add(\"2\");\n}\n```\n\n偏向锁：**当线程访问同步方法或者同步代码块的时候，会先判断对象头存储的线程是否为当前线程，而不需要进行CAS操作进行加锁和解锁，避免轻量级锁。**用于处理只有一个线程进入同步块中的情况**\n\n**轻量级锁：**假设大部分同步代码一般都处于无锁竞争状态，在无竞争的情况下应该尽量避免使用锁，取而代之的是在monitorenter和monitorexit中只需要依靠一条CAS原子指令就可以完成锁的获取及释放。当存在锁竞争的情况下，执行CAS指令失败的线程将调用操作系统互斥锁进入到阻塞状态，当锁被释放的时候被唤醒。**用于处理多个线程交替进入同步块的情况**\n\n**适应性自旋：**当线程在获取轻量级锁的过程中执行CAS操作失败时，升级为重量级锁，当前线程会自旋，自旋一定时间再次尝试获取锁，成功则避免进入阻塞状态，减少CPU的切换消耗，如果自旋后尝试还是无法获取则进入阻塞状态，等待其他线程释放对象锁。java虚拟机内部会对自旋的次数自动调整，如果上次自旋后成功获取锁则减少下次自旋次数，如果自旋后还是无法获取到对象锁，会减少下次的自旋字数，避免在自旋长期占用CPU资源。\n\n**重量级锁**：**用于多个线程同时进入同步块的情况**\n\n## 锁优化实现原理\n\n### java 对象头\n\n在java中每个对象都可以作为一个锁，继承Object中的wait和notify方法，在hotspot虚拟机中，对象在内存的分布分为3个部分：对象头，实例数据，和对齐填充。在对象头中的Mark Word存储了对象的锁信息，Mark Word被设计成一个非固定的数据结构以便在极小的空间内存存储尽量多的数据，它会根据对象的状态复用自己的存储空间，也就是说，Mark Word会随着程序的运行发生变化，变化状态如下\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-10-28/87461048.jpg)\n\n### monitor锁对象\n\n**monitor是线程私有的数据结构，存储在栈中**，每一个线程都有一个可用monitor列表，同时还有一个全局的可用列表，当线程可用monitor列表为空的时候会请求全局可用列表补充。\n\n在 java 虚拟机中，线程一旦进入到被synchronized修饰的方法或代码块时，指定的锁对象的对象头存储指向monitor对象的指针，这个过程称为锁对象的膨胀。同时monitor 中的Owner存放拥有该对象锁的线程的唯一标识，确保一次只能有一个线程执行该部分的代码，线程在获取锁之前不允许执行该部分的代码。\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-10-28/44370183.jpg)\n\n**Owner**：初始时为NULL表示当前没有任何线程拥有该monitor record，当线程成功拥有该锁后保存持有锁的线程唯一标识，当锁被释放时又设置为NULL；\n\n**EntryQ**:关联一个系统互斥锁（semaphore），阻塞所有试图锁住monitor record失败的线程。\n\n**RcThis**:表示blocked或waiting在该monitor record上的所有线程的个数。\n\n**Nest**:用来实现重入锁的计数。\n\n**HashCode**:保存从对象头拷贝过来的HashCode值（可能还包含GC age）。\n\n**Candidate**:用来避免不必要的阻塞或等待线程唤醒，因为每一次只有一个线程能够成功拥有锁，如果每次前一个释放锁的线程唤醒所有正在阻塞或等待的线程，会引起不必要的上下文切换（从阻塞到就绪然后因为竞争锁失败又被阻塞）从而导致性能严重下降。Candidate只有两种可能的值0表示没有需要唤醒的线程1表示要唤醒一个继任线程来竞争锁。\n\nJava中锁有四种状态，**无锁状态，偏向锁状态，轻量级锁状态和重量级锁状态**，它会随着竞争情况逐渐升级。锁可以升级但不能降级，目的是为了提高获得锁和释放锁的效率。\n\n### 偏向锁\n\n**引入背景**：Hotspot 的作者经过以往的研究发现大多数情况下锁不仅不存在多线程竞争，而且总是由同一线程多次获得，为了让线程获得锁的代价更低而引入了偏向锁。当一个线程访问同步块并获取锁时，会在对象头和栈帧中的锁记录里存储锁偏向的线程 ID，以后该线程在进入和退出同步块时不需要花费CAS操作来加锁和解锁，而只需简单的测试一下对象头的Mark Word里是否存储着指向当前线程的偏向锁，如果测试成功，表示线程已经获得了锁，如果测试失败，则需要再测试下 Mark Word中偏向锁的标识是否设置成 1（表示当前是偏向锁），如果没有设置，则使用 CAS 竞争锁，如果设置了，则尝试使用 CAS 将对象头的偏向锁指向当前线程。\n\n```java\npublic static void main(String[] args) {\n  method1();\n  method2();\n}\nsynchronized static void method1() {}\nsynchronized static void method2() {}\n```\n\n**加锁**：当Thread#1进入临界区时，JVM会将lockObject的对象头Mark Word的锁标志位设为“01”，同时会用CAS操作把Thread#1的线程ID记录到Mark Word中，此时进入偏向模式。所谓“偏向”，指的是这个锁会偏向于Thread#1，若接下来没有其他线程进入临界区，则Thread#1再出入临界区无需再执行任何同步操作。也就是说，若只有Thread#1会进入临界区，实际上只有Thread#1初次进入临界区时需要执行CAS操作，以后再出入临界区都不会有同步操作带来的开销。\n\n然而情况一是一个比较理想的情况，更多时候Thread#2也会尝试进入临界区。若Thread#2尝试进入时Thread#1已退出临界区，即此时lockObject处于未锁定状态，这时说明偏向锁上发生了竞争（对应情况二），此时会撤销偏向，Mark Word中不再存放偏向线程ID，而是存放hashCode和GC分代年龄，同时锁标识位变为“01”（表示未锁定），这时Thread#2会获取lockObject的轻量级锁。因为此时Thread#1和Thread#2交替进入临界区，所以偏向锁无法满足需求，需要膨胀到轻量级锁。\n\n**解除锁**：偏向锁使用了一种等到竞争出现才释放锁的机制，所以当其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁。偏向锁的撤销，需要等待全局安全点（在这个时间点上没有字节码正在执行），它会首先暂停拥有偏向锁的线程，然后检查持有偏向锁的线程是否活着，如果线程不处于活动状态，则将对象头设置成无锁状态，如果线程仍然活着，拥有偏向锁的栈会被执行，遍历偏向对象的锁记录，栈中的锁记录和对象头的Mark Word要么重新偏向于其他线程，要么恢复到无锁或者标记对象不适合作为偏向锁，最后唤醒暂停的线程。\n\n![偏向锁](http://omdq6di7v.bkt.clouddn.com/17-10-28/40695590.jpg)\n\n### 轻量级锁\n\n**引入背景**：这种锁实现的背后基于这样一种假设，即在真实的情况下我们程序中的大部分同步代码一般都处于无锁竞争状态（即单线程执行环境），在无锁竞争的情况下完全可以避免调用操作系统层面的**重量级互斥锁**，取而代之的是在monitorenter和monitorexit中**只需要依靠一条CAS原子指令就可以完成锁的获取及释放**。当存在锁竞争的情况下，执行CAS指令失败的线程将调用操作系统互斥锁进入到阻塞状态，当锁被释放的时候被唤醒\n\n**加锁**： 线程在执行同步块之前， 线程首先从自己的可用moniter record列表中取得一个空闲的monite对象，初始Nest和Owner值分别被预先设置为1和该线程自己的标识，并将对象头中的Mark Word复制到锁记录中，官方称为Displaced Mark Word。然后线程尝试使用 CAS 将对象头中的Mark Word替换为指向monitor对象的指针。如果成功，当前线程获得锁，如果失败，表示其他线程竞争锁，当前线程便尝试使用**自旋**来获取锁。,**如果有两条以上的线程争用同一个锁，那轻量级锁就不再有效，要膨胀为重量级锁，锁标志的状态值变为”10”，Mark Word中存储的就是指向重量级（互斥量）的指针。当达到一定的次数时如果仍然没有成功获得锁，则开始准备进入阻塞状态，将rfThis的值原子性的加1**\n\n如果Mark Word中已经指向一个monitor对象，并且该monitor对象中的Owner中保存的线程标识是线程自己，这就是重入锁的情况，只需要简单的将Nest加1即可\n\n**释放锁**:首先使用原子的 CAS 操作来将Displaced Mark Word替换回到对象头，如果成功，则表示没有竞争发生。如果失败，表示当前锁存在竞争，锁就会膨胀成重量级锁。\n\n![轻量级锁](http://omdq6di7v.bkt.clouddn.com/17-10-28/21119997.jpg)\n\n\n\n### 重量级锁\n\n**加锁**：Mark Word标记为10，其他线程进入同步阻塞状态\n\n**释放锁**：\n\n1. 检查该对象是否处于膨胀状态并且该线程是这个锁的拥有者，如果发现不对则抛出异常。\n2. 检查Nest字段是否大于1，如果大于1则简单的将Nest减1并继续拥有锁，如果等于1，则进入到步骤3。\n3. 检查rfThis是否大于0，设置Owner为空然后唤醒一个正在阻塞或等待的线程再一次试图获取锁，如果等于0则进入到步骤4\n4. 将对象头的LockWord置为空，解除和monitor对象的关联，释放对象锁，同时将这个空的monitor对象再次放入线程的可用monitor列表。        \n\n\n### 总结\n\n- 偏向锁、轻量级锁都是乐观锁，重量级锁是悲观锁。 没有任何线程来访问同步块的时候，对象锁是可偏向的，这意味着当有第一个线程进入同步块的访问锁对象的时候，会获取对象的偏向锁，这个线程在修改锁对象的对象头成为偏向锁的时候使用CAS操作，并将对象头中的ThreadID改成自己的ID，之后该线程再次访问该锁对象，只需要对比ID，不需要再使用CAS在进行操作。\n\n\n- 一旦有第二个线程访问锁对象，因为偏向锁不会主动释放，所以第二个线程可以看到对象时偏向状态，这时表明在这个对象上已经存在竞争了，检查原来持有该对象锁的线程是否依然存活，如果挂了，则可以将对象变为无锁状态，然后重新偏向新的线程，如果原来的偏向的线程依然存活，则马上执行那个线程的操作栈，检查该对象的使用情况，如果仍然需要持有偏向锁，则偏向锁升级为轻量级锁，（**偏向锁就是这个时候升级为轻量级锁的**）。如果不存在使用了，则可以将对象回复成无锁状态，然后重新偏向。\n- 轻量级锁认为竞争存在，但一般两个线程对于同一个锁的操作都会错开，或者存在竞争时线程进行几次**自旋**，另一个线程就会释放锁。 但是当自旋超过一定的次数后还无法获得对象锁，轻量级锁膨胀为重量级锁，重量级锁使除了拥有锁的线程以外的线程都阻塞，防止CPU空转。\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-10-28/39811669.jpg)\n\n\n## 参考资料\n\n[深入浅出synchronized](http://www.jianshu.com/p/19f861ab749e)\n\n[Java中synchronized的实现原理与应用](http://www.infoq.com/cn/articles/java-se-16-synchronized/)","slug":"多线程/java synchronized原理","published":1,"updated":"2018-09-12T03:03:21.828Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnhr004owlkv4h1v3ojq"},{"title":"java多线程","date":"2017-09-01T05:51:24.000Z","_content":"# java多线程\n\n多线程是多个线程竞争CPU，就绪状态的线程进行排队，当CPU选中线程就执行一个时间片，之后再次进行竞争。\n\n在单个单核CPU上多线程运行不会出现共享内存问题，但是随着多核多个CPU的出现，多线程运行在不同的运行内存中，并发操作共享内存会产生一系列并发问题需要解决。\n\n<!--more-->\n\n- 优点：\n\n  - 适当的提高程序的执行效率（多个线程同时执行）\n  - 适当的提高了资源利用率（CPU、内存等）\n- 缺点：\n  - 占用一定的内存空间。\n  - 线程越多CPU的调度开销越大。\n  - 程序的复杂度会上升。\n\n## 多线程模式\n\n- 并行线程模式：\n\n  常用的并发线程模式，将任务使用多个线程并行执行处理\n\n  - 优点\n    - 提升简单，只需要控制并发线程的数量进行操控，一般通过压测找到最合适的并发量\n    - 更适用于尽量少操作共享变量并且相互之间独立的多线程\n  - 缺点\n    - 操作共享变量的时候逻辑变复杂，如果使用锁机制会导致性能下降\n    - 共享变量需要每次去操作主内存中变量，无法使用线程空间中变量，性能偏低\n    - 共享变量使用不可变对象或者使用多个版本控制又无法达到线程之间一致性\n    - 多个线程之间无法保证运行的顺序性\n\n  ![image](http://omdq6di7v.bkt.clouddn.com/17-9-29/34093455.jpg)\n\n- 事件驱动模式：\n\n  将一个任务分解多步，每个步骤由一个线程去执行，类似生产线,会有多个生产线并存，并发生交叉，上个执行完毕后通过事件监听通知下个环节线程进行操作，各环节线程之间不存在并发操作共享变量情况\n\n  ![image](http://omdq6di7v.bkt.clouddn.com/17-9-30/15328264.jpg)\n\n  每个环节中间加入channel，解耦两个环节线程\n\n  ![image](http://omdq6di7v.bkt.clouddn.com/17-9-29/89911687.jpg)\n\n  - 优点\n    - 各个环节线程不涉及同时操作共享变量，不需考虑并发问题\n    - 直接使用线程工作空间copy的变量，只需最后操作主内存变量，性能提高\n    - 单线程模式下可以实现更多的算法和使用更多的数据结构来提升性能\n    - 实现任务拆分后的顺序执行\n  - 缺点\n    - 任务被拆分执行后可能在不同应用的不同线程执行，观察任务执行轨迹会比较麻烦\n    - 需要一系列的嵌套的事件回调方法，代码逻辑复杂\n\n\n## 线程阻塞到运行性能问题\n\n对于单核CPU来说（对于多核CPU，此处就理解为一个核），CPU在一个时刻只能运行一个线程，当在运行一个线程的过程中转去运行另外一个线程，这个叫做线程上下文切换。由于可能当前线程的任务并没有执行完毕，所以在切换时需要保存线程的运行状态(程序计数器、CPU寄存器状态)，以便下次重新切换回来时能够继续切换之前的状态运行。对于线程的上下文切换实际上就是存储和恢复CPU状态的过程，它使得线程执行能够从中断点恢复执行。每次大约需要占用8w多CPU时间周期\n\n上下文切换会带来直接和间接两种因素影响程序性能的消耗. \n\n- 直接消耗包括: CPU寄存器需要保存和加载, 系统调度器的代码需要执行, TLB实例需要重新加载, CPU 的pipeline需要刷掉; \n- 间接消耗指的是多核的cache之间得共享数据, 间接消耗对于程序的影响要看线程工作区操作数据的大小\n\n引起上下文切换的原因大概有以下几种: \n\n1. 当前执行任务的时间片用完之后, 系统CPU正常调度下一个任务 \n2. 当前执行任务碰到IO阻塞, 调度器将挂起此任务, 继续下一任务 \n3. 多个任务抢占锁资源, 当前任务没有抢到,被调度器挂起, 继续下一任务 \n4. 用户代码挂起当前任务, 让出CPU时间","source":"_posts/多线程/java多线程.md","raw":"---\ntitle: java多线程\ndate: 2017-09-01 13:51:24\ntags:\n- 多线程\ncategories:\n- java基础\n---\n# java多线程\n\n多线程是多个线程竞争CPU，就绪状态的线程进行排队，当CPU选中线程就执行一个时间片，之后再次进行竞争。\n\n在单个单核CPU上多线程运行不会出现共享内存问题，但是随着多核多个CPU的出现，多线程运行在不同的运行内存中，并发操作共享内存会产生一系列并发问题需要解决。\n\n<!--more-->\n\n- 优点：\n\n  - 适当的提高程序的执行效率（多个线程同时执行）\n  - 适当的提高了资源利用率（CPU、内存等）\n- 缺点：\n  - 占用一定的内存空间。\n  - 线程越多CPU的调度开销越大。\n  - 程序的复杂度会上升。\n\n## 多线程模式\n\n- 并行线程模式：\n\n  常用的并发线程模式，将任务使用多个线程并行执行处理\n\n  - 优点\n    - 提升简单，只需要控制并发线程的数量进行操控，一般通过压测找到最合适的并发量\n    - 更适用于尽量少操作共享变量并且相互之间独立的多线程\n  - 缺点\n    - 操作共享变量的时候逻辑变复杂，如果使用锁机制会导致性能下降\n    - 共享变量需要每次去操作主内存中变量，无法使用线程空间中变量，性能偏低\n    - 共享变量使用不可变对象或者使用多个版本控制又无法达到线程之间一致性\n    - 多个线程之间无法保证运行的顺序性\n\n  ![image](http://omdq6di7v.bkt.clouddn.com/17-9-29/34093455.jpg)\n\n- 事件驱动模式：\n\n  将一个任务分解多步，每个步骤由一个线程去执行，类似生产线,会有多个生产线并存，并发生交叉，上个执行完毕后通过事件监听通知下个环节线程进行操作，各环节线程之间不存在并发操作共享变量情况\n\n  ![image](http://omdq6di7v.bkt.clouddn.com/17-9-30/15328264.jpg)\n\n  每个环节中间加入channel，解耦两个环节线程\n\n  ![image](http://omdq6di7v.bkt.clouddn.com/17-9-29/89911687.jpg)\n\n  - 优点\n    - 各个环节线程不涉及同时操作共享变量，不需考虑并发问题\n    - 直接使用线程工作空间copy的变量，只需最后操作主内存变量，性能提高\n    - 单线程模式下可以实现更多的算法和使用更多的数据结构来提升性能\n    - 实现任务拆分后的顺序执行\n  - 缺点\n    - 任务被拆分执行后可能在不同应用的不同线程执行，观察任务执行轨迹会比较麻烦\n    - 需要一系列的嵌套的事件回调方法，代码逻辑复杂\n\n\n## 线程阻塞到运行性能问题\n\n对于单核CPU来说（对于多核CPU，此处就理解为一个核），CPU在一个时刻只能运行一个线程，当在运行一个线程的过程中转去运行另外一个线程，这个叫做线程上下文切换。由于可能当前线程的任务并没有执行完毕，所以在切换时需要保存线程的运行状态(程序计数器、CPU寄存器状态)，以便下次重新切换回来时能够继续切换之前的状态运行。对于线程的上下文切换实际上就是存储和恢复CPU状态的过程，它使得线程执行能够从中断点恢复执行。每次大约需要占用8w多CPU时间周期\n\n上下文切换会带来直接和间接两种因素影响程序性能的消耗. \n\n- 直接消耗包括: CPU寄存器需要保存和加载, 系统调度器的代码需要执行, TLB实例需要重新加载, CPU 的pipeline需要刷掉; \n- 间接消耗指的是多核的cache之间得共享数据, 间接消耗对于程序的影响要看线程工作区操作数据的大小\n\n引起上下文切换的原因大概有以下几种: \n\n1. 当前执行任务的时间片用完之后, 系统CPU正常调度下一个任务 \n2. 当前执行任务碰到IO阻塞, 调度器将挂起此任务, 继续下一任务 \n3. 多个任务抢占锁资源, 当前任务没有抢到,被调度器挂起, 继续下一任务 \n4. 用户代码挂起当前任务, 让出CPU时间","slug":"多线程/java多线程","published":1,"updated":"2018-09-12T03:03:21.828Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnhs004twlkvhh10iybn"},{"title":"java并发之Condition","date":"2017-11-23T12:05:40.000Z","_content":"\n# java并发之Condition\n\n使用synchronize中，获取锁的线程可以调用wait放弃执行权，并且进入阻塞状态，可以通过调用notify唤醒其他阻塞在当前锁的线程。在JUC中Lock中同样提供了相似的机制，可以通过lock.newCondition创建一个Condition对象，调用condition的await和signal同样可以实现。\n\n<!--more-->\n\n## 实现原理\n\nAQS中有个内部对象ConditionObject实现了Condition接口，通过ConditionObject实现阻塞和唤醒功能。\n\n### 阻塞流程\n\n- ConditionObject中维护一个双端等待队列，通过两个指针firstWaiter和lastWaiter引入首尾。\n\n\n- 当加锁成的线程调用await方法后，会释放锁，即state-1，同时向ConditionObject中的队列中添加当前线程节点，并且设置状态为-2，然后当前线程调用park进入阻塞状态\n\n  ```java\n  public final void await() throws InterruptedException {\n      if (Thread.interrupted())\n          throw new InterruptedException();\n      Node node = addConditionWaiter();//加入到 Condition的waiter队列中\n      int savedState = fullyRelease(node);//释放Lock锁 即state-1\n      int interruptMode = 0;\n      while (!isOnSyncQueue(node)) {\n          LockSupport.park(this);\n          if ((interruptMode = checkInterruptWhileWaiting(node)) != 0)\n              break;\n      }\n    //阻塞\n      if (acquireQueued(node, savedState) && interruptMode != THROW_IE)\n          interruptMode = REINTERRUPT;\n      if (node.nextWaiter != null) // clean up if cancelled\n          unlinkCancelledWaiters();\n      if (interruptMode != 0)\n          reportInterruptAfterWait(interruptMode);\n  }\n  ```\n\n### 唤醒流程\n\n- 调用signal方法进行线程的唤醒，获取等待队列首部的节点，然后该节点尝试获取锁，将该节点加入Lock的等待队列中，同时\n\n  ```java\n  public final void signal() {\n      if (!isHeldExclusively())\n          throw new IllegalMonitorStateException();\n      Node first = firstWaiter;//获取头节点\n      if (first != null)\n          doSignal(first);\n  }\n  ```\n\n\n- 唤醒头部首个没有取消的线程\n\n  ```java\n  private void doSignal(Node first) {\n      do {//移除头节点\n          if ( (firstWaiter = first.nextWaiter) == null)\n              lastWaiter = null;\n          first.nextWaiter = null;\n      } while (!transferForSignal(first) &&\n               (first = firstWaiter) != null);\n  }\n  //signalAll其实就是将所有等待的节点顺序加入到获取Lock的队列中\n  private void doSignalAll(Node first) {\n    lastWaiter = firstWaiter = null;\n    do {\n      Node next = first.nextWaiter;\n      first.nextWaiter = null;\n      transferForSignal(first);\n      first = next;\n    } while (first != null);\n  }\n  ```\n\n- 唤醒其实就是将该节点加入到获取Lock的等待队列中\n\n  ```java\n  final boolean transferForSignal(Node node) {\n     //节点线程已经被取消返回false，会取下个节点\n      if (!compareAndSetWaitStatus(node, Node.CONDITION, 0))\n          return false;\n    //将该节点加入 lock的等待队列\n      Node p = enq(node);\n      int ws = p.waitStatus;\n    //如果状态是取消的或者设置状态失败，则激活线程，避免状态获取错误\n      if (ws > 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL))\n          LockSupport.unpark(node.thread);\n      return true;\n  }\n  ```","source":"_posts/多线程/java并发之Condition.md","raw":"---\ntitle: java并发之Condition\ndate: 2017-11-23 20:05:40\ntags:\n- 多线程\ncategories:\n- java基础\n---\n\n# java并发之Condition\n\n使用synchronize中，获取锁的线程可以调用wait放弃执行权，并且进入阻塞状态，可以通过调用notify唤醒其他阻塞在当前锁的线程。在JUC中Lock中同样提供了相似的机制，可以通过lock.newCondition创建一个Condition对象，调用condition的await和signal同样可以实现。\n\n<!--more-->\n\n## 实现原理\n\nAQS中有个内部对象ConditionObject实现了Condition接口，通过ConditionObject实现阻塞和唤醒功能。\n\n### 阻塞流程\n\n- ConditionObject中维护一个双端等待队列，通过两个指针firstWaiter和lastWaiter引入首尾。\n\n\n- 当加锁成的线程调用await方法后，会释放锁，即state-1，同时向ConditionObject中的队列中添加当前线程节点，并且设置状态为-2，然后当前线程调用park进入阻塞状态\n\n  ```java\n  public final void await() throws InterruptedException {\n      if (Thread.interrupted())\n          throw new InterruptedException();\n      Node node = addConditionWaiter();//加入到 Condition的waiter队列中\n      int savedState = fullyRelease(node);//释放Lock锁 即state-1\n      int interruptMode = 0;\n      while (!isOnSyncQueue(node)) {\n          LockSupport.park(this);\n          if ((interruptMode = checkInterruptWhileWaiting(node)) != 0)\n              break;\n      }\n    //阻塞\n      if (acquireQueued(node, savedState) && interruptMode != THROW_IE)\n          interruptMode = REINTERRUPT;\n      if (node.nextWaiter != null) // clean up if cancelled\n          unlinkCancelledWaiters();\n      if (interruptMode != 0)\n          reportInterruptAfterWait(interruptMode);\n  }\n  ```\n\n### 唤醒流程\n\n- 调用signal方法进行线程的唤醒，获取等待队列首部的节点，然后该节点尝试获取锁，将该节点加入Lock的等待队列中，同时\n\n  ```java\n  public final void signal() {\n      if (!isHeldExclusively())\n          throw new IllegalMonitorStateException();\n      Node first = firstWaiter;//获取头节点\n      if (first != null)\n          doSignal(first);\n  }\n  ```\n\n\n- 唤醒头部首个没有取消的线程\n\n  ```java\n  private void doSignal(Node first) {\n      do {//移除头节点\n          if ( (firstWaiter = first.nextWaiter) == null)\n              lastWaiter = null;\n          first.nextWaiter = null;\n      } while (!transferForSignal(first) &&\n               (first = firstWaiter) != null);\n  }\n  //signalAll其实就是将所有等待的节点顺序加入到获取Lock的队列中\n  private void doSignalAll(Node first) {\n    lastWaiter = firstWaiter = null;\n    do {\n      Node next = first.nextWaiter;\n      first.nextWaiter = null;\n      transferForSignal(first);\n      first = next;\n    } while (first != null);\n  }\n  ```\n\n- 唤醒其实就是将该节点加入到获取Lock的等待队列中\n\n  ```java\n  final boolean transferForSignal(Node node) {\n     //节点线程已经被取消返回false，会取下个节点\n      if (!compareAndSetWaitStatus(node, Node.CONDITION, 0))\n          return false;\n    //将该节点加入 lock的等待队列\n      Node p = enq(node);\n      int ws = p.waitStatus;\n    //如果状态是取消的或者设置状态失败，则激活线程，避免状态获取错误\n      if (ws > 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL))\n          LockSupport.unpark(node.thread);\n      return true;\n  }\n  ```","slug":"多线程/java并发之Condition","published":1,"updated":"2018-09-12T03:03:21.829Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnht004vwlkv3xb6ipuw"},{"title":"java并发之CountDownLatch","date":"2017-11-21T07:11:30.000Z","_content":"\n# java并发之CountDownLatch\n\n当创建一个 new CountDownLatch(n)的时候相当执行了n次lock.lock()，将AQS的state设置为n，对资源重入了n次，后面每次执行await相当于去获取这个锁的资源，都会被阻塞，除非state减为0。\n\n调用countDown就是讲state减1，需要执行n次countDown才能释放资源。当state减为0的时候唤醒等待队列头的线程，被唤醒的线程会传播试的唤醒队列中下一个线程\n\n<!--more-->\n\n## 用法\n\n```java\npublic class CountdownLatchTest {\n  public static void main(String[] args) {\n    ExecutorService service = Executors.newCachedThreadPool();\n    final CountDownLatch cdOrder = new CountDownLatch(1);\n    final CountDownLatch cdAnswer = new CountDownLatch(3);\t\t\n    for(int i=0;i<3;i++){\n      Runnable runnable = new Runnable(){\n        public void run(){\n          try {\n            System.out.println(\"线程\" + Thread.currentThread().getName() + \n                               \"正准备接受命令\");\t\t\t\t\t\t\n            cdOrder.await();\n            System.out.println(\"线程\" + Thread.currentThread().getName() + \n                               \"已接受命令\");\t\t\t\t\t\t\t\t\n            Thread.sleep((long)(Math.random()*10000));\t\n            System.out.println(\"线程\" + Thread.currentThread().getName() + \n                               \"回应命令处理结果\");\t\t\t\t\t\t\n            cdAnswer.countDown();\t\t\t\t\t\t\n          } catch (Exception e) {\n            e.printStackTrace();\n          }\t\t\t\t\n        }\n      };\n      service.execute(runnable);\n    }\t\t\n    try {\n      Thread.sleep((long)(Math.random()*10000));\n\n      System.out.println(\"线程\" + Thread.currentThread().getName() + \n                         \"即将发布命令\");\t\t\t\t\t\t\n      cdOrder.countDown();\n      System.out.println(\"线程\" + Thread.currentThread().getName() + \n                         \"已发送命令，正在等待结果\");\t\n      cdAnswer.await();\n      System.out.println(\"线程\" + Thread.currentThread().getName() + \n                         \"已收到所有响应结果\");\t\n    } catch (Exception e) {\n      e.printStackTrace();\n    }\t\t\t\t\n    service.shutdown();\n\n  }\n}\n/*\n线程pool-1-thread-2正准备接受命令\n线程pool-1-thread-1正准备接受命令\n线程pool-1-thread-3正准备接受命令\n线程main即将发布命令\n线程main已发送命令，正在等待结果\n线程pool-1-thread-2已接受命令\n线程pool-1-thread-1已接受命令\n线程pool-1-thread-3已接受命令\n线程pool-1-thread-3回应命令处理结果\n线程pool-1-thread-1回应命令处理结果\n线程pool-1-thread-2回应命令处理结果\n线程main已收到所有响应结果\n*/\n```\n## 源码分析\n\n- 构造方法需要传递一个int类型的数，用于设置同时运行的线程的梳理\n\n  ```java\n  public CountDownLatch(int count) {\n      if (count < 0) throw new IllegalArgumentException(\"count < 0\");\n      this.sync = new Sync(count);\n  }\n  ```\n\n\n- CountDownLatch基于内部类Sync，Sync继承了AQS，是AQS的共享模式的一种实现\n\n  ```java\n  private static final class Sync extends AbstractQueuedSynchronizer {\n      private static final long serialVersionUID = 4982264981922014374L;\n      Sync(int count) {\n          setState(count);\n      }\n      int getCount() {\n          return getState();\n      }\n      protected int tryAcquireShared(int acquires) {\n        //当state不为0的时候，线程无法获取到锁，返回-1\n        //当阻塞的线程可以获取锁，则返回1，可以唤醒阻塞的线程\n          return (getState() == 0) ? 1 : -1;\n      }\n      protected boolean tryReleaseShared(int releases) {\n          // Decrement count; signal when transition to zero\n          for (;;) {\n              int c = getState();\n              if (c == 0)\n                  return false;\n              int nextc = c-1;\n              if (compareAndSetState(c, nextc))\n                  return nextc == 0;\n          }\n      }\n  }\n  ```\n\n- 获取共享锁资源\n\n  ```java\n  //获取一个资源，允许中断\n  public void await() throws InterruptedException {\n      sync.acquireSharedInterruptibly(1);//可中断模式获取1个资源\n  }\n  //设置等待超时时间\n  public boolean await(long timeout, TimeUnit unit) throws InterruptedException {\n     return sync.tryAcquireSharedNanos(1, unit.toNanos(timeout));//可中断模式获取1个资源\n  }\n  ```\n\n- 调用AQS中获取锁资源\n\n  ```java\n  public final void acquireSharedInterruptibly(int arg) throws InterruptedException {\n      if (Thread.interrupted())//中断直接抛出异常\n          throw new InterruptedException();\n      if (tryAcquireShared(arg) < 0)//如果无法获取到资源，添加到等待队列等待\n          doAcquireSharedInterruptibly(arg);\n  }\n  ```\n\n- 获取锁资源，当前线程节点加入等待队列，再次尝试获取锁资源，如果获取成功 state-1，否则当前线程进入阻塞状态，当线程激活后，会尝试激活下一个节点，传播激活，直到激活队列中所有的线程\n\n  ```java\n  private void doAcquireSharedInterruptibly(int arg)throws InterruptedException {\n      final Node node = addWaiter(Node.SHARED);//加入等待队列 并指定nextWaiter\n      boolean failed = true;\n      try {\n          for (;;) {\n              final Node p = node.predecessor();\n              if (p == head) {\n                  int r = tryAcquireShared(arg);\n                  if (r >= 0) {\n                      setHeadAndPropagate(node, r);//激活下一个节点\n                      p.next = null; // help GC\n                      failed = false;\n                      return;\n                  }\n              }\n              if (shouldParkAfterFailedAcquire(p, node) &&\n                  parkAndCheckInterrupt())\n                  throw new InterruptedException();\n          }\n      } finally {\n          if (failed)\n              cancelAcquire(node);\n      }\n  }\n  ```\n\n- 激活等待队列中的下一个节点\n\n  ```java\n  private void setHeadAndPropagate(Node node, int propagate) {\n      Node h = head; // Record old head for check below\n      setHead(node);\n      //判断锁状态\n      if (propagate > 0 || h == null || h.waitStatus < 0 ||\n          (h = head) == null || h.waitStatus < 0) {\n          Node s = node.next;\n          if (s == null || s.isShared())//如果节点是 共享模式\n              doReleaseShared();//唤醒下一个节点\n      }\n  }\n  ```\n\n- 调用countDown方法释放锁资源\n\n  ```java\n  public void countDown() {\n      sync.releaseShared(1);\n  }\n  ```\n\n- 调用继承自AQS的 releaseShared方法， 用于释放共享锁资源\n\n  ```java\n  public final boolean releaseShared(int arg) {\n      if (tryReleaseShared(arg)) {//回调CountDownLatch中的实现\n          doReleaseShared();\n          return true;\n      }\n      return false;\n  }\n  //Sync中的实现 将state-1\n  protected boolean tryReleaseShared(int releases) {\n    // Decrement count; signal when transition to zero\n    for (;;) {\n      int c = getState();\n      if (c == 0)//已经为0 不需要再次减\n        return false;\n      int nextc = c-1;\n      if (compareAndSetState(c, nextc))\n        return nextc == 0;\n    }\n  }\n  ```\n\n- 等待队列出队，激活队列头部线程\n\n  ```java\n  private void doReleaseShared() {\n     //循环激活\n      for (;;) {\n          Node h = head;\n          if (h != null && h != tail) {\n              int ws = h.waitStatus;\n              if (ws == Node.SIGNAL) {\n                  if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0))\n                      continue;            // loop to recheck cases\n                  unparkSuccessor(h);//激活队列头线程\n              }//当ws无状态的时候，设置为-3，代表当前运行的时候要激活队列中的下一个\n              else if (ws == 0 && !compareAndSetWaitStatus(h, 0, Node.PROPAGATE))\n                  continue;               \n          }\n          if (h == head)   //激活队列头的线程后 跳出循环                \n              break;\n      }\n  }\n  ```\n\n- 激活队列中的线程\n\n  ```java\n  private void unparkSuccessor(Node node) {\n     \n      int ws = node.waitStatus;\n    //当前节点的线程已经运行完毕，并完成下一个节点的激活任务，将状态设置为0\n      if (ws < 0)\n          compareAndSetWaitStatus(node, ws, 0);\n\n      Node s = node.next;\n      //只激活节点状态不是取消的 取消的状态为1\n      if (s == null || s.waitStatus > 0) {\n          s = null;\n          for (Node t = tail; t != null && t != node; t = t.prev)\n              if (t.waitStatus <= 0)\n                  s = t;\n      }\n      if (s != null)\n          LockSupport.unpark(s.thread);\n  }\n  ```\n\n\n\n","source":"_posts/多线程/java并发之CountDownLatch.md","raw":"---\ntitle: java并发之CountDownLatch\ndate: 2017-11-21 15:11:30\ntags:\n- 多线程\ncategories:\n- java基础\n\n---\n\n# java并发之CountDownLatch\n\n当创建一个 new CountDownLatch(n)的时候相当执行了n次lock.lock()，将AQS的state设置为n，对资源重入了n次，后面每次执行await相当于去获取这个锁的资源，都会被阻塞，除非state减为0。\n\n调用countDown就是讲state减1，需要执行n次countDown才能释放资源。当state减为0的时候唤醒等待队列头的线程，被唤醒的线程会传播试的唤醒队列中下一个线程\n\n<!--more-->\n\n## 用法\n\n```java\npublic class CountdownLatchTest {\n  public static void main(String[] args) {\n    ExecutorService service = Executors.newCachedThreadPool();\n    final CountDownLatch cdOrder = new CountDownLatch(1);\n    final CountDownLatch cdAnswer = new CountDownLatch(3);\t\t\n    for(int i=0;i<3;i++){\n      Runnable runnable = new Runnable(){\n        public void run(){\n          try {\n            System.out.println(\"线程\" + Thread.currentThread().getName() + \n                               \"正准备接受命令\");\t\t\t\t\t\t\n            cdOrder.await();\n            System.out.println(\"线程\" + Thread.currentThread().getName() + \n                               \"已接受命令\");\t\t\t\t\t\t\t\t\n            Thread.sleep((long)(Math.random()*10000));\t\n            System.out.println(\"线程\" + Thread.currentThread().getName() + \n                               \"回应命令处理结果\");\t\t\t\t\t\t\n            cdAnswer.countDown();\t\t\t\t\t\t\n          } catch (Exception e) {\n            e.printStackTrace();\n          }\t\t\t\t\n        }\n      };\n      service.execute(runnable);\n    }\t\t\n    try {\n      Thread.sleep((long)(Math.random()*10000));\n\n      System.out.println(\"线程\" + Thread.currentThread().getName() + \n                         \"即将发布命令\");\t\t\t\t\t\t\n      cdOrder.countDown();\n      System.out.println(\"线程\" + Thread.currentThread().getName() + \n                         \"已发送命令，正在等待结果\");\t\n      cdAnswer.await();\n      System.out.println(\"线程\" + Thread.currentThread().getName() + \n                         \"已收到所有响应结果\");\t\n    } catch (Exception e) {\n      e.printStackTrace();\n    }\t\t\t\t\n    service.shutdown();\n\n  }\n}\n/*\n线程pool-1-thread-2正准备接受命令\n线程pool-1-thread-1正准备接受命令\n线程pool-1-thread-3正准备接受命令\n线程main即将发布命令\n线程main已发送命令，正在等待结果\n线程pool-1-thread-2已接受命令\n线程pool-1-thread-1已接受命令\n线程pool-1-thread-3已接受命令\n线程pool-1-thread-3回应命令处理结果\n线程pool-1-thread-1回应命令处理结果\n线程pool-1-thread-2回应命令处理结果\n线程main已收到所有响应结果\n*/\n```\n## 源码分析\n\n- 构造方法需要传递一个int类型的数，用于设置同时运行的线程的梳理\n\n  ```java\n  public CountDownLatch(int count) {\n      if (count < 0) throw new IllegalArgumentException(\"count < 0\");\n      this.sync = new Sync(count);\n  }\n  ```\n\n\n- CountDownLatch基于内部类Sync，Sync继承了AQS，是AQS的共享模式的一种实现\n\n  ```java\n  private static final class Sync extends AbstractQueuedSynchronizer {\n      private static final long serialVersionUID = 4982264981922014374L;\n      Sync(int count) {\n          setState(count);\n      }\n      int getCount() {\n          return getState();\n      }\n      protected int tryAcquireShared(int acquires) {\n        //当state不为0的时候，线程无法获取到锁，返回-1\n        //当阻塞的线程可以获取锁，则返回1，可以唤醒阻塞的线程\n          return (getState() == 0) ? 1 : -1;\n      }\n      protected boolean tryReleaseShared(int releases) {\n          // Decrement count; signal when transition to zero\n          for (;;) {\n              int c = getState();\n              if (c == 0)\n                  return false;\n              int nextc = c-1;\n              if (compareAndSetState(c, nextc))\n                  return nextc == 0;\n          }\n      }\n  }\n  ```\n\n- 获取共享锁资源\n\n  ```java\n  //获取一个资源，允许中断\n  public void await() throws InterruptedException {\n      sync.acquireSharedInterruptibly(1);//可中断模式获取1个资源\n  }\n  //设置等待超时时间\n  public boolean await(long timeout, TimeUnit unit) throws InterruptedException {\n     return sync.tryAcquireSharedNanos(1, unit.toNanos(timeout));//可中断模式获取1个资源\n  }\n  ```\n\n- 调用AQS中获取锁资源\n\n  ```java\n  public final void acquireSharedInterruptibly(int arg) throws InterruptedException {\n      if (Thread.interrupted())//中断直接抛出异常\n          throw new InterruptedException();\n      if (tryAcquireShared(arg) < 0)//如果无法获取到资源，添加到等待队列等待\n          doAcquireSharedInterruptibly(arg);\n  }\n  ```\n\n- 获取锁资源，当前线程节点加入等待队列，再次尝试获取锁资源，如果获取成功 state-1，否则当前线程进入阻塞状态，当线程激活后，会尝试激活下一个节点，传播激活，直到激活队列中所有的线程\n\n  ```java\n  private void doAcquireSharedInterruptibly(int arg)throws InterruptedException {\n      final Node node = addWaiter(Node.SHARED);//加入等待队列 并指定nextWaiter\n      boolean failed = true;\n      try {\n          for (;;) {\n              final Node p = node.predecessor();\n              if (p == head) {\n                  int r = tryAcquireShared(arg);\n                  if (r >= 0) {\n                      setHeadAndPropagate(node, r);//激活下一个节点\n                      p.next = null; // help GC\n                      failed = false;\n                      return;\n                  }\n              }\n              if (shouldParkAfterFailedAcquire(p, node) &&\n                  parkAndCheckInterrupt())\n                  throw new InterruptedException();\n          }\n      } finally {\n          if (failed)\n              cancelAcquire(node);\n      }\n  }\n  ```\n\n- 激活等待队列中的下一个节点\n\n  ```java\n  private void setHeadAndPropagate(Node node, int propagate) {\n      Node h = head; // Record old head for check below\n      setHead(node);\n      //判断锁状态\n      if (propagate > 0 || h == null || h.waitStatus < 0 ||\n          (h = head) == null || h.waitStatus < 0) {\n          Node s = node.next;\n          if (s == null || s.isShared())//如果节点是 共享模式\n              doReleaseShared();//唤醒下一个节点\n      }\n  }\n  ```\n\n- 调用countDown方法释放锁资源\n\n  ```java\n  public void countDown() {\n      sync.releaseShared(1);\n  }\n  ```\n\n- 调用继承自AQS的 releaseShared方法， 用于释放共享锁资源\n\n  ```java\n  public final boolean releaseShared(int arg) {\n      if (tryReleaseShared(arg)) {//回调CountDownLatch中的实现\n          doReleaseShared();\n          return true;\n      }\n      return false;\n  }\n  //Sync中的实现 将state-1\n  protected boolean tryReleaseShared(int releases) {\n    // Decrement count; signal when transition to zero\n    for (;;) {\n      int c = getState();\n      if (c == 0)//已经为0 不需要再次减\n        return false;\n      int nextc = c-1;\n      if (compareAndSetState(c, nextc))\n        return nextc == 0;\n    }\n  }\n  ```\n\n- 等待队列出队，激活队列头部线程\n\n  ```java\n  private void doReleaseShared() {\n     //循环激活\n      for (;;) {\n          Node h = head;\n          if (h != null && h != tail) {\n              int ws = h.waitStatus;\n              if (ws == Node.SIGNAL) {\n                  if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0))\n                      continue;            // loop to recheck cases\n                  unparkSuccessor(h);//激活队列头线程\n              }//当ws无状态的时候，设置为-3，代表当前运行的时候要激活队列中的下一个\n              else if (ws == 0 && !compareAndSetWaitStatus(h, 0, Node.PROPAGATE))\n                  continue;               \n          }\n          if (h == head)   //激活队列头的线程后 跳出循环                \n              break;\n      }\n  }\n  ```\n\n- 激活队列中的线程\n\n  ```java\n  private void unparkSuccessor(Node node) {\n     \n      int ws = node.waitStatus;\n    //当前节点的线程已经运行完毕，并完成下一个节点的激活任务，将状态设置为0\n      if (ws < 0)\n          compareAndSetWaitStatus(node, ws, 0);\n\n      Node s = node.next;\n      //只激活节点状态不是取消的 取消的状态为1\n      if (s == null || s.waitStatus > 0) {\n          s = null;\n          for (Node t = tail; t != null && t != node; t = t.prev)\n              if (t.waitStatus <= 0)\n                  s = t;\n      }\n      if (s != null)\n          LockSupport.unpark(s.thread);\n  }\n  ```\n\n\n\n","slug":"多线程/java并发之CountDownLatch","published":1,"updated":"2018-09-12T03:03:21.829Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnhv004zwlkvan4l18hb"},{"title":"java并发之AQS原理","date":"2017-10-28T15:09:44.000Z","_content":"\n# java并发之AQS原理\n\n如果说java.util.concurrent的基础是CAS的话，那么AQS就是整个Java并发包的核心了，ReentrantLock、CountDownLatch、Semaphore等都是基于AQS实现的。\n\nAQS内部维护了一个volatile int state和一个FIFO线程等待队列，当state的值为0的时候，任意线程可以获取执行权，当存在竞争即state不为0时，将线程添加到等待队列并阻塞，等待当前占用state的线程原子减少state并激活队列头的节点线程。自定义同步器在实现时只需要实现共享资源state的获取与释放方式即可tryLock和tryRelease方法，等待队列的维护由AQS内部实现。\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-10-31/72709347.jpg)\n\nAQS内部对线程的阻塞依赖LockSupport.part(thread)，其功能是用来代替wait和notity/notifyall的，更好的地方是LockSupport对park方法和unpark方法的调用没有先后的限制，而notify/notifyall必须在wait调用之后调用。\n\n<!--more-->\n\n## AQS模式\n\nAQS内部提供了两种实现，即独占模式和共享模式，在独占模式下只运行同时一个线程访问代码块如ReentrantLock，共享模式下允许指定多个线程同时访问代码块，如Semaphore和CountDownLatch\n\n- 独占模式：实现类覆写以下方法\n  - tryAcquire(int)：尝试获取资源，成功则返回true，失败则返回false。\n  - tryRelease(int)：尝试释放资源，成功则返回true，失败则返回false。\n- 共享模式：实现类覆写以下方法\n  - tryAcquireShared(int)：尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。\n  - tryReleaseShared(int)：尝试释放资源，如果释放后允许唤醒后续等待结点返回true，否则返回false。\n\n## 源码分析\n\n以ReentrantLock为例，state初始化为0，表示未锁定状态。A线程lock()时，会调用tryAcquire()独占该锁并将state+1。此后，其他线程再tryAcquire()时就会失败，直到A线程unlock()到state=0（即释放锁）为止，其它线程才有机会获取该锁。当然，释放锁之前，A线程自己是可以重复获取此锁的（state会累加），这就是可重入的概念。但要注意，获取多少次就要释放多么次，这样才能保证state是能回到零态的\n\n### 独占锁加锁流程\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-11-21/97036145.jpg)\n\n- 首先AQS内部维护了一个节点类型，用于存储被阻塞的线程,内部维护了被阻塞线程的状态\n\n  ​\tCANCELLED，值为1，表示当前的线程被取消。\n\n  　　 SIGNAL，值为-1，表示当前节点的后继节点包含的线程需要运行，需要进行unpark操作。\n\n  　　 CONDITION，值为-2，表示当前节点在等待condition，也就是在condition queue中。\n\n  　　 PROPAGATE，值为-3，表示当前场景下后续的acquireShared能够得以执行。\n\n  　　值为0，表示当前节点在sync queue中，等待着获取锁。\n\n  ```java\n  tatic final class Node {\n      /** Marker to indicate a node is waiting in shared mode */\n      static final Node SHARED = new Node();\n      /** Marker to indicate a node is waiting in exclusive mode */\n      static final Node EXCLUSIVE = null;\n      static final int CANCELLED =  1;\n      static final int SIGNAL    = -1;\n      static final int CONDITION = -2;\n      /** waitStatus value to indicate the next acquireShared should unconditionally propagate*/\n      static final int PROPAGATE = -3;\n      volatile int waitStatus;//当前被阻塞的线程的状态\n      volatile Node prev;//指向上一个节点\n      volatile Node next;//指向下一个节点\n      volatile Thread thread;//被阻塞的线程\n    \t//等待condition的下一个线程\n      Node nextWaiter;\n      final boolean isShared() {\n          return nextWaiter == SHARED;\n      }\n      final Node predecessor() throws NullPointerException {\n          Node p = prev;\n          if (p == null)\n              throw new NullPointerException();\n          else\n              return p;\n      }\n  }\n  ```\n\n- ReetrantLock内部的Sync类继承AbstractQueuedSynchronizer，调用lock方法的时候实际上是原子性去设置state为1，成功则竞争成功，失败就加入等待队列\n\n  ```java\n   final void lock() {\n     if (compareAndSetState(0, 1))//原子性设置state为1，如果成功，设置当前获取执行权的为当前线程\n       setExclusiveOwnerThread(Thread.currentThread());\n     else\n       acquire(1);//调用AQS的acquire方法\n   }\n  ```\n  ![image](http://omdq6di7v.bkt.clouddn.com/17-11-17/82736707.jpg)\n\n- AQS中的acquire方法，调用钩子方法tryAcquire，tryAcquire由子类覆盖实现，如果获取资源成功，则当前线程获取执行权，如果失败，调用acquireQueued将当前线程加入等待队列，设置当前为独占锁模式，并阻塞当前线程\n\n  ```java\n  public final void acquire(int arg) {\n    //子类需要覆写tryAcquire方法\n  \tif (!tryAcquire(arg) &&acquireQueued(addWaiter(Node.EXCLUSIVE), arg))\n  \t\tselfInterrupt();//阻塞线程无法响应中断，需要获得执行权后响应在阻塞状态下的中断信号\n  }\n  ```\n\n- ReetrantLock中覆写了tryAcquire原子设置state为1，当前线程获取执行权，之后的其他访问该同步块的线程将被阻塞直到当前线程释放；如果获取资源失败，首先判断当前拥有获取资源的线程是是否为当前线程，如果是，当前线程是重入锁，只需要将state+1即可，执行线程任务；否则获取资源失败，返回false，加入等待队列\n\n  ```java\n  protected final boolean tryAcquire(int acquires) {\n    return nonfairTryAcquire(acquires);//实际调用nonfairTryAcquire\n  }\n  final boolean nonfairTryAcquire(int acquires) {\n      final Thread current = Thread.currentThread();\n      int c = getState();\n      if (c == 0) {//再次尝试获取资源\n          if (compareAndSetState(0, acquires)) {\n              setExclusiveOwnerThread(current);//如果获取资源成功，设置当前占用执行权的为当前线程\n              return true;//\n          }\n      }\n    //如果是当前线程，重入锁实现\n      else if (current == getExclusiveOwnerThread()) {\n          int nextc = c + acquires;\n          if (nextc < 0) // overflow\n              throw new Error(\"Maximum lock count exceeded\");\n          setState(nextc);\n          return true;\n      }\n      return false;\n  }\n  ```\n\n- AQS中封装的竞争失败线程的入队功能，在enq方法中，使用死循环+CAS模式保证了多线程并发模式下的成功入队，每次能够保证只有一个成功，如果失败下次重试，如果是N个线程，那么每个线程最多loop N次，最终都能够成功。**在这里最终无法保证线程的公平入队，出队能够保证FIFO。**\n\n  ```Java\n  private Node addWaiter(Node mode) {\n      Node node = new Node(Thread.currentThread(), mode);\n      // Try the fast path of enq; backup to full enq on failure\n      Node pred = tail;\n    \t//节点已经初始化\n      if (pred != null) {\n        //尝试将节点加到队尾，在无竞争情况下保证会成功返回，如果失败再调用enq方法，循环尝试\n          node.prev = pred;\n          if (compareAndSetTail(pred, node)) {\n              pred.next = node;\n              return node;\n          }\n      }\n      enq(node);//尾结点为空(即还没有被初始化过)，或者是compareAndSetTail操作失败，则入队列\n      return node;\n  }\n  //将节点添加到队列的尾部\n  private Node enq(final Node node) {\n    for (;;) {//死循环进行CAS操作，直到成功返回\n      Node t = tail;\n      if (t == null) { // 当队列为空时init空节点\n        if (compareAndSetHead(new Node()))//头节点为空\n          tail = head;\n      } else {\n        node.prev = t;\n        //尝试将节点加到队尾，如果失败在循环重试，多线程并发，无法保证线程的入队顺序\n        if (compareAndSetTail(t, node)) {\n          t.next = node;\n          //返回队尾节点\n          return t;\n        }\n      }\n    }\n  }\n  //\n  private final boolean compareAndSetTail(Node expect, Node update) {\n    return unsafe.compareAndSwapObject(this, tailOffset, expect, update);\n  }\n  ```\n\n- 线程已经加入等待队列，并返回所处队列的节点node，**当前线程进入阻塞状态，直到其他线程释放资源后唤醒自己，然后在获取CPU执行权**，在死循环中CAS获取资源直到成功移除等待队列中获取资源的节点，线程获取执行权并返回中断标识，\n\n  ```java\n  final boolean acquireQueued(final Node node, int arg) {\n      boolean failed = true;\n      try {\n          boolean interrupted = false;//中断标识\n        //自旋  当线程从阻塞状态被唤醒后再次循环获取资源，如果是interrupt唤醒，循环再次获取锁\n          for (;;) {\n              final Node p = node.predecessor();//获取前一个节点\n            //如果前一个节点已经是head(空的节点)，当前节点已经是排队中的第一个，则尝试去获取资源\n              if (p == head && tryAcquire(arg)) {\n                  setHead(node);//加锁成功后将从队列中移除 当前节点，保证head节点为空的\n                  p.next = null; // help GC\n                  failed = false;\n                  return interrupted;//获得资源，当前线程获取执行权\n              }\n            //在阻塞线程之前判断线程状态是否适合阻塞\n              if (shouldParkAfterFailedAcquire(p, node) && parkAndCheckInterrupt())\n                  interrupted = true;\n          }\n      } finally {\n          if (failed)\n              cancelAcquire(node);\n      }\n  }\n  ```\n  在线程阻塞之前调用shouldParkAfterFailedAcquire方法检查线程状态是否应该阻塞，避免队列中其他线程已经都被取消，当前线程无效等待\n\n- 只有当前节点前面的节点状态是SIGNAL的，这样当前一个节点释放资源后才能通知唤醒后一个等待的节点。所以当前线程在被阻塞前，需要保证前一个节点的状态为SIGNAL，如果已是取消状态，则从队列中移除，\n\n  ```java\n  private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) {\n      int ws = pred.waitStatus;//获取前一个节点的状态\n      if (ws == Node.SIGNAL)//如果前一个节点状态已经为SIGNAL，则当前线程可以被阻塞了\n          return true;\n      if (ws > 0) {\n          do {//如果前一个节点已经被取消，从等待队列中移除已被取消的节点  循环操作，跳过被取消的线程\n              node.prev = pred = pred.prev;\n          } while (pred.waitStatus > 0);\n          pred.next = node;\n      } else {\n        //为PROPAGATE -3 或者是0 表示无状态,(为CONDITION -2时，表示此节点在condition queue中)\n        //比较并设置设置其状态为SIGNAL，通知他在释放资源后激活自己，如果失败 继续在acquireQueued循环\n          compareAndSetWaitStatus(pred, ws, Node.SIGNAL);\n      }\n      return false;\n  }\n  ```\n\n- 调用LockSupport.park(thread)阻塞线程，直到获得执行权的线程调用unpark(thread)激活当前线程，再次尝试去获取资源，等待线程被激活的顺序是遵从队列的FIFO原则的，无法达到公平锁是因为入队的顺序无法保证\n\n  当线程被激活后，返回中断信号，用于响应在阻塞状态下无法响应的中断信号，如果阻塞期间被中断过则会调用selfInterrupt()方法，执行当前线程interrupt()\n\n  ```java\n  private final boolean parkAndCheckInterrupt() {\n      LockSupport.park(this);//当前线程被阻塞在该位置\n      return Thread.interrupted();//当前线程是否已被中断，并清除中断标记位，防止再次park时失效\n  }\n  static void selfInterrupt() {\n    Thread.currentThread().interrupt();//当前线程发出中断信号\n  }\n  ```\n\n- 总结 \n\n  acquireQueued()方法总结\n\n  1. 结点进入队尾后，检查状态，找到安全休息点；\n  2. 调用park()进入waiting状态，等待unpark()或interrupt()唤醒自己；\n  3. 被唤醒后，循环再次获取资源。如果拿到，head出队，将head指向当前结点，并返回从入队到拿到号的整个过程中是否被中断过的信号；如果没拿到，继续流程1。\n\n  acquire()方法总结\n\n  1. 调用自定义同步器的tryAcquire()尝试直接去获取资源，如果成功则直接返回；\n\n  2. 没成功，则addWaiter()将该线程加入等待队列的尾部，并标记为独占模式；\n\n  3. acquireQueued()使线程在等待队列中休息，有机会时（轮到自己，会被unpark()）会去尝试获取资源。获取到资源后才返回。如果在整个等待过程中被中断过，则返回true，否则返回false。\n\n  4. 如果线程在等待过程中被中断过，它是不响应的。只是获取资源后才再进行自我中断selfInterrupt()，将中断补上。\n\n     ![image](http://omdq6di7v.bkt.clouddn.com/17-10-31/24929912.jpg)\n\n### 独占锁释放锁流程\n\n独占锁的释放主要是将共享资源从n减到0，然后激活等待队列中的头部节点，在激活的时候只激活一个，并且是等待队列的头部，避免了notify的随机激活(不可控制)和notifyAll激活所有(CPU竞争)，\n\n- ReetrantLock中的unlock方法实际调用的Sync类继承的AQS的realse方法，每次unlock是对state进行原子减1\n\n  ```java\n  public void unlock() {\n    sync.release(1);//调用AQS的release方法操作state\n  }\n  ```\n\n- AQS中的realse调用tryRealse操作state，tryRealse用于减state的值，是AQS中定义的钩子方法，由子类覆盖实现，当state减为0的时候尝试唤醒等待队列中头部节点\n\n  ```java\n  public final boolean release(int arg) {\n      if (tryRelease(arg)) {//先将status减去\n          Node h = head;\n        //当state减为0的时候尝试唤醒等待队列中头部节点\n          if (h != null && h.waitStatus != 0)//\n              unparkSuccessor(h);\n          return true;\n      }\n      return false;\n  }\n  ```\n\n- 在Sync中实现了tryRelease方法,在realse的时候已经保证了当前只有一个线程，不会有并发问题，所以只需要将state-1就行，重入多少次则需要release多少次，当state减为0的时候表示不再占用资源，将独占资源的线程设置为null，并且调用unpark唤醒等待队列中的第一个阻塞线程。\n\n  ```Java\n  protected final boolean tryRelease(int releases) {\n      int c = getState() - releases;\n      if (Thread.currentThread() != getExclusiveOwnerThread())\n          throw new IllegalMonitorStateException();\n      boolean free = false;\n      if (c == 0) {\n          free = true;\n          setExclusiveOwnerThread(null);\n      }\n      setState(c);\n      return free;\n  }\n  ```\n\n- **用unpark()唤醒等待队列中最前边的那个未放弃线程**，即状态为SIGNAL 的节点。\n\n  ```java\n  private void unparkSuccessor(Node node) {\n      /*\n       * If status is negative (i.e., possibly needing signal) try\n       * to clear in anticipation of signalling.  It is OK if this\n       * fails or if status is changed by waiting thread.\n       */\n      int ws = node.waitStatus;\n      if (ws < 0)//状态值小于0，为SIGNAL -1 或 CONDITION -2 或 PROPAGATE -3\n          compareAndSetWaitStatus(node, ws, 0);\n\n      Node s = node.next;\n      if (s == null || s.waitStatus > 0) {//如果下一个节点为空或者取消，则找队列中下一个不为空并未取消的节点\n          s = null;//从后往前找到最前面未被取消的节点\n          for (Node t = tail; t != null && t != node; t = t.prev)\n              if (t.waitStatus <= 0)\n                  s = t;\n      }\n      if (s != null)\n          LockSupport.unpark(s.thread);//唤醒\n  }\n  ```\n\n### 共享锁加锁流程\n\n以CountDownLatch以例，任务分为n个子线程去执行，state也初始化为n（注意N要与线程个数一致）。这N个子线程是并行执行的，每个子线程执行完后countDown()一次，state会CAS减1。等到所有子线程都执行完后(即state=0)，会unpark()主调用线程，然后主调用线程就会从await()函数返回，继续后余动作。\n\n- 共享模式下调用的是tryAcquireShared\n\n- 内部调用doAcquireShared\n\n- 在当前节点被唤醒的时候，需要传播性的唤醒队列中的下一个节点\n\n  ```java\n  private void doAcquireShared(int arg) {\n  final Node node = addWaiter(Node.SHARED); //指定node节点模式，比独享锁多了一个nextWaiter\n  boolean failed = true;\n  try {\n      boolean interrupted = false;\n      for (;;) {\n          final Node p = node.predecessor();//获取前一个节点\n          if (p == head) {//如果前一个节点是head，head是当前获取资源在运行的线程，自己是最可能拿到资源\n              int r = tryAcquireShared(arg);//尝试获取资源\n              if (r >= 0) {//如果成功\n                  setHeadAndPropagate(node, r);//将head指向自己，如果state不为0 再次唤醒队列中下一个\n                  p.next = null; // help GC\n                  if (interrupted)//如果等待过程有收到中断，补上中断标记\n                      selfInterrupt();\n                  failed = false;\n                  return;\n              }\n          }\n        //如果获取不到资源，寻找安全点，阻塞，等待获取资源的线程调用unpark 唤醒\n          if (shouldParkAfterFailedAcquire(p, node) &&\n              parkAndCheckInterrupt())\n              interrupted = true;\n      }\n  } finally {\n      if (failed)\n          cancelAcquire(node);\n  }\n  }\n  ```\n\n\n- 自己被唤醒后，判断资源是否有空余，如果有则唤醒队列中自己下一个节点线程\n\n  ```java\n  private void setHeadAndPropagate(Node node, int propagate) {\n      Node h = head; // Record old head for check below\n      setHead(node);//head指向当前节点\n      //如果还有剩余量，继续唤醒下一个邻居线程\n      if (propagate > 0 || h == null || h.waitStatus < 0 ||\n          (h = head) == null || h.waitStatus < 0) {\n          Node s = node.next;\n          if (s == null || s.isShared())\n              doReleaseShared();\n      }\n  }\n  ```\n\n### 共享锁释放锁流程\n\n- 释放锁就是由子类实现去改变state数量，然后在AQS中去唤醒等待队列中的头部节点\n\n  ```java\n  public final boolean releaseShared(int arg) {\n      if (tryReleaseShared(arg)) {//操作state并判断是否需要激活等待队列头部节点\n          doReleaseShared();\n          return true;\n      }\n      return false;\n  }\n  ```\n\n- fff\n\n  ```java\n  private void doReleaseShared() {\n      \n      for (;;) {\n          Node h = head;\n          if (h != null && h != tail) {//等待队列存在等待线程\n              int ws = h.waitStatus;\n              if (ws == Node.SIGNAL) {//需要保证将清除节点状态，失败则for循环中重新校验\n                  if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0))\n                      continue;            // loop to recheck cases\n                  unparkSuccessor(h);//激活下一个节点\n              }\n              else if (ws == 0 &&\n                       !compareAndSetWaitStatus(h, 0, Node.PROPAGATE))//设置为-3，在下次\n                  continue;                // loop on failed CAS\n          }\n          if (h == head) //如果\n              break;\n      }\n  }\n  ```\n\n## 其他方法\n\n- 可中断锁\n\n  ```java\n  private void doAcquireInterruptibly(int arg)\n      throws InterruptedException {\n      final Node node = addWaiter(Node.EXCLUSIVE);//入等待队列\n      boolean failed = true;\n      try {\n          for (;;) {\n              final Node p = node.predecessor();\n              if (p == head && tryAcquire(arg)) {\n                  setHead(node);\n                  p.next = null; // help GC\n                  failed = false;\n                  return;\n              }\n              if (shouldParkAfterFailedAcquire(p, node) &&\n                  parkAndCheckInterrupt())\n                //如果是中断唤醒线程 则抛出异常\n                  throw new InterruptedException();\n          }\n      } finally {\n          if (failed) //如果中断 设置节点状态为取消 ，并unpark队列中的线程\n              cancelAcquire(node);\n      }\n  }\n  ```\n\n- 超时获取锁\n\n  ```java\n  private boolean doAcquireNanos(int arg, long nanosTimeout)\n          throws InterruptedException {\n      if (nanosTimeout <= 0L)\n          return false;\n      final long deadline = System.nanoTime() + nanosTimeout;\n      final Node node = addWaiter(Node.EXCLUSIVE);//入等待队列\n      boolean failed = true;\n      try {\n          for (;;) {\n              final Node p = node.predecessor();\n              if (p == head && tryAcquire(arg)) {\n                  setHead(node);\n                  p.next = null; // help GC\n                  failed = false;\n                  return true;\n              }\n              nanosTimeout = deadline - System.nanoTime();\n              if (nanosTimeout <= 0L)//等待够时间后直接返回false\n                  return false;\n            //自旋够设置时间后 阻塞一段时间\n              if (shouldParkAfterFailedAcquire(p, node) &&\n                  nanosTimeout > spinForTimeoutThreshold)\n                  LockSupport.parkNanos(this, nanosTimeout);\n              if (Thread.interrupted())\n                  throw new InterruptedException();\n          }\n      } finally {\n          if (failed)\n              cancelAcquire(node);\n      }\n  }\n  ```\n\n- 设置为取消状态\n\n  ```java\n  private void cancelAcquire(Node node) {\n      // Ignore if node doesn't exist\n      if (node == null)\n          return;\n      node.thread = null;\n      // Skip cancelled predecessors\n      Node pred = node.prev;\n      while (pred.waitStatus > 0)\n          node.prev = pred = pred.prev;\n\n      // predNext is the apparent node to unsplice. CASes below will\n      // fail if not, in which case, we lost race vs another cancel\n      // or signal, so no further action is necessary.\n      Node predNext = pred.next;\n    //设置为取消状态\n      node.waitStatus = Node.CANCELLED;\n      //如果当前节点为队尾，直接移除\n      if (node == tail && compareAndSetTail(node, pred)) {\n          compareAndSetNext(pred, predNext, null);\n      } else {\n          // If successor needs signal, try to set pred's next-link\n          // so it will get one. Otherwise wake it up to propagate.\n          int ws;\n          if (pred != head &&\n              ((ws = pred.waitStatus) == Node.SIGNAL ||\n               (ws <= 0 && compareAndSetWaitStatus(pred, ws, Node.SIGNAL))) &&\n              pred.thread != null) {\n              Node next = node.next;\n              if (next != null && next.waitStatus <= 0)\n                  compareAndSetNext(pred, predNext, next);\n          } else {\n              unparkSuccessor(node);\n          }\n          node.next = node; // help GC\n      }\n  }\n  ```","source":"_posts/多线程/java并发之AQS原理.md","raw":"---\ntitle: java并发之AQS原理\ndate: 2017-10-28 23:09:44\ntags:\n- 多线程\ncategories:\n- java基础\n---\n\n# java并发之AQS原理\n\n如果说java.util.concurrent的基础是CAS的话，那么AQS就是整个Java并发包的核心了，ReentrantLock、CountDownLatch、Semaphore等都是基于AQS实现的。\n\nAQS内部维护了一个volatile int state和一个FIFO线程等待队列，当state的值为0的时候，任意线程可以获取执行权，当存在竞争即state不为0时，将线程添加到等待队列并阻塞，等待当前占用state的线程原子减少state并激活队列头的节点线程。自定义同步器在实现时只需要实现共享资源state的获取与释放方式即可tryLock和tryRelease方法，等待队列的维护由AQS内部实现。\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-10-31/72709347.jpg)\n\nAQS内部对线程的阻塞依赖LockSupport.part(thread)，其功能是用来代替wait和notity/notifyall的，更好的地方是LockSupport对park方法和unpark方法的调用没有先后的限制，而notify/notifyall必须在wait调用之后调用。\n\n<!--more-->\n\n## AQS模式\n\nAQS内部提供了两种实现，即独占模式和共享模式，在独占模式下只运行同时一个线程访问代码块如ReentrantLock，共享模式下允许指定多个线程同时访问代码块，如Semaphore和CountDownLatch\n\n- 独占模式：实现类覆写以下方法\n  - tryAcquire(int)：尝试获取资源，成功则返回true，失败则返回false。\n  - tryRelease(int)：尝试释放资源，成功则返回true，失败则返回false。\n- 共享模式：实现类覆写以下方法\n  - tryAcquireShared(int)：尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。\n  - tryReleaseShared(int)：尝试释放资源，如果释放后允许唤醒后续等待结点返回true，否则返回false。\n\n## 源码分析\n\n以ReentrantLock为例，state初始化为0，表示未锁定状态。A线程lock()时，会调用tryAcquire()独占该锁并将state+1。此后，其他线程再tryAcquire()时就会失败，直到A线程unlock()到state=0（即释放锁）为止，其它线程才有机会获取该锁。当然，释放锁之前，A线程自己是可以重复获取此锁的（state会累加），这就是可重入的概念。但要注意，获取多少次就要释放多么次，这样才能保证state是能回到零态的\n\n### 独占锁加锁流程\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-11-21/97036145.jpg)\n\n- 首先AQS内部维护了一个节点类型，用于存储被阻塞的线程,内部维护了被阻塞线程的状态\n\n  ​\tCANCELLED，值为1，表示当前的线程被取消。\n\n  　　 SIGNAL，值为-1，表示当前节点的后继节点包含的线程需要运行，需要进行unpark操作。\n\n  　　 CONDITION，值为-2，表示当前节点在等待condition，也就是在condition queue中。\n\n  　　 PROPAGATE，值为-3，表示当前场景下后续的acquireShared能够得以执行。\n\n  　　值为0，表示当前节点在sync queue中，等待着获取锁。\n\n  ```java\n  tatic final class Node {\n      /** Marker to indicate a node is waiting in shared mode */\n      static final Node SHARED = new Node();\n      /** Marker to indicate a node is waiting in exclusive mode */\n      static final Node EXCLUSIVE = null;\n      static final int CANCELLED =  1;\n      static final int SIGNAL    = -1;\n      static final int CONDITION = -2;\n      /** waitStatus value to indicate the next acquireShared should unconditionally propagate*/\n      static final int PROPAGATE = -3;\n      volatile int waitStatus;//当前被阻塞的线程的状态\n      volatile Node prev;//指向上一个节点\n      volatile Node next;//指向下一个节点\n      volatile Thread thread;//被阻塞的线程\n    \t//等待condition的下一个线程\n      Node nextWaiter;\n      final boolean isShared() {\n          return nextWaiter == SHARED;\n      }\n      final Node predecessor() throws NullPointerException {\n          Node p = prev;\n          if (p == null)\n              throw new NullPointerException();\n          else\n              return p;\n      }\n  }\n  ```\n\n- ReetrantLock内部的Sync类继承AbstractQueuedSynchronizer，调用lock方法的时候实际上是原子性去设置state为1，成功则竞争成功，失败就加入等待队列\n\n  ```java\n   final void lock() {\n     if (compareAndSetState(0, 1))//原子性设置state为1，如果成功，设置当前获取执行权的为当前线程\n       setExclusiveOwnerThread(Thread.currentThread());\n     else\n       acquire(1);//调用AQS的acquire方法\n   }\n  ```\n  ![image](http://omdq6di7v.bkt.clouddn.com/17-11-17/82736707.jpg)\n\n- AQS中的acquire方法，调用钩子方法tryAcquire，tryAcquire由子类覆盖实现，如果获取资源成功，则当前线程获取执行权，如果失败，调用acquireQueued将当前线程加入等待队列，设置当前为独占锁模式，并阻塞当前线程\n\n  ```java\n  public final void acquire(int arg) {\n    //子类需要覆写tryAcquire方法\n  \tif (!tryAcquire(arg) &&acquireQueued(addWaiter(Node.EXCLUSIVE), arg))\n  \t\tselfInterrupt();//阻塞线程无法响应中断，需要获得执行权后响应在阻塞状态下的中断信号\n  }\n  ```\n\n- ReetrantLock中覆写了tryAcquire原子设置state为1，当前线程获取执行权，之后的其他访问该同步块的线程将被阻塞直到当前线程释放；如果获取资源失败，首先判断当前拥有获取资源的线程是是否为当前线程，如果是，当前线程是重入锁，只需要将state+1即可，执行线程任务；否则获取资源失败，返回false，加入等待队列\n\n  ```java\n  protected final boolean tryAcquire(int acquires) {\n    return nonfairTryAcquire(acquires);//实际调用nonfairTryAcquire\n  }\n  final boolean nonfairTryAcquire(int acquires) {\n      final Thread current = Thread.currentThread();\n      int c = getState();\n      if (c == 0) {//再次尝试获取资源\n          if (compareAndSetState(0, acquires)) {\n              setExclusiveOwnerThread(current);//如果获取资源成功，设置当前占用执行权的为当前线程\n              return true;//\n          }\n      }\n    //如果是当前线程，重入锁实现\n      else if (current == getExclusiveOwnerThread()) {\n          int nextc = c + acquires;\n          if (nextc < 0) // overflow\n              throw new Error(\"Maximum lock count exceeded\");\n          setState(nextc);\n          return true;\n      }\n      return false;\n  }\n  ```\n\n- AQS中封装的竞争失败线程的入队功能，在enq方法中，使用死循环+CAS模式保证了多线程并发模式下的成功入队，每次能够保证只有一个成功，如果失败下次重试，如果是N个线程，那么每个线程最多loop N次，最终都能够成功。**在这里最终无法保证线程的公平入队，出队能够保证FIFO。**\n\n  ```Java\n  private Node addWaiter(Node mode) {\n      Node node = new Node(Thread.currentThread(), mode);\n      // Try the fast path of enq; backup to full enq on failure\n      Node pred = tail;\n    \t//节点已经初始化\n      if (pred != null) {\n        //尝试将节点加到队尾，在无竞争情况下保证会成功返回，如果失败再调用enq方法，循环尝试\n          node.prev = pred;\n          if (compareAndSetTail(pred, node)) {\n              pred.next = node;\n              return node;\n          }\n      }\n      enq(node);//尾结点为空(即还没有被初始化过)，或者是compareAndSetTail操作失败，则入队列\n      return node;\n  }\n  //将节点添加到队列的尾部\n  private Node enq(final Node node) {\n    for (;;) {//死循环进行CAS操作，直到成功返回\n      Node t = tail;\n      if (t == null) { // 当队列为空时init空节点\n        if (compareAndSetHead(new Node()))//头节点为空\n          tail = head;\n      } else {\n        node.prev = t;\n        //尝试将节点加到队尾，如果失败在循环重试，多线程并发，无法保证线程的入队顺序\n        if (compareAndSetTail(t, node)) {\n          t.next = node;\n          //返回队尾节点\n          return t;\n        }\n      }\n    }\n  }\n  //\n  private final boolean compareAndSetTail(Node expect, Node update) {\n    return unsafe.compareAndSwapObject(this, tailOffset, expect, update);\n  }\n  ```\n\n- 线程已经加入等待队列，并返回所处队列的节点node，**当前线程进入阻塞状态，直到其他线程释放资源后唤醒自己，然后在获取CPU执行权**，在死循环中CAS获取资源直到成功移除等待队列中获取资源的节点，线程获取执行权并返回中断标识，\n\n  ```java\n  final boolean acquireQueued(final Node node, int arg) {\n      boolean failed = true;\n      try {\n          boolean interrupted = false;//中断标识\n        //自旋  当线程从阻塞状态被唤醒后再次循环获取资源，如果是interrupt唤醒，循环再次获取锁\n          for (;;) {\n              final Node p = node.predecessor();//获取前一个节点\n            //如果前一个节点已经是head(空的节点)，当前节点已经是排队中的第一个，则尝试去获取资源\n              if (p == head && tryAcquire(arg)) {\n                  setHead(node);//加锁成功后将从队列中移除 当前节点，保证head节点为空的\n                  p.next = null; // help GC\n                  failed = false;\n                  return interrupted;//获得资源，当前线程获取执行权\n              }\n            //在阻塞线程之前判断线程状态是否适合阻塞\n              if (shouldParkAfterFailedAcquire(p, node) && parkAndCheckInterrupt())\n                  interrupted = true;\n          }\n      } finally {\n          if (failed)\n              cancelAcquire(node);\n      }\n  }\n  ```\n  在线程阻塞之前调用shouldParkAfterFailedAcquire方法检查线程状态是否应该阻塞，避免队列中其他线程已经都被取消，当前线程无效等待\n\n- 只有当前节点前面的节点状态是SIGNAL的，这样当前一个节点释放资源后才能通知唤醒后一个等待的节点。所以当前线程在被阻塞前，需要保证前一个节点的状态为SIGNAL，如果已是取消状态，则从队列中移除，\n\n  ```java\n  private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) {\n      int ws = pred.waitStatus;//获取前一个节点的状态\n      if (ws == Node.SIGNAL)//如果前一个节点状态已经为SIGNAL，则当前线程可以被阻塞了\n          return true;\n      if (ws > 0) {\n          do {//如果前一个节点已经被取消，从等待队列中移除已被取消的节点  循环操作，跳过被取消的线程\n              node.prev = pred = pred.prev;\n          } while (pred.waitStatus > 0);\n          pred.next = node;\n      } else {\n        //为PROPAGATE -3 或者是0 表示无状态,(为CONDITION -2时，表示此节点在condition queue中)\n        //比较并设置设置其状态为SIGNAL，通知他在释放资源后激活自己，如果失败 继续在acquireQueued循环\n          compareAndSetWaitStatus(pred, ws, Node.SIGNAL);\n      }\n      return false;\n  }\n  ```\n\n- 调用LockSupport.park(thread)阻塞线程，直到获得执行权的线程调用unpark(thread)激活当前线程，再次尝试去获取资源，等待线程被激活的顺序是遵从队列的FIFO原则的，无法达到公平锁是因为入队的顺序无法保证\n\n  当线程被激活后，返回中断信号，用于响应在阻塞状态下无法响应的中断信号，如果阻塞期间被中断过则会调用selfInterrupt()方法，执行当前线程interrupt()\n\n  ```java\n  private final boolean parkAndCheckInterrupt() {\n      LockSupport.park(this);//当前线程被阻塞在该位置\n      return Thread.interrupted();//当前线程是否已被中断，并清除中断标记位，防止再次park时失效\n  }\n  static void selfInterrupt() {\n    Thread.currentThread().interrupt();//当前线程发出中断信号\n  }\n  ```\n\n- 总结 \n\n  acquireQueued()方法总结\n\n  1. 结点进入队尾后，检查状态，找到安全休息点；\n  2. 调用park()进入waiting状态，等待unpark()或interrupt()唤醒自己；\n  3. 被唤醒后，循环再次获取资源。如果拿到，head出队，将head指向当前结点，并返回从入队到拿到号的整个过程中是否被中断过的信号；如果没拿到，继续流程1。\n\n  acquire()方法总结\n\n  1. 调用自定义同步器的tryAcquire()尝试直接去获取资源，如果成功则直接返回；\n\n  2. 没成功，则addWaiter()将该线程加入等待队列的尾部，并标记为独占模式；\n\n  3. acquireQueued()使线程在等待队列中休息，有机会时（轮到自己，会被unpark()）会去尝试获取资源。获取到资源后才返回。如果在整个等待过程中被中断过，则返回true，否则返回false。\n\n  4. 如果线程在等待过程中被中断过，它是不响应的。只是获取资源后才再进行自我中断selfInterrupt()，将中断补上。\n\n     ![image](http://omdq6di7v.bkt.clouddn.com/17-10-31/24929912.jpg)\n\n### 独占锁释放锁流程\n\n独占锁的释放主要是将共享资源从n减到0，然后激活等待队列中的头部节点，在激活的时候只激活一个，并且是等待队列的头部，避免了notify的随机激活(不可控制)和notifyAll激活所有(CPU竞争)，\n\n- ReetrantLock中的unlock方法实际调用的Sync类继承的AQS的realse方法，每次unlock是对state进行原子减1\n\n  ```java\n  public void unlock() {\n    sync.release(1);//调用AQS的release方法操作state\n  }\n  ```\n\n- AQS中的realse调用tryRealse操作state，tryRealse用于减state的值，是AQS中定义的钩子方法，由子类覆盖实现，当state减为0的时候尝试唤醒等待队列中头部节点\n\n  ```java\n  public final boolean release(int arg) {\n      if (tryRelease(arg)) {//先将status减去\n          Node h = head;\n        //当state减为0的时候尝试唤醒等待队列中头部节点\n          if (h != null && h.waitStatus != 0)//\n              unparkSuccessor(h);\n          return true;\n      }\n      return false;\n  }\n  ```\n\n- 在Sync中实现了tryRelease方法,在realse的时候已经保证了当前只有一个线程，不会有并发问题，所以只需要将state-1就行，重入多少次则需要release多少次，当state减为0的时候表示不再占用资源，将独占资源的线程设置为null，并且调用unpark唤醒等待队列中的第一个阻塞线程。\n\n  ```Java\n  protected final boolean tryRelease(int releases) {\n      int c = getState() - releases;\n      if (Thread.currentThread() != getExclusiveOwnerThread())\n          throw new IllegalMonitorStateException();\n      boolean free = false;\n      if (c == 0) {\n          free = true;\n          setExclusiveOwnerThread(null);\n      }\n      setState(c);\n      return free;\n  }\n  ```\n\n- **用unpark()唤醒等待队列中最前边的那个未放弃线程**，即状态为SIGNAL 的节点。\n\n  ```java\n  private void unparkSuccessor(Node node) {\n      /*\n       * If status is negative (i.e., possibly needing signal) try\n       * to clear in anticipation of signalling.  It is OK if this\n       * fails or if status is changed by waiting thread.\n       */\n      int ws = node.waitStatus;\n      if (ws < 0)//状态值小于0，为SIGNAL -1 或 CONDITION -2 或 PROPAGATE -3\n          compareAndSetWaitStatus(node, ws, 0);\n\n      Node s = node.next;\n      if (s == null || s.waitStatus > 0) {//如果下一个节点为空或者取消，则找队列中下一个不为空并未取消的节点\n          s = null;//从后往前找到最前面未被取消的节点\n          for (Node t = tail; t != null && t != node; t = t.prev)\n              if (t.waitStatus <= 0)\n                  s = t;\n      }\n      if (s != null)\n          LockSupport.unpark(s.thread);//唤醒\n  }\n  ```\n\n### 共享锁加锁流程\n\n以CountDownLatch以例，任务分为n个子线程去执行，state也初始化为n（注意N要与线程个数一致）。这N个子线程是并行执行的，每个子线程执行完后countDown()一次，state会CAS减1。等到所有子线程都执行完后(即state=0)，会unpark()主调用线程，然后主调用线程就会从await()函数返回，继续后余动作。\n\n- 共享模式下调用的是tryAcquireShared\n\n- 内部调用doAcquireShared\n\n- 在当前节点被唤醒的时候，需要传播性的唤醒队列中的下一个节点\n\n  ```java\n  private void doAcquireShared(int arg) {\n  final Node node = addWaiter(Node.SHARED); //指定node节点模式，比独享锁多了一个nextWaiter\n  boolean failed = true;\n  try {\n      boolean interrupted = false;\n      for (;;) {\n          final Node p = node.predecessor();//获取前一个节点\n          if (p == head) {//如果前一个节点是head，head是当前获取资源在运行的线程，自己是最可能拿到资源\n              int r = tryAcquireShared(arg);//尝试获取资源\n              if (r >= 0) {//如果成功\n                  setHeadAndPropagate(node, r);//将head指向自己，如果state不为0 再次唤醒队列中下一个\n                  p.next = null; // help GC\n                  if (interrupted)//如果等待过程有收到中断，补上中断标记\n                      selfInterrupt();\n                  failed = false;\n                  return;\n              }\n          }\n        //如果获取不到资源，寻找安全点，阻塞，等待获取资源的线程调用unpark 唤醒\n          if (shouldParkAfterFailedAcquire(p, node) &&\n              parkAndCheckInterrupt())\n              interrupted = true;\n      }\n  } finally {\n      if (failed)\n          cancelAcquire(node);\n  }\n  }\n  ```\n\n\n- 自己被唤醒后，判断资源是否有空余，如果有则唤醒队列中自己下一个节点线程\n\n  ```java\n  private void setHeadAndPropagate(Node node, int propagate) {\n      Node h = head; // Record old head for check below\n      setHead(node);//head指向当前节点\n      //如果还有剩余量，继续唤醒下一个邻居线程\n      if (propagate > 0 || h == null || h.waitStatus < 0 ||\n          (h = head) == null || h.waitStatus < 0) {\n          Node s = node.next;\n          if (s == null || s.isShared())\n              doReleaseShared();\n      }\n  }\n  ```\n\n### 共享锁释放锁流程\n\n- 释放锁就是由子类实现去改变state数量，然后在AQS中去唤醒等待队列中的头部节点\n\n  ```java\n  public final boolean releaseShared(int arg) {\n      if (tryReleaseShared(arg)) {//操作state并判断是否需要激活等待队列头部节点\n          doReleaseShared();\n          return true;\n      }\n      return false;\n  }\n  ```\n\n- fff\n\n  ```java\n  private void doReleaseShared() {\n      \n      for (;;) {\n          Node h = head;\n          if (h != null && h != tail) {//等待队列存在等待线程\n              int ws = h.waitStatus;\n              if (ws == Node.SIGNAL) {//需要保证将清除节点状态，失败则for循环中重新校验\n                  if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0))\n                      continue;            // loop to recheck cases\n                  unparkSuccessor(h);//激活下一个节点\n              }\n              else if (ws == 0 &&\n                       !compareAndSetWaitStatus(h, 0, Node.PROPAGATE))//设置为-3，在下次\n                  continue;                // loop on failed CAS\n          }\n          if (h == head) //如果\n              break;\n      }\n  }\n  ```\n\n## 其他方法\n\n- 可中断锁\n\n  ```java\n  private void doAcquireInterruptibly(int arg)\n      throws InterruptedException {\n      final Node node = addWaiter(Node.EXCLUSIVE);//入等待队列\n      boolean failed = true;\n      try {\n          for (;;) {\n              final Node p = node.predecessor();\n              if (p == head && tryAcquire(arg)) {\n                  setHead(node);\n                  p.next = null; // help GC\n                  failed = false;\n                  return;\n              }\n              if (shouldParkAfterFailedAcquire(p, node) &&\n                  parkAndCheckInterrupt())\n                //如果是中断唤醒线程 则抛出异常\n                  throw new InterruptedException();\n          }\n      } finally {\n          if (failed) //如果中断 设置节点状态为取消 ，并unpark队列中的线程\n              cancelAcquire(node);\n      }\n  }\n  ```\n\n- 超时获取锁\n\n  ```java\n  private boolean doAcquireNanos(int arg, long nanosTimeout)\n          throws InterruptedException {\n      if (nanosTimeout <= 0L)\n          return false;\n      final long deadline = System.nanoTime() + nanosTimeout;\n      final Node node = addWaiter(Node.EXCLUSIVE);//入等待队列\n      boolean failed = true;\n      try {\n          for (;;) {\n              final Node p = node.predecessor();\n              if (p == head && tryAcquire(arg)) {\n                  setHead(node);\n                  p.next = null; // help GC\n                  failed = false;\n                  return true;\n              }\n              nanosTimeout = deadline - System.nanoTime();\n              if (nanosTimeout <= 0L)//等待够时间后直接返回false\n                  return false;\n            //自旋够设置时间后 阻塞一段时间\n              if (shouldParkAfterFailedAcquire(p, node) &&\n                  nanosTimeout > spinForTimeoutThreshold)\n                  LockSupport.parkNanos(this, nanosTimeout);\n              if (Thread.interrupted())\n                  throw new InterruptedException();\n          }\n      } finally {\n          if (failed)\n              cancelAcquire(node);\n      }\n  }\n  ```\n\n- 设置为取消状态\n\n  ```java\n  private void cancelAcquire(Node node) {\n      // Ignore if node doesn't exist\n      if (node == null)\n          return;\n      node.thread = null;\n      // Skip cancelled predecessors\n      Node pred = node.prev;\n      while (pred.waitStatus > 0)\n          node.prev = pred = pred.prev;\n\n      // predNext is the apparent node to unsplice. CASes below will\n      // fail if not, in which case, we lost race vs another cancel\n      // or signal, so no further action is necessary.\n      Node predNext = pred.next;\n    //设置为取消状态\n      node.waitStatus = Node.CANCELLED;\n      //如果当前节点为队尾，直接移除\n      if (node == tail && compareAndSetTail(node, pred)) {\n          compareAndSetNext(pred, predNext, null);\n      } else {\n          // If successor needs signal, try to set pred's next-link\n          // so it will get one. Otherwise wake it up to propagate.\n          int ws;\n          if (pred != head &&\n              ((ws = pred.waitStatus) == Node.SIGNAL ||\n               (ws <= 0 && compareAndSetWaitStatus(pred, ws, Node.SIGNAL))) &&\n              pred.thread != null) {\n              Node next = node.next;\n              if (next != null && next.waitStatus <= 0)\n                  compareAndSetNext(pred, predNext, next);\n          } else {\n              unparkSuccessor(node);\n          }\n          node.next = node; // help GC\n      }\n  }\n  ```","slug":"多线程/java并发之AQS原理","published":1,"updated":"2018-09-12T03:03:21.829Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnhw0053wlkvthjkxwqm"},{"title":"java并发之CyclicBarrier","date":"2017-11-21T07:10:30.000Z","_content":"\n# java并发之CyclicBarrier\n\nCyclicBarrier初始化时规定一个数目，然后计算调用了CyclicBarrier.await()进入等待的线程数。当线程数达到了这个数目时，所有进入等待状态的线程被唤醒并继续。\n\n当线程A调用Exchange对象的exchange()方法后，他会陷入阻塞状态，直到线程B也调用了exchange()方法，然后以线程安全的方式交换数据，之后线程A和B继续运行\n\n调用await()方法计数加1，若加1后的值不等于构造方法的值，则线程阻塞\n\nCyclicBarrier加计数方式 CountDownLatch是减计数方式,CyclicBarrier可以重复使用已经通过的障碍，而CountdownLatch不能重复使用。\n\n<!--more-->\n\n## 用例\n\n```java\npublic class CyclicBarrierTest {\n\n  public static void main(String[] args) {\n    ExecutorService service = Executors.newCachedThreadPool();\n    final  CyclicBarrier cb = new CyclicBarrier(3);\n    for(int i=0;i<3;i++){\n      Runnable runnable = new Runnable(){\n        public void run(){\n          try {\n            Thread.sleep((long)(Math.random()*10000));\t\n            System.out.println(\"线程\" + Thread.currentThread().getName() + \n                               \"即将到达集合地点1，当前已有\" + (cb.getNumberWaiting()+1) + \"个已经到达，\" + (cb.getNumberWaiting()==2?\"都到齐了，继续走啊\":\"正在等候\"));\t\t\t\t\t\t\n            cb.await();\n\n            Thread.sleep((long)(Math.random()*10000));\t\n            System.out.println(\"线程\" + Thread.currentThread().getName() + \n                               \"即将到达集合地点2，当前已有\" + (cb.getNumberWaiting()+1) + \"个已经到达，\" + (cb.getNumberWaiting()==2?\"都到齐了，继续走啊\":\"正在等候\"));\n            cb.await();\t\n            Thread.sleep((long)(Math.random()*10000));\t\n            System.out.println(\"线程\" + Thread.currentThread().getName() + \n                               \"即将到达集合地点3，当前已有\" + (cb.getNumberWaiting() + 1) + \"个已经到达，\" + (cb.getNumberWaiting()==2?\"都到齐了，继续走啊\":\"正在等候\"));\t\t\t\t\t\t\n            cb.await();\t\t\t\t\t\t\n          } catch (Exception e) {\n            e.printStackTrace();\n          }\t\t\t\t\n        }\n      };\n      service.execute(runnable);\n    }\n    service.shutdown();\n  }\n}\n/*\n线程pool-1-thread-2即将到达集合地点1，当前已有1个已经到达，正在等候\n线程pool-1-thread-3即将到达集合地点1，当前已有2个已经到达，正在等候\n线程pool-1-thread-1即将到达集合地点1，当前已有3个已经到达，都到齐了，继续走啊\n线程pool-1-thread-2即将到达集合地点2，当前已有1个已经到达，正在等候\n线程pool-1-thread-1即将到达集合地点2，当前已有2个已经到达，正在等候\n线程pool-1-thread-3即将到达集合地点2，当前已有3个已经到达，都到齐了，继续走啊\n线程pool-1-thread-3即将到达集合地点3，当前已有1个已经到达，正在等候\n线程pool-1-thread-1即将到达集合地点3，当前已有2个已经到达，正在等候\n线程pool-1-thread-2即将到达集合地点3，当前已有3个已经到达，都到齐了，继续走啊\n*/\n```\n## 实现原理\n\nCyclicBarrier底层是基于ReentrantLock和它的一个Condition实现的。CyclicBarrier内部有个计数，每次调用await方法后先加锁，然后计数减1，减之后不为0,则调用Condition的await方法，让出执行权，当前线程进入阻塞状态；当计数减之后为0则signalAll，激活所有阻塞的线程。\n\n```java\nprivate int dowait(boolean timed, long nanos)\n    throws InterruptedException, BrokenBarrierException,\n           TimeoutException {\n    final ReentrantLock lock = this.lock;\n    lock.lock();\n    try {\n        final Generation g = generation;\n\n        if (g.broken)\n            throw new BrokenBarrierException();\n\n        if (Thread.interrupted()) {\n           // 损坏当前屏障，并且唤醒所有的线程，只有拥有锁的时候才会调用\n            breakBarrier();\n            throw new InterruptedException();\n        }\n\n        int index = --count;//减1\n        if (index == 0) {  // tripped\n            boolean ranAction = false;\n            try {\n                final Runnable command = barrierCommand;\n                if (command != null)\n                    command.run();\n                ranAction = true;\n                nextGeneration();//激活等待的线程\n                return 0;\n            } finally {\n                if (!ranAction)   \n                    breakBarrier();\n            }\n        }\n\n        // loop until tripped, broken, interrupted, or timed out\n        for (;;) {\n            try {\n                if (!timed)\n                    trip.await();\n                else if (nanos > 0L)\n                    nanos = trip.awaitNanos(nanos);\n            } catch (InterruptedException ie) {\n                if (g == generation && ! g.broken) {\n                    breakBarrier();\n                    throw ie;\n                } else {\n                    Thread.currentThread().interrupt();\n                }\n            }\n\n            if (g.broken)\n                throw new BrokenBarrierException();\n\n            if (g != generation)\n                return index;\n\n            if (timed && nanos <= 0L) {\n                breakBarrier();\n                throw new TimeoutException();\n            }\n        }\n    } finally {\n        lock.unlock();\n    }\n}\n```","source":"_posts/多线程/java并发之CyclicBarrier.md","raw":"---\ntitle: java并发之CyclicBarrier\ndate: 2017-11-21 15:10:30\ntags:\n- 多线程\ncategories:\n- java基础\n\n---\n\n# java并发之CyclicBarrier\n\nCyclicBarrier初始化时规定一个数目，然后计算调用了CyclicBarrier.await()进入等待的线程数。当线程数达到了这个数目时，所有进入等待状态的线程被唤醒并继续。\n\n当线程A调用Exchange对象的exchange()方法后，他会陷入阻塞状态，直到线程B也调用了exchange()方法，然后以线程安全的方式交换数据，之后线程A和B继续运行\n\n调用await()方法计数加1，若加1后的值不等于构造方法的值，则线程阻塞\n\nCyclicBarrier加计数方式 CountDownLatch是减计数方式,CyclicBarrier可以重复使用已经通过的障碍，而CountdownLatch不能重复使用。\n\n<!--more-->\n\n## 用例\n\n```java\npublic class CyclicBarrierTest {\n\n  public static void main(String[] args) {\n    ExecutorService service = Executors.newCachedThreadPool();\n    final  CyclicBarrier cb = new CyclicBarrier(3);\n    for(int i=0;i<3;i++){\n      Runnable runnable = new Runnable(){\n        public void run(){\n          try {\n            Thread.sleep((long)(Math.random()*10000));\t\n            System.out.println(\"线程\" + Thread.currentThread().getName() + \n                               \"即将到达集合地点1，当前已有\" + (cb.getNumberWaiting()+1) + \"个已经到达，\" + (cb.getNumberWaiting()==2?\"都到齐了，继续走啊\":\"正在等候\"));\t\t\t\t\t\t\n            cb.await();\n\n            Thread.sleep((long)(Math.random()*10000));\t\n            System.out.println(\"线程\" + Thread.currentThread().getName() + \n                               \"即将到达集合地点2，当前已有\" + (cb.getNumberWaiting()+1) + \"个已经到达，\" + (cb.getNumberWaiting()==2?\"都到齐了，继续走啊\":\"正在等候\"));\n            cb.await();\t\n            Thread.sleep((long)(Math.random()*10000));\t\n            System.out.println(\"线程\" + Thread.currentThread().getName() + \n                               \"即将到达集合地点3，当前已有\" + (cb.getNumberWaiting() + 1) + \"个已经到达，\" + (cb.getNumberWaiting()==2?\"都到齐了，继续走啊\":\"正在等候\"));\t\t\t\t\t\t\n            cb.await();\t\t\t\t\t\t\n          } catch (Exception e) {\n            e.printStackTrace();\n          }\t\t\t\t\n        }\n      };\n      service.execute(runnable);\n    }\n    service.shutdown();\n  }\n}\n/*\n线程pool-1-thread-2即将到达集合地点1，当前已有1个已经到达，正在等候\n线程pool-1-thread-3即将到达集合地点1，当前已有2个已经到达，正在等候\n线程pool-1-thread-1即将到达集合地点1，当前已有3个已经到达，都到齐了，继续走啊\n线程pool-1-thread-2即将到达集合地点2，当前已有1个已经到达，正在等候\n线程pool-1-thread-1即将到达集合地点2，当前已有2个已经到达，正在等候\n线程pool-1-thread-3即将到达集合地点2，当前已有3个已经到达，都到齐了，继续走啊\n线程pool-1-thread-3即将到达集合地点3，当前已有1个已经到达，正在等候\n线程pool-1-thread-1即将到达集合地点3，当前已有2个已经到达，正在等候\n线程pool-1-thread-2即将到达集合地点3，当前已有3个已经到达，都到齐了，继续走啊\n*/\n```\n## 实现原理\n\nCyclicBarrier底层是基于ReentrantLock和它的一个Condition实现的。CyclicBarrier内部有个计数，每次调用await方法后先加锁，然后计数减1，减之后不为0,则调用Condition的await方法，让出执行权，当前线程进入阻塞状态；当计数减之后为0则signalAll，激活所有阻塞的线程。\n\n```java\nprivate int dowait(boolean timed, long nanos)\n    throws InterruptedException, BrokenBarrierException,\n           TimeoutException {\n    final ReentrantLock lock = this.lock;\n    lock.lock();\n    try {\n        final Generation g = generation;\n\n        if (g.broken)\n            throw new BrokenBarrierException();\n\n        if (Thread.interrupted()) {\n           // 损坏当前屏障，并且唤醒所有的线程，只有拥有锁的时候才会调用\n            breakBarrier();\n            throw new InterruptedException();\n        }\n\n        int index = --count;//减1\n        if (index == 0) {  // tripped\n            boolean ranAction = false;\n            try {\n                final Runnable command = barrierCommand;\n                if (command != null)\n                    command.run();\n                ranAction = true;\n                nextGeneration();//激活等待的线程\n                return 0;\n            } finally {\n                if (!ranAction)   \n                    breakBarrier();\n            }\n        }\n\n        // loop until tripped, broken, interrupted, or timed out\n        for (;;) {\n            try {\n                if (!timed)\n                    trip.await();\n                else if (nanos > 0L)\n                    nanos = trip.awaitNanos(nanos);\n            } catch (InterruptedException ie) {\n                if (g == generation && ! g.broken) {\n                    breakBarrier();\n                    throw ie;\n                } else {\n                    Thread.currentThread().interrupt();\n                }\n            }\n\n            if (g.broken)\n                throw new BrokenBarrierException();\n\n            if (g != generation)\n                return index;\n\n            if (timed && nanos <= 0L) {\n                breakBarrier();\n                throw new TimeoutException();\n            }\n        }\n    } finally {\n        lock.unlock();\n    }\n}\n```","slug":"多线程/java并发之CyclicBarrier","published":1,"updated":"2018-09-12T03:03:21.830Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnhy0057wlkvtppkuia8"},{"title":"java并发之Exchanger","date":"2017-11-22T09:28:52.000Z","_content":"\n# java并发之Exchanger\n\nExchanger可以在两个线程之间交换数据，只能是2个线程，他不支持更多的线程之间互换数据。\n\n\n当线程A调用Exchange对象的exchange()方法后，他会陷入阻塞状态，直到线程B也调用了exchange()方法，然后以线程安全的方式交换数据，之后线程A和B继续运行\n\n<!--more-->\n\n## 用法\n\n```java\npublic class ExchangerTest {\n  public static void main(String[] args) {\n    ExecutorService service = Executors.newCachedThreadPool();\n    final Exchanger exchanger = new Exchanger();\n    service.execute(new Runnable(){\n      public void run() {\n        try {\t\t\t\t\n\n          String data1 = \"zxx\";\n          System.out.println(\"线程\" + Thread.currentThread().getName() + \n                             \"正在把数据\" + data1 +\"换出去\");\n          Thread.sleep((long)(Math.random()*10000));\n          String data2 = (String)exchanger.exchange(data1);\n          System.out.println(\"线程\" + Thread.currentThread().getName() + \n                             \"换回的数据为\" + data2);\n        }catch(Exception e){\n\n        }\n      }\t\n    });\n    service.execute(new Runnable(){\n      public void run() {\n        try {\t\t\t\t\n\n          String data1 = \"lhm\";\n          System.out.println(\"线程\" + Thread.currentThread().getName() + \n                             \"正在把数据\" + data1 +\"换出去\");\n          Thread.sleep((long)(Math.random()*10000));\t\t\t\t\t\n          String data2 = (String)exchanger.exchange(data1);\n          System.out.println(\"线程\" + Thread.currentThread().getName() + \n                             \"换回的数据为\" + data2);\n        }catch(Exception e){\n\n        }\t\t\t\t\n      }\t\n    });\t\t\n  }\n}\n/*\n线程pool-1-thread-1正在把数据zxx换出去\n线程pool-1-thread-2正在把数据lhm换出去\n线程pool-1-thread-2换回的数据为zxx\n线程pool-1-thread-1换回的数据为lhm\n*/\n```","source":"_posts/多线程/java并发之Exchanger.md","raw":"---\ntitle: java并发之Exchanger\ndate: 2017-11-22 17:28:52\ntags:\n- 多线程\ncategories:\n- java基础\n---\n\n# java并发之Exchanger\n\nExchanger可以在两个线程之间交换数据，只能是2个线程，他不支持更多的线程之间互换数据。\n\n\n当线程A调用Exchange对象的exchange()方法后，他会陷入阻塞状态，直到线程B也调用了exchange()方法，然后以线程安全的方式交换数据，之后线程A和B继续运行\n\n<!--more-->\n\n## 用法\n\n```java\npublic class ExchangerTest {\n  public static void main(String[] args) {\n    ExecutorService service = Executors.newCachedThreadPool();\n    final Exchanger exchanger = new Exchanger();\n    service.execute(new Runnable(){\n      public void run() {\n        try {\t\t\t\t\n\n          String data1 = \"zxx\";\n          System.out.println(\"线程\" + Thread.currentThread().getName() + \n                             \"正在把数据\" + data1 +\"换出去\");\n          Thread.sleep((long)(Math.random()*10000));\n          String data2 = (String)exchanger.exchange(data1);\n          System.out.println(\"线程\" + Thread.currentThread().getName() + \n                             \"换回的数据为\" + data2);\n        }catch(Exception e){\n\n        }\n      }\t\n    });\n    service.execute(new Runnable(){\n      public void run() {\n        try {\t\t\t\t\n\n          String data1 = \"lhm\";\n          System.out.println(\"线程\" + Thread.currentThread().getName() + \n                             \"正在把数据\" + data1 +\"换出去\");\n          Thread.sleep((long)(Math.random()*10000));\t\t\t\t\t\n          String data2 = (String)exchanger.exchange(data1);\n          System.out.println(\"线程\" + Thread.currentThread().getName() + \n                             \"换回的数据为\" + data2);\n        }catch(Exception e){\n\n        }\t\t\t\t\n      }\t\n    });\t\t\n  }\n}\n/*\n线程pool-1-thread-1正在把数据zxx换出去\n线程pool-1-thread-2正在把数据lhm换出去\n线程pool-1-thread-2换回的数据为zxx\n线程pool-1-thread-1换回的数据为lhm\n*/\n```","slug":"多线程/java并发之Exchanger","published":1,"updated":"2018-09-12T03:03:21.830Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnhz005bwlkvhajjcwti"},{"title":"java并发之LockSupport","date":"2017-11-16T10:53:41.000Z","_content":"\n# java并发之LockSupport\n\nLockSupport提供了park和unpark方法， 通过这两个方法实现线程的阻塞和唤醒，park和unpark方法类比suspend和resume方法，不过避免了这两个方法可能会出现的死锁问题。JUC包中的线程阻塞和唤醒都依赖LockSupport类。LockSupport底层是通过Unsafe实现线程的阻塞。\n\n<!--more-->\n\n## 实现\n\nLockSupport和每个使用它的线程都与一个许可(permit)关联。permit相当于1，0的开关，默认是0，调用一次unpark就加1变成1，调用一次park会消费permit, 也就是将1变成0，同时park立即返回。再次调用park会变成block（因为permit为0了，会阻塞在这里，直到permit变为1）, 这时调用unpark会把permit置为1。每个线程都有一个相关的permit, **permit最多只有一个** ，重复调用unpark也不会积累。\n\npark()和unpark()不会有 “Thread.suspend和Thread.resume所可能引发的死锁” 问题，由于许可的存在，调用 park 的线程和另一个试图将其 unpark 的线程之间的竞争将保持活性。\n\n## park 阻塞\n\n- park方法用于阻塞当前线程，当当前线程调用park后，在以下情况下会重新激活\n\n   1. 该线程作为参数调用了 unpark(thread)\n   2. 该线程被 interrupt ，打断\n   3. park的时候指定了阻塞时间，超过该时间后，线程激活\n\n- park底层基于UNSAFE的park方法,当time是绝对时间(到1970年的毫秒数)的时候，isAbsolute传true，当time是相对时间的时候，isAbsolute传false。当time为0时，表示一直阻塞，直到调用unpark或者当前线程被interrupt\n\n  ```java\n  public native void park(boolean isAbsolute, long time);\n  ```\n\n- 如果调用线程被中断，则park方法会返回。同时park也拥有可以设置超时时间的版本。\n\n- park 还各自支持一个 blocker 对象参数。此对象在线程受阻塞时被记录，以允许监视工具和诊断工具确定线程受阻塞的原因。（这样的工具可以使用方法 getBlocker(java.lang.Thread) 访问 blocker。）建议最好使用这些形式，而不是不带此参数的原始形式。在锁实现中提供的作为 blocker 的普通参数是 this。\n\n   该对象被LockSupport的getBlocker和setBlocker来获取和设置，且都是通过地址偏移量方式获取和修改的\n\n   ```java\n   public static void park(Object blocker) {\n       Thread t = Thread.currentThread();\n       setBlocker(t, blocker);\n       UNSAFE.park(false, 0L);\n       setBlocker(t, null);//线程被唤醒后重新将blocker设置为空\n   }\n   public static Object getBlocker(Thread t) {\n     if (t == null)\n       throw new NullPointerException();\n     return UNSAFE.getObjectVolatile(t, parkBlockerOffset);\n   }\n   ```\n\n- LockSupport提供parkNanos方法，支持阻塞一段时间后自动唤醒\n\n   ```java\n   public static void parkNanos(Object blocker, long nanos) {\n       if (nanos > 0) {\n           Thread t = Thread.currentThread();\n           setBlocker(t, blocker);\n           UNSAFE.park(false, nanos);\n           setBlocker(t, null);\n       }\n   }\n   ```\n\n- LockSupport提供parkUntil方法，支持当前线程阻塞至某个时间点后自动唤醒\n\n   ```java\n   public static void parkUntil(long deadline) {\n       UNSAFE.park(true, deadline);\n   }\n   ```\n\n## unpark 唤醒\n\n- unpark底层基于UNSAFE的unpark方法,调用该方法时需要保证该线程存活\n\n  ```java\n  public native void unpark(Thread thread);\n  ```\n\n- LockSupport中的unpark方法\n\n  ```java\n  public static void unpark(Thread thread) {\n  \tif (thread != null)//需要保证线程不为空\n      \tUNSAFE.unpark(thread);\n  }\n  ```\n\n## interrupt唤醒\n\n- interrupt可以使一个park后的线程唤醒，而不会抛出任何异常，同unpark唤醒的区别，只在于线程有了中断标识，一般在线程被激活后，通过Thread.interrupted()或者Thread.currentThread().isInterrupted()判断线程被唤醒的途径，然后进入不同的逻辑\n- 当线程有中断标识的时候，调用park 线程是无法进入阻塞状态的。所以一般都是在死循环中调用park，每次唤醒都重复去判断是否获取到锁，防止是中断导致线程唤醒。如果是中断唤醒的，还要清除中断标识，调用Thread.interrupted\n\n##  park\\unpark和wait\\notify区别\n\n- 当线程启动后，在调用park之前，如果调用了unpark，该线程一样会被唤醒，当时如果在wait前面调用notify，该线程时无法被唤醒的。**注意** unpark只能抵消一次park，如果连续多次park，线程一样会处于阻塞状态\n\n- wait和notify在调用前需要先持有对象锁，而park和unpark则没有这个要求\n\n- park可以响应中断(interrupt)请求，而不会抛出异常，当线程从park被激活后，需要判断下线程时被unpark还是interrupt唤醒的，通过Thread.currentThread.isInterrupt() 来判断线程是否中断的同时清除中断标识，防止线程无法park，同时要记录下线程是被中断过的，在获取到锁后再调用interrupt，加上中断标识，用于后期的逻辑判断\n\n  ```java\n  //用于避免 interrupt导致唤醒线程\n  while (waiters.peek() != current ||!locked.compareAndSet(false, true)) {\n    LockSupport.park(this);\n    //如果是interrupt导致唤醒线程，需要清除中断标记位，否则在循环中无法park线程\n    if (Thread.interrupted()){\n      wasInterrupted = true;//记录下 线程已经被中断，后期调用 thread.interrupt()\n    }\n  }\n  ```\n\n## 实例\n\n```java\n/**\n * 先进先出独占锁实现\n */\npublic class FIFOMutex {\n    private final AtomicBoolean locked = new AtomicBoolean(false);\n    private final Queue<Thread> waiters = new ConcurrentLinkedQueue<Thread>();\n\n    public void lock() {\n        boolean wasInterrupted = false;\n        Thread current = Thread.currentThread();\n        waiters.add(current);\n\n        // 使用while循环，每次线程被唤醒则再次判断，防止并发问题\n        // 先判断当前线程是否在队列头，然后再尝试加锁，保证FIFO\n        while (waiters.peek() != current ||\n                !locked.compareAndSet(false, true)) {\n            LockSupport.park(this);\n            //判断线程时是否是因为被打断而被唤醒的，设置wasInterrupted为true，等待拿到锁后再补上中断标识\n            //使用interrupted清除中断标识，否则park将无法使线程进入阻塞状态\n            if (Thread.interrupted())\n//            if(current.isInterrupted())\n                wasInterrupted = true;\n        }\n\n        waiters.remove();\n        if (wasInterrupted)  //如果线程运行期间被中断过，重新中断当前线程\n            current.interrupt();\n    }\n\n    public void unlock() {\n        locked.set(false);  //释放锁\n        LockSupport.unpark(waiters.peek());  //激活队列头部线程\n    }\n }\n```","source":"_posts/多线程/java并发之LockSupport.md","raw":"---\ntitle: java并发之LockSupport\ndate: 2017-11-16 18:53:41\ntags:\n- 多线程\ncategories:\n- java基础\n---\n\n# java并发之LockSupport\n\nLockSupport提供了park和unpark方法， 通过这两个方法实现线程的阻塞和唤醒，park和unpark方法类比suspend和resume方法，不过避免了这两个方法可能会出现的死锁问题。JUC包中的线程阻塞和唤醒都依赖LockSupport类。LockSupport底层是通过Unsafe实现线程的阻塞。\n\n<!--more-->\n\n## 实现\n\nLockSupport和每个使用它的线程都与一个许可(permit)关联。permit相当于1，0的开关，默认是0，调用一次unpark就加1变成1，调用一次park会消费permit, 也就是将1变成0，同时park立即返回。再次调用park会变成block（因为permit为0了，会阻塞在这里，直到permit变为1）, 这时调用unpark会把permit置为1。每个线程都有一个相关的permit, **permit最多只有一个** ，重复调用unpark也不会积累。\n\npark()和unpark()不会有 “Thread.suspend和Thread.resume所可能引发的死锁” 问题，由于许可的存在，调用 park 的线程和另一个试图将其 unpark 的线程之间的竞争将保持活性。\n\n## park 阻塞\n\n- park方法用于阻塞当前线程，当当前线程调用park后，在以下情况下会重新激活\n\n   1. 该线程作为参数调用了 unpark(thread)\n   2. 该线程被 interrupt ，打断\n   3. park的时候指定了阻塞时间，超过该时间后，线程激活\n\n- park底层基于UNSAFE的park方法,当time是绝对时间(到1970年的毫秒数)的时候，isAbsolute传true，当time是相对时间的时候，isAbsolute传false。当time为0时，表示一直阻塞，直到调用unpark或者当前线程被interrupt\n\n  ```java\n  public native void park(boolean isAbsolute, long time);\n  ```\n\n- 如果调用线程被中断，则park方法会返回。同时park也拥有可以设置超时时间的版本。\n\n- park 还各自支持一个 blocker 对象参数。此对象在线程受阻塞时被记录，以允许监视工具和诊断工具确定线程受阻塞的原因。（这样的工具可以使用方法 getBlocker(java.lang.Thread) 访问 blocker。）建议最好使用这些形式，而不是不带此参数的原始形式。在锁实现中提供的作为 blocker 的普通参数是 this。\n\n   该对象被LockSupport的getBlocker和setBlocker来获取和设置，且都是通过地址偏移量方式获取和修改的\n\n   ```java\n   public static void park(Object blocker) {\n       Thread t = Thread.currentThread();\n       setBlocker(t, blocker);\n       UNSAFE.park(false, 0L);\n       setBlocker(t, null);//线程被唤醒后重新将blocker设置为空\n   }\n   public static Object getBlocker(Thread t) {\n     if (t == null)\n       throw new NullPointerException();\n     return UNSAFE.getObjectVolatile(t, parkBlockerOffset);\n   }\n   ```\n\n- LockSupport提供parkNanos方法，支持阻塞一段时间后自动唤醒\n\n   ```java\n   public static void parkNanos(Object blocker, long nanos) {\n       if (nanos > 0) {\n           Thread t = Thread.currentThread();\n           setBlocker(t, blocker);\n           UNSAFE.park(false, nanos);\n           setBlocker(t, null);\n       }\n   }\n   ```\n\n- LockSupport提供parkUntil方法，支持当前线程阻塞至某个时间点后自动唤醒\n\n   ```java\n   public static void parkUntil(long deadline) {\n       UNSAFE.park(true, deadline);\n   }\n   ```\n\n## unpark 唤醒\n\n- unpark底层基于UNSAFE的unpark方法,调用该方法时需要保证该线程存活\n\n  ```java\n  public native void unpark(Thread thread);\n  ```\n\n- LockSupport中的unpark方法\n\n  ```java\n  public static void unpark(Thread thread) {\n  \tif (thread != null)//需要保证线程不为空\n      \tUNSAFE.unpark(thread);\n  }\n  ```\n\n## interrupt唤醒\n\n- interrupt可以使一个park后的线程唤醒，而不会抛出任何异常，同unpark唤醒的区别，只在于线程有了中断标识，一般在线程被激活后，通过Thread.interrupted()或者Thread.currentThread().isInterrupted()判断线程被唤醒的途径，然后进入不同的逻辑\n- 当线程有中断标识的时候，调用park 线程是无法进入阻塞状态的。所以一般都是在死循环中调用park，每次唤醒都重复去判断是否获取到锁，防止是中断导致线程唤醒。如果是中断唤醒的，还要清除中断标识，调用Thread.interrupted\n\n##  park\\unpark和wait\\notify区别\n\n- 当线程启动后，在调用park之前，如果调用了unpark，该线程一样会被唤醒，当时如果在wait前面调用notify，该线程时无法被唤醒的。**注意** unpark只能抵消一次park，如果连续多次park，线程一样会处于阻塞状态\n\n- wait和notify在调用前需要先持有对象锁，而park和unpark则没有这个要求\n\n- park可以响应中断(interrupt)请求，而不会抛出异常，当线程从park被激活后，需要判断下线程时被unpark还是interrupt唤醒的，通过Thread.currentThread.isInterrupt() 来判断线程是否中断的同时清除中断标识，防止线程无法park，同时要记录下线程是被中断过的，在获取到锁后再调用interrupt，加上中断标识，用于后期的逻辑判断\n\n  ```java\n  //用于避免 interrupt导致唤醒线程\n  while (waiters.peek() != current ||!locked.compareAndSet(false, true)) {\n    LockSupport.park(this);\n    //如果是interrupt导致唤醒线程，需要清除中断标记位，否则在循环中无法park线程\n    if (Thread.interrupted()){\n      wasInterrupted = true;//记录下 线程已经被中断，后期调用 thread.interrupt()\n    }\n  }\n  ```\n\n## 实例\n\n```java\n/**\n * 先进先出独占锁实现\n */\npublic class FIFOMutex {\n    private final AtomicBoolean locked = new AtomicBoolean(false);\n    private final Queue<Thread> waiters = new ConcurrentLinkedQueue<Thread>();\n\n    public void lock() {\n        boolean wasInterrupted = false;\n        Thread current = Thread.currentThread();\n        waiters.add(current);\n\n        // 使用while循环，每次线程被唤醒则再次判断，防止并发问题\n        // 先判断当前线程是否在队列头，然后再尝试加锁，保证FIFO\n        while (waiters.peek() != current ||\n                !locked.compareAndSet(false, true)) {\n            LockSupport.park(this);\n            //判断线程时是否是因为被打断而被唤醒的，设置wasInterrupted为true，等待拿到锁后再补上中断标识\n            //使用interrupted清除中断标识，否则park将无法使线程进入阻塞状态\n            if (Thread.interrupted())\n//            if(current.isInterrupted())\n                wasInterrupted = true;\n        }\n\n        waiters.remove();\n        if (wasInterrupted)  //如果线程运行期间被中断过，重新中断当前线程\n            current.interrupt();\n    }\n\n    public void unlock() {\n        locked.set(false);  //释放锁\n        LockSupport.unpark(waiters.peek());  //激活队列头部线程\n    }\n }\n```","slug":"多线程/java并发之LockSupport","published":1,"updated":"2018-09-12T03:03:21.830Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfni0005ewlkvrqmgmckd"},{"title":"java并发之ReentrantLock","date":"2017-10-29T01:35:30.000Z","_content":"\n# java并发之ReentrantLock\n\nReentrantLock是基于AQS实现的可重入独享锁，内部提供了公平锁和非公平锁两种方式。\n\n<!--more-->\n\n## ReentrantLock和synchronized的区别\n\n1. ReentrantLock在等待锁时可以使用lockInterruptibly()方法选择中断， 改为处理其他事情，而synchronized关键字，线程需要一直等待下去。同样的，tryLock()方法可以设置超时时间，用于在超时时间内一直获取不到锁时进行中断。\n2. ReentrantLock可以实现公平锁，而synchronized的锁是非公平的。\n3. ReentrantLock拥有方便的方法用于获取正在等待锁的线程。\n4. ReentrantLock可以同时绑定多个Condition对象，而synchronized中，锁对象的wait()和notify()或notifyAll()方法可以实现一个隐含的条件，如果要和多于一个条件关联时，只能再加一个额外的锁，而ReentrantLock只需要多次调用newCondition方法即可。\n\n## ReentrantLock的非公平/公平锁实现原理\n\n### 非公平锁\n\n由于线程在unlock的时候是先将status减去，然后再去激活队列头部的线程，所以在这两个操作之间如果有线程lock可以成功，队列头部被激活的线程再次尝试获取锁的时候会失败，然后再次进入阻塞状态\n\n```java\nstatic final class NonfairSync extends Sync {\n  // 获得锁\n  final void lock() {\n    if (compareAndSetState(0, 1)) // 比较并设置状态成功，状态0表示锁没有被占用\n      // 把当前线程设置独占了锁\n      setExclusiveOwnerThread(Thread.currentThread());\n    else // 锁已经被占用，或者set失败\n      // 以独占模式获取对象，忽略中断\n      acquire(1); \n  }\n\n  protected final boolean tryAcquire(int acquires) {\n    return nonfairTryAcquire(acquires);\n  }\n}\n\nfinal boolean nonfairTryAcquire(int acquires) {\n  final Thread current = Thread.currentThread();\n  int c = getState();\n  if (c == 0) {//直接获取锁\n    if (compareAndSetState(0, acquires)) {\n      setExclusiveOwnerThread(current);\n      return true;\n    }\n  }\n  else if (current == getExclusiveOwnerThread()) {\n    int nextc = c + acquires;\n    if (nextc < 0) // overflow\n      throw new Error(\"Maximum lock count exceeded\");\n    setState(nextc);\n    return true;\n  }\n  return false;\n}\n```\n\n### 公平锁\n\n公平锁的实现是控制获取锁的线程在操作status之前，首先判断等待队列是否存在等待线程，如果存在则当前线程放入队列，进入阻塞状态\n\n- 在去加锁的时候，首先需要判断当前线程是否在首节点，如果不是则返回false；非公平锁是当一个线程新启动并且status为0的时候就可以获取资源，不能保证等待队列中的线程获取到锁\n\n  ```java\n  protected final boolean tryAcquire(int acquires) {\n      final Thread current = Thread.currentThread();\n      int c = getState();\n      if (c == 0) {\n          if (!hasQueuedPredecessors() &&\n              compareAndSetState(0, acquires)) {\n              setExclusiveOwnerThread(current);\n              return true;\n          }\n      }\n      else if (current == getExclusiveOwnerThread()) {//重入锁\n          int nextc = c + acquires;\n          if (nextc < 0)\n              throw new Error(\"Maximum lock count exceeded\");\n          setState(nextc);\n          return true;\n      }\n      return false;\n  }\n  ```\n\n- 查询是否存在其他线程等待时间比当前线程长，当存在的时候返回true，当队列为空或者当前线程已经在head的时候返回false\n\n  ```java\n  public final boolean hasQueuedPredecessors() {\n      Node t = tail; // Read fields in reverse initialization order\n      Node h = head;\n      Node s;\n    //当前队列存在等待线程，并且该线程不是当前线程\n      return h != t &&\n          ((s = h.next) == null || s.thread != Thread.currentThread());\n  }\n  ```","source":"_posts/多线程/java并发之ReentrantLock.md","raw":"---\ntitle: java并发之ReentrantLock\ndate: 2017-10-29 09:35:30\ntags:\n- 多线程\ncategories:\n- java基础\n---\n\n# java并发之ReentrantLock\n\nReentrantLock是基于AQS实现的可重入独享锁，内部提供了公平锁和非公平锁两种方式。\n\n<!--more-->\n\n## ReentrantLock和synchronized的区别\n\n1. ReentrantLock在等待锁时可以使用lockInterruptibly()方法选择中断， 改为处理其他事情，而synchronized关键字，线程需要一直等待下去。同样的，tryLock()方法可以设置超时时间，用于在超时时间内一直获取不到锁时进行中断。\n2. ReentrantLock可以实现公平锁，而synchronized的锁是非公平的。\n3. ReentrantLock拥有方便的方法用于获取正在等待锁的线程。\n4. ReentrantLock可以同时绑定多个Condition对象，而synchronized中，锁对象的wait()和notify()或notifyAll()方法可以实现一个隐含的条件，如果要和多于一个条件关联时，只能再加一个额外的锁，而ReentrantLock只需要多次调用newCondition方法即可。\n\n## ReentrantLock的非公平/公平锁实现原理\n\n### 非公平锁\n\n由于线程在unlock的时候是先将status减去，然后再去激活队列头部的线程，所以在这两个操作之间如果有线程lock可以成功，队列头部被激活的线程再次尝试获取锁的时候会失败，然后再次进入阻塞状态\n\n```java\nstatic final class NonfairSync extends Sync {\n  // 获得锁\n  final void lock() {\n    if (compareAndSetState(0, 1)) // 比较并设置状态成功，状态0表示锁没有被占用\n      // 把当前线程设置独占了锁\n      setExclusiveOwnerThread(Thread.currentThread());\n    else // 锁已经被占用，或者set失败\n      // 以独占模式获取对象，忽略中断\n      acquire(1); \n  }\n\n  protected final boolean tryAcquire(int acquires) {\n    return nonfairTryAcquire(acquires);\n  }\n}\n\nfinal boolean nonfairTryAcquire(int acquires) {\n  final Thread current = Thread.currentThread();\n  int c = getState();\n  if (c == 0) {//直接获取锁\n    if (compareAndSetState(0, acquires)) {\n      setExclusiveOwnerThread(current);\n      return true;\n    }\n  }\n  else if (current == getExclusiveOwnerThread()) {\n    int nextc = c + acquires;\n    if (nextc < 0) // overflow\n      throw new Error(\"Maximum lock count exceeded\");\n    setState(nextc);\n    return true;\n  }\n  return false;\n}\n```\n\n### 公平锁\n\n公平锁的实现是控制获取锁的线程在操作status之前，首先判断等待队列是否存在等待线程，如果存在则当前线程放入队列，进入阻塞状态\n\n- 在去加锁的时候，首先需要判断当前线程是否在首节点，如果不是则返回false；非公平锁是当一个线程新启动并且status为0的时候就可以获取资源，不能保证等待队列中的线程获取到锁\n\n  ```java\n  protected final boolean tryAcquire(int acquires) {\n      final Thread current = Thread.currentThread();\n      int c = getState();\n      if (c == 0) {\n          if (!hasQueuedPredecessors() &&\n              compareAndSetState(0, acquires)) {\n              setExclusiveOwnerThread(current);\n              return true;\n          }\n      }\n      else if (current == getExclusiveOwnerThread()) {//重入锁\n          int nextc = c + acquires;\n          if (nextc < 0)\n              throw new Error(\"Maximum lock count exceeded\");\n          setState(nextc);\n          return true;\n      }\n      return false;\n  }\n  ```\n\n- 查询是否存在其他线程等待时间比当前线程长，当存在的时候返回true，当队列为空或者当前线程已经在head的时候返回false\n\n  ```java\n  public final boolean hasQueuedPredecessors() {\n      Node t = tail; // Read fields in reverse initialization order\n      Node h = head;\n      Node s;\n    //当前队列存在等待线程，并且该线程不是当前线程\n      return h != t &&\n          ((s = h.next) == null || s.thread != Thread.currentThread());\n  }\n  ```","slug":"多线程/java并发之ReentrantLock","published":1,"updated":"2018-09-12T03:03:21.830Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfni2005iwlkvmhcg8xh5"},{"title":"java并发之Semaphore","date":"2017-11-21T10:36:58.000Z","_content":"\n# java并发之Semaphore\n\nSemaphore称为计数信号量，它允许n个任务同时访问某个资源，可以将信号量看做是在向外分发使用资源的许可证，只有成功获取许可证，才能使用资源。\n\n当占有许可证的线程释放了许可证后，其他线程又可以获取许可证。\n\n<!--more-->\n\n## 用法\n\n- 调用acquire方法获取许可证，获取成功后state会减1，获取失败，则线程加入等待队列阻塞\n- release 释放许可证，调用release后state会加1\n\n```java\npublic class SemaphoreTest {\n  public static void main(String[] args) {\n    ExecutorService service = Executors.newCachedThreadPool();\n    final  Semaphore sp = new Semaphore(3);\n    for(int i=0;i<10;i++){\n      Runnable runnable = new Runnable(){\n        public void run(){\n          try {\n            sp.acquire();\n          } catch (InterruptedException e1) {\n            e1.printStackTrace();\n          }\n          System.out.println(\"线程\" + Thread.currentThread().getName() + \n                             \"进入，当前已有\" + (3-sp.availablePermits()) + \"个并发\");\n          try {\n            Thread.sleep((long)(Math.random()*10000));\n          } catch (InterruptedException e) {\n            e.printStackTrace();\n          }\n          System.out.println(\"线程\" + Thread.currentThread().getName() + \n                             \"即将离开\");\t\t\t\t\t\n          sp.release();\n          //下面代码有时候执行不准确，因为其没有和上面的代码合成原子单元\n          System.out.println(\"线程\" + Thread.currentThread().getName() + \n                             \"已离开，当前已有\" + (3-sp.availablePermits()) + \"个并发\");\t\t\t\n        }\n      };\n      service.execute(runnable);\t\t\t\n    }\n  }\n}\n/*\n线程pool-1-thread-2进入，当前已有3个并发\n线程pool-1-thread-1进入，当前已有3个并发\n线程pool-1-thread-3进入，当前已有3个并发\n线程pool-1-thread-3即将离开\n线程pool-1-thread-3已离开，当前已有2个并发\n线程pool-1-thread-4进入，当前已有3个并发\n线程pool-1-thread-4即将离开\n线程pool-1-thread-5进入，当前已有3个并发\n线程pool-1-thread-4已离开，当前已有3个并发\n线程pool-1-thread-2即将离开\n线程pool-1-thread-6进入，当前已有3个并发\n线程pool-1-thread-2已离开，当前已有3个并发\n线程pool-1-thread-1即将离开\n线程pool-1-thread-7进入，当前已有3个并发\n线程pool-1-thread-1已离开，当前已有3个并发\n线程pool-1-thread-6即将离开\n线程pool-1-thread-8进入，当前已有3个并发\n线程pool-1-thread-6已离开，当前已有3个并发\n线程pool-1-thread-5即将离开\n线程pool-1-thread-5已离开，当前已有3个并发\n线程pool-1-thread-9进入，当前已有3个并发\n线程pool-1-thread-9即将离开\n线程pool-1-thread-10进入，当前已有3个并发\n线程pool-1-thread-9已离开，当前已有3个并发\n线程pool-1-thread-10即将离开\n线程pool-1-thread-10已离开，当前已有2个并发\n线程pool-1-thread-7即将离开\n线程pool-1-thread-7已离开，当前已有1个并发\n线程pool-1-thread-8即将离开\n线程pool-1-thread-8已离开，当前已有0个并发\n*/\n```\n## 实现原理\n\n- 创建Semaphore的时候，指定了许可证的数量n，其实就是将AQS的state设置为n\n- 调用Semaphore的acquire方法的时候会尝试将state减一，减完之后如果state<0则获取许可证失败\n- 如果是Semaphore的tryAcquire则直接返回false，如果是acquire方法，将调用AQS中的acquireShared进入等待队列进行阻塞，等待获取许可证的线程唤醒，自己被唤醒的时候传播性的唤醒队列中的下一个，跟CountDownLatch一样\n- 调用release方法会将state加1，并唤醒等待队列的头节点\n\n### 实现步骤\n\n- 首先看下Sempaphore的构造方法，内部是基于实现AQS的Sync来实现的。提供了公平模式和非公平模式两种。\n\n  ```java\n  //非公平模式\n  public Semaphore(int permits) {\n      sync = new NonfairSync(permits);\n  }\n  //公平模式\n  public Semaphore(int permits, boolean fair) {\n  \tsync = fair ? new FairSync(permits) : new NonfairSync(permits);\n  }\n  ```\n\n- Sempaphore中的内部类Sync，实现了AQS的共享锁模式，重写了tryAcquireShared、tryReleaseShared方法\n\n  ```java\n  static final class NonfairSync extends Sync { //非公平模式实现\n      private static final long serialVersionUID = -2694183684443567898L;\n      NonfairSync(int permits) {//设置AQS中的state\n          super(permits);\n      }\n\n      protected int tryAcquireShared(int acquires) {\n          return nonfairTryAcquireShared(acquires);\n      }\n  }\n  static final class FairSync extends Sync { //公平模式实现\n      private static final long serialVersionUID = 2014338818796000944L;\n      FairSync(int permits) {\n          super(permits);\n      }\n      protected int tryAcquireShared(int acquires) {\n        //判断state是否减到0，如果减到了返回负数会阻塞，否则返回正数，获的许可证\n          for (;;) {\n              if (hasQueuedPredecessors())//公平模式就是必须要保证当前线程在等待队列的头部才去获取锁\n                  return -1;\n              int available = getState();\n              int remaining = available - acquires;\n              if (remaining < 0 ||\t\t\n                  compareAndSetState(available, remaining))\n                  return remaining;\n          }\n      }\n  }\n  ```\n\n- Sync类中覆写了Sync中的acquire和release的同时，添加了额外操作state的方法\n\n  ```java\n  abstract static class Sync extends AbstractQueuedSynchronizer {\n      private static final long serialVersionUID = 1192457210091910933L;\n\n      Sync(int permits) {\n          setState(permits);\n      }\n\n      final int getPermits() {\n          return getState();\n      }\n\n      final int nonfairTryAcquireShared(int acquires) {\n          for (;;) {\n              int available = getState();\n              int remaining = available - acquires;\n              if (remaining < 0 ||\n                  compareAndSetState(available, remaining))\n                  return remaining;\n          }\n      }\n    //释放资源，state+1\n      protected final boolean tryReleaseShared(int releases) {\n          for (;;) {\n              int current = getState();\n              int next = current + releases;\n              if (next < current) // overflow\n                  throw new Error(\"Maximum permit count exceeded\");\n              if (compareAndSetState(current, next))\n                  return true;\n          }\n      }\n    \t//运行期间减少许可证的数量\n      final void reducePermits(int reductions) {\n          for (;;) {\n              int current = getState();\n              int next = current - reductions;\n              if (next > current) // underflow\n                  throw new Error(\"Permit count underflow\");\n              if (compareAndSetState(current, next))\n                  return;\n          }\n      }\n    //清空所有许可证\n      final int drainPermits() {\n          for (;;) {\n              int current = getState();\n              if (current == 0 || compareAndSetState(current, 0))\n                  return current;\n          }\n      }\n  }\n  ```\n\n- 获取许可证并运行\n\n  ```java\n  //获取许可证，如果失败，进入等待队列阻塞，阻塞期间允许中断\n  public void acquire(int permits) throws InterruptedException {\n  \tif (permits < 0) throw new IllegalArgumentException();\n          sync.acquireSharedInterruptibly(permits);\n  }\n  //获取许可证，如果失败，进入等待队列阻塞，阻塞期间不允许中断\n  public void acquireUninterruptibly(int permits) {\n  \tif (permits < 0) throw new IllegalArgumentException();\n  \t\tsync.acquireShared(permits);\n  }\n  //获取许可证，如果失败，返回false\n  public boolean tryAcquire(int permits) {\n    if (permits < 0) throw new IllegalArgumentException();\n          return sync.nonfairTryAcquireShared(permits) >= 0;\n  }\n  //指定超时时间\n  public boolean tryAcquire(int permits, long timeout, TimeUnit unit)\n  throws InterruptedException {\n      if (permits < 0) throw new IllegalArgumentException();\n      return sync.tryAcquireSharedNanos(permits, unit.toNanos(timeout));\n  }\n  ```\n\n- 释放许可证\n\n  ```java\n  public void release(int permits) {\n      if (permits < 0) throw new IllegalArgumentException();\n      sync.releaseShared(permits);\n  }\n  ```\n\n- 运行区间动态修改许可证的总数\n\n  ```java\n  protected void reducePermits(int reduction) {\n      if (reduction < 0) throw new IllegalArgumentException();\n      sync.reducePermits(reduction);\n  }\n  public int drainPermits() { //清空剩余的许可证\n    return sync.drainPermits();\n  }\n  ```","source":"_posts/多线程/java并发之Semaphore.md","raw":"---\ntitle: java并发之Semaphore\ndate: 2017-11-21 18:36:58\ntags:\n- 多线程\ncategories:\n- java基础\n---\n\n# java并发之Semaphore\n\nSemaphore称为计数信号量，它允许n个任务同时访问某个资源，可以将信号量看做是在向外分发使用资源的许可证，只有成功获取许可证，才能使用资源。\n\n当占有许可证的线程释放了许可证后，其他线程又可以获取许可证。\n\n<!--more-->\n\n## 用法\n\n- 调用acquire方法获取许可证，获取成功后state会减1，获取失败，则线程加入等待队列阻塞\n- release 释放许可证，调用release后state会加1\n\n```java\npublic class SemaphoreTest {\n  public static void main(String[] args) {\n    ExecutorService service = Executors.newCachedThreadPool();\n    final  Semaphore sp = new Semaphore(3);\n    for(int i=0;i<10;i++){\n      Runnable runnable = new Runnable(){\n        public void run(){\n          try {\n            sp.acquire();\n          } catch (InterruptedException e1) {\n            e1.printStackTrace();\n          }\n          System.out.println(\"线程\" + Thread.currentThread().getName() + \n                             \"进入，当前已有\" + (3-sp.availablePermits()) + \"个并发\");\n          try {\n            Thread.sleep((long)(Math.random()*10000));\n          } catch (InterruptedException e) {\n            e.printStackTrace();\n          }\n          System.out.println(\"线程\" + Thread.currentThread().getName() + \n                             \"即将离开\");\t\t\t\t\t\n          sp.release();\n          //下面代码有时候执行不准确，因为其没有和上面的代码合成原子单元\n          System.out.println(\"线程\" + Thread.currentThread().getName() + \n                             \"已离开，当前已有\" + (3-sp.availablePermits()) + \"个并发\");\t\t\t\n        }\n      };\n      service.execute(runnable);\t\t\t\n    }\n  }\n}\n/*\n线程pool-1-thread-2进入，当前已有3个并发\n线程pool-1-thread-1进入，当前已有3个并发\n线程pool-1-thread-3进入，当前已有3个并发\n线程pool-1-thread-3即将离开\n线程pool-1-thread-3已离开，当前已有2个并发\n线程pool-1-thread-4进入，当前已有3个并发\n线程pool-1-thread-4即将离开\n线程pool-1-thread-5进入，当前已有3个并发\n线程pool-1-thread-4已离开，当前已有3个并发\n线程pool-1-thread-2即将离开\n线程pool-1-thread-6进入，当前已有3个并发\n线程pool-1-thread-2已离开，当前已有3个并发\n线程pool-1-thread-1即将离开\n线程pool-1-thread-7进入，当前已有3个并发\n线程pool-1-thread-1已离开，当前已有3个并发\n线程pool-1-thread-6即将离开\n线程pool-1-thread-8进入，当前已有3个并发\n线程pool-1-thread-6已离开，当前已有3个并发\n线程pool-1-thread-5即将离开\n线程pool-1-thread-5已离开，当前已有3个并发\n线程pool-1-thread-9进入，当前已有3个并发\n线程pool-1-thread-9即将离开\n线程pool-1-thread-10进入，当前已有3个并发\n线程pool-1-thread-9已离开，当前已有3个并发\n线程pool-1-thread-10即将离开\n线程pool-1-thread-10已离开，当前已有2个并发\n线程pool-1-thread-7即将离开\n线程pool-1-thread-7已离开，当前已有1个并发\n线程pool-1-thread-8即将离开\n线程pool-1-thread-8已离开，当前已有0个并发\n*/\n```\n## 实现原理\n\n- 创建Semaphore的时候，指定了许可证的数量n，其实就是将AQS的state设置为n\n- 调用Semaphore的acquire方法的时候会尝试将state减一，减完之后如果state<0则获取许可证失败\n- 如果是Semaphore的tryAcquire则直接返回false，如果是acquire方法，将调用AQS中的acquireShared进入等待队列进行阻塞，等待获取许可证的线程唤醒，自己被唤醒的时候传播性的唤醒队列中的下一个，跟CountDownLatch一样\n- 调用release方法会将state加1，并唤醒等待队列的头节点\n\n### 实现步骤\n\n- 首先看下Sempaphore的构造方法，内部是基于实现AQS的Sync来实现的。提供了公平模式和非公平模式两种。\n\n  ```java\n  //非公平模式\n  public Semaphore(int permits) {\n      sync = new NonfairSync(permits);\n  }\n  //公平模式\n  public Semaphore(int permits, boolean fair) {\n  \tsync = fair ? new FairSync(permits) : new NonfairSync(permits);\n  }\n  ```\n\n- Sempaphore中的内部类Sync，实现了AQS的共享锁模式，重写了tryAcquireShared、tryReleaseShared方法\n\n  ```java\n  static final class NonfairSync extends Sync { //非公平模式实现\n      private static final long serialVersionUID = -2694183684443567898L;\n      NonfairSync(int permits) {//设置AQS中的state\n          super(permits);\n      }\n\n      protected int tryAcquireShared(int acquires) {\n          return nonfairTryAcquireShared(acquires);\n      }\n  }\n  static final class FairSync extends Sync { //公平模式实现\n      private static final long serialVersionUID = 2014338818796000944L;\n      FairSync(int permits) {\n          super(permits);\n      }\n      protected int tryAcquireShared(int acquires) {\n        //判断state是否减到0，如果减到了返回负数会阻塞，否则返回正数，获的许可证\n          for (;;) {\n              if (hasQueuedPredecessors())//公平模式就是必须要保证当前线程在等待队列的头部才去获取锁\n                  return -1;\n              int available = getState();\n              int remaining = available - acquires;\n              if (remaining < 0 ||\t\t\n                  compareAndSetState(available, remaining))\n                  return remaining;\n          }\n      }\n  }\n  ```\n\n- Sync类中覆写了Sync中的acquire和release的同时，添加了额外操作state的方法\n\n  ```java\n  abstract static class Sync extends AbstractQueuedSynchronizer {\n      private static final long serialVersionUID = 1192457210091910933L;\n\n      Sync(int permits) {\n          setState(permits);\n      }\n\n      final int getPermits() {\n          return getState();\n      }\n\n      final int nonfairTryAcquireShared(int acquires) {\n          for (;;) {\n              int available = getState();\n              int remaining = available - acquires;\n              if (remaining < 0 ||\n                  compareAndSetState(available, remaining))\n                  return remaining;\n          }\n      }\n    //释放资源，state+1\n      protected final boolean tryReleaseShared(int releases) {\n          for (;;) {\n              int current = getState();\n              int next = current + releases;\n              if (next < current) // overflow\n                  throw new Error(\"Maximum permit count exceeded\");\n              if (compareAndSetState(current, next))\n                  return true;\n          }\n      }\n    \t//运行期间减少许可证的数量\n      final void reducePermits(int reductions) {\n          for (;;) {\n              int current = getState();\n              int next = current - reductions;\n              if (next > current) // underflow\n                  throw new Error(\"Permit count underflow\");\n              if (compareAndSetState(current, next))\n                  return;\n          }\n      }\n    //清空所有许可证\n      final int drainPermits() {\n          for (;;) {\n              int current = getState();\n              if (current == 0 || compareAndSetState(current, 0))\n                  return current;\n          }\n      }\n  }\n  ```\n\n- 获取许可证并运行\n\n  ```java\n  //获取许可证，如果失败，进入等待队列阻塞，阻塞期间允许中断\n  public void acquire(int permits) throws InterruptedException {\n  \tif (permits < 0) throw new IllegalArgumentException();\n          sync.acquireSharedInterruptibly(permits);\n  }\n  //获取许可证，如果失败，进入等待队列阻塞，阻塞期间不允许中断\n  public void acquireUninterruptibly(int permits) {\n  \tif (permits < 0) throw new IllegalArgumentException();\n  \t\tsync.acquireShared(permits);\n  }\n  //获取许可证，如果失败，返回false\n  public boolean tryAcquire(int permits) {\n    if (permits < 0) throw new IllegalArgumentException();\n          return sync.nonfairTryAcquireShared(permits) >= 0;\n  }\n  //指定超时时间\n  public boolean tryAcquire(int permits, long timeout, TimeUnit unit)\n  throws InterruptedException {\n      if (permits < 0) throw new IllegalArgumentException();\n      return sync.tryAcquireSharedNanos(permits, unit.toNanos(timeout));\n  }\n  ```\n\n- 释放许可证\n\n  ```java\n  public void release(int permits) {\n      if (permits < 0) throw new IllegalArgumentException();\n      sync.releaseShared(permits);\n  }\n  ```\n\n- 运行区间动态修改许可证的总数\n\n  ```java\n  protected void reducePermits(int reduction) {\n      if (reduction < 0) throw new IllegalArgumentException();\n      sync.reducePermits(reduction);\n  }\n  public int drainPermits() { //清空剩余的许可证\n    return sync.drainPermits();\n  }\n  ```","slug":"多线程/java并发之Semaphore","published":1,"updated":"2018-09-12T03:03:21.831Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfni3005lwlkvn10xlovu"},{"title":"java并发之StampedLock","date":"2017-10-29T01:37:47.000Z","_content":"\n# java并发之StampedLock \n\nStamedLock 防止读线程多的时候写线程饥饿现象，读不阻塞写，写成功后重读\n\n<!--more-->","source":"_posts/多线程/java并发之StampedLock.md","raw":"---\ntitle: java并发之StampedLock\ndate: 2017-10-29 09:37:47\ntags:\n- 多线程\ncategories:\n- java基础\n\n---\n\n# java并发之StampedLock \n\nStamedLock 防止读线程多的时候写线程饥饿现象，读不阻塞写，写成功后重读\n\n<!--more-->","slug":"多线程/java并发之StampedLock","published":1,"updated":"2018-09-12T03:03:21.831Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfni4005owlkvzjfn4hi5"},{"title":"java并发之ThreadLocal","date":"2017-11-13T09:19:15.000Z","_content":"\n# java并发之ThreadLocal\n\n多线程中存在共享变量并发的问题，如果每个线程的变量只能自己才能访问到，那么就不会存在线程安全问题。ThreadLocal就是jdk中提供了用于存储线程本地变量的类。\n\n对于多线程资源共享的问题，同步机制采用了“以时间换空间”的方式，而ThreadLocal采用了“以空间换时间”的方式。\n\n<!--more-->\n\n## 实现原理\n\n- 每个线程都一个一个threadLocals变量，是一个map，定义在Thread类中，通过ThreadLocal进行初始化。用于存储线程所有的ThreadLocal\n\n  ```java\n  ThreadLocal.ThreadLocalMap threadLocals = null;\n  ```\n\n- ThreadLocal的set方法，获取当前线程的threadLocals变量，如果不为空则以当前threadLocal对象为key，存储变量\n\n  值得**注意**：map中的key是threadLocal对象，这是因为一个线程可以持有多个threadLocal对象\n\n  ```java\n  public void set(T value) {\n      Thread t = Thread.currentThread();\n      ThreadLocalMap map = getMap(t);//获取当前线程的threadLocals\n      if (map != null)\n          map.set(this, value);\n      else\n          createMap(t, value);\n  }\n  ```\n\n- 如果没有map，则创建map，并存储变量\n\n  ```java\n  void createMap(Thread t, T firstValue) {\n      t.threadLocals = new ThreadLocalMap(this, firstValue);\n  }\n  ```\n\n- ThreadLocal的get方法，先获取当前线程的ThreadLocalMap，然后以调用者threadLocal为key获取变量\n\n  ```java\n  public T get() {\n      Thread t = Thread.currentThread();\n      ThreadLocalMap map = getMap(t);//t.threadLocals\n      if (map != null) {\n          ThreadLocalMap.Entry e = map.getEntry(this);\n          if (e != null) {\n              @SuppressWarnings(\"unchecked\")\n              T result = (T)e.value;\n              return result;\n          }\n      }\n      return setInitialValue();\n  }\n  ```\n\n- ThreadLocal的remove方法，移除以当前ThreadLocal对象为key的值\n\n  ```java\n  public void remove() {\n      ThreadLocalMap m = getMap(Thread.currentThread());\n      if (m != null)\n          m.remove(this);\n  }\n  ```\n\n## 父子线程间通信InheritableThreadLocal\n\n- Thread类中有属性用于父线程给子线程传递变量\n\n  ```java\n  ThreadLocal.ThreadLocalMap inheritableThreadLocals = null;\n  ```\n\n- InheritableThreadLocal继承ThreadLocal，用于父线程向子线程传递变量\n\n  ```java\n  public class InheritableThreadLocal<T> extends ThreadLocal<T> {\n     //为子线程传递变量\n      protected T childValue(T parentValue) {\n          return parentValue;\n      }\n  \t//覆写 getMap 返回inheritableThreadLocals\n      ThreadLocalMap getMap(Thread t) {\n         return t.inheritableThreadLocals;\n      }\n  \t//覆写 createMap 创建ThreadLocalMap并为inheritableThreadLocals赋值\n      void createMap(Thread t, T firstValue) {\n          t.inheritableThreadLocals = new ThreadLocalMap(this, firstValue);\n      }\n  }\n  ```\n\n- Thread创建的时候在init方法中会判断父线程的inheritableThreadLocals是否为空，如果不为空会把父线程中inheritableThreadLocals定义属性拷贝一份到当前线程的inheritableThreadLocals中\n\n  ```java\n  private void init(ThreadGroup g, Runnable target, String name,\n                    long stackSize, AccessControlContext acc) {\n    ...\n    Thread parent = currentThread();\n    ...\n      if (parent.inheritableThreadLocals != null)\n        this.inheritableThreadLocals = ThreadLocal.createInheritedMap(parent.inheritableThreadLocals);\n    ...\n  }\n  ```\n\n- ThreadLocal中对父线程中的inheritableThreadLocals属性进行了浅拷贝，key和value都是原来的引用地址，这样子线程通过InheritableThreadLocal的get方法就能获取到父线程中定义的引用，通过引用访问变量\n\n  ```java\n  static ThreadLocalMap createInheritedMap(ThreadLocalMap parentMap) {\n      return new ThreadLocalMap(parentMap);\n  }\n  private ThreadLocalMap(ThreadLocalMap parentMap) {\n    Entry[] parentTable = parentMap.table;\n    int len = parentTable.length;\n    setThreshold(len);\n    table = new Entry[len];\n\n    for (int j = 0; j < len; j++) {\n      Entry e = parentTable[j];\n      if (e != null) {\n        @SuppressWarnings(\"unchecked\")\n        ThreadLocal<Object> key = (ThreadLocal<Object>) e.get();\n        if (key != null) {\n          Object value = key.childValue(e.value);\n          Entry c = new Entry(key, value);\n          int h = key.threadLocalHashCode & (len - 1);\n          while (table[h] != null)\n            h = nextIndex(h, len);\n          table[h] = c;\n          size++;\n        }\n      }\n    }\n  }\n  ```\n\n## 用法 \n\n- InheritableThreadLocal 可以继承父线程的属性值\n\n```java\npublic class TestThreadLocal{\n\n\tstatic final ThreadLocal<String> threadLocal = new ThreadLocal<String>();\n\tstatic final InheritableThreadLocal<String> inheritableThreadLocal = new InheritableThreadLocal<String>();\n\tpublic static void main(String[] args) {\n\t\tthreadLocal.set(\"主线程局部变量\");\n\t\tinheritableThreadLocal.set(\"可继承的父类的局部变量\");\n\t\tnew Thread(new Runnable() {\n\t\t\t\n\t\t\t@Override\n\t\t\tpublic void run() {\n\t\t\t\tSystem.out.println(threadLocal.get());//null\n\t\t\t\tSystem.out.println(inheritableThreadLocal.get());//可继承的父类的局部变量\n\t\t\t}\n\t\t}).start();\n\t}\n}\n```\n\n- 自定义ThreadLocal\n\n```java\npublic class ThreadLocalTest\n{\n\tprivate static int data = 1;\n\n\tstatic ThreadLocal threadLocal = new ThreadLocal();\n\tpublic static void main(String[] args)\n\t{\n\t\tfor (int i = 0; i < 2; i++)\n\t\t{\n\t\t\tnew Thread(new Runnable()\n\t\t\t{\n\t\t\t\t@Override\n\t\t\t\tpublic void run()\n\t\t\t\t{\n\t\t\t\t\tint data = new Random().nextInt();\n\t\t\t\t\tMyThreadLocal.getInstance().put(\"data\", data);\n\t\t\t\t\tSystem.out.println(Thread.currentThread().getName()\n\t\t\t\t\t\t\t+ \" get data \" + data);\n\t\t\t\t\tSystem.out.println(Thread.currentThread().getName()\n\t\t\t\t\t\t\t+ MyThreadLocal.getInstance());\n\t\t\t\t\tnew A().get();\n\t\t\t\t\tnew B().get();\n\t\t\t\t}\n\t\t\t}).start();\n\t\t}\n\t}\n\n\tstatic class A\n\t{\n\t\tpublic void get()\n\t\t{\n\t\t\tSystem.out.println(\"A from \" + Thread.currentThread().getName()\n\t\t\t\t\t+ \" get data \" + MyThreadLocal.getInstance().get(\"data\"));\n\t\t}\n\t}\n\n\tstatic class B\n\t{\n\t\tpublic void get()\n\t\t{\n\t\t\tSystem.out.println(\"B from \" + Thread.currentThread().getName()\n\t\t\t\t\t+ \" get data \" + MyThreadLocal.getInstance().get(\"data\"));\n\t\t}\n\t}\n\n\tstatic class MyThreadLocal extends HashMap\n\t{\n\t\tprivate MyThreadLocal()\n\t\t{\n\t\t};\n\t\tprivate static MyThreadLocal instance;\n\n\t\tpublic static MyThreadLocal getInstance()\n\t\t{// 因为每个线程不一样对象，所以不需要添加同步\n\t\t\tif (threadLocal.get() == null)\n\t\t\t{\n\t\t\t\tinstance = new MyThreadLocal();\n\t\t\t\tmap.set(instance);\n\t\t\t}\n\t\t\treturn (MyThreadLocal) map.get();\n\t\t}\n\t}\n}\n```\n- 数据库连接实现线程绑定\n\n```java\nimport java.io.InputStream;\nimport java.sql.Connection;\nimport java.sql.DriverManager;\nimport java.sql.ResultSet;\nimport java.sql.SQLException;\nimport java.sql.Statement;\nimport java.util.Properties;\n\nimport cn.zlz.exception.DaoException;\n\npublic class JdbcUtils {\n\t\n\tprivate JdbcUtils(){}\n\t\n\tprivate static String url;\n\tprivate static String user;\n\tprivate static String password;\n\t\n\t\n\tprivate static ThreadLocal<Connection> tl = new ThreadLocal<Connection>();\n\t\n\t// 将四要素抽取至配置文件\n\tstatic {\n\t\ttry {\n\t\t\t//读取配置文件   获得四要素\n\t\t\tProperties props = new Properties();\n\t\t\tInputStream inStream = JdbcUtils.class.getClassLoader()\n\t\t\t\t\t.getResourceAsStream(\"jdbc.properties\");\n\t\t\tprops.load(inStream);\n\t\t\t\n\t\t\tString driverClass = props.getProperty(\"driverClass\");\n\t\t\turl = props.getProperty(\"url\");\n\t\t\tuser = props.getProperty(\"user\");\n\t\t\tpassword = props.getProperty(\"password\");\n\t\t\t\n\t\t\t// 注册驱动\n\t\t\tClass.forName(driverClass);\n\t\t} catch (Exception e) {\n\t\t\tthrow new ExceptionInInitializerError(e);\n\t\t}\n\t}\n\t\n\t// 获得数据库连接\n\tpublic static Connection getConnection() throws SQLException {\n\t\t// 返回当前线程绑定的连接  原因是该连接上有事务\n\t\tConnection conn = tl.get();\n\t\t// 如果conn 为 null    说明线程上未绑定连接\n\t\tif(conn==null) {\n\t\t\t// 获得与数据库的连接\n\t\t\tconn = DriverManager.getConnection(url, user, password);\n\t\t\t// 绑定到当前线程\n\t\t\ttl.set(conn);\n\t\t}\n\t\treturn conn;\n\t}\n\t\n\t// 开启事务\n\tpublic static void startTransaction() {\n\t\ttry {\n\t\t\t// 获得当前线程上绑定的连接\n\t\t\tConnection conn = getConnection();\n\t\t\t// 开启事务\n\t\t\tconn.setAutoCommit(false);\n\t\t} catch (SQLException e) {\n\t\t\tthrow new DaoException(e);\n\t\t}\n\t}\n\t\n\t// 提交事务\n\tpublic static void commit() {\n\t\t// 获得当前线程上绑定的连接\n\t\tConnection conn = tl.get();\n\t\t// 判断\n\t\tif(conn!=null) {\n\t\t\ttry {\n\t\t\t\t// 如果线程上有连接 提交该连接事务\n\t\t\t\tconn.commit();\n\t\t\t} catch (SQLException e) {\n\t\t\t\tthrow new DaoException(e);\n\t\t\t}\n\t\t}\n\t}\n\t\n\t// 回滚事务\n\tpublic static void rollback() {\n\t\t// 获得当前线程上绑定的连接\n\t\tConnection conn = tl.get();\n\t\t// 判断\n\t\tif(conn!=null) {\n\t\t\ttry {\n\t\t\t\t// 如果线程上有连接 回滚事务\n\t\t\t\tconn.rollback();\n\t\t\t} catch (SQLException e) {\n\t\t\t\tthrow new DaoException(e);\n\t\t\t}\n\t\t}\n\t}\n\t\n\t// 关闭连接     关闭当前线程上绑定的连接\n\tpublic static void close() {\n\t\t// 获得当前线程上绑定的连接\n\t\tConnection conn = tl.get();\n\t\t// 判断\n\t\tif(conn!=null) {\n\t\t\ttry {\n\t\t\t\t// 如果线程上有连接 关闭连接\n\t\t\t\tconn.close();\n\t\t\t} catch (SQLException e) {\n\t\t\t\tthrow new DaoException(e);\n\t\t\t}\n\t\t\t// 移除当前线程绑定的 connnection 对象\n\t\t\ttl.remove();\n\t\t}\n\t}\n\t\n\tpublic static void release(Connection conn, Statement stmt, ResultSet rs) {\n\t\tif(rs!=null) {\n\t\t\ttry {\n\t\t\t\trs.close();\n\t\t\t} catch (SQLException e) {\n\t\t\t\te.printStackTrace();\n\t\t\t}\n\t\t\trs = null;\n\t\t}\n\t\t\n\t\tif(stmt!=null) {\n\t\t\ttry {\n\t\t\t\tstmt.close();\n\t\t\t} catch (SQLException e) {\n\t\t\t\te.printStackTrace();\n\t\t\t}\n\t\t\tstmt = null;\n\t\t}\n\t\t\n\t\tif(conn!=null) {\n\t\t\ttry {\n\t\t\t\tconn.close();\n\t\t\t} catch (SQLException e) {\n\t\t\t\te.printStackTrace();\n\t\t\t}\n\t\t\tconn = null;\n\t\t}\n\t}\n}\n```\n## 参考资料","source":"_posts/多线程/java并发之ThreadLocal.md","raw":"---\ntitle: java并发之ThreadLocal\ndate: 2017-11-13 17:19:15\ntags:\n- 多线程\ncategories:\n- java基础\n---\n\n# java并发之ThreadLocal\n\n多线程中存在共享变量并发的问题，如果每个线程的变量只能自己才能访问到，那么就不会存在线程安全问题。ThreadLocal就是jdk中提供了用于存储线程本地变量的类。\n\n对于多线程资源共享的问题，同步机制采用了“以时间换空间”的方式，而ThreadLocal采用了“以空间换时间”的方式。\n\n<!--more-->\n\n## 实现原理\n\n- 每个线程都一个一个threadLocals变量，是一个map，定义在Thread类中，通过ThreadLocal进行初始化。用于存储线程所有的ThreadLocal\n\n  ```java\n  ThreadLocal.ThreadLocalMap threadLocals = null;\n  ```\n\n- ThreadLocal的set方法，获取当前线程的threadLocals变量，如果不为空则以当前threadLocal对象为key，存储变量\n\n  值得**注意**：map中的key是threadLocal对象，这是因为一个线程可以持有多个threadLocal对象\n\n  ```java\n  public void set(T value) {\n      Thread t = Thread.currentThread();\n      ThreadLocalMap map = getMap(t);//获取当前线程的threadLocals\n      if (map != null)\n          map.set(this, value);\n      else\n          createMap(t, value);\n  }\n  ```\n\n- 如果没有map，则创建map，并存储变量\n\n  ```java\n  void createMap(Thread t, T firstValue) {\n      t.threadLocals = new ThreadLocalMap(this, firstValue);\n  }\n  ```\n\n- ThreadLocal的get方法，先获取当前线程的ThreadLocalMap，然后以调用者threadLocal为key获取变量\n\n  ```java\n  public T get() {\n      Thread t = Thread.currentThread();\n      ThreadLocalMap map = getMap(t);//t.threadLocals\n      if (map != null) {\n          ThreadLocalMap.Entry e = map.getEntry(this);\n          if (e != null) {\n              @SuppressWarnings(\"unchecked\")\n              T result = (T)e.value;\n              return result;\n          }\n      }\n      return setInitialValue();\n  }\n  ```\n\n- ThreadLocal的remove方法，移除以当前ThreadLocal对象为key的值\n\n  ```java\n  public void remove() {\n      ThreadLocalMap m = getMap(Thread.currentThread());\n      if (m != null)\n          m.remove(this);\n  }\n  ```\n\n## 父子线程间通信InheritableThreadLocal\n\n- Thread类中有属性用于父线程给子线程传递变量\n\n  ```java\n  ThreadLocal.ThreadLocalMap inheritableThreadLocals = null;\n  ```\n\n- InheritableThreadLocal继承ThreadLocal，用于父线程向子线程传递变量\n\n  ```java\n  public class InheritableThreadLocal<T> extends ThreadLocal<T> {\n     //为子线程传递变量\n      protected T childValue(T parentValue) {\n          return parentValue;\n      }\n  \t//覆写 getMap 返回inheritableThreadLocals\n      ThreadLocalMap getMap(Thread t) {\n         return t.inheritableThreadLocals;\n      }\n  \t//覆写 createMap 创建ThreadLocalMap并为inheritableThreadLocals赋值\n      void createMap(Thread t, T firstValue) {\n          t.inheritableThreadLocals = new ThreadLocalMap(this, firstValue);\n      }\n  }\n  ```\n\n- Thread创建的时候在init方法中会判断父线程的inheritableThreadLocals是否为空，如果不为空会把父线程中inheritableThreadLocals定义属性拷贝一份到当前线程的inheritableThreadLocals中\n\n  ```java\n  private void init(ThreadGroup g, Runnable target, String name,\n                    long stackSize, AccessControlContext acc) {\n    ...\n    Thread parent = currentThread();\n    ...\n      if (parent.inheritableThreadLocals != null)\n        this.inheritableThreadLocals = ThreadLocal.createInheritedMap(parent.inheritableThreadLocals);\n    ...\n  }\n  ```\n\n- ThreadLocal中对父线程中的inheritableThreadLocals属性进行了浅拷贝，key和value都是原来的引用地址，这样子线程通过InheritableThreadLocal的get方法就能获取到父线程中定义的引用，通过引用访问变量\n\n  ```java\n  static ThreadLocalMap createInheritedMap(ThreadLocalMap parentMap) {\n      return new ThreadLocalMap(parentMap);\n  }\n  private ThreadLocalMap(ThreadLocalMap parentMap) {\n    Entry[] parentTable = parentMap.table;\n    int len = parentTable.length;\n    setThreshold(len);\n    table = new Entry[len];\n\n    for (int j = 0; j < len; j++) {\n      Entry e = parentTable[j];\n      if (e != null) {\n        @SuppressWarnings(\"unchecked\")\n        ThreadLocal<Object> key = (ThreadLocal<Object>) e.get();\n        if (key != null) {\n          Object value = key.childValue(e.value);\n          Entry c = new Entry(key, value);\n          int h = key.threadLocalHashCode & (len - 1);\n          while (table[h] != null)\n            h = nextIndex(h, len);\n          table[h] = c;\n          size++;\n        }\n      }\n    }\n  }\n  ```\n\n## 用法 \n\n- InheritableThreadLocal 可以继承父线程的属性值\n\n```java\npublic class TestThreadLocal{\n\n\tstatic final ThreadLocal<String> threadLocal = new ThreadLocal<String>();\n\tstatic final InheritableThreadLocal<String> inheritableThreadLocal = new InheritableThreadLocal<String>();\n\tpublic static void main(String[] args) {\n\t\tthreadLocal.set(\"主线程局部变量\");\n\t\tinheritableThreadLocal.set(\"可继承的父类的局部变量\");\n\t\tnew Thread(new Runnable() {\n\t\t\t\n\t\t\t@Override\n\t\t\tpublic void run() {\n\t\t\t\tSystem.out.println(threadLocal.get());//null\n\t\t\t\tSystem.out.println(inheritableThreadLocal.get());//可继承的父类的局部变量\n\t\t\t}\n\t\t}).start();\n\t}\n}\n```\n\n- 自定义ThreadLocal\n\n```java\npublic class ThreadLocalTest\n{\n\tprivate static int data = 1;\n\n\tstatic ThreadLocal threadLocal = new ThreadLocal();\n\tpublic static void main(String[] args)\n\t{\n\t\tfor (int i = 0; i < 2; i++)\n\t\t{\n\t\t\tnew Thread(new Runnable()\n\t\t\t{\n\t\t\t\t@Override\n\t\t\t\tpublic void run()\n\t\t\t\t{\n\t\t\t\t\tint data = new Random().nextInt();\n\t\t\t\t\tMyThreadLocal.getInstance().put(\"data\", data);\n\t\t\t\t\tSystem.out.println(Thread.currentThread().getName()\n\t\t\t\t\t\t\t+ \" get data \" + data);\n\t\t\t\t\tSystem.out.println(Thread.currentThread().getName()\n\t\t\t\t\t\t\t+ MyThreadLocal.getInstance());\n\t\t\t\t\tnew A().get();\n\t\t\t\t\tnew B().get();\n\t\t\t\t}\n\t\t\t}).start();\n\t\t}\n\t}\n\n\tstatic class A\n\t{\n\t\tpublic void get()\n\t\t{\n\t\t\tSystem.out.println(\"A from \" + Thread.currentThread().getName()\n\t\t\t\t\t+ \" get data \" + MyThreadLocal.getInstance().get(\"data\"));\n\t\t}\n\t}\n\n\tstatic class B\n\t{\n\t\tpublic void get()\n\t\t{\n\t\t\tSystem.out.println(\"B from \" + Thread.currentThread().getName()\n\t\t\t\t\t+ \" get data \" + MyThreadLocal.getInstance().get(\"data\"));\n\t\t}\n\t}\n\n\tstatic class MyThreadLocal extends HashMap\n\t{\n\t\tprivate MyThreadLocal()\n\t\t{\n\t\t};\n\t\tprivate static MyThreadLocal instance;\n\n\t\tpublic static MyThreadLocal getInstance()\n\t\t{// 因为每个线程不一样对象，所以不需要添加同步\n\t\t\tif (threadLocal.get() == null)\n\t\t\t{\n\t\t\t\tinstance = new MyThreadLocal();\n\t\t\t\tmap.set(instance);\n\t\t\t}\n\t\t\treturn (MyThreadLocal) map.get();\n\t\t}\n\t}\n}\n```\n- 数据库连接实现线程绑定\n\n```java\nimport java.io.InputStream;\nimport java.sql.Connection;\nimport java.sql.DriverManager;\nimport java.sql.ResultSet;\nimport java.sql.SQLException;\nimport java.sql.Statement;\nimport java.util.Properties;\n\nimport cn.zlz.exception.DaoException;\n\npublic class JdbcUtils {\n\t\n\tprivate JdbcUtils(){}\n\t\n\tprivate static String url;\n\tprivate static String user;\n\tprivate static String password;\n\t\n\t\n\tprivate static ThreadLocal<Connection> tl = new ThreadLocal<Connection>();\n\t\n\t// 将四要素抽取至配置文件\n\tstatic {\n\t\ttry {\n\t\t\t//读取配置文件   获得四要素\n\t\t\tProperties props = new Properties();\n\t\t\tInputStream inStream = JdbcUtils.class.getClassLoader()\n\t\t\t\t\t.getResourceAsStream(\"jdbc.properties\");\n\t\t\tprops.load(inStream);\n\t\t\t\n\t\t\tString driverClass = props.getProperty(\"driverClass\");\n\t\t\turl = props.getProperty(\"url\");\n\t\t\tuser = props.getProperty(\"user\");\n\t\t\tpassword = props.getProperty(\"password\");\n\t\t\t\n\t\t\t// 注册驱动\n\t\t\tClass.forName(driverClass);\n\t\t} catch (Exception e) {\n\t\t\tthrow new ExceptionInInitializerError(e);\n\t\t}\n\t}\n\t\n\t// 获得数据库连接\n\tpublic static Connection getConnection() throws SQLException {\n\t\t// 返回当前线程绑定的连接  原因是该连接上有事务\n\t\tConnection conn = tl.get();\n\t\t// 如果conn 为 null    说明线程上未绑定连接\n\t\tif(conn==null) {\n\t\t\t// 获得与数据库的连接\n\t\t\tconn = DriverManager.getConnection(url, user, password);\n\t\t\t// 绑定到当前线程\n\t\t\ttl.set(conn);\n\t\t}\n\t\treturn conn;\n\t}\n\t\n\t// 开启事务\n\tpublic static void startTransaction() {\n\t\ttry {\n\t\t\t// 获得当前线程上绑定的连接\n\t\t\tConnection conn = getConnection();\n\t\t\t// 开启事务\n\t\t\tconn.setAutoCommit(false);\n\t\t} catch (SQLException e) {\n\t\t\tthrow new DaoException(e);\n\t\t}\n\t}\n\t\n\t// 提交事务\n\tpublic static void commit() {\n\t\t// 获得当前线程上绑定的连接\n\t\tConnection conn = tl.get();\n\t\t// 判断\n\t\tif(conn!=null) {\n\t\t\ttry {\n\t\t\t\t// 如果线程上有连接 提交该连接事务\n\t\t\t\tconn.commit();\n\t\t\t} catch (SQLException e) {\n\t\t\t\tthrow new DaoException(e);\n\t\t\t}\n\t\t}\n\t}\n\t\n\t// 回滚事务\n\tpublic static void rollback() {\n\t\t// 获得当前线程上绑定的连接\n\t\tConnection conn = tl.get();\n\t\t// 判断\n\t\tif(conn!=null) {\n\t\t\ttry {\n\t\t\t\t// 如果线程上有连接 回滚事务\n\t\t\t\tconn.rollback();\n\t\t\t} catch (SQLException e) {\n\t\t\t\tthrow new DaoException(e);\n\t\t\t}\n\t\t}\n\t}\n\t\n\t// 关闭连接     关闭当前线程上绑定的连接\n\tpublic static void close() {\n\t\t// 获得当前线程上绑定的连接\n\t\tConnection conn = tl.get();\n\t\t// 判断\n\t\tif(conn!=null) {\n\t\t\ttry {\n\t\t\t\t// 如果线程上有连接 关闭连接\n\t\t\t\tconn.close();\n\t\t\t} catch (SQLException e) {\n\t\t\t\tthrow new DaoException(e);\n\t\t\t}\n\t\t\t// 移除当前线程绑定的 connnection 对象\n\t\t\ttl.remove();\n\t\t}\n\t}\n\t\n\tpublic static void release(Connection conn, Statement stmt, ResultSet rs) {\n\t\tif(rs!=null) {\n\t\t\ttry {\n\t\t\t\trs.close();\n\t\t\t} catch (SQLException e) {\n\t\t\t\te.printStackTrace();\n\t\t\t}\n\t\t\trs = null;\n\t\t}\n\t\t\n\t\tif(stmt!=null) {\n\t\t\ttry {\n\t\t\t\tstmt.close();\n\t\t\t} catch (SQLException e) {\n\t\t\t\te.printStackTrace();\n\t\t\t}\n\t\t\tstmt = null;\n\t\t}\n\t\t\n\t\tif(conn!=null) {\n\t\t\ttry {\n\t\t\t\tconn.close();\n\t\t\t} catch (SQLException e) {\n\t\t\t\te.printStackTrace();\n\t\t\t}\n\t\t\tconn = null;\n\t\t}\n\t}\n}\n```\n## 参考资料","slug":"多线程/java并发之ThreadLocal","published":1,"updated":"2018-09-12T03:03:21.832Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfni5005rwlkvhm7gmk8q"},{"title":"java并发之无锁CAS","date":"2017-10-29T01:28:53.000Z","_content":"\n# java并发之无锁CAS\n\n\n\n上面的乐观锁用到的机制就是CAS，Compare and Swap。\n\nCAS有3个操作数，内存值V，旧的预期值A，要修改的新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则什么都不做。\n\n非阻塞算法 （nonblocking algorithms）\n\n一个线程的失败或者挂起不应该影响其他线程的失败或挂起的算法。\n\n现代的CPU提供了特殊的指令，可以自动更新共享数据，而且能够检测到其他线程的干扰，而 compareAndSet() 就用这些代替了锁定。\n\n在没有锁的机制下可能需要借助volatile原语，保证线程间的数据是可见的（共享的）。\n\n\n\n在这里采用了CAS操作，每次从内存中读取数据然后将此数据和+1后的结果进行CAS操作，如果成功就返回结果，否则重试直到成功为止。\n\n而compareAndSet利用JNI来完成CPU指令的操作。\n\npublic final boolean compareAndSet(int expect, int update) {   \n\n​    return unsafe.compareAndSwapInt(this, valueOffset, expect, update);\n\n​    }\n\n整体的过程就是这样子的，利用CPU的CAS指令，同时借助JNI来完成Java的非阻塞算法。其它原子操作都是利用类似的特性完成的。\n\n而整个J.U.C都是建立在CAS之上的，因此对于synchronized阻塞算法，J.U.C在性能上有了很大的提升。\n\nCAS看起来很爽，但是会导致“ABA问题”。\n\nCAS算法实现一个重要前提需要取出内存中某时刻的数据，而在下时刻比较并替换，那么在这个时间差类会导致数据的变化。\n\n比如说一个线程one从内存位置V中取出A，这时候另一个线程two也从内存中取出A，并且two进行了一些操作变成了B，然后two又将V位置的数据变成A，这时候线程one进行CAS操作发现内存中仍然是A，然后one操作成功。尽管线程one的CAS操作成功，但是不代表这个过程就是没有问题的。如果链表的头在变化了两次后恢复了原值，但是不代表链表就没有变化。因此前面提到的原子操作AtomicStampedReference/AtomicMarkableReference就很有用了。这允许一对变化的元素进行原子操作。\n\n<!--more-->\n\n### 无锁优点\n\n- 当获取所有权失败后可以选择下一步操作，而不是只能被阻塞\n- 避免死锁和锁饿死情况\n- 线程不会被阻塞，线程的阻塞和恢复是非常\n- 耗费性能的，cpu 需要在内核态和用户态切换\n- 降低线程的延迟，少去阻塞和激活环节，提高了线程的响应速度\n\n\n\n乐观锁更好的用在竞争比较低的场景，如果竞争激烈，线程会浪费很多cpu时间周期做无谓的变量拷贝和修改，并且最后还失败。\n\n1、使用CAS在线程冲突严重时，会大幅降低程序性能；CAS只适合于线程冲突较少的情况使用。\n\n2、synchronized在jdk1.6之后，已经改进优化。synchronized的底层实现主要依靠Lock-Free的队列，基本思路是自旋后阻塞，竞争切换后继续竞争锁，稍微牺牲了公平性，但获得了高吞吐量。在线程冲突较少的情况下，可以获得和CAS类似的性能；而线程冲突严重的情况下，性能远高于CAS。\n\n使用AutomicReference 的时候，修改时会拷贝一个对象，然后修改拷贝后的对象，cas设置变量指针指向新的对象，当对象很大的时候，会浪费很多cpu 时间周期进行对象的拷贝\n\n\n\nsynchronized锁机制存在以下问题：\n\n（1）在多线程竞争下，加锁、释放锁会导致比较多的上下文切换和调度延时，引起性能问题。\n\n（2）一个线程持有锁会导致其它所有需要此锁的线程挂起。\n\n（3）如果一个优先级高的线程等待一个优先级低的线程释放锁会导致优先级倒置，引起性能风险。\n\nvolatile是不错的机制，但是volatile不能保证原子性。因此对于同步最终还是要回到锁机制上来。\n\n独占锁是一种悲观锁，synchronized就是一种独占锁，会导致其它所有需要锁的线程挂起，等待持有锁的线程释放锁。而另一个更加有效的锁就是乐观锁。所谓乐观锁就是，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。\n\n\n\n[抓紧时间看下啊](http://zl198751.iteye.com/blog/1848575?hmsr=toutiao.io&utm_medium=toutiao.io&utm_source=toutiao.io)","source":"_posts/多线程/java并发之无锁CAS.md","raw":"---\ntitle: java并发之无锁CAS\ndate: 2017-10-29 09:28:53\ntags:\n- 多线程\ncategories:\n- java基础\n---\n\n# java并发之无锁CAS\n\n\n\n上面的乐观锁用到的机制就是CAS，Compare and Swap。\n\nCAS有3个操作数，内存值V，旧的预期值A，要修改的新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则什么都不做。\n\n非阻塞算法 （nonblocking algorithms）\n\n一个线程的失败或者挂起不应该影响其他线程的失败或挂起的算法。\n\n现代的CPU提供了特殊的指令，可以自动更新共享数据，而且能够检测到其他线程的干扰，而 compareAndSet() 就用这些代替了锁定。\n\n在没有锁的机制下可能需要借助volatile原语，保证线程间的数据是可见的（共享的）。\n\n\n\n在这里采用了CAS操作，每次从内存中读取数据然后将此数据和+1后的结果进行CAS操作，如果成功就返回结果，否则重试直到成功为止。\n\n而compareAndSet利用JNI来完成CPU指令的操作。\n\npublic final boolean compareAndSet(int expect, int update) {   \n\n​    return unsafe.compareAndSwapInt(this, valueOffset, expect, update);\n\n​    }\n\n整体的过程就是这样子的，利用CPU的CAS指令，同时借助JNI来完成Java的非阻塞算法。其它原子操作都是利用类似的特性完成的。\n\n而整个J.U.C都是建立在CAS之上的，因此对于synchronized阻塞算法，J.U.C在性能上有了很大的提升。\n\nCAS看起来很爽，但是会导致“ABA问题”。\n\nCAS算法实现一个重要前提需要取出内存中某时刻的数据，而在下时刻比较并替换，那么在这个时间差类会导致数据的变化。\n\n比如说一个线程one从内存位置V中取出A，这时候另一个线程two也从内存中取出A，并且two进行了一些操作变成了B，然后two又将V位置的数据变成A，这时候线程one进行CAS操作发现内存中仍然是A，然后one操作成功。尽管线程one的CAS操作成功，但是不代表这个过程就是没有问题的。如果链表的头在变化了两次后恢复了原值，但是不代表链表就没有变化。因此前面提到的原子操作AtomicStampedReference/AtomicMarkableReference就很有用了。这允许一对变化的元素进行原子操作。\n\n<!--more-->\n\n### 无锁优点\n\n- 当获取所有权失败后可以选择下一步操作，而不是只能被阻塞\n- 避免死锁和锁饿死情况\n- 线程不会被阻塞，线程的阻塞和恢复是非常\n- 耗费性能的，cpu 需要在内核态和用户态切换\n- 降低线程的延迟，少去阻塞和激活环节，提高了线程的响应速度\n\n\n\n乐观锁更好的用在竞争比较低的场景，如果竞争激烈，线程会浪费很多cpu时间周期做无谓的变量拷贝和修改，并且最后还失败。\n\n1、使用CAS在线程冲突严重时，会大幅降低程序性能；CAS只适合于线程冲突较少的情况使用。\n\n2、synchronized在jdk1.6之后，已经改进优化。synchronized的底层实现主要依靠Lock-Free的队列，基本思路是自旋后阻塞，竞争切换后继续竞争锁，稍微牺牲了公平性，但获得了高吞吐量。在线程冲突较少的情况下，可以获得和CAS类似的性能；而线程冲突严重的情况下，性能远高于CAS。\n\n使用AutomicReference 的时候，修改时会拷贝一个对象，然后修改拷贝后的对象，cas设置变量指针指向新的对象，当对象很大的时候，会浪费很多cpu 时间周期进行对象的拷贝\n\n\n\nsynchronized锁机制存在以下问题：\n\n（1）在多线程竞争下，加锁、释放锁会导致比较多的上下文切换和调度延时，引起性能问题。\n\n（2）一个线程持有锁会导致其它所有需要此锁的线程挂起。\n\n（3）如果一个优先级高的线程等待一个优先级低的线程释放锁会导致优先级倒置，引起性能风险。\n\nvolatile是不错的机制，但是volatile不能保证原子性。因此对于同步最终还是要回到锁机制上来。\n\n独占锁是一种悲观锁，synchronized就是一种独占锁，会导致其它所有需要锁的线程挂起，等待持有锁的线程释放锁。而另一个更加有效的锁就是乐观锁。所谓乐观锁就是，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。\n\n\n\n[抓紧时间看下啊](http://zl198751.iteye.com/blog/1848575?hmsr=toutiao.io&utm_medium=toutiao.io&utm_source=toutiao.io)","slug":"多线程/java并发之无锁CAS","published":1,"updated":"2018-09-12T03:03:21.832Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfni6005uwlkvqglxflg5"},{"title":"java线程","date":"2017-09-01T03:51:24.000Z","_content":"\n# java线程\n\n在早期的操作系统中并没有线程的概念，进程是能拥有资源和独立运行的最小单位，也是程序执行的最小单位。任务调度采用的是时间片轮转的抢占式调度方式，而进程是任务调度的最小单位，每个进程有各自独立的一块内存，使得各个进程之间内存地址相互隔离。\n\n后来，随着计算机的发展，对CPU的要求越来越高，进程之间的切换开销较大，已经无法满足越来越复杂的程序的要求了。于是就发明了线程，线程是程序执行中一个单一的顺序控制流程，是程序执行流的最小单元，是处理器调度和分派的基本单位。一个进程可以有一个或多个线程，各个线程之间共享程序的内存空间(也就是所在进程的内存空间)。一个标准的线程由线程ID、当前指令指针(PC)、寄存器和堆栈组成。而进程由内存空间(代码、数据、进程空间、打开的文件)和一个或多个线程组成。\n\n## 两种创建线程的方式\n\n- 继承Thread类覆写run方法\n\n```java\nThread thread = new Thread()\n{\n  @Override\n  public void run()\n  { \n    System.out.println(\"执行线程\");\n  }\n}\nthread.start();\n```\n\n- 实现runnable接口\n\n```java\nnew Thread(new Runnable()\n           {\n               @Override\n               public void run()\n               {\n                   System.out.println(\"执行线程\");\n               }\n           }\n          ).start();\n```\n\n当一个线程既覆写了Thread的run方法，又实现类Runnable接口，那么是执行覆写的run方法还是执行Runnable接口中的run方法？答案是执行覆写的run方法，因为重写了run方法，不会再执行Thread中的run方法，也就不会执行到Runnable中的run方法\n\n```java\n@Override\npublic void run() {\n  if (target != null) {\n    target.run();\n  }\n}\n```\n\n建议使用实现Runnable接口,面向接口编程，同时线程池的情况下，如果是实现Runnable接口，可以把任务对象放入队列，等有空闲线程时再执行，如果是覆写Thread的run方法，导致创建一批Thread对象\n\n## start与run区别\n\n**start：** 启动线程，真正实现了多线程运行。这时此线程是处于就绪状态， 并没有运行。 然后通过此Thread类调用方法run()来完成其运行操作的， 这里方法run()称为线程体，它包含了要执行的这个线程的内容， run方法运行结束， 此线程终止,然后CPU再调度其它线程。\n\n**run：** 方法当作普通方法被主线程调用，程序还是要顺序执行，要等待run方法体执行完毕后，才可继续执行下面的代码， 程序中只有主线程这一个线程。 \n\n##  sleep 和 wait 区别\n\n\n- **Thread.sleep ()** ：使当前线程在指定的时间处于阻塞状态。**线程一直持有对象的锁** 。如果另一线程调用了 interrupt ()方法，它将唤醒那个“睡眠的”线程。使用Thread调用，**只对当前线程有效** 。线程唤醒后直接进入可运行状态。\n- **object.wait (long timeout)** ：使当前线程出于阻塞状态\n  1. 不能使用Thread调用，只能使用object调用，\n  2. 在调用wait前，**线程先要获取这个对象的对象锁，所以都是在同步代码块中调用wait** ，调用wait后，当前线程释放锁并把当前线程添加到等待队列中，随后另一线程B获取对象锁来调用 object.notify ()，将唤醒原来等待中的线程，线程B执行完毕后然后释放该锁。\n\n## sleep和yield的区别\n\n1. **sleep**方法暂停当前线程后，会给其他线程执行机会，不会理会线程的优先级。但**yield**则会给优先级相同或高优先级的线程执行机会,Thread.sleep(0)让某些优先级比较低的线程也能获取到CPU控制权,用于平衡CPU控制权\n2. **sleep**方法会将线程转入**阻塞状态**，直到经过阻塞时间才会转入到就绪状态；而**yield**则只是强制当前线程进入**就绪状态**,不会将线程转入到阻塞状态,因此完全有可能调用yield方法暂停之后，立即再次获得处理器资源继续运行。\n3. **sleep**声明抛出了InterruptedException异常，所以调用sleep方法时，要么捕获异常，要么抛出异常。而**yield**没有申明抛出任何异常\n\n## join方法\n\njoin方法内部实现调用的wait方法，t1.join() 当前线程会以t1为对象锁，然后当前线程进行阻塞等待状态，当t1运行完毕后t1对象销毁，然后当前线程持有的锁也就失效 了，当前线程从阻塞状态进入就绪状态\n\n以一个线程为对象锁，执行了wait方法之后，如果这个线程执行完毕会自动唤醒等待这个锁的线程\n\n```java\npublic final synchronized void join(long millis)throws InterruptedException {//使用synchronize\n  long base = System.currentTimeMillis();\n  long now = 0;\n  if (millis < 0) {\n    throw new IllegalArgumentException(\"timeout value is negative\");\n  }\n  if (millis == 0) {\n    while (isAlive()) {//防止是被interrupt唤醒的情况，必须要等到线程销毁\n      wait(0);\n    }\n  } else {\n    while (isAlive()) {\n      long delay = millis - now;\n      if (delay <= 0) {\n        break;\n      }\n      wait(delay);//进入阻塞状态\n      now = System.currentTimeMillis() - base;\n    }\n  }\n}\n```\n\n\n\n## 线程中断\n\n由于stop线程太暴力，所以使用中断指令可以使线程更加优雅的做出停止动作，中断不会对线程做任务动作，只是和线程进行一次通信，发出一个中断信号，线程在运行区间可以收到中断信号\n\n当线程wait后被interrupt，需要等待线程获到锁后才能响应中断\n\n- t.interrupt():用于中断线程。调用该方法的线程的状态为将被置为\"中断\"状态。线程中断仅仅是置线程的中断状态位，不会停止线程。需要用户自己去监视线程的状态为并做处理。\n- t.isInterrupted():用于判断线程是否被中断，调用该方法不会清除线程的中断状态，如果未true，多次调用还是true。\n- Thread.interrupted ():用于判断当前线程的中断状态，调用该方法会清除线程的中断状态，如果线程第一次调用为true，被清除后，第二次调用返回false，除非对线程再次调用interrupt()\n- sleep、wait状态的线程也可以响应中断，一旦线程被中断，会抛出InterruptedException，然后会jvm清除线程中断状态，所以在try catch中调用isInterrupted无法返回true，直接写逻辑就可以了。\n\n```java\nthread.interrupt();//调用线程中断\n@Override\npublic void run() {\n  synchronized (this) {\n    while (true) {\n      System.out.println(Thread.currentThread().getName() + \">>>>运行\");\n      if(Thread.currentThread().isInterrupted()){{//在运行区间，手动响应中断指示，做出反应\n        System.out.println(\"thread is interrupted\");\n        break;\n      }\n    }\n  }\n}\n  \n //sleep会抛出interruptException是希望线程在等待状态下也可以响应中断指令，从而做出\n  try{\n    Thread.sleep(2000);\n  } catch (InterruptedException e) {\n    System.out.println(\"Interruted When Sleep\");\n    //设置中断状态，抛出异常后会清除中断标记位，重新调用interrupt，在while中才能获取到中断标志\n    Thread.currentThread().interrupt();\n  }\n```\n\n## 线程优先级\n\n线程默认的优先级是创建它的执行线程的优先级。可以通过setPriority(int newPriority)更改线程的优先级\n\n线程优先级为1~10之间的正整数，JVM从不会改变一个线程的优先级。当设计多线程应用程序的时候，一定不要依赖于线程的优先级，因为JVM不会保证优先级高的线程先被执行，只是几率高\n\n## 守护线程\n\n在后台默默地完成一些系统性的服务，比如垃圾回收线程、JIT线程就可以理解为守护线程， 当一个Java应用内，只有守护线程时，Java虚拟机就会自然退出,如果前台的进程都死亡，那么后台进程也死亡\n\n在创建线程的时候，如果父类线程是守护线程，那么子类默认也会是守护线程，在创建线程池使用默认线程工厂的话，会默认设置为非守护线程\n\n```java\nThread t=new DaemonT();\nt.setDaemon(true);//必须要在start前设置\nt.start();\n\npublic Thread newThread(Runnable r) {\n    Thread t = new Thread(group, r,namePrefix + threadNumber.getAndIncrement(),0);\n    if (t.isDaemon())\n        t.setDaemon(false);\n    if (t.getPriority() != Thread.NORM_PRIORITY)\n        t.setPriority(Thread.NORM_PRIORITY);\n    return t;\n}\n```\n\n## 线程安全\n\n首先存在多个线程，操作共享变量，如果多个线程读共享变量不会发生线程安全问题，只有当多个线程同时对共享变量进行写操作的时候会发生线程安全问题\n\n线程安全问题解决方案\n\n- 避免操作共享变量\n- 多读单一写\n- 共享变量设计为不可变对象，如没有set方法\n- CAS操作\n- 加锁\n\n## Callable接口\n\nFuture是jdk对Future模式的实现，Future模式的核心就是异步\n\nFutureTask 实现了 Runnable 和 Future，所以兼顾两者优点，既可以在 Thread 中使用，又可以在 ExecutorService 中使用。\n\n```java\nCallable<String> callable = new Callable<String>() {\n    @Override\n    public String call() throws Exception {\n        return \"test\";\n    }\n};\nFutureTask<String> task = new FutureTask<String>(callable);\nThread t = new Thread(task);\nt.start(); // 启动线程\ntask.cancel(true); // 取消线程\n```\n\n使用 FutureTask 的好处是 FutureTask 是为了弥补 Thread 的不足而设计的，它可以让程序员准确地知道线程什么时候执行完成并获得到线程执行完成后返回的结果。FutureTask 是一种可以取消的异步的计算任务，它的计算是通过 Callable 实现的，它等价于可以携带结果的Runnable，并且有三个状态：等待、运行和完成。完成包括所有计算以任意的方式结束，包括正常结束、取消和异常。","source":"_posts/多线程/java线程.md","raw":"---\ntitle: java线程\ndate: 2017-09-01 11:51:24\ntags:\n- 多线程\ncategories:\n- java基础\n---\n\n# java线程\n\n在早期的操作系统中并没有线程的概念，进程是能拥有资源和独立运行的最小单位，也是程序执行的最小单位。任务调度采用的是时间片轮转的抢占式调度方式，而进程是任务调度的最小单位，每个进程有各自独立的一块内存，使得各个进程之间内存地址相互隔离。\n\n后来，随着计算机的发展，对CPU的要求越来越高，进程之间的切换开销较大，已经无法满足越来越复杂的程序的要求了。于是就发明了线程，线程是程序执行中一个单一的顺序控制流程，是程序执行流的最小单元，是处理器调度和分派的基本单位。一个进程可以有一个或多个线程，各个线程之间共享程序的内存空间(也就是所在进程的内存空间)。一个标准的线程由线程ID、当前指令指针(PC)、寄存器和堆栈组成。而进程由内存空间(代码、数据、进程空间、打开的文件)和一个或多个线程组成。\n\n## 两种创建线程的方式\n\n- 继承Thread类覆写run方法\n\n```java\nThread thread = new Thread()\n{\n  @Override\n  public void run()\n  { \n    System.out.println(\"执行线程\");\n  }\n}\nthread.start();\n```\n\n- 实现runnable接口\n\n```java\nnew Thread(new Runnable()\n           {\n               @Override\n               public void run()\n               {\n                   System.out.println(\"执行线程\");\n               }\n           }\n          ).start();\n```\n\n当一个线程既覆写了Thread的run方法，又实现类Runnable接口，那么是执行覆写的run方法还是执行Runnable接口中的run方法？答案是执行覆写的run方法，因为重写了run方法，不会再执行Thread中的run方法，也就不会执行到Runnable中的run方法\n\n```java\n@Override\npublic void run() {\n  if (target != null) {\n    target.run();\n  }\n}\n```\n\n建议使用实现Runnable接口,面向接口编程，同时线程池的情况下，如果是实现Runnable接口，可以把任务对象放入队列，等有空闲线程时再执行，如果是覆写Thread的run方法，导致创建一批Thread对象\n\n## start与run区别\n\n**start：** 启动线程，真正实现了多线程运行。这时此线程是处于就绪状态， 并没有运行。 然后通过此Thread类调用方法run()来完成其运行操作的， 这里方法run()称为线程体，它包含了要执行的这个线程的内容， run方法运行结束， 此线程终止,然后CPU再调度其它线程。\n\n**run：** 方法当作普通方法被主线程调用，程序还是要顺序执行，要等待run方法体执行完毕后，才可继续执行下面的代码， 程序中只有主线程这一个线程。 \n\n##  sleep 和 wait 区别\n\n\n- **Thread.sleep ()** ：使当前线程在指定的时间处于阻塞状态。**线程一直持有对象的锁** 。如果另一线程调用了 interrupt ()方法，它将唤醒那个“睡眠的”线程。使用Thread调用，**只对当前线程有效** 。线程唤醒后直接进入可运行状态。\n- **object.wait (long timeout)** ：使当前线程出于阻塞状态\n  1. 不能使用Thread调用，只能使用object调用，\n  2. 在调用wait前，**线程先要获取这个对象的对象锁，所以都是在同步代码块中调用wait** ，调用wait后，当前线程释放锁并把当前线程添加到等待队列中，随后另一线程B获取对象锁来调用 object.notify ()，将唤醒原来等待中的线程，线程B执行完毕后然后释放该锁。\n\n## sleep和yield的区别\n\n1. **sleep**方法暂停当前线程后，会给其他线程执行机会，不会理会线程的优先级。但**yield**则会给优先级相同或高优先级的线程执行机会,Thread.sleep(0)让某些优先级比较低的线程也能获取到CPU控制权,用于平衡CPU控制权\n2. **sleep**方法会将线程转入**阻塞状态**，直到经过阻塞时间才会转入到就绪状态；而**yield**则只是强制当前线程进入**就绪状态**,不会将线程转入到阻塞状态,因此完全有可能调用yield方法暂停之后，立即再次获得处理器资源继续运行。\n3. **sleep**声明抛出了InterruptedException异常，所以调用sleep方法时，要么捕获异常，要么抛出异常。而**yield**没有申明抛出任何异常\n\n## join方法\n\njoin方法内部实现调用的wait方法，t1.join() 当前线程会以t1为对象锁，然后当前线程进行阻塞等待状态，当t1运行完毕后t1对象销毁，然后当前线程持有的锁也就失效 了，当前线程从阻塞状态进入就绪状态\n\n以一个线程为对象锁，执行了wait方法之后，如果这个线程执行完毕会自动唤醒等待这个锁的线程\n\n```java\npublic final synchronized void join(long millis)throws InterruptedException {//使用synchronize\n  long base = System.currentTimeMillis();\n  long now = 0;\n  if (millis < 0) {\n    throw new IllegalArgumentException(\"timeout value is negative\");\n  }\n  if (millis == 0) {\n    while (isAlive()) {//防止是被interrupt唤醒的情况，必须要等到线程销毁\n      wait(0);\n    }\n  } else {\n    while (isAlive()) {\n      long delay = millis - now;\n      if (delay <= 0) {\n        break;\n      }\n      wait(delay);//进入阻塞状态\n      now = System.currentTimeMillis() - base;\n    }\n  }\n}\n```\n\n\n\n## 线程中断\n\n由于stop线程太暴力，所以使用中断指令可以使线程更加优雅的做出停止动作，中断不会对线程做任务动作，只是和线程进行一次通信，发出一个中断信号，线程在运行区间可以收到中断信号\n\n当线程wait后被interrupt，需要等待线程获到锁后才能响应中断\n\n- t.interrupt():用于中断线程。调用该方法的线程的状态为将被置为\"中断\"状态。线程中断仅仅是置线程的中断状态位，不会停止线程。需要用户自己去监视线程的状态为并做处理。\n- t.isInterrupted():用于判断线程是否被中断，调用该方法不会清除线程的中断状态，如果未true，多次调用还是true。\n- Thread.interrupted ():用于判断当前线程的中断状态，调用该方法会清除线程的中断状态，如果线程第一次调用为true，被清除后，第二次调用返回false，除非对线程再次调用interrupt()\n- sleep、wait状态的线程也可以响应中断，一旦线程被中断，会抛出InterruptedException，然后会jvm清除线程中断状态，所以在try catch中调用isInterrupted无法返回true，直接写逻辑就可以了。\n\n```java\nthread.interrupt();//调用线程中断\n@Override\npublic void run() {\n  synchronized (this) {\n    while (true) {\n      System.out.println(Thread.currentThread().getName() + \">>>>运行\");\n      if(Thread.currentThread().isInterrupted()){{//在运行区间，手动响应中断指示，做出反应\n        System.out.println(\"thread is interrupted\");\n        break;\n      }\n    }\n  }\n}\n  \n //sleep会抛出interruptException是希望线程在等待状态下也可以响应中断指令，从而做出\n  try{\n    Thread.sleep(2000);\n  } catch (InterruptedException e) {\n    System.out.println(\"Interruted When Sleep\");\n    //设置中断状态，抛出异常后会清除中断标记位，重新调用interrupt，在while中才能获取到中断标志\n    Thread.currentThread().interrupt();\n  }\n```\n\n## 线程优先级\n\n线程默认的优先级是创建它的执行线程的优先级。可以通过setPriority(int newPriority)更改线程的优先级\n\n线程优先级为1~10之间的正整数，JVM从不会改变一个线程的优先级。当设计多线程应用程序的时候，一定不要依赖于线程的优先级，因为JVM不会保证优先级高的线程先被执行，只是几率高\n\n## 守护线程\n\n在后台默默地完成一些系统性的服务，比如垃圾回收线程、JIT线程就可以理解为守护线程， 当一个Java应用内，只有守护线程时，Java虚拟机就会自然退出,如果前台的进程都死亡，那么后台进程也死亡\n\n在创建线程的时候，如果父类线程是守护线程，那么子类默认也会是守护线程，在创建线程池使用默认线程工厂的话，会默认设置为非守护线程\n\n```java\nThread t=new DaemonT();\nt.setDaemon(true);//必须要在start前设置\nt.start();\n\npublic Thread newThread(Runnable r) {\n    Thread t = new Thread(group, r,namePrefix + threadNumber.getAndIncrement(),0);\n    if (t.isDaemon())\n        t.setDaemon(false);\n    if (t.getPriority() != Thread.NORM_PRIORITY)\n        t.setPriority(Thread.NORM_PRIORITY);\n    return t;\n}\n```\n\n## 线程安全\n\n首先存在多个线程，操作共享变量，如果多个线程读共享变量不会发生线程安全问题，只有当多个线程同时对共享变量进行写操作的时候会发生线程安全问题\n\n线程安全问题解决方案\n\n- 避免操作共享变量\n- 多读单一写\n- 共享变量设计为不可变对象，如没有set方法\n- CAS操作\n- 加锁\n\n## Callable接口\n\nFuture是jdk对Future模式的实现，Future模式的核心就是异步\n\nFutureTask 实现了 Runnable 和 Future，所以兼顾两者优点，既可以在 Thread 中使用，又可以在 ExecutorService 中使用。\n\n```java\nCallable<String> callable = new Callable<String>() {\n    @Override\n    public String call() throws Exception {\n        return \"test\";\n    }\n};\nFutureTask<String> task = new FutureTask<String>(callable);\nThread t = new Thread(task);\nt.start(); // 启动线程\ntask.cancel(true); // 取消线程\n```\n\n使用 FutureTask 的好处是 FutureTask 是为了弥补 Thread 的不足而设计的，它可以让程序员准确地知道线程什么时候执行完成并获得到线程执行完成后返回的结果。FutureTask 是一种可以取消的异步的计算任务，它的计算是通过 Callable 实现的，它等价于可以携带结果的Runnable，并且有三个状态：等待、运行和完成。完成包括所有计算以任意的方式结束，包括正常结束、取消和异常。","slug":"多线程/java线程","published":1,"updated":"2018-09-12T03:03:21.832Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfni7005xwlkvpyleilhg"},{"title":"java线程池","date":"2017-09-01T07:51:24.000Z","_content":"\n#  线程池\n\n当需要使用多线程的时候，通常需要创建一个新的线程去执行程序，但是如果不停的创建线程，会消耗更多的内存，增加cpu切换的速度，那么这时就需要使用线程池控制对线程进行有效的控制,线程池不是为了提供性能，而是为了控制线程数量从而达到控制资源，防止内存溢出。\n\n<!--more-->\n\n线程池的优点：\n1. 降低系统资源消耗，通过重用已存在的线程，降低线程创建和销毁造成的消耗；\n2. 有效的控制线程的最大并发数，线程若是无限制的创建，会增加资源竞争，导致CPU切换严重引起阻塞、引发oom等。线程池能有效管控线程，统一分配、调优，提供资源使用率；\n3. 提高系统响应速度，当有任务到达时，立即执行，无需等待新线程的创建；\n4. 能够对线程进行简单的管理并提供定时执行、间隔执行等功能。\n\n\nExecutorService基于池化的线程来执行用户提交的任务，通常可以简单的通过Executors提供的工厂方法来创建ThreadPoolExecutor实例。\n\n主要包括以下几个方面:\n\n- 线程池大小参数的设置 \n- 工作线程的创建\n- 空闲线程的回收\n- 阻塞队列的使用\n- 任务拒绝策略\n- 线程池Hook\n\n## 线程池实现原理\n\n### 线程池的组成部分\n\n1. 线程池管理器：用于创建并管理线程池\n2. 工作线程：线程池中的线程\n3. 任务接口：每个任务必须实现的接口，用于工作线程调度其运行\n4. 任务队列：用于存放待处理的任务，提供一种缓冲机制\n\n### 线程池的实现方式\n\n​\t\t\t\t\t`ThreadPoolExecutor的构造函数`\n\n```java\npublic ThreadPoolExecutor(int corePoolSize,\n                              int maximumPoolSize,\n                              long keepAliveTime,\n                              TimeUnit unit,\n                              BlockingQueue<Runnable> workQueue,\n                              ThreadFactory threadFactory,\n                              RejectedExecutionHandler handler) {\n        if (corePoolSize < 0 ||\n            maximumPoolSize <= 0 ||\n            maximumPoolSize < corePoolSize ||\n            keepAliveTime < 0)\n            throw new IllegalArgumentException();\n        if (workQueue == null || threadFactory == null || handler == null)\n            throw new NullPointerException();\n        this.corePoolSize = corePoolSize;\n        this.maximumPoolSize = maximumPoolSize;\n        this.workQueue = workQueue;\n        this.keepAliveTime = unit.toNanos(keepAliveTime);\n        this.threadFactory = threadFactory;\n        this.handler = handler;\n    }\n```\n\n- corePoolSize：线程池的核心线程数，默认情况下会永远存活，当ThreadPoolExecutor 中的方法 allowCoreThreadTimeOut(boolean value) 设置为 true 时，如果在指定时间没有新任务来时，核心线程也会被终止\n- maximumPoolSize：线程池中允许的最大线程数，当队列满了，且已创建的线程数小于maximumPoolSize，则线程池会创建新的线程来执行任务。对于无界队列，可忽略该参数。\n- keepAliveTime：空闲线程结束的超时时间\n- unit：是一个枚举，它表示的是 keepAliveTime 的单位\n- workQueue：工作队列，用于存放任务\n- threadFactory：线程工厂，使用new Thread()为线程池提供新线程的创建，默认为DefaultThreadFactory类。由同一个threadFactory创建的线程，属于同一个ThreadGroup，创建的线程优先级都为Thread.NORM_PRIORITY\n- handler：拒绝策略，当线程数超过上限并且工作队列满了情况下对任务线程的处理策略，默认策略为ThreadPoolExecutor.AbortPolicy\n\n#### 线程池工作过程\n\n1. 线程池刚创建时，里面没有一个线程。任务队列是作为参数传进来的。不过，就算队列里面有任务，线程池也不会马上执行它们。\n\n2. 当调用 execute() 方法添加一个任务时，线程池会做如下判断：\n\n   - 如果正在运行的线程数量小于 corePoolSize，那么马上创建线程运行这个任务,即使线程池中的线程都处于空闲状态，也要创建新的线程来处理被添加的任务\n\n   - 如果正在运行的线程数量大于或等于 corePoolSize，那么将这个任务放入队列\n\n   - 如果这时候队列满了，而且正在运行的线程数量小于 maximumPoolSize，那么还是要创建非核心线程立刻运行这个任务\n\n   - 如果队列满了，而且正在运行的线程数量大于或等于 maximumPoolSize，那么线程池会抛出异常RejectExecutionException。\n\n     ```java\n     public void execute(Runnable command) {\n       if (command == null)\n         throw new NullPointerException();\n       int c = ctl.get();\n       //小于核心线程，则新建核心线程并执行任务\n       if (workerCountOf(c) < corePoolSize) {\n         //添加时检查线程数据\n         if (addWorker(command, true))\n           return;\n         c = ctl.get();\n       }\n       //添加队列成功需要再次检查线程池状态和线程数量\n       if (isRunning(c) && workQueue.offer(command)) {\n         int recheck = ctl.get();\n         //如果线程池停掉了 从队列移除任务并拒绝\n         if (! isRunning(recheck) && remove(command))\n           reject(command);\n         //如果线程数小了，创建额外线程，对线程池进行补偿，但是不执行任务\n         else if (workerCountOf(recheck) == 0)\n           addWorker(null, false);\n       }\n       //创建小于maxSize的线程并执行任务\n       else if (!addWorker(command, false))\n         reject(command);//失败调用拒绝策略\n     }\n     ```\n\n     ​\n\n   ![image](http://omdq6di7v.bkt.clouddn.com/17-9-4/28653757.jpg)\n\n   - 当一个线程完成任务时，它会从队列中取下一个任务来执行。\n   - 当一个线程无事可做，超过一定的时间（keepAliveTime）时，线程池会判断，如果当前运行的线程数大于 corePoolSize，那么这个线程就被停掉。所以线程池的所有任务完成后，它最终会收缩到 corePoolSize 的大小。\n   - submit当我们使用submit来提交任务时,它会返回一个future,我们就可以通过这个future来判断任务是否执行成功，还可以通过future的get方法来获取返回值。如果子线程任务没有完成，get方法会阻塞住直到任务完成，而使用get(long timeout, TimeUnit unit)方法则会阻塞一段时间后立即返回，这时候有可能任务并没有执行完。\n\n```java\npublic class CustomThreadPool {\n\n    public static void main(String[] args) {\n        //任务队列 LinkedBlockingQueue\n        //BlockingQueue<Runnable> workQueue = new LinkedBlockingQueue();//最多使用掉corePoolSize\n\n        //任务队列 ArrayBlockingQueue\n        /*\n            pool-1-thread-1：excute task0\n            pool-1-thread-4：excute task7 //当任务队列已满，线程池中线程数还未达到maxsize，创建新的线程执行新进来的任务\n            pool-1-thread-3：excute task2\n            pool-1-thread-5：excute task8\n            pool-1-thread-2：excute task1\n            java.util.concurrent.RejectedExecutionException: Task cn.zlz.pool.Task@63947c6b rejected from j...//拒绝\n            pool-1-thread-1：excute task3 //任务队列中的任务等待线程池中的线程空闲时执行\n            pool-1-thread-5：excute task4\n            pool-1-thread-3：excute task5\n            pool-1-thread-4：excute task6\n         */\n        BlockingQueue<Runnable> workQueue = new ArrayBlockingQueue<Runnable>(4);//\n\n        //线程工厂\n        ThreadFactory factory = Executors.defaultThreadFactory();\n        //拒绝策略\n        RejectedExecutionHandler handler = new ThreadPoolExecutor.AbortPolicy();\n\n        //创建线程池 coresize：3 max：5\n        ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(3, 5, 5l,\n                TimeUnit.MILLISECONDS, workQueue, factory, handler);\n        try {\n            for (int i = 0; i < 10; i++) {\n                threadPoolExecutor.execute(new Task(i));\n            }\n            System.out.println(\"main\");\n        }finally {\n            threadPoolExecutor.shutdown();//停止接收任务，并等待执行中的任务执行完毕后停止\n            //threadPoolExecutor.shutdownNow();//立即关闭线程池中的所有线程\n        }\n    }\n}\n\nclass Task implements Runnable{\n    private int index;\n    public Task (int index){\n        this.index = index;\n    }\n\n    @Override\n    public void run() {\n        System.out.println(Thread.currentThread().getName()+\"：excute task\"+index);\n        try {\n            Thread.sleep(3000);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n    }\n}\n```\n\n### 线程池状态\n\n- RUNNING：可以添加工作线程并执行队列中的任务\n- SHUTDOWN：停止创建新的工作线程并停止接收新的任务，等待当前剩余任务的执行完毕 SHUTDOWN()\n- STOP：停止创建新的工作线程，停止执行队列任务，中断正在执行的任务线程 shutdownNow()\n- TIDYING：任务队列为空，workerCount减为0，准备调用terminated方法 STOP -> TIDYING\n- TERMINATED：terminated方法执行完毕，所有线程都得到释放 terminated()\n\n#### 工作队列选择\n\n**直接递交：**\n\n- 工作队列的默认选项是 **SynchronousQueue**，这种队列会将提交的任务直接传送给工作线程，而不持有。如果当前没有工作线程来处理，即任务放入队列失败，则根据线程池的实现，会引发新的工作线程创建，因此新提交的任务会被处理。这种策略在当提交的一批任务之间有依赖关系的时候避免了锁竞争消耗。\n- 这种队列最好是配合maximumPoolSizes线程数来使用，从而避免任务被拒绝。同时我们必须要考虑到一种场景，当任务到来的速度大于任务处理的速度，将会引起无限制的线程数不断的增加。\n\n**无界队列：**\n\n- 使用无界队列如LinkedBlockingQueue没有指定最大容量的时候，将会引起当核心线程都在忙的时候，新的任务被放在队列上，因此，永远不会有大于corePoolSize的线程被创建，因此maximumPoolSize参数将失效。\n- 这种队列比较适合所有的任务都不相互依赖，独立执行。举个例子，如网页服务器中，每个线程独立处理请求。但是当任务处理速度小于任务进入速度的时候会引起队列的无限膨胀。\n\n**有界队列：**\n\n- 有界队列如ArrayBlockingQueue帮助限制资源的消耗，但是不容易控制。队列长度和maximumPoolSize这两个值会相互影响，使用大的队列和小maximumPoolSize会最大限度地降低 CPU 使用率、操作系统资源和上下文切换开销，但是会降低吞吐量，如果任务被频繁的阻塞如IO线程，系统其实可以调度更多的线程。使用小的队列通常需要大maximumPoolSize，这时CPU 使用率较高，但是可能遇到不可接受的调度开销，这样也会降低吞吐量。\n- 总结一下**是IO密集型可以考虑调大maximumPoolSize多些线程来平衡CPU的使用，CPU密集型可以考虑调销maximumPoolSize少些线程减少线程调度的消耗。**\n\n#### 空闲线程回收\n\n如果当前池子中的工作线程数大于corePoolSize，如果超过这个数字的线程处于空闲的时间大于keepAliveTime，则这些线程将会被终止，这是一种减少不必要资源消耗的策略。这个参数可以在运行时被改变，\n\n可以通过调用allowCoreThreadTimeout(true)将过期回收策略应用于核心线程进行回收。\n\n####  拒绝策略\n\n当新的任务到来的而线程池被关闭的时候，或线程数和队列已经达到上限的时候，需要拒绝任务，以下几种拒绝策略：\n\n- ThreadPoolExecutor.AbortPolicy：直接抛出RejectedExecutionException异常。\n- ThreadPoolExecutor.CallerRunsPolicy：使用调用者所线程来执行这个任务，这是一种feedback策略，会阻塞调用者线程，降低任务提交的速度。\n- ThreadPoolExecutor.DiscardPolicy：直接丢弃无法执行的任务\n- ThreadPoolExecutor.DiscardOldestPolicy：从任务队列头部开始丢弃任务，然后重新尝试执行新任务（如果再次失败，则重复此过程），一种类似最旧丢弃策略\n- 自定义拒绝策略：实现RejectedExecutionHandler自定义拒绝策略\n\n#### 线程池的执行\n\n- execute(Runnable)\n\n  异步执行一个runable对象，无法得知线程执行状态和结果\n\n  ```java\n  ExecutorService threadPool = Executors.newCachedThreadPool();//缓冲池\n  threadPool.execute(()->System.out.print(\"run\"));\n  ```\n\n\n- submit(Runnable)\n\n  异步执行一个runable对象，返回一个future对象，调用future.get()会阻塞主线程运行，获取线程运行结果，程序正常接收返回null\n\n  ```java\n  ExecutorService threadPool = Executors.newCachedThreadPool();//缓冲池\n  Future<?> future = threadPool.submit(() -> System.out.println(\"run\"));\n  try {\n    System.out.println(future.get());//null\n  } catch (InterruptedException e) {\n    e.printStackTrace();\n  } catch (ExecutionException e) {\n    e.printStackTrace();\n  }\n  ```\n\n- submit(Callable)\n\n  异步执行一个callable对象，返回一个future对象，通过future.get()可以获取callable的返回值\n\n  ```java\n  Future future = executorService.submit(n() -> return \"run\");\n  System.out.println(\"future.get() = \" + future.get());\n  ```\n\n- invokeAny()\n\n  提交一个callable对象集合，随机返回一个线程执行结果。只能表明其中一个已执行结束。\n\n  如果其中一个任务执行结束(或者抛了一个异常)，其他 Callable 将被取消\n\n  ```java\n  ExecutorService threadPool = Executors.newCachedThreadPool();//缓冲池\n  List<Callable<String>> list =new ArrayList();\n  list.add(()->\"task1\");\n  list.add(()->\"task2\");\n  list.add(()->\"task3\");\n  String result = threadPool.invokeAny(list);\n  System.out.println(result);//task1 or task2 or task3\n  threadPool.shutdown();\n  ```\n\n- invokeAll()\n\n  提交一个callable对象集合,返回执行结果的Future list对象\n\n  ```java\n  ExecutorService threadPool = Executors.newCachedThreadPool();//缓冲池\n  List<Callable<String>> list = new ArrayList();\n  list.add(() -> \"task1\");\n  list.add(() -> \"task2\");\n  list.add(() -> \"task3\");\n  List<Future<String>> futures = null;\n  futures = threadPool.invokeAll(list);\n  for(Future<String> future:futures){\n    System.out.println(future.get());\n  }\n  ```\n\n  ​\n\n### 利用Hook嵌入你的行为\n\nThreadPoolExecutor提供了protected类型可以被覆盖的钩子方法，允许用户在任务执行之前会执行之后做一些事情。继承线程池并重写线程池的beforeExecute()，afterExecute()和terminated()方法，可以在任务执行前、后和线程池关闭前自定义行为。我们可以通过它来实现比如初始化ThreadLocal、收集统计信息、记录日志、监控任务的平均执行时间、最大执行时间和最小执行时间等。\n\n如果hook方法执行失败，则内部的工作线程的执行将会失败或被中断。\n\n利用线程池提供的参数进行监控，参数如下：\n\n- taskCount：线程池需要执行的任务数量。\n- completedTaskCount：线程池在运行过程中已完成的任务数量，小于或等于taskCount。\n- largestPoolSize：线程池曾经创建过的最大线程数量，通过这个数据可以知道线程池是否满过。如等于线程池的最大大小，则表示线程池曾经满了。\n- getPoolSize：线程池的线程数量。如果线程池不销毁的话，池里的线程不会自动销毁，所以这个大小只增不减。\n- getActiveCount：获取活动的线程数。\n- getQueue：访问queue队列以进行一些统计或者debug工作\n\n```java\npublic class CustomThreadPoolExecutor extends ThreadPoolExecutor {\n\n    private final ThreadLocal<Long> startLocal = new ThreadLocal();\n    private final AtomicLong numTask = new AtomicLong();\n    private final AtomicLong totalTime = new AtomicLong();\n\n    public CustomThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue<Runnable> workQueue) {\n        super(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue);\n    }\n\n    @Override\n    protected void beforeExecute(Thread t, Runnable r) {\n        long start = System.currentTimeMillis();\n        //记录开始时间\n        startLocal.set(start);\n        System.out.println(t.getName() + \"start excute\");\n        //最后调用父类\n        super.beforeExecute(t, r);\n\n    }\n\n    @Override\n    protected void afterExecute(Runnable r, Throwable t) {\n        //先调用父类\n        super.afterExecute(r, t);\n        if (t == null && r instanceof Future<?>) {\n            try {\n                Object result = ((Future<?>) r).get();\n            } catch (CancellationException ce) {\n                t = ce;\n            } catch (ExecutionException ee) {\n                t = ee.getCause();\n            } catch (InterruptedException ie) {\n                Thread.currentThread().interrupt(); // ignore/reset\n            }\n        }\n        long end = System.currentTimeMillis();\n        numTask.incrementAndGet();\n        long useTime = end - (startLocal.get());\n        System.out.println(Thread.currentThread().getName()+\":运行时间为：\"+useTime);\n        totalTime.addAndGet(useTime);\n    }\n\n    @Override\n    protected void terminated() {\n        System.out.println(\"线程池终止\");\n        System.out.println(\"线程池中线程平均用时为：\"+totalTime.get()/numTask.get());\n        super.terminated();\n\n    }\n\n    public static void main(String[] args) {\n        CustomThreadPoolExecutor customThreadPoolExecutor = new CustomThreadPoolExecutor(3, 5, 3, TimeUnit.SECONDS, new LinkedBlockingQueue<>());\n        for(int i=0;i<5;i++){\n            customThreadPoolExecutor.execute(new Task(i));\n        }\n        customThreadPoolExecutor.shutdown();\n    }\n}\nclass Task implements Runnable {\n    private int index;\n\n    public Task(int index) {\n        this.index = index;\n    }\n\n    @Override\n    public void run() {\n        System.out.println(Thread.currentThread().getName() + \"：excute task\" + index);\n        try {\n            Thread.sleep(3000);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n    }\n}\n```\n\n运行结果\n\n```\npool-1-thread-1start excute\npool-1-thread-3start excute\npool-1-thread-2start excute\npool-1-thread-3：excute task2\npool-1-thread-1：excute task0\npool-1-thread-2：excute task1\npool-1-thread-3:运行时间为：3005\npool-1-thread-1:运行时间为：3005\npool-1-thread-2:运行时间为：3005\npool-1-thread-1start excute\npool-1-thread-1：excute task4\npool-1-thread-3start excute\npool-1-thread-3：excute task3\npool-1-thread-1:运行时间为：3001\npool-1-thread-3:运行时间为：3001\n线程池终止\n线程池中线程平均用时为：3003\n```\n\n\n\n### 关闭线程池\n\n当线程池不再被引用并且工作线程数为0的时候，线程池将被终止。我们也可以调用shutdown来手动终止线程池。如果我们忘记调用shutdown，为了让线程资源被释放，我们还可以使用keepAliveTime和allowCoreThreadTimeOut来达到目的。\n- shutdown()：不会立即的终止线程池，而是要等所有任务缓存队列中的任务都执行完后才终止，但再也不会接受新的任务。\n\n- shutdownNow()：立即终止线程池，并尝试打断正在执行的任务，并且清空任务缓存队列，返回尚未执行的任务。\n\n\n## Executors四种线程池\n\n1. Executors.newSingleThreadExecutor\n\n   SingleThreadExecutor是单个线程的线程池，即线程池中每次只有一个线程在运行，单线程串行执行任务。如果这个唯一的线程因为异常结束，那么会有一个新的线程来替代它。\n\n   此线程池保证任务的执行顺序按照任务的提交顺序执行。任务队列为LinkedBlockingQueue\n\n   ```java\n   public static ExecutorService newSingleThreadExecutor() {\n           return new FinalizableDelegatedExecutorService\n               (new ThreadPoolExecutor(1, 1,\n                                       0L, TimeUnit.MILLISECONDS,\n                                       new LinkedBlockingQueue<Runnable>()));\n       }\n   ```\n\n2. Executors.newFixedThreadPool。\n\n   FixedThreadPool是固定数量的线程池，只有核心线程，每提交一个任务就是一个线程，直到达到线程池的最大数量，然后后面进入等待队列，直到前面的任务完成才继续执行。线程池的大小一旦达到最大值就会保持不变，如果某个线程因为执行异常而结束，那么线程池会补充一个新线程。任务队列为LinkedBlockingQueue\n\n   ```java\n   public static ExecutorService newFixedThreadPool(int nThreads) {\n           return new ThreadPoolExecutor(nThreads, nThreads,\n                                         0L, TimeUnit.MILLISECONDS,\n                                         new LinkedBlockingQueue<Runnable>());\n   ```\n\n3. Executors.newCachedThreadPool\n\n   CachedThreadPool是可缓存线程池。如果线程池的大小超过了处理任务所需要的线程，那么就会回收部分空闲（60秒不执行任务）的线程，当任务数增加时，此线程池又可以智能的添加新线程来处理任务。此线程池不会对线程池大小做限制，线程池大小完全依赖于操作系统（或者说JVM）能够创建的最大线程大小。其中，SynchronousQueue是一个是缓冲区为1的阻塞队列。任务队列为SynchronousQueue\n\n   ```java\n   public static ExecutorService newCachedThreadPool() {\n           return new ThreadPoolExecutor(0, Integer.MAX_VALUE,\n                                         60L, TimeUnit.SECONDS,\n                                         new SynchronousQueue<Runnable>());\n       }\n   ```\n\n4. Executors.ScheduledThreadPool\n\n   ScheduledThreadPool是核心线程池固定，大小无限制的线程池，支持定时和周期性的执行线程。创建一个周期性执行任务的线程池。如果闲置,非核心线程池会在`DEFAULT_KEEPALIVEMILLIS`时间内回收。任务队列为DelayedWorkQueue\n\n   ```java\n   public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) {\n           return new ScheduledThreadPoolExecutor(corePoolSize);\n       }\n   public ScheduledThreadPoolExecutor(int corePoolSize) {\n           super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS,\n                 new DelayedWorkQueue());\n       }\n   /*该任务将会在首个 initialDelay 之后得到执行，然后每个 period 时间之后重复执行。period 被解释为前一个执行的开始和下一个执行的开始之间的间隔时间。如果给定任务的执行抛出了异常，该任务将不再执行。如果没有任何异常的话，这个任务将会持续循环执行到 ScheduledExecutorService 被关闭。如果一个任务占用了比计划的时间间隔更长的时候，下一次执行将在当前执行结束执行才开始。计划任务在同一时间不会有多个线程同时执行*/\n   scheduleAtFixedRate (Runnable, long initialDelay, long period, TimeUnit timeunit)\n   /*该方法中，period 则被解释为前一个执行的结束和下一个执行的开始之间的间隔。*/\n   scheduleWithFixedDelay (Runnable, long initialDelay, long period, TimeUnit timeunit)\n\n   ```\n\n5. Executors.newWorkStealingPool（待整理）\n\n  ```java\n  public static ExecutorService newWorkStealingPool(int parallelism) {\n      return new ForkJoinPool\n          (parallelism,\n           ForkJoinPool.defaultForkJoinWorkerThreadFactory,\n           null, true);\n  }\n  ```\n\n## 使用技巧\n\n- 需要针对具体情况而具体处理，不同的任务类别应采用不同规模的线程池，任务类别可划分为CPU密集型任务、IO密集型任务和混合型任务。(N代表CPU个数)\n- 对于CPU密集型任务：线程池中线程个数应尽量少，如配置N+1个线程的线程池；\n- 对于IO密集型任务：由于IO操作速度远低于CPU速度，那么在运行这类任务时，CPU绝大多数时间处于空闲状态，那么线程池可以配置尽量多些的线程，以提高CPU利用率，如2*N；\n- 对于混合型任务：可以拆分为CPU密集型任务和IO密集型任务，当这两类任务执行时间相差无几时，通过拆分再执行的吞吐率高于串行执行的吞吐率，但若这两类任务执行时间有数据级的差距，那么没有拆分的意义。\n\n## 参考资料\n\n[【从0到1学习Java线程池】Java线程池原理](http://blog.luoyuanhang.com/2017/02/27/thread-pool-in-java-2/)","source":"_posts/多线程/java线程池.md","raw":"---\ntitle: java线程池\ndate: 2017-09-01 15:51:24\ntags:\n- 多线程\ncategories:\n- java基础\n\n---\n\n#  线程池\n\n当需要使用多线程的时候，通常需要创建一个新的线程去执行程序，但是如果不停的创建线程，会消耗更多的内存，增加cpu切换的速度，那么这时就需要使用线程池控制对线程进行有效的控制,线程池不是为了提供性能，而是为了控制线程数量从而达到控制资源，防止内存溢出。\n\n<!--more-->\n\n线程池的优点：\n1. 降低系统资源消耗，通过重用已存在的线程，降低线程创建和销毁造成的消耗；\n2. 有效的控制线程的最大并发数，线程若是无限制的创建，会增加资源竞争，导致CPU切换严重引起阻塞、引发oom等。线程池能有效管控线程，统一分配、调优，提供资源使用率；\n3. 提高系统响应速度，当有任务到达时，立即执行，无需等待新线程的创建；\n4. 能够对线程进行简单的管理并提供定时执行、间隔执行等功能。\n\n\nExecutorService基于池化的线程来执行用户提交的任务，通常可以简单的通过Executors提供的工厂方法来创建ThreadPoolExecutor实例。\n\n主要包括以下几个方面:\n\n- 线程池大小参数的设置 \n- 工作线程的创建\n- 空闲线程的回收\n- 阻塞队列的使用\n- 任务拒绝策略\n- 线程池Hook\n\n## 线程池实现原理\n\n### 线程池的组成部分\n\n1. 线程池管理器：用于创建并管理线程池\n2. 工作线程：线程池中的线程\n3. 任务接口：每个任务必须实现的接口，用于工作线程调度其运行\n4. 任务队列：用于存放待处理的任务，提供一种缓冲机制\n\n### 线程池的实现方式\n\n​\t\t\t\t\t`ThreadPoolExecutor的构造函数`\n\n```java\npublic ThreadPoolExecutor(int corePoolSize,\n                              int maximumPoolSize,\n                              long keepAliveTime,\n                              TimeUnit unit,\n                              BlockingQueue<Runnable> workQueue,\n                              ThreadFactory threadFactory,\n                              RejectedExecutionHandler handler) {\n        if (corePoolSize < 0 ||\n            maximumPoolSize <= 0 ||\n            maximumPoolSize < corePoolSize ||\n            keepAliveTime < 0)\n            throw new IllegalArgumentException();\n        if (workQueue == null || threadFactory == null || handler == null)\n            throw new NullPointerException();\n        this.corePoolSize = corePoolSize;\n        this.maximumPoolSize = maximumPoolSize;\n        this.workQueue = workQueue;\n        this.keepAliveTime = unit.toNanos(keepAliveTime);\n        this.threadFactory = threadFactory;\n        this.handler = handler;\n    }\n```\n\n- corePoolSize：线程池的核心线程数，默认情况下会永远存活，当ThreadPoolExecutor 中的方法 allowCoreThreadTimeOut(boolean value) 设置为 true 时，如果在指定时间没有新任务来时，核心线程也会被终止\n- maximumPoolSize：线程池中允许的最大线程数，当队列满了，且已创建的线程数小于maximumPoolSize，则线程池会创建新的线程来执行任务。对于无界队列，可忽略该参数。\n- keepAliveTime：空闲线程结束的超时时间\n- unit：是一个枚举，它表示的是 keepAliveTime 的单位\n- workQueue：工作队列，用于存放任务\n- threadFactory：线程工厂，使用new Thread()为线程池提供新线程的创建，默认为DefaultThreadFactory类。由同一个threadFactory创建的线程，属于同一个ThreadGroup，创建的线程优先级都为Thread.NORM_PRIORITY\n- handler：拒绝策略，当线程数超过上限并且工作队列满了情况下对任务线程的处理策略，默认策略为ThreadPoolExecutor.AbortPolicy\n\n#### 线程池工作过程\n\n1. 线程池刚创建时，里面没有一个线程。任务队列是作为参数传进来的。不过，就算队列里面有任务，线程池也不会马上执行它们。\n\n2. 当调用 execute() 方法添加一个任务时，线程池会做如下判断：\n\n   - 如果正在运行的线程数量小于 corePoolSize，那么马上创建线程运行这个任务,即使线程池中的线程都处于空闲状态，也要创建新的线程来处理被添加的任务\n\n   - 如果正在运行的线程数量大于或等于 corePoolSize，那么将这个任务放入队列\n\n   - 如果这时候队列满了，而且正在运行的线程数量小于 maximumPoolSize，那么还是要创建非核心线程立刻运行这个任务\n\n   - 如果队列满了，而且正在运行的线程数量大于或等于 maximumPoolSize，那么线程池会抛出异常RejectExecutionException。\n\n     ```java\n     public void execute(Runnable command) {\n       if (command == null)\n         throw new NullPointerException();\n       int c = ctl.get();\n       //小于核心线程，则新建核心线程并执行任务\n       if (workerCountOf(c) < corePoolSize) {\n         //添加时检查线程数据\n         if (addWorker(command, true))\n           return;\n         c = ctl.get();\n       }\n       //添加队列成功需要再次检查线程池状态和线程数量\n       if (isRunning(c) && workQueue.offer(command)) {\n         int recheck = ctl.get();\n         //如果线程池停掉了 从队列移除任务并拒绝\n         if (! isRunning(recheck) && remove(command))\n           reject(command);\n         //如果线程数小了，创建额外线程，对线程池进行补偿，但是不执行任务\n         else if (workerCountOf(recheck) == 0)\n           addWorker(null, false);\n       }\n       //创建小于maxSize的线程并执行任务\n       else if (!addWorker(command, false))\n         reject(command);//失败调用拒绝策略\n     }\n     ```\n\n     ​\n\n   ![image](http://omdq6di7v.bkt.clouddn.com/17-9-4/28653757.jpg)\n\n   - 当一个线程完成任务时，它会从队列中取下一个任务来执行。\n   - 当一个线程无事可做，超过一定的时间（keepAliveTime）时，线程池会判断，如果当前运行的线程数大于 corePoolSize，那么这个线程就被停掉。所以线程池的所有任务完成后，它最终会收缩到 corePoolSize 的大小。\n   - submit当我们使用submit来提交任务时,它会返回一个future,我们就可以通过这个future来判断任务是否执行成功，还可以通过future的get方法来获取返回值。如果子线程任务没有完成，get方法会阻塞住直到任务完成，而使用get(long timeout, TimeUnit unit)方法则会阻塞一段时间后立即返回，这时候有可能任务并没有执行完。\n\n```java\npublic class CustomThreadPool {\n\n    public static void main(String[] args) {\n        //任务队列 LinkedBlockingQueue\n        //BlockingQueue<Runnable> workQueue = new LinkedBlockingQueue();//最多使用掉corePoolSize\n\n        //任务队列 ArrayBlockingQueue\n        /*\n            pool-1-thread-1：excute task0\n            pool-1-thread-4：excute task7 //当任务队列已满，线程池中线程数还未达到maxsize，创建新的线程执行新进来的任务\n            pool-1-thread-3：excute task2\n            pool-1-thread-5：excute task8\n            pool-1-thread-2：excute task1\n            java.util.concurrent.RejectedExecutionException: Task cn.zlz.pool.Task@63947c6b rejected from j...//拒绝\n            pool-1-thread-1：excute task3 //任务队列中的任务等待线程池中的线程空闲时执行\n            pool-1-thread-5：excute task4\n            pool-1-thread-3：excute task5\n            pool-1-thread-4：excute task6\n         */\n        BlockingQueue<Runnable> workQueue = new ArrayBlockingQueue<Runnable>(4);//\n\n        //线程工厂\n        ThreadFactory factory = Executors.defaultThreadFactory();\n        //拒绝策略\n        RejectedExecutionHandler handler = new ThreadPoolExecutor.AbortPolicy();\n\n        //创建线程池 coresize：3 max：5\n        ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(3, 5, 5l,\n                TimeUnit.MILLISECONDS, workQueue, factory, handler);\n        try {\n            for (int i = 0; i < 10; i++) {\n                threadPoolExecutor.execute(new Task(i));\n            }\n            System.out.println(\"main\");\n        }finally {\n            threadPoolExecutor.shutdown();//停止接收任务，并等待执行中的任务执行完毕后停止\n            //threadPoolExecutor.shutdownNow();//立即关闭线程池中的所有线程\n        }\n    }\n}\n\nclass Task implements Runnable{\n    private int index;\n    public Task (int index){\n        this.index = index;\n    }\n\n    @Override\n    public void run() {\n        System.out.println(Thread.currentThread().getName()+\"：excute task\"+index);\n        try {\n            Thread.sleep(3000);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n    }\n}\n```\n\n### 线程池状态\n\n- RUNNING：可以添加工作线程并执行队列中的任务\n- SHUTDOWN：停止创建新的工作线程并停止接收新的任务，等待当前剩余任务的执行完毕 SHUTDOWN()\n- STOP：停止创建新的工作线程，停止执行队列任务，中断正在执行的任务线程 shutdownNow()\n- TIDYING：任务队列为空，workerCount减为0，准备调用terminated方法 STOP -> TIDYING\n- TERMINATED：terminated方法执行完毕，所有线程都得到释放 terminated()\n\n#### 工作队列选择\n\n**直接递交：**\n\n- 工作队列的默认选项是 **SynchronousQueue**，这种队列会将提交的任务直接传送给工作线程，而不持有。如果当前没有工作线程来处理，即任务放入队列失败，则根据线程池的实现，会引发新的工作线程创建，因此新提交的任务会被处理。这种策略在当提交的一批任务之间有依赖关系的时候避免了锁竞争消耗。\n- 这种队列最好是配合maximumPoolSizes线程数来使用，从而避免任务被拒绝。同时我们必须要考虑到一种场景，当任务到来的速度大于任务处理的速度，将会引起无限制的线程数不断的增加。\n\n**无界队列：**\n\n- 使用无界队列如LinkedBlockingQueue没有指定最大容量的时候，将会引起当核心线程都在忙的时候，新的任务被放在队列上，因此，永远不会有大于corePoolSize的线程被创建，因此maximumPoolSize参数将失效。\n- 这种队列比较适合所有的任务都不相互依赖，独立执行。举个例子，如网页服务器中，每个线程独立处理请求。但是当任务处理速度小于任务进入速度的时候会引起队列的无限膨胀。\n\n**有界队列：**\n\n- 有界队列如ArrayBlockingQueue帮助限制资源的消耗，但是不容易控制。队列长度和maximumPoolSize这两个值会相互影响，使用大的队列和小maximumPoolSize会最大限度地降低 CPU 使用率、操作系统资源和上下文切换开销，但是会降低吞吐量，如果任务被频繁的阻塞如IO线程，系统其实可以调度更多的线程。使用小的队列通常需要大maximumPoolSize，这时CPU 使用率较高，但是可能遇到不可接受的调度开销，这样也会降低吞吐量。\n- 总结一下**是IO密集型可以考虑调大maximumPoolSize多些线程来平衡CPU的使用，CPU密集型可以考虑调销maximumPoolSize少些线程减少线程调度的消耗。**\n\n#### 空闲线程回收\n\n如果当前池子中的工作线程数大于corePoolSize，如果超过这个数字的线程处于空闲的时间大于keepAliveTime，则这些线程将会被终止，这是一种减少不必要资源消耗的策略。这个参数可以在运行时被改变，\n\n可以通过调用allowCoreThreadTimeout(true)将过期回收策略应用于核心线程进行回收。\n\n####  拒绝策略\n\n当新的任务到来的而线程池被关闭的时候，或线程数和队列已经达到上限的时候，需要拒绝任务，以下几种拒绝策略：\n\n- ThreadPoolExecutor.AbortPolicy：直接抛出RejectedExecutionException异常。\n- ThreadPoolExecutor.CallerRunsPolicy：使用调用者所线程来执行这个任务，这是一种feedback策略，会阻塞调用者线程，降低任务提交的速度。\n- ThreadPoolExecutor.DiscardPolicy：直接丢弃无法执行的任务\n- ThreadPoolExecutor.DiscardOldestPolicy：从任务队列头部开始丢弃任务，然后重新尝试执行新任务（如果再次失败，则重复此过程），一种类似最旧丢弃策略\n- 自定义拒绝策略：实现RejectedExecutionHandler自定义拒绝策略\n\n#### 线程池的执行\n\n- execute(Runnable)\n\n  异步执行一个runable对象，无法得知线程执行状态和结果\n\n  ```java\n  ExecutorService threadPool = Executors.newCachedThreadPool();//缓冲池\n  threadPool.execute(()->System.out.print(\"run\"));\n  ```\n\n\n- submit(Runnable)\n\n  异步执行一个runable对象，返回一个future对象，调用future.get()会阻塞主线程运行，获取线程运行结果，程序正常接收返回null\n\n  ```java\n  ExecutorService threadPool = Executors.newCachedThreadPool();//缓冲池\n  Future<?> future = threadPool.submit(() -> System.out.println(\"run\"));\n  try {\n    System.out.println(future.get());//null\n  } catch (InterruptedException e) {\n    e.printStackTrace();\n  } catch (ExecutionException e) {\n    e.printStackTrace();\n  }\n  ```\n\n- submit(Callable)\n\n  异步执行一个callable对象，返回一个future对象，通过future.get()可以获取callable的返回值\n\n  ```java\n  Future future = executorService.submit(n() -> return \"run\");\n  System.out.println(\"future.get() = \" + future.get());\n  ```\n\n- invokeAny()\n\n  提交一个callable对象集合，随机返回一个线程执行结果。只能表明其中一个已执行结束。\n\n  如果其中一个任务执行结束(或者抛了一个异常)，其他 Callable 将被取消\n\n  ```java\n  ExecutorService threadPool = Executors.newCachedThreadPool();//缓冲池\n  List<Callable<String>> list =new ArrayList();\n  list.add(()->\"task1\");\n  list.add(()->\"task2\");\n  list.add(()->\"task3\");\n  String result = threadPool.invokeAny(list);\n  System.out.println(result);//task1 or task2 or task3\n  threadPool.shutdown();\n  ```\n\n- invokeAll()\n\n  提交一个callable对象集合,返回执行结果的Future list对象\n\n  ```java\n  ExecutorService threadPool = Executors.newCachedThreadPool();//缓冲池\n  List<Callable<String>> list = new ArrayList();\n  list.add(() -> \"task1\");\n  list.add(() -> \"task2\");\n  list.add(() -> \"task3\");\n  List<Future<String>> futures = null;\n  futures = threadPool.invokeAll(list);\n  for(Future<String> future:futures){\n    System.out.println(future.get());\n  }\n  ```\n\n  ​\n\n### 利用Hook嵌入你的行为\n\nThreadPoolExecutor提供了protected类型可以被覆盖的钩子方法，允许用户在任务执行之前会执行之后做一些事情。继承线程池并重写线程池的beforeExecute()，afterExecute()和terminated()方法，可以在任务执行前、后和线程池关闭前自定义行为。我们可以通过它来实现比如初始化ThreadLocal、收集统计信息、记录日志、监控任务的平均执行时间、最大执行时间和最小执行时间等。\n\n如果hook方法执行失败，则内部的工作线程的执行将会失败或被中断。\n\n利用线程池提供的参数进行监控，参数如下：\n\n- taskCount：线程池需要执行的任务数量。\n- completedTaskCount：线程池在运行过程中已完成的任务数量，小于或等于taskCount。\n- largestPoolSize：线程池曾经创建过的最大线程数量，通过这个数据可以知道线程池是否满过。如等于线程池的最大大小，则表示线程池曾经满了。\n- getPoolSize：线程池的线程数量。如果线程池不销毁的话，池里的线程不会自动销毁，所以这个大小只增不减。\n- getActiveCount：获取活动的线程数。\n- getQueue：访问queue队列以进行一些统计或者debug工作\n\n```java\npublic class CustomThreadPoolExecutor extends ThreadPoolExecutor {\n\n    private final ThreadLocal<Long> startLocal = new ThreadLocal();\n    private final AtomicLong numTask = new AtomicLong();\n    private final AtomicLong totalTime = new AtomicLong();\n\n    public CustomThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue<Runnable> workQueue) {\n        super(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue);\n    }\n\n    @Override\n    protected void beforeExecute(Thread t, Runnable r) {\n        long start = System.currentTimeMillis();\n        //记录开始时间\n        startLocal.set(start);\n        System.out.println(t.getName() + \"start excute\");\n        //最后调用父类\n        super.beforeExecute(t, r);\n\n    }\n\n    @Override\n    protected void afterExecute(Runnable r, Throwable t) {\n        //先调用父类\n        super.afterExecute(r, t);\n        if (t == null && r instanceof Future<?>) {\n            try {\n                Object result = ((Future<?>) r).get();\n            } catch (CancellationException ce) {\n                t = ce;\n            } catch (ExecutionException ee) {\n                t = ee.getCause();\n            } catch (InterruptedException ie) {\n                Thread.currentThread().interrupt(); // ignore/reset\n            }\n        }\n        long end = System.currentTimeMillis();\n        numTask.incrementAndGet();\n        long useTime = end - (startLocal.get());\n        System.out.println(Thread.currentThread().getName()+\":运行时间为：\"+useTime);\n        totalTime.addAndGet(useTime);\n    }\n\n    @Override\n    protected void terminated() {\n        System.out.println(\"线程池终止\");\n        System.out.println(\"线程池中线程平均用时为：\"+totalTime.get()/numTask.get());\n        super.terminated();\n\n    }\n\n    public static void main(String[] args) {\n        CustomThreadPoolExecutor customThreadPoolExecutor = new CustomThreadPoolExecutor(3, 5, 3, TimeUnit.SECONDS, new LinkedBlockingQueue<>());\n        for(int i=0;i<5;i++){\n            customThreadPoolExecutor.execute(new Task(i));\n        }\n        customThreadPoolExecutor.shutdown();\n    }\n}\nclass Task implements Runnable {\n    private int index;\n\n    public Task(int index) {\n        this.index = index;\n    }\n\n    @Override\n    public void run() {\n        System.out.println(Thread.currentThread().getName() + \"：excute task\" + index);\n        try {\n            Thread.sleep(3000);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n    }\n}\n```\n\n运行结果\n\n```\npool-1-thread-1start excute\npool-1-thread-3start excute\npool-1-thread-2start excute\npool-1-thread-3：excute task2\npool-1-thread-1：excute task0\npool-1-thread-2：excute task1\npool-1-thread-3:运行时间为：3005\npool-1-thread-1:运行时间为：3005\npool-1-thread-2:运行时间为：3005\npool-1-thread-1start excute\npool-1-thread-1：excute task4\npool-1-thread-3start excute\npool-1-thread-3：excute task3\npool-1-thread-1:运行时间为：3001\npool-1-thread-3:运行时间为：3001\n线程池终止\n线程池中线程平均用时为：3003\n```\n\n\n\n### 关闭线程池\n\n当线程池不再被引用并且工作线程数为0的时候，线程池将被终止。我们也可以调用shutdown来手动终止线程池。如果我们忘记调用shutdown，为了让线程资源被释放，我们还可以使用keepAliveTime和allowCoreThreadTimeOut来达到目的。\n- shutdown()：不会立即的终止线程池，而是要等所有任务缓存队列中的任务都执行完后才终止，但再也不会接受新的任务。\n\n- shutdownNow()：立即终止线程池，并尝试打断正在执行的任务，并且清空任务缓存队列，返回尚未执行的任务。\n\n\n## Executors四种线程池\n\n1. Executors.newSingleThreadExecutor\n\n   SingleThreadExecutor是单个线程的线程池，即线程池中每次只有一个线程在运行，单线程串行执行任务。如果这个唯一的线程因为异常结束，那么会有一个新的线程来替代它。\n\n   此线程池保证任务的执行顺序按照任务的提交顺序执行。任务队列为LinkedBlockingQueue\n\n   ```java\n   public static ExecutorService newSingleThreadExecutor() {\n           return new FinalizableDelegatedExecutorService\n               (new ThreadPoolExecutor(1, 1,\n                                       0L, TimeUnit.MILLISECONDS,\n                                       new LinkedBlockingQueue<Runnable>()));\n       }\n   ```\n\n2. Executors.newFixedThreadPool。\n\n   FixedThreadPool是固定数量的线程池，只有核心线程，每提交一个任务就是一个线程，直到达到线程池的最大数量，然后后面进入等待队列，直到前面的任务完成才继续执行。线程池的大小一旦达到最大值就会保持不变，如果某个线程因为执行异常而结束，那么线程池会补充一个新线程。任务队列为LinkedBlockingQueue\n\n   ```java\n   public static ExecutorService newFixedThreadPool(int nThreads) {\n           return new ThreadPoolExecutor(nThreads, nThreads,\n                                         0L, TimeUnit.MILLISECONDS,\n                                         new LinkedBlockingQueue<Runnable>());\n   ```\n\n3. Executors.newCachedThreadPool\n\n   CachedThreadPool是可缓存线程池。如果线程池的大小超过了处理任务所需要的线程，那么就会回收部分空闲（60秒不执行任务）的线程，当任务数增加时，此线程池又可以智能的添加新线程来处理任务。此线程池不会对线程池大小做限制，线程池大小完全依赖于操作系统（或者说JVM）能够创建的最大线程大小。其中，SynchronousQueue是一个是缓冲区为1的阻塞队列。任务队列为SynchronousQueue\n\n   ```java\n   public static ExecutorService newCachedThreadPool() {\n           return new ThreadPoolExecutor(0, Integer.MAX_VALUE,\n                                         60L, TimeUnit.SECONDS,\n                                         new SynchronousQueue<Runnable>());\n       }\n   ```\n\n4. Executors.ScheduledThreadPool\n\n   ScheduledThreadPool是核心线程池固定，大小无限制的线程池，支持定时和周期性的执行线程。创建一个周期性执行任务的线程池。如果闲置,非核心线程池会在`DEFAULT_KEEPALIVEMILLIS`时间内回收。任务队列为DelayedWorkQueue\n\n   ```java\n   public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) {\n           return new ScheduledThreadPoolExecutor(corePoolSize);\n       }\n   public ScheduledThreadPoolExecutor(int corePoolSize) {\n           super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS,\n                 new DelayedWorkQueue());\n       }\n   /*该任务将会在首个 initialDelay 之后得到执行，然后每个 period 时间之后重复执行。period 被解释为前一个执行的开始和下一个执行的开始之间的间隔时间。如果给定任务的执行抛出了异常，该任务将不再执行。如果没有任何异常的话，这个任务将会持续循环执行到 ScheduledExecutorService 被关闭。如果一个任务占用了比计划的时间间隔更长的时候，下一次执行将在当前执行结束执行才开始。计划任务在同一时间不会有多个线程同时执行*/\n   scheduleAtFixedRate (Runnable, long initialDelay, long period, TimeUnit timeunit)\n   /*该方法中，period 则被解释为前一个执行的结束和下一个执行的开始之间的间隔。*/\n   scheduleWithFixedDelay (Runnable, long initialDelay, long period, TimeUnit timeunit)\n\n   ```\n\n5. Executors.newWorkStealingPool（待整理）\n\n  ```java\n  public static ExecutorService newWorkStealingPool(int parallelism) {\n      return new ForkJoinPool\n          (parallelism,\n           ForkJoinPool.defaultForkJoinWorkerThreadFactory,\n           null, true);\n  }\n  ```\n\n## 使用技巧\n\n- 需要针对具体情况而具体处理，不同的任务类别应采用不同规模的线程池，任务类别可划分为CPU密集型任务、IO密集型任务和混合型任务。(N代表CPU个数)\n- 对于CPU密集型任务：线程池中线程个数应尽量少，如配置N+1个线程的线程池；\n- 对于IO密集型任务：由于IO操作速度远低于CPU速度，那么在运行这类任务时，CPU绝大多数时间处于空闲状态，那么线程池可以配置尽量多些的线程，以提高CPU利用率，如2*N；\n- 对于混合型任务：可以拆分为CPU密集型任务和IO密集型任务，当这两类任务执行时间相差无几时，通过拆分再执行的吞吐率高于串行执行的吞吐率，但若这两类任务执行时间有数据级的差距，那么没有拆分的意义。\n\n## 参考资料\n\n[【从0到1学习Java线程池】Java线程池原理](http://blog.luoyuanhang.com/2017/02/27/thread-pool-in-java-2/)","slug":"多线程/java线程池","published":1,"updated":"2018-09-12T03:03:21.833Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfni80060wlkv8e8agnjv"},{"title":"java线程状态","date":"2017-09-01T04:51:24.000Z","_content":"\n#  java线程状态\n\n线程从创建到销毁经过了**新建、就绪、运行、阻塞、死亡**等状态，jdk的中一个方法、磁盘io、网络io都会导致线程状态的切换。理解线程的运行状态对于掌握线程的运行情况、多线程调优至关重要。\n\n<!--more-->\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-10-20/35976214.jpg)\n\n### 线程间的状态转换:\n\n1. **新建(new)**：一个new出来的线程对象，还未执行。\n2. **就绪(runnable)**：线程对象创建并调用了该对象的**start()**方法后。该状态的线程位于可运行线程池中，等待被线程调度选中，获取cpu 的使用权 ，但是此时还未执行，处于就绪状态。\n3. **运行(running)**：可运行状态(runnable)的线程获得了cpu 时间片（timeslice）,执行程序代码。\n4. **阻塞(block)**：阻塞状态是指线程因为某种原因放弃了cpu 使用权，即让出了cpu时间片，暂时停止运行。直到线程进入可运行(runnable)状态，才有机会再次获得cpu时间片转到运行(running)状态。**阻塞和运行的切换涉及当前线程执行上下文内容的保存和恢复，非常耗费cpu资源**，阻塞的情况分三种： \n   - 等待阻塞：运行(running)的线程执行o.wait()方法，JVM会把该线程放入等待队列(waitting queue)中。\n   - 同步阻塞：运行(running)的线程在获取对象的同步锁时，若该同步锁被别的线程占用，则JVM会把该线程放入对象锁的锁池(lock pool)中。\n   - 其他阻塞：运行(running)的线程执行Thread.sleep(long ms)或t.join()方法，或者发出了I/O请求时，JVM会把该线程置为阻塞状态。当sleep()状态超时、join()等待线程终止或者超时、或者I/O处理完毕时，线程重新转入可运行(runnable)状态。\n5. **死亡(dead)**：线程run()、main() 方法执行结束，或者**因异常**退出了run()方法，则该线程结束生命周期。死亡的线程不可再次复生。\n\n### 改变线程状态的行为\n\n1. Thread.sleep(long millis)：一定是当前线程调用此方法，当前线程切换为**阻塞状态** ，但不释放对象锁，millis后线程自动苏醒切换为**就绪状态** 。\n\n2. Thread.yield()：一定是当前线程调用此方法，当前线程放弃获取的cpu时间片，由**运行状态**切换到**就绪状态** ，可再次竞争CPU使用权。作用：让相同优先级的线程轮流执行，但并不保证一定会轮流执行。实际中无法保证**yield()**达到让步目的，因为让步的线程还有可能被线程调度程序再次选中。\n\n3. obj.wait()：当前线程调用对象的wait()方法，当前线程释放对象锁，进入等待队列。依靠notify()/notifyAll()唤醒或者wait(long timeout)timeout时间到自动唤醒。\n\n4. LockSupport.park():将当前线程置为等待状态，同wait的区别是无需获取对象锁，调用unpark方法唤醒\n\n5. obj.notify()唤醒在此对象监视器上等待的单个线程，选择是任意性的。notifyAll()唤醒在此对象监视器上等待的所有线程。当线程调用notify()后只是激活其他线程，自己并不会释放对象锁，知道当前线程执行完毕后才释放对象锁。\n\n6. t.join()/t.join(long millis)：当前线程里调用其它线程的join方法，当前线程阻塞，其实是以其他线程对象做为锁对象进入阻塞等待状态，直到这个线程**运行完毕死亡**之后释放锁进入**就绪状态**\n\n   ```java\n   //join方法的内部实现是通过wait方法\n   while (isAlive()) {//判断调用join方法的线程是否依然存活，如果是，当前线程调用wait方法\n      long delay = millis - now;\n      if (delay <= 0) {\n        break;\n      }\n      wait(delay);\n      now = System.currentTimeMillis() - base;\n    }\n   ```\n\n## 参考资料\n\n[我是一个线程](http://mp.weixin.qq.com/s?__biz=MzAxOTc0NzExNg==&mid=416915373&idx=1&sn=f80a13b099237534a3ef777d511d831a&scene=25#wechat_redirect)","source":"_posts/多线程/java线程状态.md","raw":"---\ntitle: java线程状态\ndate: 2017-09-01 12:51:24\ntags:\n- 多线程\ncategories:\n- java基础\n\n---\n\n#  java线程状态\n\n线程从创建到销毁经过了**新建、就绪、运行、阻塞、死亡**等状态，jdk的中一个方法、磁盘io、网络io都会导致线程状态的切换。理解线程的运行状态对于掌握线程的运行情况、多线程调优至关重要。\n\n<!--more-->\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-10-20/35976214.jpg)\n\n### 线程间的状态转换:\n\n1. **新建(new)**：一个new出来的线程对象，还未执行。\n2. **就绪(runnable)**：线程对象创建并调用了该对象的**start()**方法后。该状态的线程位于可运行线程池中，等待被线程调度选中，获取cpu 的使用权 ，但是此时还未执行，处于就绪状态。\n3. **运行(running)**：可运行状态(runnable)的线程获得了cpu 时间片（timeslice）,执行程序代码。\n4. **阻塞(block)**：阻塞状态是指线程因为某种原因放弃了cpu 使用权，即让出了cpu时间片，暂时停止运行。直到线程进入可运行(runnable)状态，才有机会再次获得cpu时间片转到运行(running)状态。**阻塞和运行的切换涉及当前线程执行上下文内容的保存和恢复，非常耗费cpu资源**，阻塞的情况分三种： \n   - 等待阻塞：运行(running)的线程执行o.wait()方法，JVM会把该线程放入等待队列(waitting queue)中。\n   - 同步阻塞：运行(running)的线程在获取对象的同步锁时，若该同步锁被别的线程占用，则JVM会把该线程放入对象锁的锁池(lock pool)中。\n   - 其他阻塞：运行(running)的线程执行Thread.sleep(long ms)或t.join()方法，或者发出了I/O请求时，JVM会把该线程置为阻塞状态。当sleep()状态超时、join()等待线程终止或者超时、或者I/O处理完毕时，线程重新转入可运行(runnable)状态。\n5. **死亡(dead)**：线程run()、main() 方法执行结束，或者**因异常**退出了run()方法，则该线程结束生命周期。死亡的线程不可再次复生。\n\n### 改变线程状态的行为\n\n1. Thread.sleep(long millis)：一定是当前线程调用此方法，当前线程切换为**阻塞状态** ，但不释放对象锁，millis后线程自动苏醒切换为**就绪状态** 。\n\n2. Thread.yield()：一定是当前线程调用此方法，当前线程放弃获取的cpu时间片，由**运行状态**切换到**就绪状态** ，可再次竞争CPU使用权。作用：让相同优先级的线程轮流执行，但并不保证一定会轮流执行。实际中无法保证**yield()**达到让步目的，因为让步的线程还有可能被线程调度程序再次选中。\n\n3. obj.wait()：当前线程调用对象的wait()方法，当前线程释放对象锁，进入等待队列。依靠notify()/notifyAll()唤醒或者wait(long timeout)timeout时间到自动唤醒。\n\n4. LockSupport.park():将当前线程置为等待状态，同wait的区别是无需获取对象锁，调用unpark方法唤醒\n\n5. obj.notify()唤醒在此对象监视器上等待的单个线程，选择是任意性的。notifyAll()唤醒在此对象监视器上等待的所有线程。当线程调用notify()后只是激活其他线程，自己并不会释放对象锁，知道当前线程执行完毕后才释放对象锁。\n\n6. t.join()/t.join(long millis)：当前线程里调用其它线程的join方法，当前线程阻塞，其实是以其他线程对象做为锁对象进入阻塞等待状态，直到这个线程**运行完毕死亡**之后释放锁进入**就绪状态**\n\n   ```java\n   //join方法的内部实现是通过wait方法\n   while (isAlive()) {//判断调用join方法的线程是否依然存活，如果是，当前线程调用wait方法\n      long delay = millis - now;\n      if (delay <= 0) {\n        break;\n      }\n      wait(delay);\n      now = System.currentTimeMillis() - base;\n    }\n   ```\n\n## 参考资料\n\n[我是一个线程](http://mp.weixin.qq.com/s?__biz=MzAxOTc0NzExNg==&mid=416915373&idx=1&sn=f80a13b099237534a3ef777d511d831a&scene=25#wechat_redirect)","slug":"多线程/java线程状态","published":1,"updated":"2018-09-12T03:03:21.833Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfni90063wlkvq7tszqir"},{"title":"spring事务","date":"2018-09-28T03:28:43.000Z","_content":"\n# spring事务\n\n## 一、在同一类中一个调用本类中另一个有事务的方法,事务是无效\n\n第一步：首先在spring的配置文件中加入以下配置\n\n```xml\n<!-- 激活自动代理功能 -->\n<aop:aspectj-autoproxy/>\n<aop:aspectj-autoproxy proxy-target-class=\"true\" expose-proxy=\"true\" />\n```\n\n第二步：将之前使用普通调用的方法,换成使用代理调用\n\n```java\n((TestService)AopContext.currentProxy()).testTransactional2();\n```\n\n或者直接使用手动回滚\n\n```java\nTransactionAspectSupport.currentTransactionStatus().setRollbackOnly();\n```\n\n## 二、spring声明式事务管理默认对非检查型异常和运行时异常进行事务回滚，而对检查型异常则不进行回滚操作\n\n1 让checked例外也回滚：在整个方法前加上 @Transactional(rollbackFor=Exception.class)\n\n 2 让unchecked例外不回滚： @Transactional(notRollbackFor=RunTimeException.class)\n\n 3 不需要事务管理的(只查询的)方法：@Transactional(propagation=Propagation.NOT_SUPPORTED)\n\n## 三、事务的传播行为\n\n```\nPROPAGATION_REQUIRED -- 支持当前事务，如果当前没有事务，就新建一个事务。这是最常见的选择。 \nPROPAGATION_SUPPORTS -- 支持当前事务，如果当前没有事务，就以非事务方式执行。 \nPROPAGATION_MANDATORY -- 支持当前事务，如果当前没有事务，就抛出异常。 \nPROPAGATION_REQUIRES_NEW -- 新建事务，如果当前存在事务，把当前事务挂起。 \nPROPAGATION_NOT_SUPPORTED -- 以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。 \nPROPAGATION_NEVER -- 以非事务方式执行，如果当前存在事务，则抛出异常。 \nPROPAGATION_NESTED -- 如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则进行与PROPAGATION_REQUIRED类似的操作。 \n\n  PROPAGATION_REQUIRES_NEW 启动一个新的, 不依赖于环境的 \"内部\" 事务. 这个事务将被完全 commited 或 rolled back 而不依赖于外部事务, 它拥有自己的隔离范围, 自己的锁, 等等. 当内部事务开始执行时, 外部事务将被挂起, 内务事务结束时, 外部事务将继续执行. \n    另一方面, PROPAGATION_NESTED 开始一个 \"嵌套的\" 事务,  它是已经存在事务的一个真正的子事务. 潜套事务开始执行时,  它将取得一个 savepoint. 如果这个嵌套事务失败, 我们将回滚到此 savepoint. 潜套事务是外部事务的一部分, 只有外部事务结束后它才会被提交. \n    由此可见, PROPAGATION_REQUIRES_NEW 和 PROPAGATION_NESTED 的最大区别在于, PROPAGATION_REQUIRES_NEW 完全是一个新的事务, 而 PROPAGATION_NESTED 则是外部事务的子事务, 如果外部事务 commit, 潜套事务也会被 commit, 这个规则同样适用于 roll back. \n\n```\n\n","source":"_posts/spring/spring事务.md","raw":"---\ntitle: spring事务\ndate: 2018-09-28 11:28:43\ntags:\n- spring \ncategories:\n- spring\n\n---\n\n# spring事务\n\n## 一、在同一类中一个调用本类中另一个有事务的方法,事务是无效\n\n第一步：首先在spring的配置文件中加入以下配置\n\n```xml\n<!-- 激活自动代理功能 -->\n<aop:aspectj-autoproxy/>\n<aop:aspectj-autoproxy proxy-target-class=\"true\" expose-proxy=\"true\" />\n```\n\n第二步：将之前使用普通调用的方法,换成使用代理调用\n\n```java\n((TestService)AopContext.currentProxy()).testTransactional2();\n```\n\n或者直接使用手动回滚\n\n```java\nTransactionAspectSupport.currentTransactionStatus().setRollbackOnly();\n```\n\n## 二、spring声明式事务管理默认对非检查型异常和运行时异常进行事务回滚，而对检查型异常则不进行回滚操作\n\n1 让checked例外也回滚：在整个方法前加上 @Transactional(rollbackFor=Exception.class)\n\n 2 让unchecked例外不回滚： @Transactional(notRollbackFor=RunTimeException.class)\n\n 3 不需要事务管理的(只查询的)方法：@Transactional(propagation=Propagation.NOT_SUPPORTED)\n\n## 三、事务的传播行为\n\n```\nPROPAGATION_REQUIRED -- 支持当前事务，如果当前没有事务，就新建一个事务。这是最常见的选择。 \nPROPAGATION_SUPPORTS -- 支持当前事务，如果当前没有事务，就以非事务方式执行。 \nPROPAGATION_MANDATORY -- 支持当前事务，如果当前没有事务，就抛出异常。 \nPROPAGATION_REQUIRES_NEW -- 新建事务，如果当前存在事务，把当前事务挂起。 \nPROPAGATION_NOT_SUPPORTED -- 以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。 \nPROPAGATION_NEVER -- 以非事务方式执行，如果当前存在事务，则抛出异常。 \nPROPAGATION_NESTED -- 如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则进行与PROPAGATION_REQUIRED类似的操作。 \n\n  PROPAGATION_REQUIRES_NEW 启动一个新的, 不依赖于环境的 \"内部\" 事务. 这个事务将被完全 commited 或 rolled back 而不依赖于外部事务, 它拥有自己的隔离范围, 自己的锁, 等等. 当内部事务开始执行时, 外部事务将被挂起, 内务事务结束时, 外部事务将继续执行. \n    另一方面, PROPAGATION_NESTED 开始一个 \"嵌套的\" 事务,  它是已经存在事务的一个真正的子事务. 潜套事务开始执行时,  它将取得一个 savepoint. 如果这个嵌套事务失败, 我们将回滚到此 savepoint. 潜套事务是外部事务的一部分, 只有外部事务结束后它才会被提交. \n    由此可见, PROPAGATION_REQUIRES_NEW 和 PROPAGATION_NESTED 的最大区别在于, PROPAGATION_REQUIRES_NEW 完全是一个新的事务, 而 PROPAGATION_NESTED 则是外部事务的子事务, 如果外部事务 commit, 潜套事务也会被 commit, 这个规则同样适用于 roll back. \n\n```\n\n","slug":"spring/spring事务","published":1,"updated":"2018-09-30T08:50:26.888Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnib0066wlkvijxa2wqe"},{"title":"volatile修饰符详解","catalog":"保证内存可见性","date":"2017-09-01T06:51:24.000Z","subtitle":"","header-img":null,"_content":"\n# volatile修饰符详解\n\njava编程语言允许线程访问共享变量，为了确保共享变量能被准确和一致的更新，线程应该确保通过排他锁单独获得这个变量。Java语言提供了volatile，在某些情况下比锁更加方便。如果一个字段被声明成volatile，java线程内存模型确保所有线程看到这个变量的值是一致的。\n\n<!--more-->\n\n## volatile 作用\n\n- 保证内存可见性\n- 防止指令重排,有序性\n- 不能解决原子性\n\n## CPU内存\n\n计算机在执行程序时，每条指令都是在CPU中执行的，而执行指令过程中，势必涉及到数据的读取和写入。由于程序运行过程中的临时数据是存放在主存（物理内存）当中的，这时就存在一个问题，由于CPU执行速度很快，而从内存读取数据和向内存写入数据的过程跟CPU执行指令的速度比起来要慢的多，因此如果任何时候对数据的操作都要通过和内存的交互来进行，会大大降低指令执行的速度。因此在CPU里面就有了高速缓存。也就是，当程序在运行过程中，会将运算需要的数据从主存复制一份到CPU的高速缓存当中，那么CPU进行计算时就可以直接从它的高速缓存读取数据和向其中写入数据，当运算结束之后，再将高速缓存中的数据刷新到主存当中,如果一个变量在多个CPU中都存在缓存（一般在多线程编程时才会出现），那么就可能存在缓存不一致的问题\n\n缓存一致性协议。最出名的就是Intel 的MESI协议，MESI协议保证了每个缓存中使用的共享变量的副本是一致的。它核心的思想是：当CPU写数据时，如果发现操作的变量是共享变量，即在其他CPU中也存在该变量的副本，会发出信号通知其他CPU将该变量的缓存行置为无效状态，因此当其他CPU需要读取这个变量时，发现自己缓存中缓存该变量的缓存行是无效的，那么它就会从内存重新读取。\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-10-18/76656449.jpg)s\n\n## java内存模型\n\njava中多线程共享的变量存储在主内存中，处理器CPU为了提高执行效率，每个线程都有自己的工作内存，工作内存保存了主内存的副本，线程要操作共享变量，实际操作的是线程工作内存的副本，操作完毕后再同步写入主内存，各个线程线程只能访问自己的工作内存，不可以访问其它线程的工作内存。\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-16/94036726-file_1489675155616_9c8e.png)\n​\t\t\t\t\t\t\t\t\t`java中线程工作内存跟主内存的交互`\n\nJava内存模型规定了工作内存与主内存之间交互的协议，首先是定义了8种原子操作：\n\n1. lock:将主内存中的变量锁定，为一个线程所独占，使用syncronize或者lock的时候\n2. unclock:将lock加的锁定解除，此时其它的线程可以有机会访问此变量，释放锁\n3. read:将主内存中的变量值读到线程的工作内存当中\n4. load:将线程工作内存中的变量指向将read读取的值的。\n5. use:将值传递给线程的代码执行引擎(多次)\n6. assign:将执行引擎处理返回的值重新赋值给变量副本\n7. store:将变量副本的值存储到主内存中。\n8. write:将主内存的共享变量指向store存储的值。\n\nJava内存模型也针对这些操作指定了必须满足的规则:\n\n1. read和load、store和write必须要成对出现，不允许单一的操作，否则会造成从主内存读取的值，工作内存不接受或者工作内存发起的写入操作而主内存无法接受的现象。\n2. 在线程中使用了assign操作改变了变量副本，那么就必须把这个副本通过store-write同步回主内存中。如果线程中没有发生assign操作，那么也不允许使用store-write同步到主内存。\n3. 在对一个变量实行use和store操作之前，必须实行过load和assign操作。\n4. 变量在同一时刻只允许一个线程对其进行lock,有多少次lock操作，就必须有多少次unlock操作。在lock操作之后会清空此变量在工作内存中原 先的副本，需要再次从主内存read-load新的值。在执行unlock操作前，需要把改变的副本同步回主存。\n\n**共享变量使用volatile修饰后，保证线程每次访问共享变量都去主内存获取，保证每次写入都会写回主内存**\n\n### 内存可见性与原子性\n\n**可见性：** 保证线程每次使用共享变量时都去主内存获取最新的，保证了read-load的一致性\n\n**原子性：** 保证线程在read-load-use-assign-store-write共享变量过程中，其它线程不能对主内存的共享变量进行修改，这时就需要lock主内存的变量，操作完毕后unlock\n\n> 如果一个字段被声明成volatile，java线程内存模型确保所有线程看到这个变量的值是一致的。\n\n### 防止指令重排\n\n**指令重排序**: JVM为了优化指令，提高程序运行效率，在不影响**单线程**程序执行结果的前提下，尽可能地提高并行度，会对代码执行顺序进行调整。在单线程下没问题，多线程的情况下指令重排序会带来许多麻烦。\n\n**内存屏障：**使用volatile后，会在该变量指令前后加入一个内存屏障，用于实现对内存操作的顺序限制。保证在volatile修饰的变量指令前的指令行无论顺序怎么变一定在volatile变量前全部执行，在volatile变量指令后的指令行无论顺序怎么变，都一定在volatile变量指令执行完后才执行。\n\n```java\n//线程1初始化User\nUser user;\nuser = new User();\n//线程2读取user\nif(user!=null){\n\tuser.getName();\n}\n```\n\nUser user = new User包括了以下三种语义：\n1：分配对象的内存空间\n2：初始化对象\n3：将user指针指向刚分配的内存地址\n\n操作2依赖于操作1，但是操作3并不依赖于操作2，所以JVM是可以针对它们进行指令的优化重排序的，优化后变为 1->3->2，这些线程1在执行完第3步而还没来得及执行完第2步的时候，如果内存刷新到了主存，那么线程2将得到一个未初始化完成的对象。\n\n```java\n//在线程A中:\ncontext = loadContext();\ninited = true;\n\n//在线程B中:\nwhile(!inited ){ //根据线程A中对inited变量的修改决定是否使用context变量\n    sleep(100);\n}\ndoSomethingwithconfig(context);\n  \n//假设线程A中发生了指令重排序:\ninited = true;\ncontext = loadContext();\n//那么B中很可能就会拿到一个尚未初始化或尚未初始化完成的context,从而引发程序错误。\n```\n\n\n\n### 代码解读可见性\n\njdk1.5之后只要有一个变量是volatile修饰的，线程去主内存读取变量的时候会把所有的变量都重新加载到线程内存，写的时候也会将所有的变量写回主内存。\n\n```java\npublic class Task implements Runnable{\n  //将count用volatile修饰，保证每次去主存读取count值，\n  //读取的同时会将running也从主存读取，不管running是否用volatile修饰\n  private volatile int count = 0;\n  private boolean running = true;\n\n  @Override\n  public void run() {\n    while(running){\n      //\n      count++;\n    }\n    System.out.println(\"子线程\"+Thread.currentThread().getName()+\"停止\");\n  }\n\n  public static void main(String[] args) throws InterruptedException {\n    Task task = new Task();\n    //启动子线程\n    new Thread(task).start();\n    Thread.currentThread().sleep(3000);\n    task.setRunning(false);\n    System.out.println(\"主线程停止\");\n  }\n\n  public void setRunning(boolean running) {\n    this.running = running;\n  }\n\n  public int getCount() {\n    return count;\n  }\n}\n```\n\n如果不使用volatile修饰共享变量，线程只会在第一次使用共享变量的时候去主内存加载建立副本，这样子线程永远不会停止\n\n使用volatile修饰修饰共享变量，在while循环的判断running值的时候，每次都去主内存获取最新的值，当主线程将running设置为false的时候，停止子线程，在while循环中使用了count变量，如果只将count用volatile修饰，也能停止子线程，由此可见，**线程去主内存读取共享变量的时候，会把所有用到的共享变量都在工作内存建立副本**\n\n### 代码解读无法实现原子性\n\n```java\npublic class Counter {\n  //使用volatile修饰共享变量\n  public volatile static int count = 0;\n\n  public static void inc() {\n    // 这里延迟1毫秒，使得结果明显\n    try {\n      Thread.sleep(1);\n    } catch (InterruptedException e) {\n    }\n    //无法保证是1000\n    count++;\n  }\n\n  public static void main(String[] args) {\n\n    // 同时启动1000个线程，去进行i++计算\n    for (int i = 0; i < 1000; i++) {\n      new Thread(new Runnable() {\n        @Override\n        public void run() {\n          Counter.inc();\n        }\n      }).start();\n    }\n    // 无法保证count值为1000\n    System.out.println(\"运行结果:Counter.count=\" + Counter.count);\n  }\n}\n```\n这段程序执行完毕后无法保证count的数量最终为1000，这是因为volatile只能保证使用count的时候去主内存读取到最新的值，但是在对count进行+1操作的时候，其它线程可能会对count进行修改+1然后写会主内存，造成最后的结果不是1000，如果要保证1000，还是要对整个read到write回主内存保证一致性，这就需要使用synchronized或者lock去实现了。\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-9-28/70069501.jpg)\n\n## 原理和实现机制\n\nlock前缀指令实际上相当于一个内存屏障（也成内存栅栏），内存屏障会提供3个功能：\n\n1. 确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成；\n2. 它会强制将对缓存的修改操作立即写入主存；\n3. 如果是写操作，它会导致其他CPU中对应的缓存行无效。\n\n## 总结\n\n- volatile无法实现原子性，只能实现可见性\n  1. 只有一个线程写共享变量，其他线程读共享变量的情况下使用volatile\n  2. 多个线程同时对共享变量进行写操作的时候，无法保证原子性\n- 当要访问的变量已在synchronized代码块中，或者为常量时，没必要使用volatile。\n- 使用volatile每次都要去操作主内存，屏蔽掉了JVM中必要的代码优化，所以在**效率上比较低**\n- **当且仅当满足以下所有条件时，才应该使用volatile变量：**\n  1. 只有一个线程写共享变量，其他线程读共享变量\n  2. 对变量的写入操作不依赖变量的当前值 （x++）\n  3. 该变量没有包含在具有其他变量的不变式中（y=x）\n  4. 防止代码重排\n\n## 参考资料\n\n[聊聊并发（一）深入分析Volatile的实现原理](http://ifeve.com/volatile/)\n\n[Java并发：volatile内存可见性和指令重排](http://www.importnew.com/23535.html)\n\n[Java Volatile Keyword](http://tutorials.jenkov.com/java-concurrency/volatile.html)\n\n","source":"_posts/多线程/volatile.md","raw":"---\ntitle: volatile修饰符详解\ncatalog: 保证内存可见性\ndate: 2017-09-01 14:51:24\nsubtitle: \"\"\nheader-img: \ntags:\n- 多线程\ncategories:\n- java基础\n\n---\n\n# volatile修饰符详解\n\njava编程语言允许线程访问共享变量，为了确保共享变量能被准确和一致的更新，线程应该确保通过排他锁单独获得这个变量。Java语言提供了volatile，在某些情况下比锁更加方便。如果一个字段被声明成volatile，java线程内存模型确保所有线程看到这个变量的值是一致的。\n\n<!--more-->\n\n## volatile 作用\n\n- 保证内存可见性\n- 防止指令重排,有序性\n- 不能解决原子性\n\n## CPU内存\n\n计算机在执行程序时，每条指令都是在CPU中执行的，而执行指令过程中，势必涉及到数据的读取和写入。由于程序运行过程中的临时数据是存放在主存（物理内存）当中的，这时就存在一个问题，由于CPU执行速度很快，而从内存读取数据和向内存写入数据的过程跟CPU执行指令的速度比起来要慢的多，因此如果任何时候对数据的操作都要通过和内存的交互来进行，会大大降低指令执行的速度。因此在CPU里面就有了高速缓存。也就是，当程序在运行过程中，会将运算需要的数据从主存复制一份到CPU的高速缓存当中，那么CPU进行计算时就可以直接从它的高速缓存读取数据和向其中写入数据，当运算结束之后，再将高速缓存中的数据刷新到主存当中,如果一个变量在多个CPU中都存在缓存（一般在多线程编程时才会出现），那么就可能存在缓存不一致的问题\n\n缓存一致性协议。最出名的就是Intel 的MESI协议，MESI协议保证了每个缓存中使用的共享变量的副本是一致的。它核心的思想是：当CPU写数据时，如果发现操作的变量是共享变量，即在其他CPU中也存在该变量的副本，会发出信号通知其他CPU将该变量的缓存行置为无效状态，因此当其他CPU需要读取这个变量时，发现自己缓存中缓存该变量的缓存行是无效的，那么它就会从内存重新读取。\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-10-18/76656449.jpg)s\n\n## java内存模型\n\njava中多线程共享的变量存储在主内存中，处理器CPU为了提高执行效率，每个线程都有自己的工作内存，工作内存保存了主内存的副本，线程要操作共享变量，实际操作的是线程工作内存的副本，操作完毕后再同步写入主内存，各个线程线程只能访问自己的工作内存，不可以访问其它线程的工作内存。\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-16/94036726-file_1489675155616_9c8e.png)\n​\t\t\t\t\t\t\t\t\t`java中线程工作内存跟主内存的交互`\n\nJava内存模型规定了工作内存与主内存之间交互的协议，首先是定义了8种原子操作：\n\n1. lock:将主内存中的变量锁定，为一个线程所独占，使用syncronize或者lock的时候\n2. unclock:将lock加的锁定解除，此时其它的线程可以有机会访问此变量，释放锁\n3. read:将主内存中的变量值读到线程的工作内存当中\n4. load:将线程工作内存中的变量指向将read读取的值的。\n5. use:将值传递给线程的代码执行引擎(多次)\n6. assign:将执行引擎处理返回的值重新赋值给变量副本\n7. store:将变量副本的值存储到主内存中。\n8. write:将主内存的共享变量指向store存储的值。\n\nJava内存模型也针对这些操作指定了必须满足的规则:\n\n1. read和load、store和write必须要成对出现，不允许单一的操作，否则会造成从主内存读取的值，工作内存不接受或者工作内存发起的写入操作而主内存无法接受的现象。\n2. 在线程中使用了assign操作改变了变量副本，那么就必须把这个副本通过store-write同步回主内存中。如果线程中没有发生assign操作，那么也不允许使用store-write同步到主内存。\n3. 在对一个变量实行use和store操作之前，必须实行过load和assign操作。\n4. 变量在同一时刻只允许一个线程对其进行lock,有多少次lock操作，就必须有多少次unlock操作。在lock操作之后会清空此变量在工作内存中原 先的副本，需要再次从主内存read-load新的值。在执行unlock操作前，需要把改变的副本同步回主存。\n\n**共享变量使用volatile修饰后，保证线程每次访问共享变量都去主内存获取，保证每次写入都会写回主内存**\n\n### 内存可见性与原子性\n\n**可见性：** 保证线程每次使用共享变量时都去主内存获取最新的，保证了read-load的一致性\n\n**原子性：** 保证线程在read-load-use-assign-store-write共享变量过程中，其它线程不能对主内存的共享变量进行修改，这时就需要lock主内存的变量，操作完毕后unlock\n\n> 如果一个字段被声明成volatile，java线程内存模型确保所有线程看到这个变量的值是一致的。\n\n### 防止指令重排\n\n**指令重排序**: JVM为了优化指令，提高程序运行效率，在不影响**单线程**程序执行结果的前提下，尽可能地提高并行度，会对代码执行顺序进行调整。在单线程下没问题，多线程的情况下指令重排序会带来许多麻烦。\n\n**内存屏障：**使用volatile后，会在该变量指令前后加入一个内存屏障，用于实现对内存操作的顺序限制。保证在volatile修饰的变量指令前的指令行无论顺序怎么变一定在volatile变量前全部执行，在volatile变量指令后的指令行无论顺序怎么变，都一定在volatile变量指令执行完后才执行。\n\n```java\n//线程1初始化User\nUser user;\nuser = new User();\n//线程2读取user\nif(user!=null){\n\tuser.getName();\n}\n```\n\nUser user = new User包括了以下三种语义：\n1：分配对象的内存空间\n2：初始化对象\n3：将user指针指向刚分配的内存地址\n\n操作2依赖于操作1，但是操作3并不依赖于操作2，所以JVM是可以针对它们进行指令的优化重排序的，优化后变为 1->3->2，这些线程1在执行完第3步而还没来得及执行完第2步的时候，如果内存刷新到了主存，那么线程2将得到一个未初始化完成的对象。\n\n```java\n//在线程A中:\ncontext = loadContext();\ninited = true;\n\n//在线程B中:\nwhile(!inited ){ //根据线程A中对inited变量的修改决定是否使用context变量\n    sleep(100);\n}\ndoSomethingwithconfig(context);\n  \n//假设线程A中发生了指令重排序:\ninited = true;\ncontext = loadContext();\n//那么B中很可能就会拿到一个尚未初始化或尚未初始化完成的context,从而引发程序错误。\n```\n\n\n\n### 代码解读可见性\n\njdk1.5之后只要有一个变量是volatile修饰的，线程去主内存读取变量的时候会把所有的变量都重新加载到线程内存，写的时候也会将所有的变量写回主内存。\n\n```java\npublic class Task implements Runnable{\n  //将count用volatile修饰，保证每次去主存读取count值，\n  //读取的同时会将running也从主存读取，不管running是否用volatile修饰\n  private volatile int count = 0;\n  private boolean running = true;\n\n  @Override\n  public void run() {\n    while(running){\n      //\n      count++;\n    }\n    System.out.println(\"子线程\"+Thread.currentThread().getName()+\"停止\");\n  }\n\n  public static void main(String[] args) throws InterruptedException {\n    Task task = new Task();\n    //启动子线程\n    new Thread(task).start();\n    Thread.currentThread().sleep(3000);\n    task.setRunning(false);\n    System.out.println(\"主线程停止\");\n  }\n\n  public void setRunning(boolean running) {\n    this.running = running;\n  }\n\n  public int getCount() {\n    return count;\n  }\n}\n```\n\n如果不使用volatile修饰共享变量，线程只会在第一次使用共享变量的时候去主内存加载建立副本，这样子线程永远不会停止\n\n使用volatile修饰修饰共享变量，在while循环的判断running值的时候，每次都去主内存获取最新的值，当主线程将running设置为false的时候，停止子线程，在while循环中使用了count变量，如果只将count用volatile修饰，也能停止子线程，由此可见，**线程去主内存读取共享变量的时候，会把所有用到的共享变量都在工作内存建立副本**\n\n### 代码解读无法实现原子性\n\n```java\npublic class Counter {\n  //使用volatile修饰共享变量\n  public volatile static int count = 0;\n\n  public static void inc() {\n    // 这里延迟1毫秒，使得结果明显\n    try {\n      Thread.sleep(1);\n    } catch (InterruptedException e) {\n    }\n    //无法保证是1000\n    count++;\n  }\n\n  public static void main(String[] args) {\n\n    // 同时启动1000个线程，去进行i++计算\n    for (int i = 0; i < 1000; i++) {\n      new Thread(new Runnable() {\n        @Override\n        public void run() {\n          Counter.inc();\n        }\n      }).start();\n    }\n    // 无法保证count值为1000\n    System.out.println(\"运行结果:Counter.count=\" + Counter.count);\n  }\n}\n```\n这段程序执行完毕后无法保证count的数量最终为1000，这是因为volatile只能保证使用count的时候去主内存读取到最新的值，但是在对count进行+1操作的时候，其它线程可能会对count进行修改+1然后写会主内存，造成最后的结果不是1000，如果要保证1000，还是要对整个read到write回主内存保证一致性，这就需要使用synchronized或者lock去实现了。\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-9-28/70069501.jpg)\n\n## 原理和实现机制\n\nlock前缀指令实际上相当于一个内存屏障（也成内存栅栏），内存屏障会提供3个功能：\n\n1. 确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成；\n2. 它会强制将对缓存的修改操作立即写入主存；\n3. 如果是写操作，它会导致其他CPU中对应的缓存行无效。\n\n## 总结\n\n- volatile无法实现原子性，只能实现可见性\n  1. 只有一个线程写共享变量，其他线程读共享变量的情况下使用volatile\n  2. 多个线程同时对共享变量进行写操作的时候，无法保证原子性\n- 当要访问的变量已在synchronized代码块中，或者为常量时，没必要使用volatile。\n- 使用volatile每次都要去操作主内存，屏蔽掉了JVM中必要的代码优化，所以在**效率上比较低**\n- **当且仅当满足以下所有条件时，才应该使用volatile变量：**\n  1. 只有一个线程写共享变量，其他线程读共享变量\n  2. 对变量的写入操作不依赖变量的当前值 （x++）\n  3. 该变量没有包含在具有其他变量的不变式中（y=x）\n  4. 防止代码重排\n\n## 参考资料\n\n[聊聊并发（一）深入分析Volatile的实现原理](http://ifeve.com/volatile/)\n\n[Java并发：volatile内存可见性和指令重排](http://www.importnew.com/23535.html)\n\n[Java Volatile Keyword](http://tutorials.jenkov.com/java-concurrency/volatile.html)\n\n","slug":"多线程/volatile","published":1,"updated":"2018-09-12T03:03:21.833Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnic0069wlkviph19zuf"},{"title":"ThreadPoolExecutor池源码解析","date":"2017-10-25T06:02:02.000Z","_content":"\n#  ThreadPoolExecutor源码解析\n\n## 源码待析\n\n- 线程池中字段\n\n  ```java\n\n  //线程池中最重要的概念，将线程池中的工作线程数量和线程池状态封装到一个int类型字段中\n  //前面两位字节表示状态，后面29位字节表示线程数量，最大为 (2^29)-1\n  private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));\n  private static final int COUNT_BITS = Integer.SIZE - 3;//总共有5个状态，需要3位来表示 (3=110)\n  private static final int CAPACITY   = (1 << COUNT_BITS) - 1;\n\n  //线程运行状态，共5个\n  private static final int RUNNING    = -1 << COUNT_BITS;//execute 接受新任务并且处理已经进入阻塞队列的任务\n  private static final int SHUTDOWN   =  0 << COUNT_BITS;//shutdown 不接受新任务，但是处理已经进入阻塞队列的任务\n  private static final int STOP       =  1 << COUNT_BITS;//shutdownNow 不接受新任务，不处理已经进入阻塞队列的任务并且中断正在运行的任务\n  private static final int TIDYING    =  2 << COUNT_BITS;//所有的任务都已经终止，workerCount为0\n  private static final int TERMINATED =  3 << COUNT_BITS;//terminated钩子函数已经运行完成\n\n  //从ctl获取线程池状态，ctl的前3位\n  private static int runStateOf(int c)     { return c & ~CAPACITY; }\n  //从线程池中获取线程数量，ctl的后29位\n  private static int workerCountOf(int c)  { return c & CAPACITY; }\n  //用线程池状态和线程池中线程数量获取ctl\n  private static int ctlOf(int rs, int wc) { return rs | wc; }\n\n  //原子WorkerCount+1\n  private boolean compareAndIncrementWorkerCount(int expect) {\n    return ctl.compareAndSet(expect, expect + 1);\n  }\n  //原子WorkerCount-1\n  private boolean compareAndDecrementWorkerCount(int expect) {\n    return ctl.compareAndSet(expect, expect - 1);\n  }\n  //原子WorkerCount-1，直到成功\n  private void decrementWorkerCount() {\n    do {} while (! compareAndDecrementWorkerCount(ctl.get()));\n  }\n  //阻塞的任务队列\n  private final BlockingQueue<Runnable> workQueue;\n  //用于对主线程进行加锁，保证workers的操作线程安全\n  private final ReentrantLock mainLock = new ReentrantLock();\n  //线程池中的任务线程\n  private final HashSet<Worker> workers = new HashSet<Worker>();\n  //用于awaitTermination\n  private final Condition termination = mainLock.newCondition();\n  ```\n\n\n\n- 线程中任务和线程的封装work\n\n  ```java\n  private final class Worker\n    extends AbstractQueuedSynchronizer\n          implements Runnable\n      {\n          private static final long serialVersionUID = 6138294804551838833L;\n  \t\t//线程的封装\n          final Thread thread;\n          //初始化时传入的任务，线程启动时执行\n          Runnable firstTask;\n          //每个线程执行完的任务数量，用于获取线程池中的总任务数(+队列中的)和执行完的总任务数\n          volatile long completedTasks;\n          Worker(Runnable firstTask) {\n              setState(-1); // inhibit interrupts until runWorker\n              this.firstTask = firstTask;\n              //调用线程工厂创建线程\n              this.thread = getThreadFactory().newThread(this);\n          }\n  \t\t//run方法\n          public void run() {\n              runWorker(this);\n          }\n          protected boolean isHeldExclusively() {\n              return getState() != 0;\n          }\n          protected boolean tryAcquire(int unused) {\n              if (compareAndSetState(0, 1)) {\n                  setExclusiveOwnerThread(Thread.currentThread());\n                  return true;\n              }\n              return false;\n          }\n          protected boolean tryRelease(int unused) {\n              setExclusiveOwnerThread(null);\n              setState(0);\n              return true;\n          }\n          public void lock()        { acquire(1); }\n          public boolean tryLock()  { return tryAcquire(1); }\n          public void unlock()      { release(1); }\n          public boolean isLocked() { return isHeldExclusively(); }\n          void interruptIfStarted() {\n              Thread t;// AQS状态大于等于0并且worker对应的线程不为null并且该线程没有被中断\n              if (getState() >= 0 && (t = thread) != null && !t.isInterrupted()) {\n                  try {\n                      t.interrupt();\n                  } catch (SecurityException ignore) {\n                  }\n              }\n          }\n      }\n  ```\n\n  ​\n\n- main线程调用线程池excute()方法，首先判断线程池中的**活动线程** 数量是否小于核心数量，如果小则创建线程并执行任务；否则判断线程池状态是否是running，然后将任务添加到任务队列，添加成功后需要再次判断线程池状态，用于回滚拒绝任务；最后如果队列已满，检查线程池中数量是否小于最大配置，如果小则创建线程，否则调用拒绝策略拒绝任务。\n\n  ```java\n  public void execute(Runnable command) {\n    if (command == null)\n      throw new NullPointerException();\n    int c = ctl.get();\n    //小于核心线程，则新建核心线程并执行任务\n    if (workerCountOf(c) < corePoolSize) {\n      //添加时检查线程数据\n      if (addWorker(command, true))\n        return;\n      c = ctl.get();\n    }\n    //添加队列成功需要再次检查线程池状态和线程数量\n    if (isRunning(c) && workQueue.offer(command)) {\n      int recheck = ctl.get();\n      //如果线程池停掉了 从队列移除任务并拒绝\n      if (! isRunning(recheck) && remove(command))\n        reject(command);\n      //如果线程池中没有活动线程了，创建线程，对线程池进行补偿，但是不立即执行任务\n      else if (workerCountOf(recheck) == 0)\n        addWorker(null, false);\n    }\n    //创建小于maxSize的线程并执行任务\n    else if (!addWorker(command, false))\n      reject(command);//失败调用拒绝策略\n  }\n  ```\n\n  ​\n\n- 添加工作线程，首先双层死循环判断是否应该新建工作线程并对变量原子操作workerCount +1，循环直到成功。然后创建Work，封装工作任务和任务线程，添加成功后start任务线程\n\n  ```java\n  private boolean addWorker(Runnable firstTask, boolean core) {\n    //双层循环 增加活动线程数量WorkerCount变量\n    retry:\n    for (;;) {\n      int c = ctl.get();\n      int rs = runStateOf(c);\n      //判断线程池被stop时或者shutdown并且任务队列为空则返回false，不接受新任务\n      if (rs >= SHUTDOWN &&\n          ! (rs == SHUTDOWN &&\n             firstTask == null &&\n             ! workQueue.isEmpty()))\n        return false;\n\n      for (;;) {\n        int wc = workerCountOf(c);//线程池中线程数量\n        //判断线程池中的线程数量是否已超过最大数或者超过核心数量配置或者超过最大数量配置\n        if (wc >= CAPACITY ||\n            wc >= (core ? corePoolSize : maximumPoolSize))\n          return false;\n        //workerCount+1  维护ctl所代表的活动线程数量\n        if (compareAndIncrementWorkerCount(c))\n          break retry;\n        c = ctl.get();  // Re-read ctl\n        //没有加成功的话并且线程池状态改变继续外层循环，重新开放校验，否则内层循环\n        if (runStateOf(c) != rs)\n          continue retry;\n        // else CAS failed due to workerCount change; retry inner loop\n      }\n    }\n\n    boolean workerStarted = false;\n    boolean workerAdded = false;\n    Worker w = null;\n    try {\n      w = new Worker(firstTask);\n      final Thread t = w.thread;\n      if (t != null) {\n        final ReentrantLock mainLock = this.mainLock;\n        //主线程加锁\n        mainLock.lock();\n        try {\n          int rs = runStateOf(ctl.get());\n  \t\t//启动工作线程前最后再次检查线程池状态\n          if (rs < SHUTDOWN ||\n              (rs == SHUTDOWN && firstTask == null)) {\n            //检查工作线程是否存活，否则抛出异常\n            if (t.isAlive()) // precheck that t is startable\n              throw new IllegalThreadStateException();\n            //将任务线程加入任务线程集合\n            workers.add(w);\n            int s = workers.size();\n            //维护线程池最大线程数量\n            if (s > largestPoolSize)\n              largestPoolSize = s;\n            workerAdded = true;\n          }\n        } finally {\n          mainLock.unlock();\n        }\n        if (workerAdded) {\n          //添加成功后，启动任务线程\n          t.start();\n          workerStarted = true;\n        }\n      }\n    } finally {\n      //失败回滚\n      if (! workerStarted)\n        addWorkerFailed(w);\n    }\n    return workerStarted;\n  }\n  ```\n\n- 添加任务线程失败需要回滚workerCount 数量并从任务线程集合中移除失败的work\n\n  ```java\n  private void addWorkerFailed(Worker w) {\n    final ReentrantLock mainLock = this.mainLock;\n    mainLock.lock();\n    try {\n      if (w != null)\n        //移除\n        workers.remove(w);\n      //减1\n      decrementWorkerCount();\n      tryTerminate();\n    } finally {\n      mainLock.unlock();\n    }\n  }\n  ```\n\n- 线程池的任务start后，会调用runWorker方法，线程会首先执行worker中封装的任务，如果没有任务则去任务队列中获取任务。获取任务后保证任务线程在线程池正常运行情况下不存在中断状态，当线程池stop后，任务线程有中断状态。\n\n  任务线程在执行前会调用钩子方法beforeExecute，由用户覆盖实现。直接使用当前线程调用任务的run方法，如果run异常，completedAbruptly为true，标识线程异常结束；执行完run方法后调用钩子方法afterExecute，同时将异常信息也传入该方法\n\n  如果任务线程不再被任务队列阻塞同时也无法获取任务，将调用processWorkerExit销毁线程\n\n  ```java\n  final void runWorker(Worker w) {\n    Thread wt = Thread.currentThread();\n    //取得第一个任务，并将任务线程处的任务置空\n    Runnable task = w.firstTask;\n    w.firstTask = null;\n    // 释放锁（设置state为0，允许中断）\n    w.unlock(); // allow interrupts\n    boolean completedAbruptly = true;\n    try {\n      //任务线程要么有初始任务，要么一直循环调用getTask获取任务\n      while (task != null || (task = getTask()) != null) {\n        w.lock();\n        //用于保证线程池正常运行情况下所有线程都没有中断状态，使用interrupted清除\n        //线程池状态stop后，任务线程加上中断状态，用户可以使用isInterrupted进行判断\n        if ((runStateAtLeast(ctl.get(), STOP) ||\n             (Thread.interrupted() &&//interrupted会清除线程的中断状态\n              runStateAtLeast(ctl.get(), STOP))) &&\n            !wt.isInterrupted())\n          wt.interrupt();//主线程会退出循环\n        try {\n          //任务执行前方法\n          beforeExecute(wt, task);\n          Throwable thrown = null;\n          try {\n            //这里使用的是run，直接调用\n            task.run();\n          } catch (RuntimeException x) {\n            thrown = x; throw x;\n          } catch (Error x) {\n            thrown = x; throw x;\n          } catch (Throwable x) {\n            thrown = x; throw new Error(x);\n          } finally {\n            //任务执行后的回调\n            afterExecute(task, thrown);\n          }\n        } finally {\n          task = null;//栈中任务指针重置\n          w.completedTasks++;//运行的任务+1\n          w.unlock();\n        }\n      }\n      //false任务线程正常运行结束，如果在执行中抛异常则为true，说明异常结束，会进行补偿\n      completedAbruptly = false;\n    } finally {\n      //销毁线程\n      processWorkerExit(w, completedAbruptly);\n    }\n  }\n  ```\n\n- 当work中没有初始任务的时候，会去任务队列中获取任务，取任务的时候首先校验线程池是否停止，如果停止就停止消费，返回null，如果线程数量超过maxSize，或者核心线程允许销毁并且当前还有活动线程，则减少活动线程，并返回null，等待存活的活动线程消费任务队列，用于减少线程池中线程数量。\n\n  检验通过后去任务对列获取线程，任务对列是BlockQueue，用于阻塞线程，如果允许空闲线程销毁，调用poll(time)，经过一定时间后销毁线程，如果不允许销毁，直接调用take()方法阻塞活动线程，线程池中任务线程处于空闲状态，等待任务队列任务进行消费。\n\n  ```java\n  private Runnable getTask() {\n        boolean timedOut = false; //当poll超时会设置为true，用于下次循环减少活动线程数\n        for (;;) {\n            int c = ctl.get();\n            int rs = runStateOf(c);\n            //线程池状态为stop是停止消费，线程池状态为shutdown并且队列为空也停止消费\n            if (rs >= SHUTDOWN && (rs >= STOP || workQueue.isEmpty())) {\n                decrementWorkerCount();//减少线程池中一个线程个数\n                return null;\n            }\n            int wc = workerCountOf(c);\n            //在线程池中所有线程时一视同仁的，只是在保存的时候保存coreSize个\n            boolean timed = allowCoreThreadTimeOut || wc > corePoolSize;\n  \t//如果线程池中线程个数超过最大maxNum设置并且队列为空时，清空线程\n            if ((wc > maximumPoolSize || (timed && timedOut))\n                && (wc > 1 || workQueue.isEmpty())) {\n              // do {} while (! compareAndDecrementWorkerCount(ctl.get()));\n                if (compareAndDecrementWorkerCount(c))\n                    return null;\n                continue;//如果减少线程失败重新获取任务\n            }\n            try {\n            //从队列中获取任务，如果队列为空 会被阻塞\n                Runnable r = timed ?\n                    workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) :\n                    workQueue.take();\n                if (r != null)\n                    return r;\n                timedOut = true;//用于下次循环跳出\n            } catch (InterruptedException retry) {\n                timedOut = false;\n            }\n        }\n    }\n  ```\n\n- 如果任务线程不再被任务队列阻塞同时也无法获取任务，将调用processWorkerExit销毁线程，在销毁线程的时候记录总执行的任务数\n\n  如果线程在调用run方法时抛出异常，在线程池未停止的情况下会新建线程进行补偿\n\n  在销毁线程的时候，判断线程池在未停止并且任务队列不为空的情况下的线程数量是否为0或者小于coreSize，如果是，创建新的Work线程对线程池进行补偿。\n\n  ```java\n  private void processWorkerExit(Worker w, boolean completedAbruptly) {\n    //如果任务线程异常结束，减少workerCount数量，在该线程结束时新建线程补偿线程池\n    if (completedAbruptly) // If abrupt, then workerCount wasn't adjusted\n      decrementWorkerCount();\n    final ReentrantLock mainLock = this.mainLock;\n    //使用main lock保证线程安全，用于统计任务线程的执行信息\n    mainLock.lock();\n    try {\n      //线程池执行总任务数++\n      completedTaskCount += w.completedTasks;\n      //从任务线程list中移除\n      workers.remove(w);\n    } finally {\n      mainLock.unlock();\n    }\n  //尝试销毁线程池\n    tryTerminate();\n\n    int c = ctl.get();\n    if (runStateLessThan(c, STOP)) { //判断线程池未停止\n      //如果任务执行异常，对线程池进行任务线程补偿\n      if (!completedAbruptly) {\n        int min = allowCoreThreadTimeOut ? 0 : corePoolSize;\n        //当任务队列还有任务的时候，线程数量小于coreSize，创建线程进行补偿\n        if (min == 0 && ! workQueue.isEmpty())\n          min = 1;\n        if (workerCountOf(c) >= min)\n          return; // replacement not needed\n      }\n      addWorker(null, false);//在addWorker中会判断数量是否超过\n    }\n  }\n  ```\n\n- 销毁线程的过程，如果线程池状态为还可以处理任务则不处理，如果线程池需要回收线程，首先回收处于空闲状态的线程，即激活处理阻塞队列take方法的线程，让线程正常运行结束。\n\n  如果线程池中存活的线程个数为0，则关闭线程池，设置线程池状态为TIDYING，并调用钩子方法terminated，设置线程池状态为TERMINATED\n\n  ```java\n  final void tryTerminate() {\n    for (;;) {\n      int c = ctl.get();\n      if (isRunning(c) ||\n          runStateAtLeast(c, TIDYING) ||\n          (runStateOf(c) == SHUTDOWN && ! workQueue.isEmpty()))\n        return;\n      if (workerCountOf(c) != 0) { \n        //唤醒被队列take阻塞的线程\n        interruptIdleWorkers(ONLY_ONE);\n        return;\n      }\n  \t//调用shutdown方法，等待所有执行中的任务执行完毕后销毁线程池\n      final ReentrantLock mainLock = this.mainLock;\n      mainLock.lock();\n      try {//判断线程池中运行线程是否为0，任务队列为空的时候销毁线程池\n        if (ctl.compareAndSet(c, ctlOf(TIDYING, 0))) {\n          try {\n            //调用钩子方法，线程池终止\n            terminated();\n          } finally {\n            ctl.set(ctlOf(TERMINATED, 0));//设置线程池最终状态\n            termination.signalAll();\n          }\n          return;\n        }\n      } finally {\n        mainLock.unlock();\n      }\n    }\n  }\n  ```\n\n- 线程池关闭shutdown\n\n  ```java\n  public void shutdown() {\n    final ReentrantLock mainLock = this.mainLock;\n    mainLock.lock();\n    try {\n      checkShutdownAccess();\n      advanceRunState(SHUTDOWN);//设置线程池状态为 shutdown 即 0+线程数量\n      interruptIdleWorkers();//中断空闲线程\n      onShutdown(); // hook for ScheduledThreadPoolExecutor\n    } finally {\n      mainLock.unlock();\n    }\n    tryTerminate();//再次销毁线程，等线程数量为0时，销毁线程池\n  }\n  //中断空闲线程\n  private void interruptIdleWorkers(boolean onlyOne) {\n    final ReentrantLock mainLock = this.mainLock;\n    mainLock.lock();\n    try {\n      for (Worker w : workers) {\n        Thread t = w.thread;\n        //通过tryLock来判断当前线程是否空闲，因为活动线程无法tryLock\n        if (!t.isInterrupted() && w.tryLock()) {\n          try {\n            t.interrupt();//会激活阻塞在队列take()方法的线程\n          } catch (SecurityException ignore) {\n          } finally {\n            w.unlock();\n          }\n        }\n        if (onlyOne)\n          break;\n      }\n    } finally {\n      mainLock.unlock();\n    }\n  }\n  ```\n\n- 线程关闭shutdownNow\n\n  ```java\n  public List<Runnable> shutdownNow() {\n      List<Runnable> tasks;\n      final ReentrantLock mainLock = this.mainLock;\n      mainLock.lock();\n      try {\n          checkShutdownAccess();\n          advanceRunState(STOP);//设置状态给为stop\n          interruptWorkers();//中断所有线程\n          tasks = drainQueue();//返回任务队列中剩余的任务\n      } finally {\n          mainLock.unlock();\n      }\n      tryTerminate();//销毁线程池\n      return tasks;\n  }\n\n  private void interruptWorkers() {\n    final ReentrantLock mainLock = this.mainLock;\n    mainLock.lock();\n    try {\n      for (Worker w : workers)\n        w.interruptIfStarted();\n    } finally {\n      mainLock.unlock();\n    }\n  }\n  ```\n\n\n## 参考资料\n\n[【JUC】JDK1.8源码分析之ThreadPoolExecutor（一）](http://www.cnblogs.com/leesf456/p/5585627.html)","source":"_posts/多线程/ThreadPoolExecutor源码解析.md","raw":"---\ntitle: ThreadPoolExecutor池源码解析\ndate: 2017-10-25 14:02:02\ntags:\n- 多线程\n- 源码解析\ncategories:\n- java基础\n\n---\n\n#  ThreadPoolExecutor源码解析\n\n## 源码待析\n\n- 线程池中字段\n\n  ```java\n\n  //线程池中最重要的概念，将线程池中的工作线程数量和线程池状态封装到一个int类型字段中\n  //前面两位字节表示状态，后面29位字节表示线程数量，最大为 (2^29)-1\n  private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));\n  private static final int COUNT_BITS = Integer.SIZE - 3;//总共有5个状态，需要3位来表示 (3=110)\n  private static final int CAPACITY   = (1 << COUNT_BITS) - 1;\n\n  //线程运行状态，共5个\n  private static final int RUNNING    = -1 << COUNT_BITS;//execute 接受新任务并且处理已经进入阻塞队列的任务\n  private static final int SHUTDOWN   =  0 << COUNT_BITS;//shutdown 不接受新任务，但是处理已经进入阻塞队列的任务\n  private static final int STOP       =  1 << COUNT_BITS;//shutdownNow 不接受新任务，不处理已经进入阻塞队列的任务并且中断正在运行的任务\n  private static final int TIDYING    =  2 << COUNT_BITS;//所有的任务都已经终止，workerCount为0\n  private static final int TERMINATED =  3 << COUNT_BITS;//terminated钩子函数已经运行完成\n\n  //从ctl获取线程池状态，ctl的前3位\n  private static int runStateOf(int c)     { return c & ~CAPACITY; }\n  //从线程池中获取线程数量，ctl的后29位\n  private static int workerCountOf(int c)  { return c & CAPACITY; }\n  //用线程池状态和线程池中线程数量获取ctl\n  private static int ctlOf(int rs, int wc) { return rs | wc; }\n\n  //原子WorkerCount+1\n  private boolean compareAndIncrementWorkerCount(int expect) {\n    return ctl.compareAndSet(expect, expect + 1);\n  }\n  //原子WorkerCount-1\n  private boolean compareAndDecrementWorkerCount(int expect) {\n    return ctl.compareAndSet(expect, expect - 1);\n  }\n  //原子WorkerCount-1，直到成功\n  private void decrementWorkerCount() {\n    do {} while (! compareAndDecrementWorkerCount(ctl.get()));\n  }\n  //阻塞的任务队列\n  private final BlockingQueue<Runnable> workQueue;\n  //用于对主线程进行加锁，保证workers的操作线程安全\n  private final ReentrantLock mainLock = new ReentrantLock();\n  //线程池中的任务线程\n  private final HashSet<Worker> workers = new HashSet<Worker>();\n  //用于awaitTermination\n  private final Condition termination = mainLock.newCondition();\n  ```\n\n\n\n- 线程中任务和线程的封装work\n\n  ```java\n  private final class Worker\n    extends AbstractQueuedSynchronizer\n          implements Runnable\n      {\n          private static final long serialVersionUID = 6138294804551838833L;\n  \t\t//线程的封装\n          final Thread thread;\n          //初始化时传入的任务，线程启动时执行\n          Runnable firstTask;\n          //每个线程执行完的任务数量，用于获取线程池中的总任务数(+队列中的)和执行完的总任务数\n          volatile long completedTasks;\n          Worker(Runnable firstTask) {\n              setState(-1); // inhibit interrupts until runWorker\n              this.firstTask = firstTask;\n              //调用线程工厂创建线程\n              this.thread = getThreadFactory().newThread(this);\n          }\n  \t\t//run方法\n          public void run() {\n              runWorker(this);\n          }\n          protected boolean isHeldExclusively() {\n              return getState() != 0;\n          }\n          protected boolean tryAcquire(int unused) {\n              if (compareAndSetState(0, 1)) {\n                  setExclusiveOwnerThread(Thread.currentThread());\n                  return true;\n              }\n              return false;\n          }\n          protected boolean tryRelease(int unused) {\n              setExclusiveOwnerThread(null);\n              setState(0);\n              return true;\n          }\n          public void lock()        { acquire(1); }\n          public boolean tryLock()  { return tryAcquire(1); }\n          public void unlock()      { release(1); }\n          public boolean isLocked() { return isHeldExclusively(); }\n          void interruptIfStarted() {\n              Thread t;// AQS状态大于等于0并且worker对应的线程不为null并且该线程没有被中断\n              if (getState() >= 0 && (t = thread) != null && !t.isInterrupted()) {\n                  try {\n                      t.interrupt();\n                  } catch (SecurityException ignore) {\n                  }\n              }\n          }\n      }\n  ```\n\n  ​\n\n- main线程调用线程池excute()方法，首先判断线程池中的**活动线程** 数量是否小于核心数量，如果小则创建线程并执行任务；否则判断线程池状态是否是running，然后将任务添加到任务队列，添加成功后需要再次判断线程池状态，用于回滚拒绝任务；最后如果队列已满，检查线程池中数量是否小于最大配置，如果小则创建线程，否则调用拒绝策略拒绝任务。\n\n  ```java\n  public void execute(Runnable command) {\n    if (command == null)\n      throw new NullPointerException();\n    int c = ctl.get();\n    //小于核心线程，则新建核心线程并执行任务\n    if (workerCountOf(c) < corePoolSize) {\n      //添加时检查线程数据\n      if (addWorker(command, true))\n        return;\n      c = ctl.get();\n    }\n    //添加队列成功需要再次检查线程池状态和线程数量\n    if (isRunning(c) && workQueue.offer(command)) {\n      int recheck = ctl.get();\n      //如果线程池停掉了 从队列移除任务并拒绝\n      if (! isRunning(recheck) && remove(command))\n        reject(command);\n      //如果线程池中没有活动线程了，创建线程，对线程池进行补偿，但是不立即执行任务\n      else if (workerCountOf(recheck) == 0)\n        addWorker(null, false);\n    }\n    //创建小于maxSize的线程并执行任务\n    else if (!addWorker(command, false))\n      reject(command);//失败调用拒绝策略\n  }\n  ```\n\n  ​\n\n- 添加工作线程，首先双层死循环判断是否应该新建工作线程并对变量原子操作workerCount +1，循环直到成功。然后创建Work，封装工作任务和任务线程，添加成功后start任务线程\n\n  ```java\n  private boolean addWorker(Runnable firstTask, boolean core) {\n    //双层循环 增加活动线程数量WorkerCount变量\n    retry:\n    for (;;) {\n      int c = ctl.get();\n      int rs = runStateOf(c);\n      //判断线程池被stop时或者shutdown并且任务队列为空则返回false，不接受新任务\n      if (rs >= SHUTDOWN &&\n          ! (rs == SHUTDOWN &&\n             firstTask == null &&\n             ! workQueue.isEmpty()))\n        return false;\n\n      for (;;) {\n        int wc = workerCountOf(c);//线程池中线程数量\n        //判断线程池中的线程数量是否已超过最大数或者超过核心数量配置或者超过最大数量配置\n        if (wc >= CAPACITY ||\n            wc >= (core ? corePoolSize : maximumPoolSize))\n          return false;\n        //workerCount+1  维护ctl所代表的活动线程数量\n        if (compareAndIncrementWorkerCount(c))\n          break retry;\n        c = ctl.get();  // Re-read ctl\n        //没有加成功的话并且线程池状态改变继续外层循环，重新开放校验，否则内层循环\n        if (runStateOf(c) != rs)\n          continue retry;\n        // else CAS failed due to workerCount change; retry inner loop\n      }\n    }\n\n    boolean workerStarted = false;\n    boolean workerAdded = false;\n    Worker w = null;\n    try {\n      w = new Worker(firstTask);\n      final Thread t = w.thread;\n      if (t != null) {\n        final ReentrantLock mainLock = this.mainLock;\n        //主线程加锁\n        mainLock.lock();\n        try {\n          int rs = runStateOf(ctl.get());\n  \t\t//启动工作线程前最后再次检查线程池状态\n          if (rs < SHUTDOWN ||\n              (rs == SHUTDOWN && firstTask == null)) {\n            //检查工作线程是否存活，否则抛出异常\n            if (t.isAlive()) // precheck that t is startable\n              throw new IllegalThreadStateException();\n            //将任务线程加入任务线程集合\n            workers.add(w);\n            int s = workers.size();\n            //维护线程池最大线程数量\n            if (s > largestPoolSize)\n              largestPoolSize = s;\n            workerAdded = true;\n          }\n        } finally {\n          mainLock.unlock();\n        }\n        if (workerAdded) {\n          //添加成功后，启动任务线程\n          t.start();\n          workerStarted = true;\n        }\n      }\n    } finally {\n      //失败回滚\n      if (! workerStarted)\n        addWorkerFailed(w);\n    }\n    return workerStarted;\n  }\n  ```\n\n- 添加任务线程失败需要回滚workerCount 数量并从任务线程集合中移除失败的work\n\n  ```java\n  private void addWorkerFailed(Worker w) {\n    final ReentrantLock mainLock = this.mainLock;\n    mainLock.lock();\n    try {\n      if (w != null)\n        //移除\n        workers.remove(w);\n      //减1\n      decrementWorkerCount();\n      tryTerminate();\n    } finally {\n      mainLock.unlock();\n    }\n  }\n  ```\n\n- 线程池的任务start后，会调用runWorker方法，线程会首先执行worker中封装的任务，如果没有任务则去任务队列中获取任务。获取任务后保证任务线程在线程池正常运行情况下不存在中断状态，当线程池stop后，任务线程有中断状态。\n\n  任务线程在执行前会调用钩子方法beforeExecute，由用户覆盖实现。直接使用当前线程调用任务的run方法，如果run异常，completedAbruptly为true，标识线程异常结束；执行完run方法后调用钩子方法afterExecute，同时将异常信息也传入该方法\n\n  如果任务线程不再被任务队列阻塞同时也无法获取任务，将调用processWorkerExit销毁线程\n\n  ```java\n  final void runWorker(Worker w) {\n    Thread wt = Thread.currentThread();\n    //取得第一个任务，并将任务线程处的任务置空\n    Runnable task = w.firstTask;\n    w.firstTask = null;\n    // 释放锁（设置state为0，允许中断）\n    w.unlock(); // allow interrupts\n    boolean completedAbruptly = true;\n    try {\n      //任务线程要么有初始任务，要么一直循环调用getTask获取任务\n      while (task != null || (task = getTask()) != null) {\n        w.lock();\n        //用于保证线程池正常运行情况下所有线程都没有中断状态，使用interrupted清除\n        //线程池状态stop后，任务线程加上中断状态，用户可以使用isInterrupted进行判断\n        if ((runStateAtLeast(ctl.get(), STOP) ||\n             (Thread.interrupted() &&//interrupted会清除线程的中断状态\n              runStateAtLeast(ctl.get(), STOP))) &&\n            !wt.isInterrupted())\n          wt.interrupt();//主线程会退出循环\n        try {\n          //任务执行前方法\n          beforeExecute(wt, task);\n          Throwable thrown = null;\n          try {\n            //这里使用的是run，直接调用\n            task.run();\n          } catch (RuntimeException x) {\n            thrown = x; throw x;\n          } catch (Error x) {\n            thrown = x; throw x;\n          } catch (Throwable x) {\n            thrown = x; throw new Error(x);\n          } finally {\n            //任务执行后的回调\n            afterExecute(task, thrown);\n          }\n        } finally {\n          task = null;//栈中任务指针重置\n          w.completedTasks++;//运行的任务+1\n          w.unlock();\n        }\n      }\n      //false任务线程正常运行结束，如果在执行中抛异常则为true，说明异常结束，会进行补偿\n      completedAbruptly = false;\n    } finally {\n      //销毁线程\n      processWorkerExit(w, completedAbruptly);\n    }\n  }\n  ```\n\n- 当work中没有初始任务的时候，会去任务队列中获取任务，取任务的时候首先校验线程池是否停止，如果停止就停止消费，返回null，如果线程数量超过maxSize，或者核心线程允许销毁并且当前还有活动线程，则减少活动线程，并返回null，等待存活的活动线程消费任务队列，用于减少线程池中线程数量。\n\n  检验通过后去任务对列获取线程，任务对列是BlockQueue，用于阻塞线程，如果允许空闲线程销毁，调用poll(time)，经过一定时间后销毁线程，如果不允许销毁，直接调用take()方法阻塞活动线程，线程池中任务线程处于空闲状态，等待任务队列任务进行消费。\n\n  ```java\n  private Runnable getTask() {\n        boolean timedOut = false; //当poll超时会设置为true，用于下次循环减少活动线程数\n        for (;;) {\n            int c = ctl.get();\n            int rs = runStateOf(c);\n            //线程池状态为stop是停止消费，线程池状态为shutdown并且队列为空也停止消费\n            if (rs >= SHUTDOWN && (rs >= STOP || workQueue.isEmpty())) {\n                decrementWorkerCount();//减少线程池中一个线程个数\n                return null;\n            }\n            int wc = workerCountOf(c);\n            //在线程池中所有线程时一视同仁的，只是在保存的时候保存coreSize个\n            boolean timed = allowCoreThreadTimeOut || wc > corePoolSize;\n  \t//如果线程池中线程个数超过最大maxNum设置并且队列为空时，清空线程\n            if ((wc > maximumPoolSize || (timed && timedOut))\n                && (wc > 1 || workQueue.isEmpty())) {\n              // do {} while (! compareAndDecrementWorkerCount(ctl.get()));\n                if (compareAndDecrementWorkerCount(c))\n                    return null;\n                continue;//如果减少线程失败重新获取任务\n            }\n            try {\n            //从队列中获取任务，如果队列为空 会被阻塞\n                Runnable r = timed ?\n                    workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) :\n                    workQueue.take();\n                if (r != null)\n                    return r;\n                timedOut = true;//用于下次循环跳出\n            } catch (InterruptedException retry) {\n                timedOut = false;\n            }\n        }\n    }\n  ```\n\n- 如果任务线程不再被任务队列阻塞同时也无法获取任务，将调用processWorkerExit销毁线程，在销毁线程的时候记录总执行的任务数\n\n  如果线程在调用run方法时抛出异常，在线程池未停止的情况下会新建线程进行补偿\n\n  在销毁线程的时候，判断线程池在未停止并且任务队列不为空的情况下的线程数量是否为0或者小于coreSize，如果是，创建新的Work线程对线程池进行补偿。\n\n  ```java\n  private void processWorkerExit(Worker w, boolean completedAbruptly) {\n    //如果任务线程异常结束，减少workerCount数量，在该线程结束时新建线程补偿线程池\n    if (completedAbruptly) // If abrupt, then workerCount wasn't adjusted\n      decrementWorkerCount();\n    final ReentrantLock mainLock = this.mainLock;\n    //使用main lock保证线程安全，用于统计任务线程的执行信息\n    mainLock.lock();\n    try {\n      //线程池执行总任务数++\n      completedTaskCount += w.completedTasks;\n      //从任务线程list中移除\n      workers.remove(w);\n    } finally {\n      mainLock.unlock();\n    }\n  //尝试销毁线程池\n    tryTerminate();\n\n    int c = ctl.get();\n    if (runStateLessThan(c, STOP)) { //判断线程池未停止\n      //如果任务执行异常，对线程池进行任务线程补偿\n      if (!completedAbruptly) {\n        int min = allowCoreThreadTimeOut ? 0 : corePoolSize;\n        //当任务队列还有任务的时候，线程数量小于coreSize，创建线程进行补偿\n        if (min == 0 && ! workQueue.isEmpty())\n          min = 1;\n        if (workerCountOf(c) >= min)\n          return; // replacement not needed\n      }\n      addWorker(null, false);//在addWorker中会判断数量是否超过\n    }\n  }\n  ```\n\n- 销毁线程的过程，如果线程池状态为还可以处理任务则不处理，如果线程池需要回收线程，首先回收处于空闲状态的线程，即激活处理阻塞队列take方法的线程，让线程正常运行结束。\n\n  如果线程池中存活的线程个数为0，则关闭线程池，设置线程池状态为TIDYING，并调用钩子方法terminated，设置线程池状态为TERMINATED\n\n  ```java\n  final void tryTerminate() {\n    for (;;) {\n      int c = ctl.get();\n      if (isRunning(c) ||\n          runStateAtLeast(c, TIDYING) ||\n          (runStateOf(c) == SHUTDOWN && ! workQueue.isEmpty()))\n        return;\n      if (workerCountOf(c) != 0) { \n        //唤醒被队列take阻塞的线程\n        interruptIdleWorkers(ONLY_ONE);\n        return;\n      }\n  \t//调用shutdown方法，等待所有执行中的任务执行完毕后销毁线程池\n      final ReentrantLock mainLock = this.mainLock;\n      mainLock.lock();\n      try {//判断线程池中运行线程是否为0，任务队列为空的时候销毁线程池\n        if (ctl.compareAndSet(c, ctlOf(TIDYING, 0))) {\n          try {\n            //调用钩子方法，线程池终止\n            terminated();\n          } finally {\n            ctl.set(ctlOf(TERMINATED, 0));//设置线程池最终状态\n            termination.signalAll();\n          }\n          return;\n        }\n      } finally {\n        mainLock.unlock();\n      }\n    }\n  }\n  ```\n\n- 线程池关闭shutdown\n\n  ```java\n  public void shutdown() {\n    final ReentrantLock mainLock = this.mainLock;\n    mainLock.lock();\n    try {\n      checkShutdownAccess();\n      advanceRunState(SHUTDOWN);//设置线程池状态为 shutdown 即 0+线程数量\n      interruptIdleWorkers();//中断空闲线程\n      onShutdown(); // hook for ScheduledThreadPoolExecutor\n    } finally {\n      mainLock.unlock();\n    }\n    tryTerminate();//再次销毁线程，等线程数量为0时，销毁线程池\n  }\n  //中断空闲线程\n  private void interruptIdleWorkers(boolean onlyOne) {\n    final ReentrantLock mainLock = this.mainLock;\n    mainLock.lock();\n    try {\n      for (Worker w : workers) {\n        Thread t = w.thread;\n        //通过tryLock来判断当前线程是否空闲，因为活动线程无法tryLock\n        if (!t.isInterrupted() && w.tryLock()) {\n          try {\n            t.interrupt();//会激活阻塞在队列take()方法的线程\n          } catch (SecurityException ignore) {\n          } finally {\n            w.unlock();\n          }\n        }\n        if (onlyOne)\n          break;\n      }\n    } finally {\n      mainLock.unlock();\n    }\n  }\n  ```\n\n- 线程关闭shutdownNow\n\n  ```java\n  public List<Runnable> shutdownNow() {\n      List<Runnable> tasks;\n      final ReentrantLock mainLock = this.mainLock;\n      mainLock.lock();\n      try {\n          checkShutdownAccess();\n          advanceRunState(STOP);//设置状态给为stop\n          interruptWorkers();//中断所有线程\n          tasks = drainQueue();//返回任务队列中剩余的任务\n      } finally {\n          mainLock.unlock();\n      }\n      tryTerminate();//销毁线程池\n      return tasks;\n  }\n\n  private void interruptWorkers() {\n    final ReentrantLock mainLock = this.mainLock;\n    mainLock.lock();\n    try {\n      for (Worker w : workers)\n        w.interruptIfStarted();\n    } finally {\n      mainLock.unlock();\n    }\n  }\n  ```\n\n\n## 参考资料\n\n[【JUC】JDK1.8源码分析之ThreadPoolExecutor（一）](http://www.cnblogs.com/leesf456/p/5585627.html)","slug":"多线程/ThreadPoolExecutor源码解析","published":1,"updated":"2018-09-12T03:03:21.828Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnid006cwlkvz51lmaxv"},{"title":"mybatis-generator源码","date":"2018-09-12T08:12:30.000Z","_content":"\n# mybatis-generator源码\n\n## 一、xml规范dtd文件解读\n\n框架中很多配置文件都是用的xml，对于xml的格式约束分两种dtd和schema两种，mybatis-generator使用的就是dtd方式。有时候在写配置的时候不看文档的话不知道如何配置，不知道都有哪些节点，节点都有哪些属性，这时可以通过配置文件的约束dtd来查看。\n\n- 元素声明\n\n- ```xml\n  <!ELEMENT generatorConfiguration (properties?, classPathEntry*, context+)>\n  ```\n\n通过`ELEMENT`声明了generatorConfiguration元素及其子元素。\n\n通过通配符声明子元素的个数 `?`标示0个或者1个，`*`标示0个或者多个，`+`标示大于等于1个\n\n- 属性声明\n\n  ```xml\n  <!ATTLIST context id ID #REQUIRED\n    defaultModelType CDATA #IMPLIED\n    targetRuntime CDATA #IMPLIED\n    introspectedColumnImpl CDATA #IMPLIED>\n  ```\n\n通过`ATTLIST`声明元素的属性，`#REQUIRED`标识属性为必须的，`#IMPLIED`标识属性为可选的\n\n## 二、整体过程\n\n![](http://omdq6di7v.bkt.clouddn.com/18-9-18/68157555.jpg)\n\n配置解析按照元素及属性顺序解析\n\n![](http://omdq6di7v.bkt.clouddn.com/18-9-18/74647471.jpg)\n\n## 三、代码片段\n\n- 反射数据库表\n\n```java\n public List<IntrospectedTable> introspectTables(TableConfiguration tc)\n              throws SQLException {\n     //获取数据库表到数据库表列的map\n     Map<ActualTableName, List<IntrospectedColumn>> columns = getColumns(tc);\n     if (columns.isEmpty()) {\n         return null;\n     }\n     //应用配置文件的配置\n     removeIgnoredColumns(tc, columns);\n     calculateExtraColumnInformation(tc, columns);\n     applyColumnOverrides(tc, columns);\n     calculateIdentityColumns(tc, columns);\n\n     List<IntrospectedTable> introspectedTables = calculateIntrospectedTables(\n         tc, columns);\n     return introspectedTables;\n }\n```\n\n\n- 生成文件对象 GeneratedJavaFile GeneratedXmlFile\n\n```java\npublic void generateFiles(ProgressCallback callback,\n        List<GeneratedJavaFile> generatedJavaFiles,\n        List<GeneratedXmlFile> generatedXmlFiles, List<String> warnings)\n        throws InterruptedException {\n\t//聚合插件的功能\n    pluginAggregator = new PluginAggregator();\n    for (PluginConfiguration pluginConfiguration : pluginConfigurations) {\n        Plugin plugin = ObjectFactory.createPlugin(this,\n                pluginConfiguration);\n        if (plugin.validate(warnings)) {\n            pluginAggregator.addPlugin(plugin);\n        } else {\n            warnings.add(getString(\"Warning.24\", //$NON-NLS-1$\n                    pluginConfiguration.getConfigurationType(), id));\n        }\n    }\n\n    if (introspectedTables != null) {\n        for (IntrospectedTable introspectedTable : introspectedTables) {\n            callback.checkCancel();\n            //构建要生成的文件的名称\n            introspectedTable.initialize();\n            //创建生成器，并添加的表配置中\n            introspectedTable.calculateGenerators(warnings, callback);\n            generatedJavaFiles.addAll(introspectedTable\n                    .getGeneratedJavaFiles());\n            generatedXmlFiles.addAll(introspectedTable\n                    .getGeneratedXmlFiles());\n\t\t\t//支持插件扩展(基于配置表)\n            generatedJavaFiles.addAll(pluginAggregator\n                    .contextGenerateAdditionalJavaFiles(introspectedTable));\n            generatedXmlFiles.addAll(pluginAggregator\n                    .contextGenerateAdditionalXmlFiles(introspectedTable));\n        }\n    }\n\t//支持额外文件生成扩展\n    generatedJavaFiles.addAll(pluginAggregator\n            .contextGenerateAdditionalJavaFiles());\n    generatedXmlFiles.addAll(pluginAggregator\n            .contextGenerateAdditionalXmlFiles());\n}\n```\n\n- 生成java文件对象类\n\n```java\npublic abstract class GeneratedFile {\n\t//目标工程\n    protected String targetProject;\n}\n```\n\n```java\npublic class GeneratedJavaFile extends GeneratedFile {\n\t//要生成的文件\n    private CompilationUnit compilationUnit;\n\t//字符集\n    private String fileEncoding;\n\t//格式化\n    private JavaFormatter javaFormatter;\n    \n    @Override\n    public String getFormattedContent() {\n        return javaFormatter.getFormattedContent(compilationUnit);\n    }\n\n}\n```\n\n生成文件的元素对象关系图\n\n![](http://omdq6di7v.bkt.clouddn.com/18-9-18/91943829.jpg)\n\n最终生成的java文件都是`TopLevelClass`、`Interface`、`TopLevelEnumeration`,都继承了`CompilationUnit`类。在这些元素对象中实现了默认的格式化输出，当调用`JavaFormatter`的时候会调用元素的默认实现\n\n\n- 写文件\n\n```java\nprivate void writeGeneratedJavaFile(GeneratedJavaFile gjf, ProgressCallback callback)\n        throws InterruptedException, IOException {\n    File targetFile;\n    String source;\n    try {\n        File directory = shellCallback.getDirectory(gjf\n                .getTargetProject(), gjf.getTargetPackage());\n        targetFile = new File(directory, gjf.getFileName());\n        if (targetFile.exists()) {\n            //通过shellCallback来控制是否能够跟之前生成的代码合并 需要自己实现\n            if (shellCallback.isMergeSupported()) {\n                source = shellCallback.mergeJavaFile(gjf\n                        .getFormattedContent(), targetFile,\n                        MergeConstants.OLD_ELEMENT_TAGS,\n                        gjf.getFileEncoding());\n            } else if (shellCallback.isOverwriteEnabled()) {\n                source = gjf.getFormattedContent();\n                warnings.add(getString(\"Warning.11\", //$NON-NLS-1$\n                        targetFile.getAbsolutePath()));\n            } else {\n                source = gjf.getFormattedContent();//格式化\n                targetFile = getUniqueFileName(directory, gjf.getFileName());\n                warnings.add(getString( \"Warning.2\", targetFile.getAbsolutePath())); \n            }\n        } else {\n            source = gjf.getFormattedContent();\n        }\n        callback.checkCancel();\n        callback.startTask(getString(\"Progress.15\", targetFile.getName())); //$NON-NLS-1$\n        writeFile(targetFile, source, gjf.getFileEncoding());//写文件\n    } catch (ShellException e) {\n        warnings.add(e.getMessage());\n    }\n}\n```\n\n\n- 加载外部jar包\n\n```java\npublic static ClassLoader getCustomClassloader(Collection<String> entries) {\n    List<URL> urls = new ArrayList<URL>();\n    File file;\n    if (entries != null) {\n        for (String classPathEntry : entries) {\n            file = new File(classPathEntry);\n            if (!file.exists()) {\n                throw new RuntimeException(getString(\"RuntimeError.9\", classPathEntry)); \n            }\n            try {\n                urls.add(file.toURI().toURL());\n            } catch (MalformedURLException e) {\n                // this shouldn't happen, but just in case...\n                throw new RuntimeException(getString( \"RuntimeError.9\", classPathEntry)); \n            }\n        }\n    }\n    //创建URLClassLoader，并指定当前线程的类加载器为父类加载器\n    ClassLoader parent = Thread.currentThread().getContextClassLoader();\n    URLClassLoader ucl = new URLClassLoader(urls.toArray(new URL[urls\n            .size()]), parent);\n    return ucl;\n}\n```\n\n- 国际化\n\n```java\npublic class Messages {\n    private static final String BUNDLE_NAME = \"org.mybatis.generator.internal.util.messages.messages\"; //$NON-NLS-1$\n\n    private static final ResourceBundle RESOURCE_BUNDLE = ResourceBundle\n            .getBundle(BUNDLE_NAME);\n\n    private Messages() {\n    }\n\n    public static String getString(String key) {\n        try {\n            return RESOURCE_BUNDLE.getString(key);\n        } catch (MissingResourceException e) {\n            return '!' + key + '!';\n        }\n    }\n    public static String getString(String key, String parm1) {\n        try {\n            return MessageFormat.format(RESOURCE_BUNDLE.getString(key),\n                    new Object[] { parm1 });\n        } catch (MissingResourceException e) {\n            return '!' + key + '!';\n        }\n    }\n}\n```\n\n","source":"_posts/源码学习/mybatis-generator源码.md","raw":"---\ntitle: mybatis-generator源码\ndate: 2018-09-12 16:12:30\ntags:\n- mybatis\ncategories:\n- 源码\n---\n\n# mybatis-generator源码\n\n## 一、xml规范dtd文件解读\n\n框架中很多配置文件都是用的xml，对于xml的格式约束分两种dtd和schema两种，mybatis-generator使用的就是dtd方式。有时候在写配置的时候不看文档的话不知道如何配置，不知道都有哪些节点，节点都有哪些属性，这时可以通过配置文件的约束dtd来查看。\n\n- 元素声明\n\n- ```xml\n  <!ELEMENT generatorConfiguration (properties?, classPathEntry*, context+)>\n  ```\n\n通过`ELEMENT`声明了generatorConfiguration元素及其子元素。\n\n通过通配符声明子元素的个数 `?`标示0个或者1个，`*`标示0个或者多个，`+`标示大于等于1个\n\n- 属性声明\n\n  ```xml\n  <!ATTLIST context id ID #REQUIRED\n    defaultModelType CDATA #IMPLIED\n    targetRuntime CDATA #IMPLIED\n    introspectedColumnImpl CDATA #IMPLIED>\n  ```\n\n通过`ATTLIST`声明元素的属性，`#REQUIRED`标识属性为必须的，`#IMPLIED`标识属性为可选的\n\n## 二、整体过程\n\n![](http://omdq6di7v.bkt.clouddn.com/18-9-18/68157555.jpg)\n\n配置解析按照元素及属性顺序解析\n\n![](http://omdq6di7v.bkt.clouddn.com/18-9-18/74647471.jpg)\n\n## 三、代码片段\n\n- 反射数据库表\n\n```java\n public List<IntrospectedTable> introspectTables(TableConfiguration tc)\n              throws SQLException {\n     //获取数据库表到数据库表列的map\n     Map<ActualTableName, List<IntrospectedColumn>> columns = getColumns(tc);\n     if (columns.isEmpty()) {\n         return null;\n     }\n     //应用配置文件的配置\n     removeIgnoredColumns(tc, columns);\n     calculateExtraColumnInformation(tc, columns);\n     applyColumnOverrides(tc, columns);\n     calculateIdentityColumns(tc, columns);\n\n     List<IntrospectedTable> introspectedTables = calculateIntrospectedTables(\n         tc, columns);\n     return introspectedTables;\n }\n```\n\n\n- 生成文件对象 GeneratedJavaFile GeneratedXmlFile\n\n```java\npublic void generateFiles(ProgressCallback callback,\n        List<GeneratedJavaFile> generatedJavaFiles,\n        List<GeneratedXmlFile> generatedXmlFiles, List<String> warnings)\n        throws InterruptedException {\n\t//聚合插件的功能\n    pluginAggregator = new PluginAggregator();\n    for (PluginConfiguration pluginConfiguration : pluginConfigurations) {\n        Plugin plugin = ObjectFactory.createPlugin(this,\n                pluginConfiguration);\n        if (plugin.validate(warnings)) {\n            pluginAggregator.addPlugin(plugin);\n        } else {\n            warnings.add(getString(\"Warning.24\", //$NON-NLS-1$\n                    pluginConfiguration.getConfigurationType(), id));\n        }\n    }\n\n    if (introspectedTables != null) {\n        for (IntrospectedTable introspectedTable : introspectedTables) {\n            callback.checkCancel();\n            //构建要生成的文件的名称\n            introspectedTable.initialize();\n            //创建生成器，并添加的表配置中\n            introspectedTable.calculateGenerators(warnings, callback);\n            generatedJavaFiles.addAll(introspectedTable\n                    .getGeneratedJavaFiles());\n            generatedXmlFiles.addAll(introspectedTable\n                    .getGeneratedXmlFiles());\n\t\t\t//支持插件扩展(基于配置表)\n            generatedJavaFiles.addAll(pluginAggregator\n                    .contextGenerateAdditionalJavaFiles(introspectedTable));\n            generatedXmlFiles.addAll(pluginAggregator\n                    .contextGenerateAdditionalXmlFiles(introspectedTable));\n        }\n    }\n\t//支持额外文件生成扩展\n    generatedJavaFiles.addAll(pluginAggregator\n            .contextGenerateAdditionalJavaFiles());\n    generatedXmlFiles.addAll(pluginAggregator\n            .contextGenerateAdditionalXmlFiles());\n}\n```\n\n- 生成java文件对象类\n\n```java\npublic abstract class GeneratedFile {\n\t//目标工程\n    protected String targetProject;\n}\n```\n\n```java\npublic class GeneratedJavaFile extends GeneratedFile {\n\t//要生成的文件\n    private CompilationUnit compilationUnit;\n\t//字符集\n    private String fileEncoding;\n\t//格式化\n    private JavaFormatter javaFormatter;\n    \n    @Override\n    public String getFormattedContent() {\n        return javaFormatter.getFormattedContent(compilationUnit);\n    }\n\n}\n```\n\n生成文件的元素对象关系图\n\n![](http://omdq6di7v.bkt.clouddn.com/18-9-18/91943829.jpg)\n\n最终生成的java文件都是`TopLevelClass`、`Interface`、`TopLevelEnumeration`,都继承了`CompilationUnit`类。在这些元素对象中实现了默认的格式化输出，当调用`JavaFormatter`的时候会调用元素的默认实现\n\n\n- 写文件\n\n```java\nprivate void writeGeneratedJavaFile(GeneratedJavaFile gjf, ProgressCallback callback)\n        throws InterruptedException, IOException {\n    File targetFile;\n    String source;\n    try {\n        File directory = shellCallback.getDirectory(gjf\n                .getTargetProject(), gjf.getTargetPackage());\n        targetFile = new File(directory, gjf.getFileName());\n        if (targetFile.exists()) {\n            //通过shellCallback来控制是否能够跟之前生成的代码合并 需要自己实现\n            if (shellCallback.isMergeSupported()) {\n                source = shellCallback.mergeJavaFile(gjf\n                        .getFormattedContent(), targetFile,\n                        MergeConstants.OLD_ELEMENT_TAGS,\n                        gjf.getFileEncoding());\n            } else if (shellCallback.isOverwriteEnabled()) {\n                source = gjf.getFormattedContent();\n                warnings.add(getString(\"Warning.11\", //$NON-NLS-1$\n                        targetFile.getAbsolutePath()));\n            } else {\n                source = gjf.getFormattedContent();//格式化\n                targetFile = getUniqueFileName(directory, gjf.getFileName());\n                warnings.add(getString( \"Warning.2\", targetFile.getAbsolutePath())); \n            }\n        } else {\n            source = gjf.getFormattedContent();\n        }\n        callback.checkCancel();\n        callback.startTask(getString(\"Progress.15\", targetFile.getName())); //$NON-NLS-1$\n        writeFile(targetFile, source, gjf.getFileEncoding());//写文件\n    } catch (ShellException e) {\n        warnings.add(e.getMessage());\n    }\n}\n```\n\n\n- 加载外部jar包\n\n```java\npublic static ClassLoader getCustomClassloader(Collection<String> entries) {\n    List<URL> urls = new ArrayList<URL>();\n    File file;\n    if (entries != null) {\n        for (String classPathEntry : entries) {\n            file = new File(classPathEntry);\n            if (!file.exists()) {\n                throw new RuntimeException(getString(\"RuntimeError.9\", classPathEntry)); \n            }\n            try {\n                urls.add(file.toURI().toURL());\n            } catch (MalformedURLException e) {\n                // this shouldn't happen, but just in case...\n                throw new RuntimeException(getString( \"RuntimeError.9\", classPathEntry)); \n            }\n        }\n    }\n    //创建URLClassLoader，并指定当前线程的类加载器为父类加载器\n    ClassLoader parent = Thread.currentThread().getContextClassLoader();\n    URLClassLoader ucl = new URLClassLoader(urls.toArray(new URL[urls\n            .size()]), parent);\n    return ucl;\n}\n```\n\n- 国际化\n\n```java\npublic class Messages {\n    private static final String BUNDLE_NAME = \"org.mybatis.generator.internal.util.messages.messages\"; //$NON-NLS-1$\n\n    private static final ResourceBundle RESOURCE_BUNDLE = ResourceBundle\n            .getBundle(BUNDLE_NAME);\n\n    private Messages() {\n    }\n\n    public static String getString(String key) {\n        try {\n            return RESOURCE_BUNDLE.getString(key);\n        } catch (MissingResourceException e) {\n            return '!' + key + '!';\n        }\n    }\n    public static String getString(String key, String parm1) {\n        try {\n            return MessageFormat.format(RESOURCE_BUNDLE.getString(key),\n                    new Object[] { parm1 });\n        } catch (MissingResourceException e) {\n            return '!' + key + '!';\n        }\n    }\n}\n```\n\n","slug":"源码学习/mybatis-generator源码","published":1,"updated":"2018-09-18T09:59:57.053Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnie006fwlkvuqffdl4f"},{"title":"队列Queue","date":"2017-09-03T16:26:48.000Z","_content":"\n# 队列Queue\n\nQueue接口与List、Set同一级别，都是继承了Collection接口。LinkedList实现了Queue接 口。\n\nQueue是一种数据结构．它有两个基本操作：在队列尾部加人一个元素，和从队列头部移除一个元素就是说，队列以一种先进先出的方式管理数据，如果你试图向一个 已经满了的阻塞队列中添加一个元素或者是从一个空的阻塞队列中移除一个元索，将导致线程阻塞．\n\n在多线程进行合作时，阻塞队列是很有用的工具。工作线程可 以定期地把中间结果存到阻塞队列中而其他工作者线线程把中间结果取出并在将来修改它们。队列会自动平衡负载。如果第一个线程集运行得比第二个慢，则第二个 线程集在等待结果时就会阻塞。如果第一个线程集运行得快，那么它将等待第二个线程集赶上来。\n\n<!--more-->\n\n## BlockingQueue\n\nBlockingQueue对于添加、移除和检查操作分别提供了四种处理方法：第一种是抛出一个异常，第二种是返回一个特殊值（null 或 false，具体取决于操作），第三种是在操作可以成功前，无限期地阻塞当前线程，第四种是等待指定时间后超时放弃。\n\n| 操作   | 抛出异常      | 特殊值      | 阻塞     | 超时                   |\n| ---- | --------- | -------- | ------ | -------------------- |\n| 插入   | add(e)    | offer(e) | put(e) | offer(e, time, unit) |\n| 移除   | remove()  | poll()   | take() | poll(time, unit)     |\n| 检查   | element() | peek()   | 不可用    | 不可用                  |\n\npoll 移除并返问队列头部的元素 如果队列为空\n\ntake 获取并移除此队列的头部，如果队列为空，则阻塞\n\npeek 返回队列头部的元素  如果队列为空，则返回null\n\ndrainTo(Collection<? super E> c) 移除此队列中所有可用的元素，并将它们添加到给定 collection 中\n\n## BlockingQueue实现类\n\n### SynchronousQueue\n\n同步的阻塞队列，其中每个插入操作必须等待另一个线程的对应移除操作 ，等待过程一直处于阻塞状态，反之亦然。同步队列没有任何内部容量。\n\n不能在同步队列上进行 `peek`，因为仅在试图要移除元素时，该元素才存在；除非另一个线程试图移除某个元素，否则也不能插入元素；也不能迭代队列，因为其中没有元素可用于迭代。队列的*头* 是尝试添加到队列中的首个已排队插入线程的元素；如果没有这样的已排队线程，则没有可用于移除的元素并且 `poll()` 将会返回 `null`。对于其他 `Collection` 方法（例如 `contains`），`SynchronousQueue` 作为一个空 collection。此队列不允许 `null` 元素。 \n\n同步队列类似于 CSP 和 Ada 中使用的 rendezvous 信道。它非常适合于传递性设计，在这种设计中，在一个线程中运行的对象要将某些信息、事件或任务传递给在另一个线程中运行的对象，它就必须与该对象同步。 \n\n对于正在等待的生产者和使用者线程而言，此类支持可选的公平排序策略。默认情况下不保证这种排序。但是，使用公平设置为 `true` 所构造的队列可保证线程以 FIFO 的顺序进行访问\n\n### ArrayBlockingQueue\n\n原理：使用一个可重入锁和这个锁生成的两个条件对象进行并发控制\n\nArrayBlockingQueue是基于数组的有界阻塞队列，初始化的时候必须要指定队列长度，`且指定长度之后不允许进行修改`。\n\n队列按FIFO原则对元素进行排序，队列头部是在队列中存活时间最长的元素，队尾则是存在时间最短的元素。\n\nArrayBlockingQueue构造方法可通过设置fairness参数来选择是否采用公平策略，如果公平参数被设置true，等待时间最长的线程会优先得到处理(队列头部)，公平性通常会降低吞吐量，但也减少了可变性和避免了“不平衡性”，可根据情况来决策。\n\n内部构成\n\n```java\n//内部数组结构\nfinal Object[] items;\n//头部指针\nint takeIndex;\n//尾部指针\nint putIndex;\n//总数\nint count;\n/** Main lock guarding all access */\nfinal ReentrantLock lock;\n/** Condition for waiting takes */\nprivate final Condition notEmpty;\n/** Condition for waiting puts */\nprivate final Condition notFull;\npublic ArrayBlockingQueue(int capacity, boolean fair) {\n  if (capacity <= 0)\n    throw new IllegalArgumentException();\n  this.items = new Object[capacity];\n  lock = new ReentrantLock(fair);\n  notEmpty = lock.newCondition();\n  notFull =  lock.newCondition();\n}\n```\n添加元素，在添加的时候使用锁保证线程安全，put 方法通过while循环控制notEmpty condition的await实现阻塞等待。\n```java\n//同理是添加\npublic void put(E e) throws InterruptedException {\n  checkNotNull(e);\n  final ReentrantLock lock = this.lock;\n  lock.lockInterruptibly();\n  try {\n    while (count == items.length)\n      notFull.await();\n    enqueue(e);\n  } finally {\n    lock.unlock();\n  }\n}\n//加入队列 个数+1 激活notEmpty\nprivate void enqueue(E x) {\n  final Object[] items = this.items;\n  items[putIndex] = x;\n  if (++putIndex == items.length)\n    putIndex = 0;\n  count++;\n  notEmpty.signal();\n}\npublic boolean offer(E e, long timeout, TimeUnit unit)\n  throws InterruptedException {\n  checkNotNull(e);\n  long nanos = unit.toNanos(timeout);\n  final ReentrantLock lock = this.lock;\n  lock.lockInterruptibly();\n  try {\n    while (count == items.length) {\n      if (nanos <= 0)\n        return false;\n      nanos = notFull.awaitNanos(nanos);\n    }\n    enqueue(e);\n    return true;\n  } finally {\n    lock.unlock();\n  }\n}\n```\n检查是否存在元素，element 是对 peek 的封装\n```java\n//获取队列头\npublic E peek() {\n  final ReentrantLock lock = this.lock;\n  lock.lock();\n  try {\n    return itemAt(takeIndex); //获取队列头 null when queue is empty\n  } finally {\n    lock.unlock();\n  }\n}\npublic E element() {\n  E x = peek();\n  if (x != null)\n    return x;\n  else\n    throw new NoSuchElementException();\n}\n```\n取走一个元素，在取走的时候使用锁保证线程安全，take方法通过while循环控制notEmpty condition的await实现阻塞等待。\n```java\n//take是基于ReentrantLock中两个条件进行await\npublic E take() throws InterruptedException {\n  final ReentrantLock lock = this.lock;\n  //如果获取了锁定立即返回，如果没有获取锁定，当前线程处于休眠状态，直到或者锁定，或者当前线程被别的线程中断\n  lock.lockInterruptibly();\n  try {\n    while (count == 0)\n      notEmpty.await();//一直为空的时候 notEmpty 等待\n    return dequeue();//唤醒notFull\n  } finally {\n    lock.unlock();\n  }\n}\n//队列-1，并返回头部元素，激活notFull\nprivate E dequeue() {\n  final Object[] items = this.items;\n  @SuppressWarnings(\"unchecked\")\n  E x = (E) items[takeIndex];\n  items[takeIndex] = null;\n  if (++takeIndex == items.length)\n    takeIndex = 0;\n  count--;\n  if (itrs != null)\n    itrs.elementDequeued();//获取头部element\n  notFull.signal();//唤醒notFull\n  return x;\n}\npublic E poll(long timeout, TimeUnit unit) throws InterruptedException {\n  long nanos = unit.toNanos(timeout);\n  final ReentrantLock lock = this.lock;\n  lock.lockInterruptibly();\n  try {\n    while (count == 0) {\n      if (nanos <= 0)\n        return null;\n      nanos = notEmpty.awaitNanos(nanos);//停止一段时间\n    }\n    return dequeue();\n  } finally {\n    lock.unlock();\n  }\n}\npublic E remove() {\n  E x = poll();\n  if (x != null)\n    return x;\n  else\n    throw new NoSuchElementException();\n}\n```\n\n### LinkedBlockingQueue\n\nLinkedBlockingQueue是一个使用单向循环链表完成队列操作的阻塞队列。\n\n内部使用放锁和拿锁，这两个锁实现阻塞(“two lock queue” algorithm)。添加数据和删除数据是可以并行进行的，当然添加数据和删除数据的时候只能有1个线程各自执行\n\n容量默认为Integer.MAX_VALUE，但是也可以选择指定其最大容量，此队列按 FIFO（先进先出）排序元素。**基于链表的队列吞吐量通常要高于基于数组的队列。**\n\n内部结构\n\n```java\n//元素结构\nstatic class Node<E> {\n  E item;\n  //单向\n  Node<E> next;\n  Node(E x) { item = x; }\n}\n//长度\nprivate final AtomicInteger count = new AtomicInteger();\n//头指针\ntransient Node<E> head;\n//尾指针\nprivate transient Node<E> last;\n//读锁\nprivate final ReentrantLock takeLock = new ReentrantLock();\n\nprivate final Condition notEmpty = takeLock.newCondition();\n//写锁\nprivate final ReentrantLock putLock = new ReentrantLock();\n\nprivate final Condition notFull = putLock.newCondition();\n```\n添加元素\n```java\npublic void put(E e) throws InterruptedException {\n        if (e == null) throw new NullPointerException();\n        // holding count negative to indicate failure unless set.\n        int c = -1;\n        Node<E> node = new Node<E>(e);\n        final ReentrantLock putLock = this.putLock;\n        final AtomicInteger count = this.count;\n        putLock.lockInterruptibly();\n        try {\n            // count在写里面使用同一个锁，取得时候用的另一个锁，写的时候判断长度\n            while (count.get() == capacity) {\n                notFull.await();\n            }\n            enqueue(node);\n          \t//添加完之后再次判断，如果没满，激活其他写线程\n            c = count.getAndIncrement();\n            if (c + 1 < capacity)\n                notFull.signal();\n        } finally {\n            putLock.unlock();\n        }\n  \t\t/// 没太明白 \n        if (c == 0)\n            signalNotEmpty();\n    }\n```\n\n### PriorityBlockingQueue \n\n基于优先级的无界阻塞队列，PriorityQueue保存队列元素的顺序不是按加入队列的顺序，而是按队列元素的大小进行重新排序。PriorityQueue中的元素可以默认自然排序（也就是数字默认是小的在队列头，字符串则按字典序排列）或者通过提供的Comparator（比较器）在队列实例化时指定的排序方式。\n\n当PriorityQueue中没有指定Comparator时，加入PriorityQueue的元素必须实现了Comparable接口（即元素是可比较的）\n\n该队列也没有上限（看了一下源码，PriorityBlockingQueue是对 PriorityQueue的再次包装，是基于堆数据结构的，而PriorityQueue是没有容量限制的，与ArrayList一样，所以在优先阻塞队列上put时是不会受阻的。虽然此队列逻辑上是无界的，但是由于资源被耗尽，所以试图执行添加操作可能会导致 OutOfMemoryError），但是如果队列为空，那么取元素的操作take就会阻塞，所以它的检索操作take是受阻的。无限的add会导致内存溢出\n\n从 iterator() 返回的 Iterator 实例不需要以优先级顺序返回元素。如果必须以优先级顺序遍历所有元素，那么让它们都通过 toArray() 方法并自己对它们排序，像 Arrays.sort(pq.toArray())。\n\n### DelayQueue\n\n基于PriorityQueue来实现的,是一个存放Delayed 元素的无界阻塞队列，只有在延迟期满时才能从中提取元素。该队列的头部是延迟期满后保存时间最长的 Delayed 元素。如果延迟都还没有期满，则队列没有头部，并且poll将返回null。当一个元素的 getDelay(TimeUnit.NANOSECONDS) 方法返回一个小于或等于零的值时，则出现期满，poll就以移除这个元素了。此队列不允许使用 null 元素。 \n\n## Deque\n\nQueue的一个子接口，双向队列是指该队列两端的元素既能入队(offer)也能出队(poll),如果将Deque限制为只能从一端入队和出队，则可实现栈的数据结构。对于栈而言，有入栈(push)和出栈(pop)，遵循先进后出原则\n\n### ArrayDeque\n\n实现Deque接口，内部是一个循环数组，可动态扩展，ArrayDeque不可以存取null元素，因为系统根据某个位置是否为null来判断元素的存在，","source":"_posts/消息队列/队列Queue.md","raw":"---\ntitle: 队列Queue\ndate: 2017-09-04 00:26:48\ntags:\n- 多线程\n- 集合\n- 数据结构\ncategories:\n- java基础\n---\n\n# 队列Queue\n\nQueue接口与List、Set同一级别，都是继承了Collection接口。LinkedList实现了Queue接 口。\n\nQueue是一种数据结构．它有两个基本操作：在队列尾部加人一个元素，和从队列头部移除一个元素就是说，队列以一种先进先出的方式管理数据，如果你试图向一个 已经满了的阻塞队列中添加一个元素或者是从一个空的阻塞队列中移除一个元索，将导致线程阻塞．\n\n在多线程进行合作时，阻塞队列是很有用的工具。工作线程可 以定期地把中间结果存到阻塞队列中而其他工作者线线程把中间结果取出并在将来修改它们。队列会自动平衡负载。如果第一个线程集运行得比第二个慢，则第二个 线程集在等待结果时就会阻塞。如果第一个线程集运行得快，那么它将等待第二个线程集赶上来。\n\n<!--more-->\n\n## BlockingQueue\n\nBlockingQueue对于添加、移除和检查操作分别提供了四种处理方法：第一种是抛出一个异常，第二种是返回一个特殊值（null 或 false，具体取决于操作），第三种是在操作可以成功前，无限期地阻塞当前线程，第四种是等待指定时间后超时放弃。\n\n| 操作   | 抛出异常      | 特殊值      | 阻塞     | 超时                   |\n| ---- | --------- | -------- | ------ | -------------------- |\n| 插入   | add(e)    | offer(e) | put(e) | offer(e, time, unit) |\n| 移除   | remove()  | poll()   | take() | poll(time, unit)     |\n| 检查   | element() | peek()   | 不可用    | 不可用                  |\n\npoll 移除并返问队列头部的元素 如果队列为空\n\ntake 获取并移除此队列的头部，如果队列为空，则阻塞\n\npeek 返回队列头部的元素  如果队列为空，则返回null\n\ndrainTo(Collection<? super E> c) 移除此队列中所有可用的元素，并将它们添加到给定 collection 中\n\n## BlockingQueue实现类\n\n### SynchronousQueue\n\n同步的阻塞队列，其中每个插入操作必须等待另一个线程的对应移除操作 ，等待过程一直处于阻塞状态，反之亦然。同步队列没有任何内部容量。\n\n不能在同步队列上进行 `peek`，因为仅在试图要移除元素时，该元素才存在；除非另一个线程试图移除某个元素，否则也不能插入元素；也不能迭代队列，因为其中没有元素可用于迭代。队列的*头* 是尝试添加到队列中的首个已排队插入线程的元素；如果没有这样的已排队线程，则没有可用于移除的元素并且 `poll()` 将会返回 `null`。对于其他 `Collection` 方法（例如 `contains`），`SynchronousQueue` 作为一个空 collection。此队列不允许 `null` 元素。 \n\n同步队列类似于 CSP 和 Ada 中使用的 rendezvous 信道。它非常适合于传递性设计，在这种设计中，在一个线程中运行的对象要将某些信息、事件或任务传递给在另一个线程中运行的对象，它就必须与该对象同步。 \n\n对于正在等待的生产者和使用者线程而言，此类支持可选的公平排序策略。默认情况下不保证这种排序。但是，使用公平设置为 `true` 所构造的队列可保证线程以 FIFO 的顺序进行访问\n\n### ArrayBlockingQueue\n\n原理：使用一个可重入锁和这个锁生成的两个条件对象进行并发控制\n\nArrayBlockingQueue是基于数组的有界阻塞队列，初始化的时候必须要指定队列长度，`且指定长度之后不允许进行修改`。\n\n队列按FIFO原则对元素进行排序，队列头部是在队列中存活时间最长的元素，队尾则是存在时间最短的元素。\n\nArrayBlockingQueue构造方法可通过设置fairness参数来选择是否采用公平策略，如果公平参数被设置true，等待时间最长的线程会优先得到处理(队列头部)，公平性通常会降低吞吐量，但也减少了可变性和避免了“不平衡性”，可根据情况来决策。\n\n内部构成\n\n```java\n//内部数组结构\nfinal Object[] items;\n//头部指针\nint takeIndex;\n//尾部指针\nint putIndex;\n//总数\nint count;\n/** Main lock guarding all access */\nfinal ReentrantLock lock;\n/** Condition for waiting takes */\nprivate final Condition notEmpty;\n/** Condition for waiting puts */\nprivate final Condition notFull;\npublic ArrayBlockingQueue(int capacity, boolean fair) {\n  if (capacity <= 0)\n    throw new IllegalArgumentException();\n  this.items = new Object[capacity];\n  lock = new ReentrantLock(fair);\n  notEmpty = lock.newCondition();\n  notFull =  lock.newCondition();\n}\n```\n添加元素，在添加的时候使用锁保证线程安全，put 方法通过while循环控制notEmpty condition的await实现阻塞等待。\n```java\n//同理是添加\npublic void put(E e) throws InterruptedException {\n  checkNotNull(e);\n  final ReentrantLock lock = this.lock;\n  lock.lockInterruptibly();\n  try {\n    while (count == items.length)\n      notFull.await();\n    enqueue(e);\n  } finally {\n    lock.unlock();\n  }\n}\n//加入队列 个数+1 激活notEmpty\nprivate void enqueue(E x) {\n  final Object[] items = this.items;\n  items[putIndex] = x;\n  if (++putIndex == items.length)\n    putIndex = 0;\n  count++;\n  notEmpty.signal();\n}\npublic boolean offer(E e, long timeout, TimeUnit unit)\n  throws InterruptedException {\n  checkNotNull(e);\n  long nanos = unit.toNanos(timeout);\n  final ReentrantLock lock = this.lock;\n  lock.lockInterruptibly();\n  try {\n    while (count == items.length) {\n      if (nanos <= 0)\n        return false;\n      nanos = notFull.awaitNanos(nanos);\n    }\n    enqueue(e);\n    return true;\n  } finally {\n    lock.unlock();\n  }\n}\n```\n检查是否存在元素，element 是对 peek 的封装\n```java\n//获取队列头\npublic E peek() {\n  final ReentrantLock lock = this.lock;\n  lock.lock();\n  try {\n    return itemAt(takeIndex); //获取队列头 null when queue is empty\n  } finally {\n    lock.unlock();\n  }\n}\npublic E element() {\n  E x = peek();\n  if (x != null)\n    return x;\n  else\n    throw new NoSuchElementException();\n}\n```\n取走一个元素，在取走的时候使用锁保证线程安全，take方法通过while循环控制notEmpty condition的await实现阻塞等待。\n```java\n//take是基于ReentrantLock中两个条件进行await\npublic E take() throws InterruptedException {\n  final ReentrantLock lock = this.lock;\n  //如果获取了锁定立即返回，如果没有获取锁定，当前线程处于休眠状态，直到或者锁定，或者当前线程被别的线程中断\n  lock.lockInterruptibly();\n  try {\n    while (count == 0)\n      notEmpty.await();//一直为空的时候 notEmpty 等待\n    return dequeue();//唤醒notFull\n  } finally {\n    lock.unlock();\n  }\n}\n//队列-1，并返回头部元素，激活notFull\nprivate E dequeue() {\n  final Object[] items = this.items;\n  @SuppressWarnings(\"unchecked\")\n  E x = (E) items[takeIndex];\n  items[takeIndex] = null;\n  if (++takeIndex == items.length)\n    takeIndex = 0;\n  count--;\n  if (itrs != null)\n    itrs.elementDequeued();//获取头部element\n  notFull.signal();//唤醒notFull\n  return x;\n}\npublic E poll(long timeout, TimeUnit unit) throws InterruptedException {\n  long nanos = unit.toNanos(timeout);\n  final ReentrantLock lock = this.lock;\n  lock.lockInterruptibly();\n  try {\n    while (count == 0) {\n      if (nanos <= 0)\n        return null;\n      nanos = notEmpty.awaitNanos(nanos);//停止一段时间\n    }\n    return dequeue();\n  } finally {\n    lock.unlock();\n  }\n}\npublic E remove() {\n  E x = poll();\n  if (x != null)\n    return x;\n  else\n    throw new NoSuchElementException();\n}\n```\n\n### LinkedBlockingQueue\n\nLinkedBlockingQueue是一个使用单向循环链表完成队列操作的阻塞队列。\n\n内部使用放锁和拿锁，这两个锁实现阻塞(“two lock queue” algorithm)。添加数据和删除数据是可以并行进行的，当然添加数据和删除数据的时候只能有1个线程各自执行\n\n容量默认为Integer.MAX_VALUE，但是也可以选择指定其最大容量，此队列按 FIFO（先进先出）排序元素。**基于链表的队列吞吐量通常要高于基于数组的队列。**\n\n内部结构\n\n```java\n//元素结构\nstatic class Node<E> {\n  E item;\n  //单向\n  Node<E> next;\n  Node(E x) { item = x; }\n}\n//长度\nprivate final AtomicInteger count = new AtomicInteger();\n//头指针\ntransient Node<E> head;\n//尾指针\nprivate transient Node<E> last;\n//读锁\nprivate final ReentrantLock takeLock = new ReentrantLock();\n\nprivate final Condition notEmpty = takeLock.newCondition();\n//写锁\nprivate final ReentrantLock putLock = new ReentrantLock();\n\nprivate final Condition notFull = putLock.newCondition();\n```\n添加元素\n```java\npublic void put(E e) throws InterruptedException {\n        if (e == null) throw new NullPointerException();\n        // holding count negative to indicate failure unless set.\n        int c = -1;\n        Node<E> node = new Node<E>(e);\n        final ReentrantLock putLock = this.putLock;\n        final AtomicInteger count = this.count;\n        putLock.lockInterruptibly();\n        try {\n            // count在写里面使用同一个锁，取得时候用的另一个锁，写的时候判断长度\n            while (count.get() == capacity) {\n                notFull.await();\n            }\n            enqueue(node);\n          \t//添加完之后再次判断，如果没满，激活其他写线程\n            c = count.getAndIncrement();\n            if (c + 1 < capacity)\n                notFull.signal();\n        } finally {\n            putLock.unlock();\n        }\n  \t\t/// 没太明白 \n        if (c == 0)\n            signalNotEmpty();\n    }\n```\n\n### PriorityBlockingQueue \n\n基于优先级的无界阻塞队列，PriorityQueue保存队列元素的顺序不是按加入队列的顺序，而是按队列元素的大小进行重新排序。PriorityQueue中的元素可以默认自然排序（也就是数字默认是小的在队列头，字符串则按字典序排列）或者通过提供的Comparator（比较器）在队列实例化时指定的排序方式。\n\n当PriorityQueue中没有指定Comparator时，加入PriorityQueue的元素必须实现了Comparable接口（即元素是可比较的）\n\n该队列也没有上限（看了一下源码，PriorityBlockingQueue是对 PriorityQueue的再次包装，是基于堆数据结构的，而PriorityQueue是没有容量限制的，与ArrayList一样，所以在优先阻塞队列上put时是不会受阻的。虽然此队列逻辑上是无界的，但是由于资源被耗尽，所以试图执行添加操作可能会导致 OutOfMemoryError），但是如果队列为空，那么取元素的操作take就会阻塞，所以它的检索操作take是受阻的。无限的add会导致内存溢出\n\n从 iterator() 返回的 Iterator 实例不需要以优先级顺序返回元素。如果必须以优先级顺序遍历所有元素，那么让它们都通过 toArray() 方法并自己对它们排序，像 Arrays.sort(pq.toArray())。\n\n### DelayQueue\n\n基于PriorityQueue来实现的,是一个存放Delayed 元素的无界阻塞队列，只有在延迟期满时才能从中提取元素。该队列的头部是延迟期满后保存时间最长的 Delayed 元素。如果延迟都还没有期满，则队列没有头部，并且poll将返回null。当一个元素的 getDelay(TimeUnit.NANOSECONDS) 方法返回一个小于或等于零的值时，则出现期满，poll就以移除这个元素了。此队列不允许使用 null 元素。 \n\n## Deque\n\nQueue的一个子接口，双向队列是指该队列两端的元素既能入队(offer)也能出队(poll),如果将Deque限制为只能从一端入队和出队，则可实现栈的数据结构。对于栈而言，有入栈(push)和出栈(pop)，遵循先进后出原则\n\n### ArrayDeque\n\n实现Deque接口，内部是一个循环数组，可动态扩展，ArrayDeque不可以存取null元素，因为系统根据某个位置是否为null来判断元素的存在，","slug":"消息队列/队列Queue","published":1,"updated":"2018-09-12T03:03:21.834Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnif006jwlkvk01zat4w"},{"title":"设计模式之中介者模式","date":"2018-06-10T12:20:11.000Z","_content":"\n#  设计模式之中介者模式\n\n中介者模式（Mediator Mode）就是用一个中介对象来封装一系列的对象交互，中介者使各对象只需要依赖中介者对象，而不需要相互之间引用，从而使其耦合松散。\n\n<!--more-->\n\n## 思考\n\n- 将对象对另一些对象的依赖转换为对一个中介者的依赖，降低了对象之间的耦合性。\n- 当依赖关系很庞大的时候会导致中介者对象特别复杂\n- 中介者模式的本质在于 **封装交互**\n- 中介者模式的目的是减少对象之间的相互依赖\n\n## 使用场景\n\n- 当存在复杂依赖关系的时候，可以尝试将对象之间的依赖交互封装到中介者对象中，对象只依赖中介者对象去进行对象间的交互\n\n## 优缺点\n\n- 优点  \n  1. 将对象之间的交互行为封装到了一起，便于集中处理\n  2. 减少了对象之间的相互依赖\n\n\n## UML图\n\n![](http://omdq6di7v.bkt.clouddn.com/18-6-10/18398682.jpg)\n\n**Mediator**：抽象中介者角色，对交互行为的行为抽象\n\n**ConcreteMediator**：具体中介者角色，持有多个对象，封装了对象之间交互的具体行为\n\n**Colleague**：抽象同事类角色，对要进行交互的一类对象的抽象。\n\n**ConcreteColleague**：具体同事类角色，持有一个中介者对象，可以同中介者对象进行交互\n\n## 代码实现\n\n中介者类\n\n```java\n//中介者抽象类\npublic abstract class Mediator {\n\t//定义交互行为\n\tpublic abstract void commuticate(String msg, Department department);\n}\n\n/**\n *中介实现类，所有的逻辑操作都在该类中进行处理\n *适用逻辑对象和逻辑稳定，但是逻辑比较复杂的情况\n */\n@Data\npublic class MediatorImpl extends Mediator {\n\n\t//持有 要交互的对象\n\tprivate FinanceDepart financeDepart;\n\tprivate MarketDepart marketDepart;\n\n\t//交互行为\n\t@Override\n\tpublic void commuticate(String msg, Department department) {\n\t\t//具体逻辑在这里处理\n\t\tif(department.getClass() == FinanceDepart.class){\n\t\t\tmarketDepart.getMessage(msg);\n\t\t}else if(department.getClass() == MarketDepart.class){\n\t\t\tfinanceDepart.getMessage(msg);\n\t\t}\n\t}\n}\n```\n\n同事类\n\n```java\n//同事抽象类\npublic abstract class Department {\n\t//持有一个中介者对象 进行交互\n\tpublic Mediator mediator;\n\n\tpublic Department(Mediator mediator) {\n\t\tthis.mediator = mediator;\n\t}\n}\n\n//财务部\npublic class FinanceDepart extends Department {\n\n\tpublic FinanceDepart(Mediator mediator) {\n\t\tsuper(mediator);\n\t}\n\t\n\t//调用中介者进行通信，将本身对象传递给中介者\n\tpublic void sendMessage(String msg) {\n\t\t mediator.commuticate(msg, this);\n\t}\n\n\tpublic void getMessage(String msg) {\n\t\tSystem.out.println(msg);\n\t}\n}\n\n//市场部\npublic class MarketDepart extends Department {\n\n\tpublic MarketDepart(Mediator mediator) {\n\t\tsuper(mediator);\n\t}\n\n\t//调用中介者进行通信，将本身对象传递给中介者\n\tpublic void sendMessage(String msg) {\n\t\tthis.mediator.commuticate(msg, this);\n\t}\n\n\tpublic void getMessage(String msg) {\n\t\tSystem.out.println(msg);\n\t}\n}\n```\n\n客户端\n\n```java\npublic class Client {\n\tpublic static void main(String[] args) {\n\t\t\n\t\t//创建一个中介者\n\t\tMediatorImpl mediator = new MediatorImpl();\n\t\t//创建逻辑对象，并将中介者给逻辑对象\n\t\tFinanceDepart financeDepart = new FinanceDepart(mediator);\n\t\tMarketDepart marketDepart = new MarketDepart(mediator);\n\t\t//中介者需要持有所有的逻辑对象\n\t\tmediator.setFinanceDepart(financeDepart);\n\t\tmediator.setMarketDepart(marketDepart);\n\t\t\n\t\tfinanceDepart.sendMessage(\"财务部喊话:要报销单\");\n\t\tmarketDepart.sendMessage(\"市场部回话：等！！！\");\n\t}\n}\n```\n\n","source":"_posts/设计模式/设计模式之中介者模式.md","raw":"---\ntitle: 设计模式之中介者模式\ndate: 2018-06-10 20:20:11\ntags:\n- 设计模式\ncategories:\n- 设计模式\n\n---\n\n#  设计模式之中介者模式\n\n中介者模式（Mediator Mode）就是用一个中介对象来封装一系列的对象交互，中介者使各对象只需要依赖中介者对象，而不需要相互之间引用，从而使其耦合松散。\n\n<!--more-->\n\n## 思考\n\n- 将对象对另一些对象的依赖转换为对一个中介者的依赖，降低了对象之间的耦合性。\n- 当依赖关系很庞大的时候会导致中介者对象特别复杂\n- 中介者模式的本质在于 **封装交互**\n- 中介者模式的目的是减少对象之间的相互依赖\n\n## 使用场景\n\n- 当存在复杂依赖关系的时候，可以尝试将对象之间的依赖交互封装到中介者对象中，对象只依赖中介者对象去进行对象间的交互\n\n## 优缺点\n\n- 优点  \n  1. 将对象之间的交互行为封装到了一起，便于集中处理\n  2. 减少了对象之间的相互依赖\n\n\n## UML图\n\n![](http://omdq6di7v.bkt.clouddn.com/18-6-10/18398682.jpg)\n\n**Mediator**：抽象中介者角色，对交互行为的行为抽象\n\n**ConcreteMediator**：具体中介者角色，持有多个对象，封装了对象之间交互的具体行为\n\n**Colleague**：抽象同事类角色，对要进行交互的一类对象的抽象。\n\n**ConcreteColleague**：具体同事类角色，持有一个中介者对象，可以同中介者对象进行交互\n\n## 代码实现\n\n中介者类\n\n```java\n//中介者抽象类\npublic abstract class Mediator {\n\t//定义交互行为\n\tpublic abstract void commuticate(String msg, Department department);\n}\n\n/**\n *中介实现类，所有的逻辑操作都在该类中进行处理\n *适用逻辑对象和逻辑稳定，但是逻辑比较复杂的情况\n */\n@Data\npublic class MediatorImpl extends Mediator {\n\n\t//持有 要交互的对象\n\tprivate FinanceDepart financeDepart;\n\tprivate MarketDepart marketDepart;\n\n\t//交互行为\n\t@Override\n\tpublic void commuticate(String msg, Department department) {\n\t\t//具体逻辑在这里处理\n\t\tif(department.getClass() == FinanceDepart.class){\n\t\t\tmarketDepart.getMessage(msg);\n\t\t}else if(department.getClass() == MarketDepart.class){\n\t\t\tfinanceDepart.getMessage(msg);\n\t\t}\n\t}\n}\n```\n\n同事类\n\n```java\n//同事抽象类\npublic abstract class Department {\n\t//持有一个中介者对象 进行交互\n\tpublic Mediator mediator;\n\n\tpublic Department(Mediator mediator) {\n\t\tthis.mediator = mediator;\n\t}\n}\n\n//财务部\npublic class FinanceDepart extends Department {\n\n\tpublic FinanceDepart(Mediator mediator) {\n\t\tsuper(mediator);\n\t}\n\t\n\t//调用中介者进行通信，将本身对象传递给中介者\n\tpublic void sendMessage(String msg) {\n\t\t mediator.commuticate(msg, this);\n\t}\n\n\tpublic void getMessage(String msg) {\n\t\tSystem.out.println(msg);\n\t}\n}\n\n//市场部\npublic class MarketDepart extends Department {\n\n\tpublic MarketDepart(Mediator mediator) {\n\t\tsuper(mediator);\n\t}\n\n\t//调用中介者进行通信，将本身对象传递给中介者\n\tpublic void sendMessage(String msg) {\n\t\tthis.mediator.commuticate(msg, this);\n\t}\n\n\tpublic void getMessage(String msg) {\n\t\tSystem.out.println(msg);\n\t}\n}\n```\n\n客户端\n\n```java\npublic class Client {\n\tpublic static void main(String[] args) {\n\t\t\n\t\t//创建一个中介者\n\t\tMediatorImpl mediator = new MediatorImpl();\n\t\t//创建逻辑对象，并将中介者给逻辑对象\n\t\tFinanceDepart financeDepart = new FinanceDepart(mediator);\n\t\tMarketDepart marketDepart = new MarketDepart(mediator);\n\t\t//中介者需要持有所有的逻辑对象\n\t\tmediator.setFinanceDepart(financeDepart);\n\t\tmediator.setMarketDepart(marketDepart);\n\t\t\n\t\tfinanceDepart.sendMessage(\"财务部喊话:要报销单\");\n\t\tmarketDepart.sendMessage(\"市场部回话：等！！！\");\n\t}\n}\n```\n\n","slug":"设计模式/设计模式之中介者模式","published":1,"updated":"2018-09-12T03:03:21.835Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnig006nwlkvz4uikg2t"},{"title":"设计模式之享元模式","date":"2018-05-25T02:11:22.000Z","_content":"\n#  设计模式之享元模式\n\n享元模式是对象的结构模式,提供一容器用来保存每次创建的对象，这样下次再创建对象的时候直接从容器获取，避免不必要的资源损耗。\n\n在享元模式中，通常是第一次请求享元工厂时，享元工厂进行共享对象的初始化，然后放入享元工厂的缓存中，之后访问直接使用缓存中的对象。\n\n<!--more-->\n\n## 认识\n\n在JAVA语言中，String类型就是使用了享元模式。String对象是final类型，对象一旦创建就不可改变。在JAVA中字符串常量都是存在常量池中的，JAVA会确保一个字符串常量在常量池中只有一个拷贝。\n\n享元对象能做到共享的关键是区分**内部状态**和**外部状态** \n- 内部状态：存储在享元对象内部，对象一旦初始化不会再发生改变的属性(外部无法修改)，能够实现共享。\n- 外部状态：外部能够进行修改的对象的属性，不可以共享。享元对象的外部状态必须由客户端保存，并在享元对象被创建之后，在需要使用的时候再传入到享元对象内部。外部状态不可以影响享元对象的内部状态，它们是相互独立的。\n\n## 思考\n\n享元工厂可以使用单例模式\n\n享元模式的本质：分离与共享\n\n**Object Pool和享元模式的区别 **\n\n- 应用Flyweight模式的关键之一是**内部状态和外部状态的区分**，而Object Pool所应用的场景基本上不会考虑这一点。\n- Flyweight模式所解决的问题之一是使大量的对象共享同一个元对象，是对空间（memory）的优化；而Object Pool主要是解决的问题是对象的创建过程很耗时、很困难，所以通过pool的方式来快速的提供对象，这是对时间（performance）的优化，当然，可能也会有空间上的考虑。\n- Flyweight模式中的元对象本身是Immutable的，是可以同时被多个客户端使用的，是一种并行的方案，而Object Pool中创建的对象一旦被某个客户端使用中，另外一个客户端就不能够同时使用这个对象，是一种串行的方案。\n\n## 使用场景\n\n1. 如果一个程序使用大量细粒度对象或者为了减少内存开销，可以使用享元模式来减少对象数量\n2. 如果对象的大多数状态都可以转换为外部状态(计算可得或外部传入)，可以用享元模式将内部状态和外部状态分离\n\n## 优缺点\n\n- 优点\n  1. 减少对象数量，节省内存空间\n\n- 缺点\n  1. 维护共享对象，需要额外开销\n  2. 系统更加复杂。为了使对象可以共享，需要将一些状态外部化，这使得程序的逻辑复杂化\n\n## UML图\n\n### 单纯享元模式\n\n所有的享元对象 都是可以共享的\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-21/9274886-file_1490110857177_96a3.png)\n\n- **抽象享元(Flyweight)角色 ：**享元对象实现的接口\n\n- **具体享元(ConcreteFlyweight)角色：** 具体享元实现类。如果有内部状态的话，必须负责为内部状态提供存储空间。\n- **享元工厂(FlyweightFactory)角色** ：负责创建和管理享元对象。 必须保证享元对象可以被系统适当地共享。当一个客户端对象调用一个享元对象的时候，享元工厂会检查系统中是否已经有一个符合要求的享元对象。如果已经有了，享元工厂提供这个已有的享元对象；如果系统中没有一个适当的享元对象的话，享元工厂就应当创建一个合适的享元对象返回并将其放入享元工厂缓存中。\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-21/4757930-file_1490110860244_3fda.png)\n\n### 复合享元模式\n\n参考：[《JAVA与模式》之享元模式](http://www.cnblogs.com/java-my-life/archive/2012/04/26/2468499.html)\n\n## 代码实现\n\n### 单纯享元模式\n\n```java\n//享元对象接口\npublic interface Flyweight {\n    //一个示意性方法，参数state是外蕴状态\n    public void operation(String state);\n}\n//享元对象\npublic class ConcreteFlyweight implements Flyweight {\n    private Character intrinsicState = null;\n    //构造函数，内部状态作为参数传入\n    public ConcreteFlyweight(Character state){\n        this.intrinsicState = state;\n    }\n   \n    //外部状态作为参数传入方法中，改变方法的行为，但是并不改变对象的内部状态。\n    @Override\n    public void operation(String state) {\n        // TODO Auto-generated method stub\n        System.out.println(\"Intrinsic State = \" + this.intrinsicState);\n        System.out.println(\"Extrinsic State = \" + state);\n    }\n}\n//享元工厂\npublic class FlyweightFactory {\n    //用于缓存共享对象\n    private Map<Character,Flyweight> files = new HashMap<Character,Flyweight>();\n    \n    public Flyweight factory(Character state){\n        //先从缓存中查找对象\n        Flyweight fly = files.get(state);\n        if(fly == null){\n            //如果对象不存在则创建一个新的Flyweight对象\n            fly = new ConcreteFlyweight(state);\n            //把这个新的Flyweight对象添加到缓存中\n            files.put(state, fly);\n        }\n        return fly;\n    }\n}\n//客户端\npublic class Client {\n    public static void main(String[] args) {\n        // 调用享元工厂获取享元对象\n        FlyweightFactory factory = new FlyweightFactory();\n        Flyweight fly = factory.factory(new Character('a'));\n        fly.operation(\"First Call\");\n        \n        fly = factory.factory(new Character('b'));\n        fly.operation(\"Second Call\");\n        \n        fly = factory.factory(new Character('a'));\n        fly.operation(\"Third Call\");\n    }\n}\n```\n\n### 复合享元模式\n\n [《JAVA与模式》之享元模式](http://www.cnblogs.com/java-my-life/archive/2012/04/26/2468499.html)","source":"_posts/设计模式/设计模式之享元模式.md","raw":"---\ntitle: 设计模式之享元模式\ndate: 2018-05-25 10:11:22\ntags:\n- 设计模式\ncategories:\n- 设计模式\n\n---\n\n#  设计模式之享元模式\n\n享元模式是对象的结构模式,提供一容器用来保存每次创建的对象，这样下次再创建对象的时候直接从容器获取，避免不必要的资源损耗。\n\n在享元模式中，通常是第一次请求享元工厂时，享元工厂进行共享对象的初始化，然后放入享元工厂的缓存中，之后访问直接使用缓存中的对象。\n\n<!--more-->\n\n## 认识\n\n在JAVA语言中，String类型就是使用了享元模式。String对象是final类型，对象一旦创建就不可改变。在JAVA中字符串常量都是存在常量池中的，JAVA会确保一个字符串常量在常量池中只有一个拷贝。\n\n享元对象能做到共享的关键是区分**内部状态**和**外部状态** \n- 内部状态：存储在享元对象内部，对象一旦初始化不会再发生改变的属性(外部无法修改)，能够实现共享。\n- 外部状态：外部能够进行修改的对象的属性，不可以共享。享元对象的外部状态必须由客户端保存，并在享元对象被创建之后，在需要使用的时候再传入到享元对象内部。外部状态不可以影响享元对象的内部状态，它们是相互独立的。\n\n## 思考\n\n享元工厂可以使用单例模式\n\n享元模式的本质：分离与共享\n\n**Object Pool和享元模式的区别 **\n\n- 应用Flyweight模式的关键之一是**内部状态和外部状态的区分**，而Object Pool所应用的场景基本上不会考虑这一点。\n- Flyweight模式所解决的问题之一是使大量的对象共享同一个元对象，是对空间（memory）的优化；而Object Pool主要是解决的问题是对象的创建过程很耗时、很困难，所以通过pool的方式来快速的提供对象，这是对时间（performance）的优化，当然，可能也会有空间上的考虑。\n- Flyweight模式中的元对象本身是Immutable的，是可以同时被多个客户端使用的，是一种并行的方案，而Object Pool中创建的对象一旦被某个客户端使用中，另外一个客户端就不能够同时使用这个对象，是一种串行的方案。\n\n## 使用场景\n\n1. 如果一个程序使用大量细粒度对象或者为了减少内存开销，可以使用享元模式来减少对象数量\n2. 如果对象的大多数状态都可以转换为外部状态(计算可得或外部传入)，可以用享元模式将内部状态和外部状态分离\n\n## 优缺点\n\n- 优点\n  1. 减少对象数量，节省内存空间\n\n- 缺点\n  1. 维护共享对象，需要额外开销\n  2. 系统更加复杂。为了使对象可以共享，需要将一些状态外部化，这使得程序的逻辑复杂化\n\n## UML图\n\n### 单纯享元模式\n\n所有的享元对象 都是可以共享的\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-21/9274886-file_1490110857177_96a3.png)\n\n- **抽象享元(Flyweight)角色 ：**享元对象实现的接口\n\n- **具体享元(ConcreteFlyweight)角色：** 具体享元实现类。如果有内部状态的话，必须负责为内部状态提供存储空间。\n- **享元工厂(FlyweightFactory)角色** ：负责创建和管理享元对象。 必须保证享元对象可以被系统适当地共享。当一个客户端对象调用一个享元对象的时候，享元工厂会检查系统中是否已经有一个符合要求的享元对象。如果已经有了，享元工厂提供这个已有的享元对象；如果系统中没有一个适当的享元对象的话，享元工厂就应当创建一个合适的享元对象返回并将其放入享元工厂缓存中。\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-21/4757930-file_1490110860244_3fda.png)\n\n### 复合享元模式\n\n参考：[《JAVA与模式》之享元模式](http://www.cnblogs.com/java-my-life/archive/2012/04/26/2468499.html)\n\n## 代码实现\n\n### 单纯享元模式\n\n```java\n//享元对象接口\npublic interface Flyweight {\n    //一个示意性方法，参数state是外蕴状态\n    public void operation(String state);\n}\n//享元对象\npublic class ConcreteFlyweight implements Flyweight {\n    private Character intrinsicState = null;\n    //构造函数，内部状态作为参数传入\n    public ConcreteFlyweight(Character state){\n        this.intrinsicState = state;\n    }\n   \n    //外部状态作为参数传入方法中，改变方法的行为，但是并不改变对象的内部状态。\n    @Override\n    public void operation(String state) {\n        // TODO Auto-generated method stub\n        System.out.println(\"Intrinsic State = \" + this.intrinsicState);\n        System.out.println(\"Extrinsic State = \" + state);\n    }\n}\n//享元工厂\npublic class FlyweightFactory {\n    //用于缓存共享对象\n    private Map<Character,Flyweight> files = new HashMap<Character,Flyweight>();\n    \n    public Flyweight factory(Character state){\n        //先从缓存中查找对象\n        Flyweight fly = files.get(state);\n        if(fly == null){\n            //如果对象不存在则创建一个新的Flyweight对象\n            fly = new ConcreteFlyweight(state);\n            //把这个新的Flyweight对象添加到缓存中\n            files.put(state, fly);\n        }\n        return fly;\n    }\n}\n//客户端\npublic class Client {\n    public static void main(String[] args) {\n        // 调用享元工厂获取享元对象\n        FlyweightFactory factory = new FlyweightFactory();\n        Flyweight fly = factory.factory(new Character('a'));\n        fly.operation(\"First Call\");\n        \n        fly = factory.factory(new Character('b'));\n        fly.operation(\"Second Call\");\n        \n        fly = factory.factory(new Character('a'));\n        fly.operation(\"Third Call\");\n    }\n}\n```\n\n### 复合享元模式\n\n [《JAVA与模式》之享元模式](http://www.cnblogs.com/java-my-life/archive/2012/04/26/2468499.html)","slug":"设计模式/设计模式之享元模式","published":1,"updated":"2018-09-12T03:03:21.835Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnih006qwlkvn496rd9t"},{"title":"设计模式之代理模式","date":"2018-05-24T09:34:39.000Z","_content":"\n#  设计模式之代理模式\n\n代理模式是对象的结构模式。代理模式给某一个对象提供一个代理对象，并由代理对象控制对原对象的引用。\n\n<!--more-->\n\n## 认识\n\n- 客户端操作代理对象时，具体的操作还是由被代理对象实现，客户端操作代理，代理操作被代理，被代理对象对于客户端是透明的。\n- 代理模式同装饰模式不同在，装饰模式是要对原对象的功能进行增强，而代理模式一般只是对原对象的使用进行控制，并不会增加原对象的任何功能。\n\n## 思考\n\n- 保护代理：可以在代理中对客户端的访问添加一些权限控制。\n- 静态代理VS动态代理\n- AOP\n- 代理模式的本质：**控制对象访问**\n\n## 使用场景\n\n1. 需要控制对原始对象的访问的时候，可以使用代理模式\n2. 需要对原始对象的访问前后添加新的逻辑时，可以使用代理模式\n\n## 优缺点\n\n- 优点\n  1. 能够在方法的执行前和执行后添加新的逻辑\n  2. 能够控制对象的访问权限\n\n- 缺点\n  1. 静态代理中如果接口发生变化，会导致代理对象的实现也改变，动态代理可以避免这个问题。\n\n## UML图\n\n代理对象和被代理对象实现同一接口，代理对象持有一个被代理对象，对于要代理的方法，进行处理，对于不代理的方法，调用被代理对象\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-21/88604957-file_1490071638253_da0a.jpg)\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-21/59422407-file_1490072489254_101bf.jpg)\n\n- **抽象对象角色(AbstractObject)**：声明被代理对象和代理对象的共同接口，在任意可以使用被代理对象的地方都可以使用代理对象\n- **被代理对象(RealObject)**：\n- **代理对象(ProxyObject)**：\n  1. 跟被代理对象实现共同的接口，可以使用代理对象替换被代理对象\n  2. 持有一个被代理对象,可以调用被代理对象\n  3. 有选择的对被代理对象的方法进行代理或者不代理\n\n## 代码实现\n\n类似装饰模式，但是代理模式中被代理对象一般不需要客户端传入，被代理的对象对于客户端是透明的\n\n```java\n//抽象对象\npublic abstract class AbstractObject {\n    //操作\n    public abstract void operation();\n}\n//被代理对象\npublic class RealObject extends AbstractObject {\n    @Override\n    public void operation() {\n        //一些操作\n        System.out.println(\"一些操作\");\n    }\n}\n//代理对象\npublic class ProxyObject extends AbstractObject{\n  \t//持有一个被代理对象\n    RealObject realObject = new RealObject();\n  \t//代理被代理对象中的方法\n    @Override\n    public void operation() {\n        //调用目标对象之前可以做相关操作\n        System.out.println(\"before\");        \n        realObject.operation();        \n        //调用目标对象之后可以做相关操作\n        System.out.println(\"after\");\n    }\n}\n//客户端调用\npublic class Client {\n\n    public static void main(String[] args) {\n        //客户端使用代理对象\n        AbstractObject obj = new ProxyObject();\n        obj.operation();\n    }\n\n}\n```\n","source":"_posts/设计模式/设计模式之代理模式.md","raw":"---\ntitle: 设计模式之代理模式\ndate: 2018-05-24 17:34:39\ntags:\n- 设计模式\ncategories:\n- 设计模式\n\n---\n\n#  设计模式之代理模式\n\n代理模式是对象的结构模式。代理模式给某一个对象提供一个代理对象，并由代理对象控制对原对象的引用。\n\n<!--more-->\n\n## 认识\n\n- 客户端操作代理对象时，具体的操作还是由被代理对象实现，客户端操作代理，代理操作被代理，被代理对象对于客户端是透明的。\n- 代理模式同装饰模式不同在，装饰模式是要对原对象的功能进行增强，而代理模式一般只是对原对象的使用进行控制，并不会增加原对象的任何功能。\n\n## 思考\n\n- 保护代理：可以在代理中对客户端的访问添加一些权限控制。\n- 静态代理VS动态代理\n- AOP\n- 代理模式的本质：**控制对象访问**\n\n## 使用场景\n\n1. 需要控制对原始对象的访问的时候，可以使用代理模式\n2. 需要对原始对象的访问前后添加新的逻辑时，可以使用代理模式\n\n## 优缺点\n\n- 优点\n  1. 能够在方法的执行前和执行后添加新的逻辑\n  2. 能够控制对象的访问权限\n\n- 缺点\n  1. 静态代理中如果接口发生变化，会导致代理对象的实现也改变，动态代理可以避免这个问题。\n\n## UML图\n\n代理对象和被代理对象实现同一接口，代理对象持有一个被代理对象，对于要代理的方法，进行处理，对于不代理的方法，调用被代理对象\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-21/88604957-file_1490071638253_da0a.jpg)\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-21/59422407-file_1490072489254_101bf.jpg)\n\n- **抽象对象角色(AbstractObject)**：声明被代理对象和代理对象的共同接口，在任意可以使用被代理对象的地方都可以使用代理对象\n- **被代理对象(RealObject)**：\n- **代理对象(ProxyObject)**：\n  1. 跟被代理对象实现共同的接口，可以使用代理对象替换被代理对象\n  2. 持有一个被代理对象,可以调用被代理对象\n  3. 有选择的对被代理对象的方法进行代理或者不代理\n\n## 代码实现\n\n类似装饰模式，但是代理模式中被代理对象一般不需要客户端传入，被代理的对象对于客户端是透明的\n\n```java\n//抽象对象\npublic abstract class AbstractObject {\n    //操作\n    public abstract void operation();\n}\n//被代理对象\npublic class RealObject extends AbstractObject {\n    @Override\n    public void operation() {\n        //一些操作\n        System.out.println(\"一些操作\");\n    }\n}\n//代理对象\npublic class ProxyObject extends AbstractObject{\n  \t//持有一个被代理对象\n    RealObject realObject = new RealObject();\n  \t//代理被代理对象中的方法\n    @Override\n    public void operation() {\n        //调用目标对象之前可以做相关操作\n        System.out.println(\"before\");        \n        realObject.operation();        \n        //调用目标对象之后可以做相关操作\n        System.out.println(\"after\");\n    }\n}\n//客户端调用\npublic class Client {\n\n    public static void main(String[] args) {\n        //客户端使用代理对象\n        AbstractObject obj = new ProxyObject();\n        obj.operation();\n    }\n\n}\n```\n","slug":"设计模式/设计模式之代理模式","published":1,"updated":"2018-09-12T03:03:21.835Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnii006uwlkvevim1f9h"},{"title":"设计模式之单例模式","date":"2018-05-23T08:28:13.000Z","_content":"\n#  设计模式之单例模式\n\n有时候需要控制一个类只需要创建一个对象，比如说创建这个对象比较消耗性能、或者这个类比较占用内存，而且单一的对象使用起来不会产生并发问题，那么就可以通过单例模式来设计这个类。\n\n<!--more-->\n\n## 思考\n\n单例模式的实质是**控制实例数量**，当需要控制一个类的实例只能有一个时，使用单例模式。\n\n## 使用场景\n\n- java中缓存的实现：正是一种懒汉式的方式，查询的时候初始化缓存一次，之后访问每次访问初始化的缓存对象\n- 数据库连接池：\n- 线程池：\n\n## 代码实现\n\n### 饿汉式\n\n- 结构\n\n\t1. 私有化无参构造函数\n\t2. 创建一个static修饰的对象\n\t3. 提供一个公共的static修饰的方法返回实例对象\n\n- 优点\n\n\t1. 线程安全\n\t2. 空间换时间\n\n```java\n//饿汉式\npublic class Singleton {\n\t//2定义一个静态变量来存储创建好的类实例直接在这里创建类实例，由虚拟机来保证只会创建一次\n\tprivate static final Singleton instance = new Singleton();\n\t//1：私有化构造方法，好在内部控制创建实例的数目\n\tprivate Singleton(){\t\t\n\t    //初始化加载后创建对象，判断不为空，再次创建，抛出异常，防止反射创建\n\t    if (instance != null){\n            throw new IllegalStateException(\"Already instantiated\");\n        }\n\t}\n\t//3：这个方法需要定义成类方法，也就是要加static\n\tpublic static Singleton getInstance(){\n\t\treturn instance;\n\t}\n\tpublic static void main(String[] args) {\n\t\tfor(int i=0;i<3;i++){\n\t\t\tSystem.out.println(Singleton.getInstance());\n\t\t}\n\t}\n}\n```\n\n### 懒汉式\n\n- 结构\n\n\t1. 私有化构造方法\n\t2. 提供一个公共的static修饰的方法获取实例\n\t3. 双重NULL判断，加锁创建实例对象返回\n\t4. 实例对象使用**volatile**修饰\n\n- 优点\n\n\t1. 节省空间\n\t2. 加锁同步后性能低于饿汉式\n\n```java\npublic class Singleton {\n\t//对保存实例的变量添加volatile的修饰,防止指令重排\n\tprivate volatile static Singleton instance = null;\n\tprivate Singleton(){\n\t}\n\tpublic static  Singleton getInstance(){\n\t\t//先检查实例是否存在，如果不存在才进入下面的同步块\n\t\tif(instance == null){\n\t\t\t//同步块，线程安全的创建实例\n\t\t\tsynchronized(Singleton.class){\n\t\t\t\t//再次检查实例是否存在，如果不存在才真的创建实例\n\t\t\t\tif(instance == null){\n\t\t\t\t\tinstance = new Singleton();\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn instance;\n\t}\n}\n```\n\n### 类级内部类实现单例\n\n```java\npublic class Singleton {\n\t //类级的内部类，也就是静态的成员式内部类，该内部类的实例与外部类的实例没有绑定关系，而且只有被调用到才会\t  //装载，从而实现了延迟加载\n\tprivate static class SingletonHolder{\n\t\t//静态初始化器，由JVM来保证线程安全\n\t\tprivate static final Singleton instance = new Singleton();\n\t}\n\t// 私有化构造方法\n\tprivate Singleton(){\n\t}\n\tpublic static  Singleton getInstance(){\n\t\treturn SingletonHolder.instance;\n\t}\n}\n```\n\n### 枚举实现单例\n\njava中的枚举其实是一种多例的实现，在枚举中只定义一个实例，那么就是最简单的一种单例模式\n\n```java\npublic enum Singleton {\t\n\t\n\tuniqueInstance(\"test\");\n\tprivate Singleton(String name){\t\n\t}\n}\n```\n\n\n\n\n\n\n","source":"_posts/设计模式/设计模式之单例模式.md","raw":"---\ntitle: 设计模式之单例模式\ndate: 2018-05-23 16:28:13\ntags:\n- 设计模式\ncategories:\n- 设计模式\n\n---\n\n#  设计模式之单例模式\n\n有时候需要控制一个类只需要创建一个对象，比如说创建这个对象比较消耗性能、或者这个类比较占用内存，而且单一的对象使用起来不会产生并发问题，那么就可以通过单例模式来设计这个类。\n\n<!--more-->\n\n## 思考\n\n单例模式的实质是**控制实例数量**，当需要控制一个类的实例只能有一个时，使用单例模式。\n\n## 使用场景\n\n- java中缓存的实现：正是一种懒汉式的方式，查询的时候初始化缓存一次，之后访问每次访问初始化的缓存对象\n- 数据库连接池：\n- 线程池：\n\n## 代码实现\n\n### 饿汉式\n\n- 结构\n\n\t1. 私有化无参构造函数\n\t2. 创建一个static修饰的对象\n\t3. 提供一个公共的static修饰的方法返回实例对象\n\n- 优点\n\n\t1. 线程安全\n\t2. 空间换时间\n\n```java\n//饿汉式\npublic class Singleton {\n\t//2定义一个静态变量来存储创建好的类实例直接在这里创建类实例，由虚拟机来保证只会创建一次\n\tprivate static final Singleton instance = new Singleton();\n\t//1：私有化构造方法，好在内部控制创建实例的数目\n\tprivate Singleton(){\t\t\n\t    //初始化加载后创建对象，判断不为空，再次创建，抛出异常，防止反射创建\n\t    if (instance != null){\n            throw new IllegalStateException(\"Already instantiated\");\n        }\n\t}\n\t//3：这个方法需要定义成类方法，也就是要加static\n\tpublic static Singleton getInstance(){\n\t\treturn instance;\n\t}\n\tpublic static void main(String[] args) {\n\t\tfor(int i=0;i<3;i++){\n\t\t\tSystem.out.println(Singleton.getInstance());\n\t\t}\n\t}\n}\n```\n\n### 懒汉式\n\n- 结构\n\n\t1. 私有化构造方法\n\t2. 提供一个公共的static修饰的方法获取实例\n\t3. 双重NULL判断，加锁创建实例对象返回\n\t4. 实例对象使用**volatile**修饰\n\n- 优点\n\n\t1. 节省空间\n\t2. 加锁同步后性能低于饿汉式\n\n```java\npublic class Singleton {\n\t//对保存实例的变量添加volatile的修饰,防止指令重排\n\tprivate volatile static Singleton instance = null;\n\tprivate Singleton(){\n\t}\n\tpublic static  Singleton getInstance(){\n\t\t//先检查实例是否存在，如果不存在才进入下面的同步块\n\t\tif(instance == null){\n\t\t\t//同步块，线程安全的创建实例\n\t\t\tsynchronized(Singleton.class){\n\t\t\t\t//再次检查实例是否存在，如果不存在才真的创建实例\n\t\t\t\tif(instance == null){\n\t\t\t\t\tinstance = new Singleton();\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn instance;\n\t}\n}\n```\n\n### 类级内部类实现单例\n\n```java\npublic class Singleton {\n\t //类级的内部类，也就是静态的成员式内部类，该内部类的实例与外部类的实例没有绑定关系，而且只有被调用到才会\t  //装载，从而实现了延迟加载\n\tprivate static class SingletonHolder{\n\t\t//静态初始化器，由JVM来保证线程安全\n\t\tprivate static final Singleton instance = new Singleton();\n\t}\n\t// 私有化构造方法\n\tprivate Singleton(){\n\t}\n\tpublic static  Singleton getInstance(){\n\t\treturn SingletonHolder.instance;\n\t}\n}\n```\n\n### 枚举实现单例\n\njava中的枚举其实是一种多例的实现，在枚举中只定义一个实例，那么就是最简单的一种单例模式\n\n```java\npublic enum Singleton {\t\n\t\n\tuniqueInstance(\"test\");\n\tprivate Singleton(String name){\t\n\t}\n}\n```\n\n\n\n\n\n\n","slug":"设计模式/设计模式之单例模式","published":1,"updated":"2018-09-12T03:03:21.835Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnij006ywlkvzkwxcl5b"},{"title":"设计模式之原型模式","date":"2018-05-24T03:38:22.000Z","_content":"\n#  设计模式之原型模式\n\n所谓原型模式就是用原型实例指定创建对象的种类，并且通过复制这些原型创建新的对象。\n\n<!--more-->\n\n## 认识\n\n原型模式要求对象实现一个可以“克隆”自身的接口，这样就可以通过复制一个实例对象本身来创建一个新的实例。通过原型实例创建新的对象，就不再需要关心这个实例本身的类型，只要实现了克隆自身的方法，就可以通过这个方法来获取新的对象，而无须再去通过new来创建。\n\n## 思考\n\n原型模式属于对象的创建模式。通过给出一个原型对象来指明所有创建的对象的类型，然后用复制这个原型对象的办法创建出更多同类型的对象。这就是选型模式的用意。\n\n**本质：克隆生成对象**\n\n## 使用场景\n\n- 如果一个系统想要独立于他想要的使用的对象时，\t使用原型模式，让系统需要新的对象时，可以通过克隆原型获取\n- 如果创建新对象成本较大，我们可以利用已有的对象进行复制来获得。\n- 如果系统要保存对象的状态，而对象的状态变化很小，或者对象本身占内存不大的时候，也可以使用原型模式配合备忘录模式来应用。相反，如果对象的状态变化很大，或者对象占用的内存很大，那么采用状态模式会比原型模式更好。 \n\n## 优缺点\n\n- 优点\n  - 对客户端隐藏具体的实现细节\n  - 原型模式允许在运行时动态改变具体的实现类型。原型模式可以在运行期间，由客户来注册符合原型接口的实现类型，也可以动态地改变具体的实现类型，看起来接口没有任何变化，但其实运行的已经是另外一个类实例了。因为克隆一个原型就类似于实例化一个类。\n\n- 缺点\n  - 最主要的缺点是每一个类都必须配备一个克隆方法。而且深度克隆实现复杂\n\n## UML图\n\n简单形式的原型模式:\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-16/35413578-file_1489679789907_6922.png)\n\n1. 客户(Client)角色：客户类提出创建对象的请求\n2. 抽象原型(Prototype)角色：这是一个抽象角色，通常由一个Java接口或Java抽象类实现。此角色给出所有的具体原型类所需的接口。\n3. 具体原型（Concrete Prototype）角色：被复制的对象。此角色需要实现抽象的原型角色所要求的接口。\n\n登记形式的原型模式:\n\n**原型管理器角色保持一个聚集，作为对所有原型对象的登记，这个角色提供必要的方法，供外界增加新的原型对象和取得已经登记过的原型对象。这样就可以实现动态管理和动态切换具体的实现对象实例**\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-17/61032482-file_1489680147193_10121.png)\n\n## 克隆方法\n\njava中定义了clone接口，可以实现clone接口，注意浅度克隆和深度克隆\n\n## 代码实现\n\n### 简单形式的原型接口\n\n适用于创建的原型对象数目较少而且比较固定的话\n\n```java\n//原型接口\npublic interface Prototype{\n    //克隆自身的方法\n    public Object clone();\n}\n//原型具体实现\npublic class ConcretePrototype1 implements Prototype {\n  \t//name属性\n  \tprivate String name;\n\t\n\tpublic String getName() {\n\t\treturn name;\n\t}\n\tpublic void setName(String name) {\n\t\tthis.name = name;\n\t}\n    public Prototype clone(){\n        //最简单的克隆，新建一个自身对象，由于没有属性就不再复制值了\n        ConcretePrototype1 prototype = new ConcretePrototype1();\n        prototype.setName(this.name);\n        return prototype;\n    }\n}\npublic class ConcretePrototype2 implements Prototype {\n  \t//name属性\n  \tprivate int age;\n\t\n\tpublic int getAge() {\n\t\treturn age;\n\t}\n\tpublic void setAge(String age) {\n\t\tthis.age = age;\n\t}\n    public Prototype clone(){\n        //最简单的克隆，新建一个自身对象，由于没有属性就不再复制值了\n        ConcretePrototype2 prototype = new ConcretePrototype2();\n        prototype.setAge(this.age);\n\t    return prototype;\n    }\n}\n//客户端\npublic class Client {\n\tpublic static void main(String[] args) {\n\t\t//先创建原型实例\n\t\tConcretePrototype1 oa1 = new ConcretePrototype1();\n\t\toa1.setName(\"原始对象name\");\n\t    System.out.println(\"这是第一次获取的对象实例=\"+oa1);\n\t    \n\t\t//通过克隆来获取新的实例\n\t    ConcretePrototype1 oa2 = (ConcretePrototype1)oa1.clone();\n\t\t//修改它的值\n\t\toa2.setName(\"克隆对象修饰后name\");\n\t\t//输出克隆出来的对象的值\n\t\tSystem.out.println(\"输出克隆出来的实例=\"+oa2);\n\t\t//再次输出原型实例的值\n\t\tSystem.out.println(\"再次输出原型实例=\"+oa1);\t\n\t\t\n\t\t//同理可以创建ConcretePrototype2\n\t}\n}\n```\n\n###  登记形式的原型模式\n\n适用于创建的原型对象数目不固定的话，客户端不保存对原型对象的引用，这个任务被交给管理员对象。在复制一个原型对象之前，客户端可以查看管理员对象是否已经有一个满足要求的原型对象。如果有，可以直接从管理员类取得这个对象引用；如果没有，客户端就需要自行复制此原型对象。\n\n```Java\n//原型管理器\npublic class PrototypeManager {\n    //用来记录原型的编号和原型实例的对应关系\n    private static Map<String,Prototype> map = new HashMap<String,Prototype>();\n    //私有化构造方法，避免外部创建实例\n    private PrototypeManager(){}\n    /**\n     * 向原型管理器里面添加或是修改某个原型注册\n     * @param prototypeId 原型编号\n     * @param prototype    原型实例\n     */\n    public synchronized static void setPrototype(String prototypeId , Prototype prototype){\n        map.put(prototypeId, prototype);\n    }\n    /**\n     * 从原型管理器里面删除某个原型注册\n     * @param prototypeId 原型编号\n     */\n    public synchronized static void removePrototype(String prototypeId){\n        map.remove(prototypeId);\n    }\n    /**\n     * 获取某个原型编号对应的原型实例\n     * @param prototypeId    原型编号\n     * @return    原型编号对应的原型实例\n     * @throws Exception    如果原型编号对应的实例不存在，则抛出异常\n     */\n    public synchronized static Prototype getPrototype(String prototypeId) throws Exception{\n        Prototype prototype = map.get(prototypeId);\n        if(prototype == null){\n            throw new Exception(\"您希望获取的原型还没有注册或已被销毁\");\n        }\n        return prototype;\n    }\n}\n\n//客户端\npublic class Client {\n    public static void main(String[]args){\n        try{\n            Prototype p1 = new ConcretePrototype1();\n            PrototypeManager.setPrototype(\"p1\", p1);\n            //获取原型来创建对象\n            Prototype p3 = PrototypeManager.getPrototype(\"p1\").clone();\n            p3.setName(\"张三\");\n            System.out.println(\"第一个实例：\" + p3);\n            //有人动态的切换了实现\n            Prototype p2 = new ConcretePrototype2();\n            PrototypeManager.setPrototype(\"p1\", p2);\n            //重新获取原型来创建对象\n            Prototype p4 = PrototypeManager.getPrototype(\"p1\").clone();\n            p4.setName(\"李四\");\n            System.out.println(\"第二个实例：\" + p4);\n            //有人注销了这个原型\n            PrototypeManager.removePrototype(\"p1\");\n            //再次获取原型来创建对象\n            Prototype p5 = PrototypeManager.getPrototype(\"p1\").clone();\n            p5.setName(\"王五\");\n            System.out.println(\"第三个实例：\" + p5);\n        }catch(Exception e){\n            e.printStackTrace();\n        }\n    }\n}\n```\n\n","source":"_posts/设计模式/设计模式之原型模式.md","raw":"---\ntitle: 设计模式之原型模式\ndate: 2018-05-24 11:38:22\ntags:\n- 设计模式\ncategories:\n- 设计模式\n\n---\n\n#  设计模式之原型模式\n\n所谓原型模式就是用原型实例指定创建对象的种类，并且通过复制这些原型创建新的对象。\n\n<!--more-->\n\n## 认识\n\n原型模式要求对象实现一个可以“克隆”自身的接口，这样就可以通过复制一个实例对象本身来创建一个新的实例。通过原型实例创建新的对象，就不再需要关心这个实例本身的类型，只要实现了克隆自身的方法，就可以通过这个方法来获取新的对象，而无须再去通过new来创建。\n\n## 思考\n\n原型模式属于对象的创建模式。通过给出一个原型对象来指明所有创建的对象的类型，然后用复制这个原型对象的办法创建出更多同类型的对象。这就是选型模式的用意。\n\n**本质：克隆生成对象**\n\n## 使用场景\n\n- 如果一个系统想要独立于他想要的使用的对象时，\t使用原型模式，让系统需要新的对象时，可以通过克隆原型获取\n- 如果创建新对象成本较大，我们可以利用已有的对象进行复制来获得。\n- 如果系统要保存对象的状态，而对象的状态变化很小，或者对象本身占内存不大的时候，也可以使用原型模式配合备忘录模式来应用。相反，如果对象的状态变化很大，或者对象占用的内存很大，那么采用状态模式会比原型模式更好。 \n\n## 优缺点\n\n- 优点\n  - 对客户端隐藏具体的实现细节\n  - 原型模式允许在运行时动态改变具体的实现类型。原型模式可以在运行期间，由客户来注册符合原型接口的实现类型，也可以动态地改变具体的实现类型，看起来接口没有任何变化，但其实运行的已经是另外一个类实例了。因为克隆一个原型就类似于实例化一个类。\n\n- 缺点\n  - 最主要的缺点是每一个类都必须配备一个克隆方法。而且深度克隆实现复杂\n\n## UML图\n\n简单形式的原型模式:\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-16/35413578-file_1489679789907_6922.png)\n\n1. 客户(Client)角色：客户类提出创建对象的请求\n2. 抽象原型(Prototype)角色：这是一个抽象角色，通常由一个Java接口或Java抽象类实现。此角色给出所有的具体原型类所需的接口。\n3. 具体原型（Concrete Prototype）角色：被复制的对象。此角色需要实现抽象的原型角色所要求的接口。\n\n登记形式的原型模式:\n\n**原型管理器角色保持一个聚集，作为对所有原型对象的登记，这个角色提供必要的方法，供外界增加新的原型对象和取得已经登记过的原型对象。这样就可以实现动态管理和动态切换具体的实现对象实例**\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-17/61032482-file_1489680147193_10121.png)\n\n## 克隆方法\n\njava中定义了clone接口，可以实现clone接口，注意浅度克隆和深度克隆\n\n## 代码实现\n\n### 简单形式的原型接口\n\n适用于创建的原型对象数目较少而且比较固定的话\n\n```java\n//原型接口\npublic interface Prototype{\n    //克隆自身的方法\n    public Object clone();\n}\n//原型具体实现\npublic class ConcretePrototype1 implements Prototype {\n  \t//name属性\n  \tprivate String name;\n\t\n\tpublic String getName() {\n\t\treturn name;\n\t}\n\tpublic void setName(String name) {\n\t\tthis.name = name;\n\t}\n    public Prototype clone(){\n        //最简单的克隆，新建一个自身对象，由于没有属性就不再复制值了\n        ConcretePrototype1 prototype = new ConcretePrototype1();\n        prototype.setName(this.name);\n        return prototype;\n    }\n}\npublic class ConcretePrototype2 implements Prototype {\n  \t//name属性\n  \tprivate int age;\n\t\n\tpublic int getAge() {\n\t\treturn age;\n\t}\n\tpublic void setAge(String age) {\n\t\tthis.age = age;\n\t}\n    public Prototype clone(){\n        //最简单的克隆，新建一个自身对象，由于没有属性就不再复制值了\n        ConcretePrototype2 prototype = new ConcretePrototype2();\n        prototype.setAge(this.age);\n\t    return prototype;\n    }\n}\n//客户端\npublic class Client {\n\tpublic static void main(String[] args) {\n\t\t//先创建原型实例\n\t\tConcretePrototype1 oa1 = new ConcretePrototype1();\n\t\toa1.setName(\"原始对象name\");\n\t    System.out.println(\"这是第一次获取的对象实例=\"+oa1);\n\t    \n\t\t//通过克隆来获取新的实例\n\t    ConcretePrototype1 oa2 = (ConcretePrototype1)oa1.clone();\n\t\t//修改它的值\n\t\toa2.setName(\"克隆对象修饰后name\");\n\t\t//输出克隆出来的对象的值\n\t\tSystem.out.println(\"输出克隆出来的实例=\"+oa2);\n\t\t//再次输出原型实例的值\n\t\tSystem.out.println(\"再次输出原型实例=\"+oa1);\t\n\t\t\n\t\t//同理可以创建ConcretePrototype2\n\t}\n}\n```\n\n###  登记形式的原型模式\n\n适用于创建的原型对象数目不固定的话，客户端不保存对原型对象的引用，这个任务被交给管理员对象。在复制一个原型对象之前，客户端可以查看管理员对象是否已经有一个满足要求的原型对象。如果有，可以直接从管理员类取得这个对象引用；如果没有，客户端就需要自行复制此原型对象。\n\n```Java\n//原型管理器\npublic class PrototypeManager {\n    //用来记录原型的编号和原型实例的对应关系\n    private static Map<String,Prototype> map = new HashMap<String,Prototype>();\n    //私有化构造方法，避免外部创建实例\n    private PrototypeManager(){}\n    /**\n     * 向原型管理器里面添加或是修改某个原型注册\n     * @param prototypeId 原型编号\n     * @param prototype    原型实例\n     */\n    public synchronized static void setPrototype(String prototypeId , Prototype prototype){\n        map.put(prototypeId, prototype);\n    }\n    /**\n     * 从原型管理器里面删除某个原型注册\n     * @param prototypeId 原型编号\n     */\n    public synchronized static void removePrototype(String prototypeId){\n        map.remove(prototypeId);\n    }\n    /**\n     * 获取某个原型编号对应的原型实例\n     * @param prototypeId    原型编号\n     * @return    原型编号对应的原型实例\n     * @throws Exception    如果原型编号对应的实例不存在，则抛出异常\n     */\n    public synchronized static Prototype getPrototype(String prototypeId) throws Exception{\n        Prototype prototype = map.get(prototypeId);\n        if(prototype == null){\n            throw new Exception(\"您希望获取的原型还没有注册或已被销毁\");\n        }\n        return prototype;\n    }\n}\n\n//客户端\npublic class Client {\n    public static void main(String[]args){\n        try{\n            Prototype p1 = new ConcretePrototype1();\n            PrototypeManager.setPrototype(\"p1\", p1);\n            //获取原型来创建对象\n            Prototype p3 = PrototypeManager.getPrototype(\"p1\").clone();\n            p3.setName(\"张三\");\n            System.out.println(\"第一个实例：\" + p3);\n            //有人动态的切换了实现\n            Prototype p2 = new ConcretePrototype2();\n            PrototypeManager.setPrototype(\"p1\", p2);\n            //重新获取原型来创建对象\n            Prototype p4 = PrototypeManager.getPrototype(\"p1\").clone();\n            p4.setName(\"李四\");\n            System.out.println(\"第二个实例：\" + p4);\n            //有人注销了这个原型\n            PrototypeManager.removePrototype(\"p1\");\n            //再次获取原型来创建对象\n            Prototype p5 = PrototypeManager.getPrototype(\"p1\").clone();\n            p5.setName(\"王五\");\n            System.out.println(\"第三个实例：\" + p5);\n        }catch(Exception e){\n            e.printStackTrace();\n        }\n    }\n}\n```\n\n","slug":"设计模式/设计模式之原型模式","published":1,"updated":"2018-09-12T03:03:21.836Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnik0072wlkvroyryj7s"},{"title":"设计模式之命令模式","date":"2018-05-29T08:15:32.000Z","_content":"\n#  设计模式之命令模式\n\n命令模式属于对象的行为模式，**命令模式是对命令的封装。命令模式把发出命令的责任和执行命令的责任分割开，委派给不同的对象**。\n\n<!--more-->\n\n## 认识\n\n每一个命令都是一个操作：请求的一方发出请求要求执行一个操作；接收的一方收到请求，并执行操作。命令模式允许请求的一方和接收的一方独立开来，使得请求的一方不必知道接收请求的一方的接口，更不必知道请求是怎么被接收，以及操作是否被执行、何时被执行，以及是怎么被执行的，实现了解耦合。\n\n## 思考\n\n命令允许请求的一方和接收请求的一方能够独立演化，从而具有以下的优点：\n\n1. 命令模式使新的命令很容易地被加入到系统里。\n2. 允许接收请求的一方决定**是否要否决请求**。\n3. 能较容易地设计一个命令队列。\n4. 可以容易地实现对请求的撤销和恢复。**Invoker中维护一个撤销命令List和一个重做命令List**\n5. 在需要的情况下，可以较容易地将命令记入日志。\n\n## 使用场景\n\n- 如果需要抽象出需要执行的动作，并参数化这些对象，可以把这些需要执行的动作抽象成命令，然后实现命令的参数化配置。\n- 如果需要在不同的时刻指定、排列和执行请求，使用命令模式可以实现请求队列化。\n- 如果需要支持取消操作，可以通过管理命令对象实现命令的恢复和重做。\n- 如果系统崩溃时，需要把对系统的操作功能重新执行一遍，可以使用命令模式，把执行过的命令存入日志列表，然后通过日志列表循环重新执行一遍功能。\n\n## 优缺点\n\n- 优点\n  - **更松散的耦合**\n\n    ​命令模式使得发起命令的对象——客户端，和具体实现命令的对象——接收者对象完全解耦，也就是说发起命令的对象完全不知道具体实现对象是谁，也不知道如何实现。\n  - **更动态的控制**\n\n    ​命令模式把请求封装起来，可以动态地对它进行参数化、队列化和日志化等操作，从而使得系统更灵活。\n\n  - **很自然的复合命令**\n\n  　　命令模式中的命令对象能够很容易地组合成复合命令，也就是宏命令，从而使系统操作更简单，功能更强大。\n\n  - **更好的扩展性**\n\n  　　由于发起命令的对象和具体的实现完全解耦，因此扩展新的命令就很容易，只需要实现新的命令对象，然后在装配的时候，把具体的实现对象设置到命令对象中，然后就可以使用这个命令对象，已有的实现完全不用变化。\n\n\n## UML图\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-23/28160345-file_1490281749243_16273.png)\n\n- **客户端(Client)角色：**创建一个具体命令(ConcreteCommand)对象并确定其接收者。\n- **命令(Command)角色：**声明了一个给所有具体命令类的抽象接口。\n- **具体命令(ConcreteCommand)角色：**定义一个接收者和行为之间的弱耦合；实现execute()方法，持有一个接受者对象，调用接受者的执行方法执行命令\n- **请求者(Invoker)角色：**负责调用命令对象执行请求，持有一个命令对象。请求者对象是客户端真正触发命令并要求命令执行相应操作的地方。\n- **接收者(Receiver)角色：**负责具体实施和执行一个请求。任何一个类都可以成为接收者，实施和执行请求的方法叫做行动方法。\n命令组装顺序图\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-28/10330806-file_1490678343446_df4f.jpg)\n\n命令执行顺序图\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-28/94749772-file_1490678397698_efed.jpg)\n\n## 代码实现\n\n### 普通命令模式\n\n```java\n//命令接口\npublic interface Command {\n    // 执行方法\n    void execute();\n}\n//具体命令角色类\npublic class ConcreteCommand implements Command {\n    //持有相应的接收者对象\n    private Receiver receiver = null;\n    //构造方法\n    public ConcreteCommand(Receiver receiver){\n        this.receiver = receiver;\n    }\n    @Override\n    public void execute() {\n        //通常会转调接收者对象的相应方法，让接收者来真正执行功能\n        receiver.action();\n    }\n\n}\n//接受者角色\npublic class Receiver {\n    // 真正执行命令相应的操作\n    public void action(){\n        System.out.println(\"执行操作\");\n    }\n}\npublic class Invoker {\n    //持有命令对象\n    private Command command = null;\n    //构造方法\n    public Invoker(Command command){\n        this.command = command;\n    }\n    //行动方法\n    public void action(){\n        //调用命令对象执行\n        command.execute();\n    }\n}\n//客户端\npublic class Client {\n\n    public static void main(String[] args) {\n        //创建接收者\n        Receiver receiver = new Receiver();\n        //创建命令对象，设定它的接收者\n        Command command = new ConcreteCommand(receiver);\n        //创建请求者，把命令对象设置进去\n        Invoker invoker = new Invoker(command);\n        //执行方法\n        invoker.action();\n    }\n}\n```\n\n### 宏命令\n\n所谓宏命令就是将多个命令聚合起来作为一个命令去处理\n\n```java\n//宏命令接口，继承命令接口\npublic interface MacroCommand extends Command {\n    //宏命令可以添加一个成员命令\n    public void add(Command cmd);\n    // 宏命令可以删除一个成员命令\n    public void remove(Command cmd);\n}\n//宏命令具体实现\npublic class MacroAudioCommand implements MacroCommand {\n    //持有一个命令集合\n    private List<Command> commandList = new ArrayList<Command>();\n  \t//实现接口方法\n    @Override\n    public void add(Command cmd) {\n        commandList.add(cmd);\n    }\n    //实现接口方法\n    @Override\n    public void remove(Command cmd) {\n        commandList.remove(cmd);\n    }\n    //实现命令执行方法，循环调用命令进行执行\n    @Override\n    public void execute() {\n        for(Command cmd : commandList){\n            cmd.execute();\n        }\n    }\n}\n```","source":"_posts/设计模式/设计模式之命令模式.md","raw":"---\ntitle: 设计模式之命令模式\ndate: 2018-05-29 16:15:32\ntags:\n- 设计模式\ncategories:\n- 设计模式\n\n---\n\n#  设计模式之命令模式\n\n命令模式属于对象的行为模式，**命令模式是对命令的封装。命令模式把发出命令的责任和执行命令的责任分割开，委派给不同的对象**。\n\n<!--more-->\n\n## 认识\n\n每一个命令都是一个操作：请求的一方发出请求要求执行一个操作；接收的一方收到请求，并执行操作。命令模式允许请求的一方和接收的一方独立开来，使得请求的一方不必知道接收请求的一方的接口，更不必知道请求是怎么被接收，以及操作是否被执行、何时被执行，以及是怎么被执行的，实现了解耦合。\n\n## 思考\n\n命令允许请求的一方和接收请求的一方能够独立演化，从而具有以下的优点：\n\n1. 命令模式使新的命令很容易地被加入到系统里。\n2. 允许接收请求的一方决定**是否要否决请求**。\n3. 能较容易地设计一个命令队列。\n4. 可以容易地实现对请求的撤销和恢复。**Invoker中维护一个撤销命令List和一个重做命令List**\n5. 在需要的情况下，可以较容易地将命令记入日志。\n\n## 使用场景\n\n- 如果需要抽象出需要执行的动作，并参数化这些对象，可以把这些需要执行的动作抽象成命令，然后实现命令的参数化配置。\n- 如果需要在不同的时刻指定、排列和执行请求，使用命令模式可以实现请求队列化。\n- 如果需要支持取消操作，可以通过管理命令对象实现命令的恢复和重做。\n- 如果系统崩溃时，需要把对系统的操作功能重新执行一遍，可以使用命令模式，把执行过的命令存入日志列表，然后通过日志列表循环重新执行一遍功能。\n\n## 优缺点\n\n- 优点\n  - **更松散的耦合**\n\n    ​命令模式使得发起命令的对象——客户端，和具体实现命令的对象——接收者对象完全解耦，也就是说发起命令的对象完全不知道具体实现对象是谁，也不知道如何实现。\n  - **更动态的控制**\n\n    ​命令模式把请求封装起来，可以动态地对它进行参数化、队列化和日志化等操作，从而使得系统更灵活。\n\n  - **很自然的复合命令**\n\n  　　命令模式中的命令对象能够很容易地组合成复合命令，也就是宏命令，从而使系统操作更简单，功能更强大。\n\n  - **更好的扩展性**\n\n  　　由于发起命令的对象和具体的实现完全解耦，因此扩展新的命令就很容易，只需要实现新的命令对象，然后在装配的时候，把具体的实现对象设置到命令对象中，然后就可以使用这个命令对象，已有的实现完全不用变化。\n\n\n## UML图\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-23/28160345-file_1490281749243_16273.png)\n\n- **客户端(Client)角色：**创建一个具体命令(ConcreteCommand)对象并确定其接收者。\n- **命令(Command)角色：**声明了一个给所有具体命令类的抽象接口。\n- **具体命令(ConcreteCommand)角色：**定义一个接收者和行为之间的弱耦合；实现execute()方法，持有一个接受者对象，调用接受者的执行方法执行命令\n- **请求者(Invoker)角色：**负责调用命令对象执行请求，持有一个命令对象。请求者对象是客户端真正触发命令并要求命令执行相应操作的地方。\n- **接收者(Receiver)角色：**负责具体实施和执行一个请求。任何一个类都可以成为接收者，实施和执行请求的方法叫做行动方法。\n命令组装顺序图\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-28/10330806-file_1490678343446_df4f.jpg)\n\n命令执行顺序图\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-28/94749772-file_1490678397698_efed.jpg)\n\n## 代码实现\n\n### 普通命令模式\n\n```java\n//命令接口\npublic interface Command {\n    // 执行方法\n    void execute();\n}\n//具体命令角色类\npublic class ConcreteCommand implements Command {\n    //持有相应的接收者对象\n    private Receiver receiver = null;\n    //构造方法\n    public ConcreteCommand(Receiver receiver){\n        this.receiver = receiver;\n    }\n    @Override\n    public void execute() {\n        //通常会转调接收者对象的相应方法，让接收者来真正执行功能\n        receiver.action();\n    }\n\n}\n//接受者角色\npublic class Receiver {\n    // 真正执行命令相应的操作\n    public void action(){\n        System.out.println(\"执行操作\");\n    }\n}\npublic class Invoker {\n    //持有命令对象\n    private Command command = null;\n    //构造方法\n    public Invoker(Command command){\n        this.command = command;\n    }\n    //行动方法\n    public void action(){\n        //调用命令对象执行\n        command.execute();\n    }\n}\n//客户端\npublic class Client {\n\n    public static void main(String[] args) {\n        //创建接收者\n        Receiver receiver = new Receiver();\n        //创建命令对象，设定它的接收者\n        Command command = new ConcreteCommand(receiver);\n        //创建请求者，把命令对象设置进去\n        Invoker invoker = new Invoker(command);\n        //执行方法\n        invoker.action();\n    }\n}\n```\n\n### 宏命令\n\n所谓宏命令就是将多个命令聚合起来作为一个命令去处理\n\n```java\n//宏命令接口，继承命令接口\npublic interface MacroCommand extends Command {\n    //宏命令可以添加一个成员命令\n    public void add(Command cmd);\n    // 宏命令可以删除一个成员命令\n    public void remove(Command cmd);\n}\n//宏命令具体实现\npublic class MacroAudioCommand implements MacroCommand {\n    //持有一个命令集合\n    private List<Command> commandList = new ArrayList<Command>();\n  \t//实现接口方法\n    @Override\n    public void add(Command cmd) {\n        commandList.add(cmd);\n    }\n    //实现接口方法\n    @Override\n    public void remove(Command cmd) {\n        commandList.remove(cmd);\n    }\n    //实现命令执行方法，循环调用命令进行执行\n    @Override\n    public void execute() {\n        for(Command cmd : commandList){\n            cmd.execute();\n        }\n    }\n}\n```","slug":"设计模式/设计模式之命令模式","published":1,"updated":"2018-09-12T03:03:21.836Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnil0076wlkvwhku4n91"},{"title":"设计模式之备忘录模式","date":"2018-06-10T12:25:23.000Z","_content":"\n#  设计模式之备忘录模式\n\n备忘录模式的用意是在不破坏封装的条件下，将一个对象的状态捕捉(Capture)住，并外部化，存储起来，从而可以在将来合适的时候把这个对象还原到存储起来的状态。备忘录模式常常与命令模式和迭代子模式一同使用。\n\n<!--more-->\n\n## 认识\n\n- 备忘录对象是一个用来存储另外一个对象内部状态的快照的对象。\n- 本质：保存和恢复内部状态\n\n## 思考\n\n- 在备忘录模式中，源发起对象是要备忘的对象。备忘录对象用来备忘某个时间点的对象状态。备忘录管理者只用来保存备忘录对象和将源对象恢复到备忘录状态\n\n- 只允许源发起对象操作备忘录对象的内部状态，其他对象不允许访问和操作备忘录对象，保证封装性\n\n- 命令模式实现中，在实现命令的撤销和重做的时候，可以使用备忘录模式，在命令操作的时候记录下操作前后的状态，然后在命令撤销和重做的时候，直接使用相应的备忘录对象来恢复状态就可以了。\n\n\n## 使用场景\n\n- 当需要回退业务的时候，可以记录上一个对象状态用于恢复\n\n## 优缺点\n\n- 优点  \n  - 可以记录对象的上一个状态，同时控制只有备忘发起者可以访问备忘录对象\n  - 将备忘录对象保存到源对象外，实现了源于备份的分开放置，互不影响\n\n- 缺点\n  - 拷贝对象进行保存，占用内存空间\n\n\n## UML图\n\n![](http://omdq6di7v.bkt.clouddn.com/18-6-11/14717603.jpg)\n\n- **备忘录**（Memento）角色：备忘录角色存储“备忘发起角色”的内部状态。“备忘发起角色”根据需要决定备忘录角色存储“备忘发起角色”的哪些内部状态。为了防止“备忘发起角色”以外的其他对象访问备忘录。备忘录实际上有两个接口，“备忘录管理者角色”只能看到备忘录提供的窄接口——对于备忘录角色中存放的属性是不可见的。“备忘发起角色”则能够看到一个宽接口——能够得到自己放入备忘录角色中属性。\n\n\n- **备忘发起**（Originator）角色：创建一个含有当前的内部状态的备忘录对象，在需要的时候使用备忘录对象恢复之前状态\n\n\n- **备忘录管理者**（Caretaker）角色：负责保存好备忘录对象。不能对备忘录对象的内容进行操作或检查。\n\n## 代码实现\n\n- 宽接口：在代码层不限制备忘录对象的访问和修改，靠开发人员自觉限制\n\n```java\n/**\n * 备忘发起者\n */\n@Data\npublic class Originator {\n\n    //用于备忘的状态\n    private String state;\n\n    public Originator(String state){\n        this.state = state;\n    }\n    public Memento createMemento(){\n        Memento memento = new Memento();\n        memento.setState(this.state);\n        return memento;\n    }\n\n    public void reset2Memento(Memento memento){\n        this.state = memento.getState();\n        System.out.println(String.format(\"发起者恢复至备忘状态%s\",memento.getState()));\n    }\n}\n/**\n * 备忘录角色\n */\n@Data\npublic class Memento {\n\n    private String state;\n}\n/**\n * 备忘录管理角色\n */\npublic class CareTaker {\n\n    private Memento memento;\n\n    //获取保存的备忘录对象\n    public Memento retrieveMemento() {\n        return this.memento;\n    }\n\n   //保存备忘录对象\n    public void saveMemento(Memento memento) {\n        this.memento = memento;\n    }\n}\npublic class Client {\n\n    public static void main(String[] args) {\n        String state = \"1\";\n        Originator originator = new Originator(state);\n        Memento memento = originator.createMemento();\n        CareTaker careTaker = new CareTaker();\n        careTaker.saveMemento(memento);\n        originator.setState(\"2\");\n        System.out.println(\"将备忘发起角色状态修改为2\");\n        originator.reset2Memento(careTaker.retrieveMemento());\n    }\n}\n```\n\n- 窄接口，将备忘录对象设计为源发起对象的private内部类，这样备忘录对象就只能被源对象访问，同时继承一个接口，可以让备忘管理者进行保存\n\n```java\n/**\n * 备忘录抽象接口,方便外部保存备忘录对象\n */\npublic interface IMemento {\n}\n/**\n * 备忘发起者\n */\n@Data\npublic class Originator {\n\n    //用于备忘的状态\n    private String state;\n\n    public Originator(String state){\n        this.state = state;\n    }\n    public Memento createMemento(){\n        Memento memento = new Memento();\n        memento.setState(this.state);\n        return memento;\n    }\n\n    //接受一个IMemento类型的备忘录对象，处理时强转为 memento\n    public void reset2Memento(IMemento memento){\n        Memento bean = (Memento)memento;\n        this.state = bean.getState();\n        System.out.println(String.format(\"发起者恢复至备忘状态%s\",bean.getState()));\n    }\n\n    //将备忘录对象设计为源对象内部类，并控制为private\n    private class Memento implements IMemento{\n        private String state;\n\n        public String getState() {\n            return state;\n        }\n\n        public void setState(String state) {\n            this.state = state;\n        }\n    }\n}\n/**\n * 备忘录管理角色\n */\npublic class CareTaker {\n\n    //管理 备忘录抽象\n    private IMemento memento;\n\n    //获取保存的备忘录对象\n    public IMemento retrieveMemento() {\n        return this.memento;\n    }\n\n   //保存备忘录对象\n    public void saveMemento(IMemento memento) {\n        this.memento = memento;\n    }\n}\npublic class Client {\n\n    public static void main(String[] args) {\n        String state = \"1\";\n        Originator originator = new Originator(state);\n        IMemento memento = originator.createMemento();\n        CareTaker careTaker = new CareTaker();\n        careTaker.saveMemento(memento);\n        originator.setState(\"2\");\n        System.out.println(\"将备忘发起角色状态修改为2\");\n        originator.reset2Memento(careTaker.retrieveMemento());\n    }\n}\n```\n\n","source":"_posts/设计模式/设计模式之备忘录模式.md","raw":"---\ntitle: 设计模式之备忘录模式\ndate: 2018-06-10 20:25:23\ntags:\n- 设计模式\ncategories:\n- 设计模式\n\n---\n\n#  设计模式之备忘录模式\n\n备忘录模式的用意是在不破坏封装的条件下，将一个对象的状态捕捉(Capture)住，并外部化，存储起来，从而可以在将来合适的时候把这个对象还原到存储起来的状态。备忘录模式常常与命令模式和迭代子模式一同使用。\n\n<!--more-->\n\n## 认识\n\n- 备忘录对象是一个用来存储另外一个对象内部状态的快照的对象。\n- 本质：保存和恢复内部状态\n\n## 思考\n\n- 在备忘录模式中，源发起对象是要备忘的对象。备忘录对象用来备忘某个时间点的对象状态。备忘录管理者只用来保存备忘录对象和将源对象恢复到备忘录状态\n\n- 只允许源发起对象操作备忘录对象的内部状态，其他对象不允许访问和操作备忘录对象，保证封装性\n\n- 命令模式实现中，在实现命令的撤销和重做的时候，可以使用备忘录模式，在命令操作的时候记录下操作前后的状态，然后在命令撤销和重做的时候，直接使用相应的备忘录对象来恢复状态就可以了。\n\n\n## 使用场景\n\n- 当需要回退业务的时候，可以记录上一个对象状态用于恢复\n\n## 优缺点\n\n- 优点  \n  - 可以记录对象的上一个状态，同时控制只有备忘发起者可以访问备忘录对象\n  - 将备忘录对象保存到源对象外，实现了源于备份的分开放置，互不影响\n\n- 缺点\n  - 拷贝对象进行保存，占用内存空间\n\n\n## UML图\n\n![](http://omdq6di7v.bkt.clouddn.com/18-6-11/14717603.jpg)\n\n- **备忘录**（Memento）角色：备忘录角色存储“备忘发起角色”的内部状态。“备忘发起角色”根据需要决定备忘录角色存储“备忘发起角色”的哪些内部状态。为了防止“备忘发起角色”以外的其他对象访问备忘录。备忘录实际上有两个接口，“备忘录管理者角色”只能看到备忘录提供的窄接口——对于备忘录角色中存放的属性是不可见的。“备忘发起角色”则能够看到一个宽接口——能够得到自己放入备忘录角色中属性。\n\n\n- **备忘发起**（Originator）角色：创建一个含有当前的内部状态的备忘录对象，在需要的时候使用备忘录对象恢复之前状态\n\n\n- **备忘录管理者**（Caretaker）角色：负责保存好备忘录对象。不能对备忘录对象的内容进行操作或检查。\n\n## 代码实现\n\n- 宽接口：在代码层不限制备忘录对象的访问和修改，靠开发人员自觉限制\n\n```java\n/**\n * 备忘发起者\n */\n@Data\npublic class Originator {\n\n    //用于备忘的状态\n    private String state;\n\n    public Originator(String state){\n        this.state = state;\n    }\n    public Memento createMemento(){\n        Memento memento = new Memento();\n        memento.setState(this.state);\n        return memento;\n    }\n\n    public void reset2Memento(Memento memento){\n        this.state = memento.getState();\n        System.out.println(String.format(\"发起者恢复至备忘状态%s\",memento.getState()));\n    }\n}\n/**\n * 备忘录角色\n */\n@Data\npublic class Memento {\n\n    private String state;\n}\n/**\n * 备忘录管理角色\n */\npublic class CareTaker {\n\n    private Memento memento;\n\n    //获取保存的备忘录对象\n    public Memento retrieveMemento() {\n        return this.memento;\n    }\n\n   //保存备忘录对象\n    public void saveMemento(Memento memento) {\n        this.memento = memento;\n    }\n}\npublic class Client {\n\n    public static void main(String[] args) {\n        String state = \"1\";\n        Originator originator = new Originator(state);\n        Memento memento = originator.createMemento();\n        CareTaker careTaker = new CareTaker();\n        careTaker.saveMemento(memento);\n        originator.setState(\"2\");\n        System.out.println(\"将备忘发起角色状态修改为2\");\n        originator.reset2Memento(careTaker.retrieveMemento());\n    }\n}\n```\n\n- 窄接口，将备忘录对象设计为源发起对象的private内部类，这样备忘录对象就只能被源对象访问，同时继承一个接口，可以让备忘管理者进行保存\n\n```java\n/**\n * 备忘录抽象接口,方便外部保存备忘录对象\n */\npublic interface IMemento {\n}\n/**\n * 备忘发起者\n */\n@Data\npublic class Originator {\n\n    //用于备忘的状态\n    private String state;\n\n    public Originator(String state){\n        this.state = state;\n    }\n    public Memento createMemento(){\n        Memento memento = new Memento();\n        memento.setState(this.state);\n        return memento;\n    }\n\n    //接受一个IMemento类型的备忘录对象，处理时强转为 memento\n    public void reset2Memento(IMemento memento){\n        Memento bean = (Memento)memento;\n        this.state = bean.getState();\n        System.out.println(String.format(\"发起者恢复至备忘状态%s\",bean.getState()));\n    }\n\n    //将备忘录对象设计为源对象内部类，并控制为private\n    private class Memento implements IMemento{\n        private String state;\n\n        public String getState() {\n            return state;\n        }\n\n        public void setState(String state) {\n            this.state = state;\n        }\n    }\n}\n/**\n * 备忘录管理角色\n */\npublic class CareTaker {\n\n    //管理 备忘录抽象\n    private IMemento memento;\n\n    //获取保存的备忘录对象\n    public IMemento retrieveMemento() {\n        return this.memento;\n    }\n\n   //保存备忘录对象\n    public void saveMemento(IMemento memento) {\n        this.memento = memento;\n    }\n}\npublic class Client {\n\n    public static void main(String[] args) {\n        String state = \"1\";\n        Originator originator = new Originator(state);\n        IMemento memento = originator.createMemento();\n        CareTaker careTaker = new CareTaker();\n        careTaker.saveMemento(memento);\n        originator.setState(\"2\");\n        System.out.println(\"将备忘发起角色状态修改为2\");\n        originator.reset2Memento(careTaker.retrieveMemento());\n    }\n}\n```\n\n","slug":"设计模式/设计模式之备忘录模式","published":1,"updated":"2018-09-12T03:03:21.836Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnin007awlkvmo40etvu"},{"title":"设计模式之工厂方法模式","date":"2018-05-23T08:41:22.000Z","_content":"\n#  设计模式之工厂方法模式\n\n工厂方法模式将创建对象的功能延迟到子类去实现，这样在添加一种对象的时候只需要再添加一个工厂的实现就可以，遵循了对扩展开发，对修改关闭的原则。\n\n<!--more-->\n\n## 认识\n\n1. 工厂方法的主要功能是让父类在不知道具体实现的情况下，完成自身的功能调用，而具体的实现延迟到子类来实现.\n2. 工厂方法模式通常是针对Product接口的每个实现类都提供一个与之对应的Factory实现类用于创建该对象\n3. 可以把工厂父类实现为一个具体的类，在父类中提供获取所需对象的默认实现方法，这样就算没有具体的子类去创建对象，也能够完成功能运行。\n\n\n## 思考\n\n1. 工厂方法的本质：**工厂是抽象的，只定义需要依赖的对象，依赖对象的创建延迟到工厂的子类中实现**\n2. 相比于简单工厂和抽象工厂，有更好的扩展性，当增加一个Product的实现类时，只需要添加一个Factory与之对应的实现类就行。\n3. 工厂方法模式中一个工厂实现类**只操作一个产品接口**，抽象工厂模式操作的是**多个产品接口**\n\n## 优缺点\n\n1. 可以在不知道具体实现的情况下编程，解耦合。\n2. 更容易扩展对象的新版本，当有一个新的对象需要创建的时候创建一个新的工厂实现类返回新的对象。\n3. 缺点是每个Product的实现都需要创建一个Factory的实现，增加了客户端调用的选择难度。\n\n## 使用场景\n\n1. 工厂方法模式作为一种创建类模式，在任何需要生成**复杂对象**的地方，都可以使用工厂方法模式，比静态工厂模式更好的扩展。\n2. 工厂方法模式将具体的操作延迟到子类实现，当父类不做任何操作，将具体操作通过抽象方法延迟到子类去实现的时候可以使用。\n3. 当父类的操作需要一个对象的时候，提供抽象方法，让子类实现抽象方法创建需要的对象，同时在父类中定义使用该对象的公共方法，实现依赖倒置。\n\n## UML图\n\n封装Product实现类的具体细节，创建一个抽象工厂，为每个Product接口的实现类都创建一个工厂实现类，在抽象方法中创建对应的Product的实现类对象。之后如果扩展Product的实现类，只需要扩展一个对象的工厂实现类就行。\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-15/74121605-file_1489586682288_f2ea.png)\n\n客户端操作工厂方法的过程\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-15/53464459-file_1489586881321_e1b2.png)\n\n\n\n## 代码实现\n\n```java\n//产品接口\npublic interface IProduct {\n\tpublic void operation();\n}\n\n//产品实现类A\npublic class ConcreateProductA implements IProduct {\n\n\tpublic void operation() {\n\t\tSystem.out.println(\"创建产品A\");\n\t}\n}\n\n//产品实现类B\npublic class ConcreateProductB implements IProduct {\n\n\tpublic void operation() {\n\t\tSystem.out.println(\"创建产品B\");\n\t}\n}\n\n//抽象工厂类\npublic abstract class Factory {\n\n\t//定义抽象，具体实现延迟到子类中实现\n\tprotected abstract IProduct getProduct();\n\n\t//提供方法供客户端调用\n\tpublic IProduct createProduct() {\n\t\t// 进行操作\n\t\tIProduct product = this.getProduct();\n\t\t// 进行操作\n\t\treturn product;\n\t}\n}\n\n//工厂实现类A\npublic class ConcreateFacotryA extends Factory {\n\n\t//实现类中创建对应的product的子类返回\n\t@Override\n\tprotected IProduct getProduct() {\n\t\treturn new ConcreateProductA();\n\t}\n}\n//工厂实现类B\npublic class ConcreateFacotryB extends Factory {\n\n\t//实现类中创建对应的product的子类返回\n\t@Override\n\tprotected IProduct getProduct() {\n\t\treturn new ConcreateProductB();\n\t}\n}\n\n//客户端调用\npublic class Client {\n\n\tpublic static void main(String[] args) {\n\t\t// 客户端调用 Factory的 ConcreateFacotryA 实现类创建对象\n\t\tFactory factoryA = new ConcreateFacotryA();\n\t\tIProduct productA = factoryA.createProduct();\n\t\tproductA.operation();\n\n\t\t// 客户端调用 Factory的 ConcreateFacotryB 实现类创建对象\n\t\tFactory factoryB = new ConcreateFacotryB();\n\t\tIProduct productB = factoryB.createProduct();\n\t\tproductB.operation();\n\t}\n}\n```\n\n通过工厂方法模式实现依赖倒置，父类(接口)无法new实例，只定义操作，而操作中所需要的外部对象，由子类实现抽象方法去创建，将对象的创建延迟到子类中，能够实现更好的扩展。同时实现依赖倒置和延迟加载。\n\n```java\npublic abstract class A1 {\n\t//工厂方法，创建C1，类似于从子类注入进来的途径\n\tprotected abstract C1 createC1();\n    \n\tpublic void t1(){\n\t\t//这里需要使用C1，可是不知道究竟是用哪一个，也就不主动去创建C1了，怎么办？\n\t\t//反正会在子类里面实现，这样更省心，这里不用管怎么获取C1，直接使用就好了\n\t\tcreateC1().tc();\n\t}\n}\n\npublic class A2 extends A1 {\n\tprotected C1 createC1() {\n\t\t//真正的选择具体实现，并创建对象\n\t\treturn new C2();\n\t}\n}\n```\n\n\n","source":"_posts/设计模式/设计模式之工厂方法模式.md","raw":"---\ntitle: 设计模式之工厂方法模式\ndate: 2018-05-23 16:41:22\ntags:\n- 设计模式\ncategories:\n- 设计模式\n\n---\n\n#  设计模式之工厂方法模式\n\n工厂方法模式将创建对象的功能延迟到子类去实现，这样在添加一种对象的时候只需要再添加一个工厂的实现就可以，遵循了对扩展开发，对修改关闭的原则。\n\n<!--more-->\n\n## 认识\n\n1. 工厂方法的主要功能是让父类在不知道具体实现的情况下，完成自身的功能调用，而具体的实现延迟到子类来实现.\n2. 工厂方法模式通常是针对Product接口的每个实现类都提供一个与之对应的Factory实现类用于创建该对象\n3. 可以把工厂父类实现为一个具体的类，在父类中提供获取所需对象的默认实现方法，这样就算没有具体的子类去创建对象，也能够完成功能运行。\n\n\n## 思考\n\n1. 工厂方法的本质：**工厂是抽象的，只定义需要依赖的对象，依赖对象的创建延迟到工厂的子类中实现**\n2. 相比于简单工厂和抽象工厂，有更好的扩展性，当增加一个Product的实现类时，只需要添加一个Factory与之对应的实现类就行。\n3. 工厂方法模式中一个工厂实现类**只操作一个产品接口**，抽象工厂模式操作的是**多个产品接口**\n\n## 优缺点\n\n1. 可以在不知道具体实现的情况下编程，解耦合。\n2. 更容易扩展对象的新版本，当有一个新的对象需要创建的时候创建一个新的工厂实现类返回新的对象。\n3. 缺点是每个Product的实现都需要创建一个Factory的实现，增加了客户端调用的选择难度。\n\n## 使用场景\n\n1. 工厂方法模式作为一种创建类模式，在任何需要生成**复杂对象**的地方，都可以使用工厂方法模式，比静态工厂模式更好的扩展。\n2. 工厂方法模式将具体的操作延迟到子类实现，当父类不做任何操作，将具体操作通过抽象方法延迟到子类去实现的时候可以使用。\n3. 当父类的操作需要一个对象的时候，提供抽象方法，让子类实现抽象方法创建需要的对象，同时在父类中定义使用该对象的公共方法，实现依赖倒置。\n\n## UML图\n\n封装Product实现类的具体细节，创建一个抽象工厂，为每个Product接口的实现类都创建一个工厂实现类，在抽象方法中创建对应的Product的实现类对象。之后如果扩展Product的实现类，只需要扩展一个对象的工厂实现类就行。\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-15/74121605-file_1489586682288_f2ea.png)\n\n客户端操作工厂方法的过程\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-15/53464459-file_1489586881321_e1b2.png)\n\n\n\n## 代码实现\n\n```java\n//产品接口\npublic interface IProduct {\n\tpublic void operation();\n}\n\n//产品实现类A\npublic class ConcreateProductA implements IProduct {\n\n\tpublic void operation() {\n\t\tSystem.out.println(\"创建产品A\");\n\t}\n}\n\n//产品实现类B\npublic class ConcreateProductB implements IProduct {\n\n\tpublic void operation() {\n\t\tSystem.out.println(\"创建产品B\");\n\t}\n}\n\n//抽象工厂类\npublic abstract class Factory {\n\n\t//定义抽象，具体实现延迟到子类中实现\n\tprotected abstract IProduct getProduct();\n\n\t//提供方法供客户端调用\n\tpublic IProduct createProduct() {\n\t\t// 进行操作\n\t\tIProduct product = this.getProduct();\n\t\t// 进行操作\n\t\treturn product;\n\t}\n}\n\n//工厂实现类A\npublic class ConcreateFacotryA extends Factory {\n\n\t//实现类中创建对应的product的子类返回\n\t@Override\n\tprotected IProduct getProduct() {\n\t\treturn new ConcreateProductA();\n\t}\n}\n//工厂实现类B\npublic class ConcreateFacotryB extends Factory {\n\n\t//实现类中创建对应的product的子类返回\n\t@Override\n\tprotected IProduct getProduct() {\n\t\treturn new ConcreateProductB();\n\t}\n}\n\n//客户端调用\npublic class Client {\n\n\tpublic static void main(String[] args) {\n\t\t// 客户端调用 Factory的 ConcreateFacotryA 实现类创建对象\n\t\tFactory factoryA = new ConcreateFacotryA();\n\t\tIProduct productA = factoryA.createProduct();\n\t\tproductA.operation();\n\n\t\t// 客户端调用 Factory的 ConcreateFacotryB 实现类创建对象\n\t\tFactory factoryB = new ConcreateFacotryB();\n\t\tIProduct productB = factoryB.createProduct();\n\t\tproductB.operation();\n\t}\n}\n```\n\n通过工厂方法模式实现依赖倒置，父类(接口)无法new实例，只定义操作，而操作中所需要的外部对象，由子类实现抽象方法去创建，将对象的创建延迟到子类中，能够实现更好的扩展。同时实现依赖倒置和延迟加载。\n\n```java\npublic abstract class A1 {\n\t//工厂方法，创建C1，类似于从子类注入进来的途径\n\tprotected abstract C1 createC1();\n    \n\tpublic void t1(){\n\t\t//这里需要使用C1，可是不知道究竟是用哪一个，也就不主动去创建C1了，怎么办？\n\t\t//反正会在子类里面实现，这样更省心，这里不用管怎么获取C1，直接使用就好了\n\t\tcreateC1().tc();\n\t}\n}\n\npublic class A2 extends A1 {\n\tprotected C1 createC1() {\n\t\t//真正的选择具体实现，并创建对象\n\t\treturn new C2();\n\t}\n}\n```\n\n\n","slug":"设计模式/设计模式之工厂方法模式","published":1,"updated":"2018-09-12T03:03:21.837Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnio007ewlkvl6yc9aym"},{"title":"java并发之ReentrantReadWriteLock","date":"2017-11-22T09:24:45.000Z","_content":"\n# java并发之ReentrantReadWriteLock\n\nReentrantReadWriteLock是读写分离锁\n\n<!--more-->\n\n## 用法\n\n```java\nclass CashData {\n  Object obj;\n  volatile boolean cacheValid;\n  ReentrantReadWriteLock rwl = new ReentrantReadWriteLock();\n  public Object load() {\n    rwl.readLock().lock();\n    if (!cacheValid) {\n      // 释放读锁\n      rwl.readLock().unlock();\n      // 要进行赋值，添加写锁\n      rwl.writeLock().lock();\n      if (!cacheValid) {\n        cacheValid = true;\n        obj = 1;\n      }\n      // Downgrade by acquiring read lock before releasing write lock\n      rwl.readLock().lock();\n      rwl.writeLock().unlock(); // Unlock write, still hold read\n\n    }\n    rwl.readLock().unlock();\n    return obj;\n  }\n}\n}\n```\n\n","source":"_posts/多线程/java并发之ReentrantReadWriteLock.md","raw":"---\ntitle: java并发之ReentrantReadWriteLock\ndate: 2017-11-22 17:24:45\ntags:\n- 多线程\ncategories:\n- java基础\n---\n\n# java并发之ReentrantReadWriteLock\n\nReentrantReadWriteLock是读写分离锁\n\n<!--more-->\n\n## 用法\n\n```java\nclass CashData {\n  Object obj;\n  volatile boolean cacheValid;\n  ReentrantReadWriteLock rwl = new ReentrantReadWriteLock();\n  public Object load() {\n    rwl.readLock().lock();\n    if (!cacheValid) {\n      // 释放读锁\n      rwl.readLock().unlock();\n      // 要进行赋值，添加写锁\n      rwl.writeLock().lock();\n      if (!cacheValid) {\n        cacheValid = true;\n        obj = 1;\n      }\n      // Downgrade by acquiring read lock before releasing write lock\n      rwl.readLock().lock();\n      rwl.writeLock().unlock(); // Unlock write, still hold read\n\n    }\n    rwl.readLock().unlock();\n    return obj;\n  }\n}\n}\n```\n\n","slug":"多线程/java并发之ReentrantReadWriteLock","published":1,"updated":"2018-09-12T03:03:21.831Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnip007iwlkvy6bhrafk"},{"title":"设计模式之模板方法模式","date":"2018-05-28T06:22:32.000Z","_content":"\n#  设计模式之模板方法模式\n\njava最重要的一个特性就是继承，通过父类定义一些公共的方法，将变化的方法放到子类中去实现。在父类中定义的方法就是模板，所有的子类都会继承父类的方法。\n\n<!--more-->\n\n## 认识\n\n模板方法模式是类的行为模式。准备一个抽象类，将部分逻辑以具体方法以及具体构造函数的形式实现，然后声明一些抽象方法来迫使子类实现剩余的逻辑。不同的子类可以以不同的方式实现这些抽象方法，从而对剩余的逻辑有不同的实现。这就是模板方法模式的用意。\n\n## 思考\n\n把程序中不变的部分抽象出来，放在抽象父类中，进行公共的实现，把变化的部分分离出去，用接口来封装隔离，将具体的实现延迟到子类，还通过父类的定义约束了子类的行为，从而使系统能有更好的复用性和扩展性\n\n实质：固定算法骨架，**子类可以置换掉父类的可变部分，但是子类却不可以改变模板方法所代表的顶级逻辑** \n\n## 使用场景\n\n- 子类具有公共的行为，抽象出来放入父类中，避免代码重复\n- 父类固定了算法骨架，具体的实现由不同的子类去具体实现\n\n## 优缺点\n\n- 优点：实现代码复用\n- 缺点：骨架固定不容易升级\n\n## UML图\n\n子类实现抽象类，抽象类中的定义了所有的行为，对公共的行为做出了实现，抽象方法由子类具体实现\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-27/7235962-file_1490591014868_2df2.jpg)\n\n## 代码实现\n\n　父类中定义的方法分为三种：抽象方法(Abstract Method)、具体方法(Concrete Method)和钩子方法(Hook Method)。\n\n　-  **抽象方法：**一个抽象方法由抽象类声明，由具体子类实现。在Java语言里抽象方法以abstract关键字标示。\n\n　-  **具体方法：**一个具体方法由抽象类声明并实现，而子类并不实现或置换。\n\n　-  **钩子方法：**一个钩子方法由抽象类声明并实现，而子类会加以扩展。通常抽象类给出的实现是一个空实现，作为方法的默认实现。\n\n```java\n//抽象父类\npublic abstract class AbstractTemplate {\n    //模板方法\n    public void templateMethod(){\n        //调用基本方法\n        abstractMethod();\n        hookMethod();\n        concreteMethod();\n    }\n    //抽象方法（由子类实现）\n    protected abstract void abstractMethod();\n    //钩子方法(由子类覆盖)\n    protected void hookMethod(){}\n    //基本方法（已经实现）\n    private final void concreteMethod(){\n        //业务相关的代码\n    }\n}\n//子类\npublic class ConcreteTemplate extends AbstractTemplate{\n    //基本方法的实现\n    @Override\n    public void abstractMethod() {\n        //业务相关的代码\n    }\n    //重写父类的方法\n    @Override\n    public void hookMethod() {\n        //业务相关的代码\n    }\n}\n```","source":"_posts/设计模式/设计模式之模板方法模式.md","raw":"---\ntitle: 设计模式之模板方法模式\ndate: 2018-05-28 14:22:32\ntags:\n- 设计模式\ncategories:\n- 设计模式\n\n---\n\n#  设计模式之模板方法模式\n\njava最重要的一个特性就是继承，通过父类定义一些公共的方法，将变化的方法放到子类中去实现。在父类中定义的方法就是模板，所有的子类都会继承父类的方法。\n\n<!--more-->\n\n## 认识\n\n模板方法模式是类的行为模式。准备一个抽象类，将部分逻辑以具体方法以及具体构造函数的形式实现，然后声明一些抽象方法来迫使子类实现剩余的逻辑。不同的子类可以以不同的方式实现这些抽象方法，从而对剩余的逻辑有不同的实现。这就是模板方法模式的用意。\n\n## 思考\n\n把程序中不变的部分抽象出来，放在抽象父类中，进行公共的实现，把变化的部分分离出去，用接口来封装隔离，将具体的实现延迟到子类，还通过父类的定义约束了子类的行为，从而使系统能有更好的复用性和扩展性\n\n实质：固定算法骨架，**子类可以置换掉父类的可变部分，但是子类却不可以改变模板方法所代表的顶级逻辑** \n\n## 使用场景\n\n- 子类具有公共的行为，抽象出来放入父类中，避免代码重复\n- 父类固定了算法骨架，具体的实现由不同的子类去具体实现\n\n## 优缺点\n\n- 优点：实现代码复用\n- 缺点：骨架固定不容易升级\n\n## UML图\n\n子类实现抽象类，抽象类中的定义了所有的行为，对公共的行为做出了实现，抽象方法由子类具体实现\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-27/7235962-file_1490591014868_2df2.jpg)\n\n## 代码实现\n\n　父类中定义的方法分为三种：抽象方法(Abstract Method)、具体方法(Concrete Method)和钩子方法(Hook Method)。\n\n　-  **抽象方法：**一个抽象方法由抽象类声明，由具体子类实现。在Java语言里抽象方法以abstract关键字标示。\n\n　-  **具体方法：**一个具体方法由抽象类声明并实现，而子类并不实现或置换。\n\n　-  **钩子方法：**一个钩子方法由抽象类声明并实现，而子类会加以扩展。通常抽象类给出的实现是一个空实现，作为方法的默认实现。\n\n```java\n//抽象父类\npublic abstract class AbstractTemplate {\n    //模板方法\n    public void templateMethod(){\n        //调用基本方法\n        abstractMethod();\n        hookMethod();\n        concreteMethod();\n    }\n    //抽象方法（由子类实现）\n    protected abstract void abstractMethod();\n    //钩子方法(由子类覆盖)\n    protected void hookMethod(){}\n    //基本方法（已经实现）\n    private final void concreteMethod(){\n        //业务相关的代码\n    }\n}\n//子类\npublic class ConcreteTemplate extends AbstractTemplate{\n    //基本方法的实现\n    @Override\n    public void abstractMethod() {\n        //业务相关的代码\n    }\n    //重写父类的方法\n    @Override\n    public void hookMethod() {\n        //业务相关的代码\n    }\n}\n```","slug":"设计模式/设计模式之模板方法模式","published":1,"updated":"2018-09-12T03:03:21.838Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnis007lwlkvfs4oidul"},{"title":"设计模式之桥接模式","date":"2018-05-25T02:42:18.000Z","_content":"\n#  设计模式之桥接模式\n\n如果说某个系统能够从多个角度来进行分类，且每一种分类都可能会变化，那就需要将多个角度分别分离出来，使得他们能独立变化，减少他们之间的耦合，这个分离过程就使用了桥接模式。所谓桥接模式就是将多个抽象部分和实现部分隔离开来，使得他们能够独立变化。\n\n<!--more-->\n\n## 认识\n\n桥接模式将继承关系转化成关联关系，封装了变化，完成了解耦，减少了系统中类的数量，也减少了代码量。\n\n## 思考\n\n-  桥接模式实现了两个抽象变化的脱耦。他们两个互相独立，不会影响到对方。\n- 对于两个独立变化的维度，使用桥接模式再适合不过了。\n\n## 使用场景\n\n- 一个类存在两个独立变化的维度，且这两个维度都需要进行扩展。\n- 如果一个系统需要在构件的抽象化角色和具体化角色之间增加更多的灵活性，避免在两个层次之间建立静态的继承联系，通过桥接模式可以使它们**在抽象层建立一个关联关系**。\n- 对于那些不希望使用继承或因为多层次继承导致系统类的个数急剧增加的系统，桥接模式尤为适用。\n\n## 优缺点\n\n- 优点\n  1. 分离抽象接口及其实现部分。提高了比继承更好的解决方案。\n  2. 桥接模式提高了系统的可扩充性，在两个变化维度中任意扩展一个维度，都不需要修改原有系统。\n  3. 实现细节对客户透明，可以对用户隐藏实现细节。\n\n## UML图\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-11-19/83566663.jpg)\n\n桥梁模式所涉及的角色有：\n\n- 抽象化(Abstraction)角色：抽象化给出的定义，并保存一个对实现化对象的引用。\n\n- 修正抽象化(RefinedAbstraction)角色：扩展抽象化角色，改变和修正父类对抽象化的定义。\n\n- 实现化(Implementor)角色：这个角色给出实现化角色的接口，但不给出具体的实现。必须指出的是，这个接口不一定和抽象化角色的接口定义相同，实际上，这两个接口可以非常不一样。实现化角色应当只给出底层操作，而抽象化角色应当只给出基于底层操作的更高一层的操作。\n\n- 具体实现化(ConcreteImplementor)角色：这个角色给出实现化角色接口的具体实现。\n\n\n## 代码实现\n\n- 抽象化角色\n\n    ```java\n    public abstract class Abstraction {\n        //在抽象层建立关系\n        protected Implementor impl;\n        public Abstraction(Implementor impl){\n            this.impl = impl;\n        }\n        //示例方法\n        public void operation(){\n            impl.operationImpl();\n        }\n    }\n    ```\n- 修正抽象化角色\n\n    ```java\n    public class RefinedAbstraction extends Abstraction {\n    \n        public RefinedAbstraction(Implementor impl) {\n            super(impl);\n        }\n        //其他的操作方法\n        public void otherOperation(){  \n        }\n    }\n    ```\n- 实现化角色\n\n    ```java\n    public abstract class Implementor {\n        //示例方法，实现抽象部分需要的某些具体功能\n        public abstract void operationImpl();\n    }\n    ```\n- 具体实现化角色\n\n    ```java\n    public class ConcreteImplementorA extends Implementor {\n        @Override\n        public void operationImpl() {\n            //具体操作\n        }\n    }\n    public class ConcreteImplementorB extends Implementor {\n        @Override\n        public void operationImpl() {\n            //具体操作\n        }\n    }\n    ```\n\n\n例如不同图形不同颜色，可以抽象出两个抽象类 图形和颜色\n\n```java\npublic abstract class Shape {\n    private Color color;\n    public void setColor(Color color) {\n        this.color = color;\n    }\n    public abstract void draw();\n}\n\npublic class Circle extends Shape{\n    public void draw() {\n        color.bepaint(\"正方形\");\n    }\n}\n\npublic class Square extends Shape{\n    public void draw() {\n        color.bepaint(\"正方形\");\n    }\n}\n\npublic interface Color {\n    public void bepaint(String shape);\n}\n\npublic class White implements Color{\n    public void bepaint(String shape) {\n        System.out.println(\"白色的\" + shape);\n    }\n}\n\npublic class Black implements Color{\n    public void bepaint(String shape) {\n        System.out.println(\"黑色的\" + shape);\n    }\n}\n\npublic class Client {\n    public static void main(String[] args) {\n        //白色\n        Color white = new White();\n        //正方形\n        Shape square = new Square();\n        //白色的正方形\n        square.setColor(white);\n        square.draw();\n        \n        //圆形\n        Shape circle = new Circle();\n        circle.setColor(white);\n        circle.draw();\n    }\n}\n```\n\n","source":"_posts/设计模式/设计模式之桥接模式.md","raw":"---\ntitle: 设计模式之桥接模式\ndate: 2018-05-25 10:42:18\ntags:\n- 设计模式\ncategories:\n- 设计模式\n\n---\n\n#  设计模式之桥接模式\n\n如果说某个系统能够从多个角度来进行分类，且每一种分类都可能会变化，那就需要将多个角度分别分离出来，使得他们能独立变化，减少他们之间的耦合，这个分离过程就使用了桥接模式。所谓桥接模式就是将多个抽象部分和实现部分隔离开来，使得他们能够独立变化。\n\n<!--more-->\n\n## 认识\n\n桥接模式将继承关系转化成关联关系，封装了变化，完成了解耦，减少了系统中类的数量，也减少了代码量。\n\n## 思考\n\n-  桥接模式实现了两个抽象变化的脱耦。他们两个互相独立，不会影响到对方。\n- 对于两个独立变化的维度，使用桥接模式再适合不过了。\n\n## 使用场景\n\n- 一个类存在两个独立变化的维度，且这两个维度都需要进行扩展。\n- 如果一个系统需要在构件的抽象化角色和具体化角色之间增加更多的灵活性，避免在两个层次之间建立静态的继承联系，通过桥接模式可以使它们**在抽象层建立一个关联关系**。\n- 对于那些不希望使用继承或因为多层次继承导致系统类的个数急剧增加的系统，桥接模式尤为适用。\n\n## 优缺点\n\n- 优点\n  1. 分离抽象接口及其实现部分。提高了比继承更好的解决方案。\n  2. 桥接模式提高了系统的可扩充性，在两个变化维度中任意扩展一个维度，都不需要修改原有系统。\n  3. 实现细节对客户透明，可以对用户隐藏实现细节。\n\n## UML图\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-11-19/83566663.jpg)\n\n桥梁模式所涉及的角色有：\n\n- 抽象化(Abstraction)角色：抽象化给出的定义，并保存一个对实现化对象的引用。\n\n- 修正抽象化(RefinedAbstraction)角色：扩展抽象化角色，改变和修正父类对抽象化的定义。\n\n- 实现化(Implementor)角色：这个角色给出实现化角色的接口，但不给出具体的实现。必须指出的是，这个接口不一定和抽象化角色的接口定义相同，实际上，这两个接口可以非常不一样。实现化角色应当只给出底层操作，而抽象化角色应当只给出基于底层操作的更高一层的操作。\n\n- 具体实现化(ConcreteImplementor)角色：这个角色给出实现化角色接口的具体实现。\n\n\n## 代码实现\n\n- 抽象化角色\n\n    ```java\n    public abstract class Abstraction {\n        //在抽象层建立关系\n        protected Implementor impl;\n        public Abstraction(Implementor impl){\n            this.impl = impl;\n        }\n        //示例方法\n        public void operation(){\n            impl.operationImpl();\n        }\n    }\n    ```\n- 修正抽象化角色\n\n    ```java\n    public class RefinedAbstraction extends Abstraction {\n    \n        public RefinedAbstraction(Implementor impl) {\n            super(impl);\n        }\n        //其他的操作方法\n        public void otherOperation(){  \n        }\n    }\n    ```\n- 实现化角色\n\n    ```java\n    public abstract class Implementor {\n        //示例方法，实现抽象部分需要的某些具体功能\n        public abstract void operationImpl();\n    }\n    ```\n- 具体实现化角色\n\n    ```java\n    public class ConcreteImplementorA extends Implementor {\n        @Override\n        public void operationImpl() {\n            //具体操作\n        }\n    }\n    public class ConcreteImplementorB extends Implementor {\n        @Override\n        public void operationImpl() {\n            //具体操作\n        }\n    }\n    ```\n\n\n例如不同图形不同颜色，可以抽象出两个抽象类 图形和颜色\n\n```java\npublic abstract class Shape {\n    private Color color;\n    public void setColor(Color color) {\n        this.color = color;\n    }\n    public abstract void draw();\n}\n\npublic class Circle extends Shape{\n    public void draw() {\n        color.bepaint(\"正方形\");\n    }\n}\n\npublic class Square extends Shape{\n    public void draw() {\n        color.bepaint(\"正方形\");\n    }\n}\n\npublic interface Color {\n    public void bepaint(String shape);\n}\n\npublic class White implements Color{\n    public void bepaint(String shape) {\n        System.out.println(\"白色的\" + shape);\n    }\n}\n\npublic class Black implements Color{\n    public void bepaint(String shape) {\n        System.out.println(\"黑色的\" + shape);\n    }\n}\n\npublic class Client {\n    public static void main(String[] args) {\n        //白色\n        Color white = new White();\n        //正方形\n        Shape square = new Square();\n        //白色的正方形\n        square.setColor(white);\n        square.draw();\n        \n        //圆形\n        Shape circle = new Circle();\n        circle.setColor(white);\n        circle.draw();\n    }\n}\n```\n\n","slug":"设计模式/设计模式之桥接模式","published":1,"updated":"2018-09-12T03:03:21.837Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnit007owlkvosrq1i17"},{"title":"设计模式之抽象工厂模式","date":"2018-05-23T09:50:12.000Z","_content":"\n#  设计模式之抽象工厂模式\n\n封装创建对象的细节，外部调用只需要关心自己想要什么和最终能得到什么结果，而不需要关心实现的过程。\n\n<!--more-->\n\n## 认识\n\n抽象工厂是同时创建**多个接口**(多个产品)的实现类对象，实现解耦合\n\n\n## 思考\n\n1. 抽象工厂模式能够处理更加复杂的对象的细节封装，可以对一个产品簇(多个接口)封装细节，对外部调用实现透明。而简单工厂模式和工厂方法模式都是对一个产品(一个接口)进行操作。\n2. 抽象工厂模式存在多个工厂实现类，可以结合简单工厂模式，根据type创建不同的抽象工厂实现类，进一步封装内部细节，进一步跟client端解耦合\n\n## 优缺点\n\n- 优点：\n  1. 分离了接口和实现\n  2. 封装了内部实现细节\n  3. 扩展新的工厂实现类容易，这需要再定义一个抽象工厂实现类\n- 缺点\n  1. 扩展新的产品类难，当新增加一个产品接口的时候，就需要同时修改所有的工厂实现类的源代码\n  2. 容易造成类层次复杂\n\n## 使用场景\n\n当工厂模式需要在工厂方法中操作多个产品(接口)的时候使用抽象工厂模式\n\n## UML图\n\n工厂需要操作多个接口\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-15/42597844-file_1489590399850_7ec7.png)\n\n## 代码实现\n\n```java\n//产品接口 A\npublic interface IProductA {\n\t  public void operation(); \n}\n//产品实现类A1\npublic class ConcreateProductA1 implements IProductA{\n\n\tpublic void operation() {\n\t\tSystem.out.println(\"创建产品A1\");\n\t}\n}\n//产品实现类A2\npublic class ConcreateProductA2 implements IProductA{\n\n\tpublic void operation() {\n\t\tSystem.out.println(\"创建产品2\");\n\t}\n}\n//产品接口B \npublic interface IProductB {\n\t  public void operation(); \n}\n//产品实现类B1\npublic class ConcreateProductB1 implements IProductB{\n\n\tpublic void operation() {\n\t\tSystem.out.println(\"创建产品B1\");\n\t}\n}\n//产品实现类B2\npublic class ConcreateProductB2 implements IProductB{\n\n\tpublic void operation() {\n\t\tSystem.out.println(\"创建产品B2\");\n\t}\n}\n//抽象工厂类 \npublic abstract class Factory {\n\t\n\t//定义抽象，具体实现延迟到子类中实现\n\tprotected abstract IProductA getProductA();\n\tprotected abstract IProductB getProductB();\n\t\n\t//提供方法供客户端调用\n\tpublic void createProduct(){\n\t\t//进行操作\n\t\tIProductA productA = this.getProductA();\n\t\tIProductB productB = this.getProductB();\n\t\t//进行操作\n\t}\n}\npublic class ConcreateFacotry1 extends Factory{\n\n\t//实现类中创建对应的productA的子类返回\n\t@Override\n\tprotected IProductA getProductA() {\n\t\treturn new ConcreateProductA1();\n\t}\n\n\t//实现类中创建对应的productB的子类返回\n\t@Override\n\tprotected IProductB getProductB() {\n\t\treturn new ConcreateProductB1();\n\t}\n}\npublic class ConcreateFacotry2 extends Factory{\n\n\t//实现类中创建对应的productA的子类返回\n\t@Override\n\tprotected IProductA getProductA() {\n\t\treturn new ConcreateProductA2();\n\t}\n\n\t//实现类中创建对应的productB的子类返回\n\t@Override\n\tprotected IProductB getProductB() {\n\t\treturn new ConcreateProductB2();\n\t}\n}\n//客户端调用\npublic class Client{\n\n\tpublic static void main(String[] args) {\n\t\t//客户端调用 Factory的 ConcreateFacotry1 实现类创建对象\n\t\tFactory factory1 = new ConcreateFacotry1();\n\t\tfactory1.createProduct();\n\t\t\n\t\t//客户端调用 Factory的 ConcreateFacotry2 实现类创建对象\n\t\tFactory factory2 = new ConcreateFacotry2();\n\t\tfactory2.createProduct();\n\t}\n}\n```","source":"_posts/设计模式/设计模式之抽象工厂模式.md","raw":"---\ntitle: 设计模式之抽象工厂模式\ndate: 2018-05-23 17:50:12\ntags:\n- 设计模式\ncategories:\n- 设计模式\n\n---\n\n#  设计模式之抽象工厂模式\n\n封装创建对象的细节，外部调用只需要关心自己想要什么和最终能得到什么结果，而不需要关心实现的过程。\n\n<!--more-->\n\n## 认识\n\n抽象工厂是同时创建**多个接口**(多个产品)的实现类对象，实现解耦合\n\n\n## 思考\n\n1. 抽象工厂模式能够处理更加复杂的对象的细节封装，可以对一个产品簇(多个接口)封装细节，对外部调用实现透明。而简单工厂模式和工厂方法模式都是对一个产品(一个接口)进行操作。\n2. 抽象工厂模式存在多个工厂实现类，可以结合简单工厂模式，根据type创建不同的抽象工厂实现类，进一步封装内部细节，进一步跟client端解耦合\n\n## 优缺点\n\n- 优点：\n  1. 分离了接口和实现\n  2. 封装了内部实现细节\n  3. 扩展新的工厂实现类容易，这需要再定义一个抽象工厂实现类\n- 缺点\n  1. 扩展新的产品类难，当新增加一个产品接口的时候，就需要同时修改所有的工厂实现类的源代码\n  2. 容易造成类层次复杂\n\n## 使用场景\n\n当工厂模式需要在工厂方法中操作多个产品(接口)的时候使用抽象工厂模式\n\n## UML图\n\n工厂需要操作多个接口\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-15/42597844-file_1489590399850_7ec7.png)\n\n## 代码实现\n\n```java\n//产品接口 A\npublic interface IProductA {\n\t  public void operation(); \n}\n//产品实现类A1\npublic class ConcreateProductA1 implements IProductA{\n\n\tpublic void operation() {\n\t\tSystem.out.println(\"创建产品A1\");\n\t}\n}\n//产品实现类A2\npublic class ConcreateProductA2 implements IProductA{\n\n\tpublic void operation() {\n\t\tSystem.out.println(\"创建产品2\");\n\t}\n}\n//产品接口B \npublic interface IProductB {\n\t  public void operation(); \n}\n//产品实现类B1\npublic class ConcreateProductB1 implements IProductB{\n\n\tpublic void operation() {\n\t\tSystem.out.println(\"创建产品B1\");\n\t}\n}\n//产品实现类B2\npublic class ConcreateProductB2 implements IProductB{\n\n\tpublic void operation() {\n\t\tSystem.out.println(\"创建产品B2\");\n\t}\n}\n//抽象工厂类 \npublic abstract class Factory {\n\t\n\t//定义抽象，具体实现延迟到子类中实现\n\tprotected abstract IProductA getProductA();\n\tprotected abstract IProductB getProductB();\n\t\n\t//提供方法供客户端调用\n\tpublic void createProduct(){\n\t\t//进行操作\n\t\tIProductA productA = this.getProductA();\n\t\tIProductB productB = this.getProductB();\n\t\t//进行操作\n\t}\n}\npublic class ConcreateFacotry1 extends Factory{\n\n\t//实现类中创建对应的productA的子类返回\n\t@Override\n\tprotected IProductA getProductA() {\n\t\treturn new ConcreateProductA1();\n\t}\n\n\t//实现类中创建对应的productB的子类返回\n\t@Override\n\tprotected IProductB getProductB() {\n\t\treturn new ConcreateProductB1();\n\t}\n}\npublic class ConcreateFacotry2 extends Factory{\n\n\t//实现类中创建对应的productA的子类返回\n\t@Override\n\tprotected IProductA getProductA() {\n\t\treturn new ConcreateProductA2();\n\t}\n\n\t//实现类中创建对应的productB的子类返回\n\t@Override\n\tprotected IProductB getProductB() {\n\t\treturn new ConcreateProductB2();\n\t}\n}\n//客户端调用\npublic class Client{\n\n\tpublic static void main(String[] args) {\n\t\t//客户端调用 Factory的 ConcreateFacotry1 实现类创建对象\n\t\tFactory factory1 = new ConcreateFacotry1();\n\t\tfactory1.createProduct();\n\t\t\n\t\t//客户端调用 Factory的 ConcreateFacotry2 实现类创建对象\n\t\tFactory factory2 = new ConcreateFacotry2();\n\t\tfactory2.createProduct();\n\t}\n}\n```","slug":"设计模式/设计模式之抽象工厂模式","published":1,"updated":"2018-09-12T03:03:21.837Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnjb008iwlkvtwe7lwt4"},{"title":"设计模式之策略模式","date":"2018-05-29T04:17:22.000Z","_content":"\n#  设计模式之策略模式\n\n策略模式属于对象的行为模式。其用意是针对一组算法，将每一个算法封装到具有共同接口的独立的类中，从而使得它们可以相互替换。策略模式使得算法可以在不影响到客户端的情况下发生变化。\n\n<!--more-->\n\n## 思考\n\n- 本质：**分离算法，选择实现**\n- **策略模式的重心**\n\n  策略模式的重心不是如何实现算法，而是如何组织、调用这些算法，从而让程序结构更灵活，具有更好的维护性和扩展性。\n\n- **算法的平等性**\n\n  策略模式一个很大的特点就是各个策略算法的平等性。对于一系列具体的策略算法，大家的地位是完全一样的，正因为这个平等性，才能实现算法之间可以相互替换。所有的策略算法在实现上也是相互独立的，相互之间是没有依赖的。**策略算法是相同行为的不同实现。**\n\n- **运行时策略的唯一性**\n\n  运行期间，**策略模式在每一个时刻只能使用一个具体的策略实现对象**，虽然可以动态地在不同的策略实现中切换，但是同时只能使用一个。\n\n- **公有的行为抽取到父类**\n\n  所有的具体策略类都有一些公有的行为。这时候，就应当把这些公有的行为放到共同的抽象策略角色Strategy类里面。当然这时候抽象策略角色必须要用Java抽象类实现，而不能使用接口。\n\n- **策略方法的选择**\n\n  - 在客户端，调用环境角色时，客户端选择具体策略传入环境角色。\n  - 客户端不管，由环境角色选择如容错机制\n\n    ```java\n    //容错机制\n    public void log(String msg){\n        //在上下文里面，自行实现对具体策略的选择\n        //优先选用策略：记录到数据库\n        LogStrategy strategy = new DbLog();\n        try{\n            strategy.log(msg);\n        }catch(Exception err){\n            //出错了，选择另一种策略\n            strategy = new FileLog();\n            strategy.log(msg);\n        }\n    }\t\n    ```\n\n## 使用场景\n\n通俗点说，当遇到使用大量if-else的场景后，条件分之执行的业务算法是**平等可相互替换的(实现功能接口)**,那么考虑使用策略模式。\n\n## 优缺点\n\n- 优点\n  1. 策略模式中所有的策略方法时平等的，可以避免大量的使用 if-else\n  2. 通过继承可以将公共代码转移到父类里面，避免代码重复\n- 缺点\n  1. 客户端必须知道所有的策略类，必须理解这些算法的区别，并自行决定使用哪一个策略类。\n  2. 当策略方法过多的时候，会生成大量的类，客户端使用复杂度上升。\n\n## UML图\n\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-20/56553601-file_1490025431315_63c2.png)\n\n- **环境(Context)角色：**持有一个Strategy的引用。\n- **抽象策略(Strategy)角色：**这是一个抽象角色，通常由一个接口或抽象类实现。定义所有策略实现的方法。\n- **具体策略(ConcreteStrategy)角色：**包装了相关的算法或行为。\n\n## 代码实现\n\n\n\n```java\n//环境角色\npublic class Context {\n    //持有一个具体策略的对象\n    private Strategy strategy;\n    /**\n     * 构造函数，传入一个具体策略对象\n     * @param strategy    具体策略对象\n     */\n    public Context(Strategy strategy){\n        this.strategy = strategy;\n    }\n    //策略方法\n    public void contextInterface(){\n\t\t//调用具体的策略方法\n        strategy.strategyInterface();\n    } \n}\n//抽象策略\npublic interface Strategy {\n    //策略方法\n    public void strategyInterface();\n}\npublic class ConcreteStrategyA implements Strategy {\n\n    @Override\n    public void strategyInterface() {\n        //相关的业务\n    }\n}\npublic class ConcreteStrategyB implements Strategy {\n\n    @Override\n    public void strategyInterface() {\n        //相关的业务\n    }\n}\n```\n\n使用场景\n\n　假设现在要设计一个贩卖各类书籍的电子商务网站的购物车系统。一个最简单的情况就是把所有货品的单价乘上数量，但是实际情况肯定比这要复杂。比如，本网站可能对所有的高级会员提供每本20%的促销折扣；对中级会员提供每本10%的促销折扣；对初级会员没有折扣。\n\n根据描述，折扣是根据以下的几个算法中的一个进行的：\n\n- 算法一：对初级会员没有折扣。\n- 算法二：对中级会员提供10%的促销折扣。\n- 算法三：对高级会员提供20%的促销折扣。\n- 使用策略模式来实现的结构图如下：\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-21/33851350-file_1490026363020_ed2.png)\n\n```java\npublic interface MemberStrategy {\n    /**\n     * 计算图书的价格\n     * @param booksPrice    图书的原价\n     * @return    计算出打折后的价格\n     */\n    public double calcPrice(double booksPrice);\n}\npublic class PrimaryMemberStrategy implements MemberStrategy {\n\n    @Override\n    public double calcPrice(double booksPrice) {\n        System.out.println(\"对于初级会员的没有折扣\");\n        return booksPrice;\n    }\n\n}\npublic class IntermediateMemberStrategy implements MemberStrategy {\n\n    @Override\n    public double calcPrice(double booksPrice) {\n        System.out.println(\"对于中级会员的折扣为10%\");\n        return booksPrice * 0.9;\n    }\n}\npublic class AdvancedMemberStrategy implements MemberStrategy {\n\n    @Override\n    public double calcPrice(double booksPrice) {\n        System.out.println(\"对于高级会员的折扣为20%\");\n        return booksPrice * 0.8;\n    }\n}\npublic class Price {\n    //持有一个具体的策略对象\n    private MemberStrategy strategy;\n    /**\n     * 构造函数，传入一个具体的策略对象\n     * @param strategy    具体的策略对象\n     */\n    public Price(MemberStrategy strategy){\n        this.strategy = strategy;\n    }\n    /**\n     * 计算图书的价格\n     * @param booksPrice    图书的原价\n     * @return    计算出打折后的价格\n     */\n    public double quote(double booksPrice){\n        return this.strategy.calcPrice(booksPrice);\n    }\n}\npublic class Client {\n\n    public static void main(String[] args) {\n        //选择并创建需要使用的策略对象\n        MemberStrategy strategy = new AdvancedMemberStrategy();\n        //创建环境\n        Price price = new Price(strategy);\n        //计算价格\n        double quote = price.quote(300);\n        System.out.println(\"图书的最终价格为：\" + quote);\n    }\n\n}\n```","source":"_posts/设计模式/设计模式之策略模式.md","raw":"---\ntitle: 设计模式之策略模式\ndate: 2018-05-29 12:17:22\ntags:\n- 设计模式\ncategories:\n- 设计模式\n\n---\n\n#  设计模式之策略模式\n\n策略模式属于对象的行为模式。其用意是针对一组算法，将每一个算法封装到具有共同接口的独立的类中，从而使得它们可以相互替换。策略模式使得算法可以在不影响到客户端的情况下发生变化。\n\n<!--more-->\n\n## 思考\n\n- 本质：**分离算法，选择实现**\n- **策略模式的重心**\n\n  策略模式的重心不是如何实现算法，而是如何组织、调用这些算法，从而让程序结构更灵活，具有更好的维护性和扩展性。\n\n- **算法的平等性**\n\n  策略模式一个很大的特点就是各个策略算法的平等性。对于一系列具体的策略算法，大家的地位是完全一样的，正因为这个平等性，才能实现算法之间可以相互替换。所有的策略算法在实现上也是相互独立的，相互之间是没有依赖的。**策略算法是相同行为的不同实现。**\n\n- **运行时策略的唯一性**\n\n  运行期间，**策略模式在每一个时刻只能使用一个具体的策略实现对象**，虽然可以动态地在不同的策略实现中切换，但是同时只能使用一个。\n\n- **公有的行为抽取到父类**\n\n  所有的具体策略类都有一些公有的行为。这时候，就应当把这些公有的行为放到共同的抽象策略角色Strategy类里面。当然这时候抽象策略角色必须要用Java抽象类实现，而不能使用接口。\n\n- **策略方法的选择**\n\n  - 在客户端，调用环境角色时，客户端选择具体策略传入环境角色。\n  - 客户端不管，由环境角色选择如容错机制\n\n    ```java\n    //容错机制\n    public void log(String msg){\n        //在上下文里面，自行实现对具体策略的选择\n        //优先选用策略：记录到数据库\n        LogStrategy strategy = new DbLog();\n        try{\n            strategy.log(msg);\n        }catch(Exception err){\n            //出错了，选择另一种策略\n            strategy = new FileLog();\n            strategy.log(msg);\n        }\n    }\t\n    ```\n\n## 使用场景\n\n通俗点说，当遇到使用大量if-else的场景后，条件分之执行的业务算法是**平等可相互替换的(实现功能接口)**,那么考虑使用策略模式。\n\n## 优缺点\n\n- 优点\n  1. 策略模式中所有的策略方法时平等的，可以避免大量的使用 if-else\n  2. 通过继承可以将公共代码转移到父类里面，避免代码重复\n- 缺点\n  1. 客户端必须知道所有的策略类，必须理解这些算法的区别，并自行决定使用哪一个策略类。\n  2. 当策略方法过多的时候，会生成大量的类，客户端使用复杂度上升。\n\n## UML图\n\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-20/56553601-file_1490025431315_63c2.png)\n\n- **环境(Context)角色：**持有一个Strategy的引用。\n- **抽象策略(Strategy)角色：**这是一个抽象角色，通常由一个接口或抽象类实现。定义所有策略实现的方法。\n- **具体策略(ConcreteStrategy)角色：**包装了相关的算法或行为。\n\n## 代码实现\n\n\n\n```java\n//环境角色\npublic class Context {\n    //持有一个具体策略的对象\n    private Strategy strategy;\n    /**\n     * 构造函数，传入一个具体策略对象\n     * @param strategy    具体策略对象\n     */\n    public Context(Strategy strategy){\n        this.strategy = strategy;\n    }\n    //策略方法\n    public void contextInterface(){\n\t\t//调用具体的策略方法\n        strategy.strategyInterface();\n    } \n}\n//抽象策略\npublic interface Strategy {\n    //策略方法\n    public void strategyInterface();\n}\npublic class ConcreteStrategyA implements Strategy {\n\n    @Override\n    public void strategyInterface() {\n        //相关的业务\n    }\n}\npublic class ConcreteStrategyB implements Strategy {\n\n    @Override\n    public void strategyInterface() {\n        //相关的业务\n    }\n}\n```\n\n使用场景\n\n　假设现在要设计一个贩卖各类书籍的电子商务网站的购物车系统。一个最简单的情况就是把所有货品的单价乘上数量，但是实际情况肯定比这要复杂。比如，本网站可能对所有的高级会员提供每本20%的促销折扣；对中级会员提供每本10%的促销折扣；对初级会员没有折扣。\n\n根据描述，折扣是根据以下的几个算法中的一个进行的：\n\n- 算法一：对初级会员没有折扣。\n- 算法二：对中级会员提供10%的促销折扣。\n- 算法三：对高级会员提供20%的促销折扣。\n- 使用策略模式来实现的结构图如下：\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-21/33851350-file_1490026363020_ed2.png)\n\n```java\npublic interface MemberStrategy {\n    /**\n     * 计算图书的价格\n     * @param booksPrice    图书的原价\n     * @return    计算出打折后的价格\n     */\n    public double calcPrice(double booksPrice);\n}\npublic class PrimaryMemberStrategy implements MemberStrategy {\n\n    @Override\n    public double calcPrice(double booksPrice) {\n        System.out.println(\"对于初级会员的没有折扣\");\n        return booksPrice;\n    }\n\n}\npublic class IntermediateMemberStrategy implements MemberStrategy {\n\n    @Override\n    public double calcPrice(double booksPrice) {\n        System.out.println(\"对于中级会员的折扣为10%\");\n        return booksPrice * 0.9;\n    }\n}\npublic class AdvancedMemberStrategy implements MemberStrategy {\n\n    @Override\n    public double calcPrice(double booksPrice) {\n        System.out.println(\"对于高级会员的折扣为20%\");\n        return booksPrice * 0.8;\n    }\n}\npublic class Price {\n    //持有一个具体的策略对象\n    private MemberStrategy strategy;\n    /**\n     * 构造函数，传入一个具体的策略对象\n     * @param strategy    具体的策略对象\n     */\n    public Price(MemberStrategy strategy){\n        this.strategy = strategy;\n    }\n    /**\n     * 计算图书的价格\n     * @param booksPrice    图书的原价\n     * @return    计算出打折后的价格\n     */\n    public double quote(double booksPrice){\n        return this.strategy.calcPrice(booksPrice);\n    }\n}\npublic class Client {\n\n    public static void main(String[] args) {\n        //选择并创建需要使用的策略对象\n        MemberStrategy strategy = new AdvancedMemberStrategy();\n        //创建环境\n        Price price = new Price(strategy);\n        //计算价格\n        double quote = price.quote(300);\n        System.out.println(\"图书的最终价格为：\" + quote);\n    }\n\n}\n```","slug":"设计模式/设计模式之策略模式","published":1,"updated":"2018-09-12T03:03:21.838Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnjd008jwlkvq1jdt4ie"},{"title":"设计模式之状态模式","date":"2018-06-04T07:45:21.000Z","_content":"\n#  设计模式之状态模式\n\n状态模式将对象的行为抽象为接口，对象不同状态对应的行为封装到具体的状态实现类中，实现了当状态改变时同时改变了它的行为。状态模式允许一个对象基于内部状态而拥有不同的行为\n\n<!--more-->\n\n## 思考\n\n状态模式重在强调对象内部状态的变化改变对象的行为，策略模式重在外部对策略的选择，策略的选择由外部条件决定， 也就是说[算法](http://lib.csdn.net/base/datastructure)的动态的切换。\n\n状态模式是让各个状态对象自己知道其下一个处理的对象是谁，责任链模式中的各个对象并不指定其下一个处理的对象到底是谁，只有在客户端才设定。\n\n## 使用场景\n\n- 使用了大量 if else语句来判断对象状态，并且每个状态对应的操作可以抽象。\n- 对象的行为依赖于它的状态（属性）并且可以根据它的状态改变而改变它的相关行为。 \n\n## 优缺点\n\n- 优点\n\n  1. 将if else判断状态的逻辑封装到了各个子状态中\n  2. 将状态的变换放到了各个子状态中\n\n- 缺点\n\n  1.  状态模式的使用必然会增加系统类和对象的个数\n  2.  状态模式的结构与实现都较为复杂，如果使用不当将导致程序结构和代码的混乱\n\n  \n\n## UML图\n\n\n\n![](http://omdq6di7v.bkt.clouddn.com/18-6-4/90791310.jpg)\n\n**环境类**（Context）:  定义客户感兴趣的接口。维护一个ConcreteState子类的实例，这个实例定义当前状态。\n\n**抽象状态类**（State）:  将状态所对应的各个行为抽象为一个接口 。 \n\n**具体状态类**（ConcreteState）: 状态实现类，提供接口中的各个行为在该状态下的具体实现。\n\n## 代码实现 \n\n抽象状态接口，将订单的各种操作行为抽象到状态接口中，具体行为实现由状态实现类提供\n\n```java\npublic interface State {\n    //取消\n    void cancel(Order order);\n    //支付\n    void pay(Order order);\n    //发货\n    void send(Order order);\n}\n\n```\n\nOrder类，相当于UML图中的context，创建订单需要指定订单的订单号和状态，初始状态为 NomalState，当操作订单行为的时候，使用状态实现类进行调用，每个状态对应的订单行为由各个状态实现类提供\n\n```java\n@Data\npublic class Order {\n    //订单号\n    private String orderNo;\n    //当前状态\n    private State state;\n\n    //默认订单为正常状态\n    public Order(String orderNo) {\n        this(orderNo,new NormalState());\n    }\n\n    public Order(String orderNo,State state) {\n        this.orderNo = orderNo;\n        this.state = state;\n    }\n    //使用内部状态进行取消\n    void cancel() {\n        state.cancel(this);\n    }\n    //使用内部状态进行支付\n    void pay() {\n        state.pay(this);\n    }\n    //使用内部状态进行发货\n    void send() {\n        state.send(this);\n    }\n}\n```\n\n正常状态可以被取消和支付，并负责将订单状态修改为对应的取消状态和已支付状态\n\n```java\n/**\n * 正常状态\n **/\npublic class NormalState implements State{\n    @Override\n    public void cancel(Order order) {\n        System.out.println(String.format(\"orderNo: %s 被取消了\",order.getOrderNo()));\n        //将当前订单设置为取消状态\n        order.setState(new CancelState());\n    }\n\n    @Override\n    public void pay(Order order) {\n        System.out.println(String.format(\"orderNo: %s 支付完成\",order.getOrderNo()));\n        //将当前订单设置为取消状态\n        order.setState(new PaidState());\n    }\n\n    @Override\n    public void send(Order order) {\n        System.out.println(String.format(\"orderNo: %s 未支付，不允许发货\",order.getOrderNo()));\n    }\n}\n```\n\n取消状态不允许再对订单进行任何操作\n\n```java\n/**\n * 取消状态\n **/\npublic class CancelState implements State{\n\n    @Override\n    public void cancel(Order order) {\n        System.out.println(String.format(\"orderNo: %s 已被取消了\",order.getOrderNo()));\n    }\n\n    @Override\n    public void pay(Order order) {\n        System.out.println(String.format(\"orderNo: %s 已被取消了\",order.getOrderNo()));\n    }\n\n    @Override\n    public void send(Order order) {\n        System.out.println(String.format(\"orderNo: %s 已被取消了\",order.getOrderNo()));\n    }\n}\n```\n\n支付状态可以被取消和发货，并负责将订单状态修改为已取消和已发货\n\n```java\n/**\n * 支付状态\n **/\npublic class PaidState implements State{\n\n    @Override\n    public void cancel(Order order) {\n        System.out.println(String.format(\"orderNo: %s 被取消了，退款会在7天内进行\",order.getOrderNo()));\n        //将当前订单设置为取消状态\n        order.setState(new CancelState());\n    }\n\n    @Override\n    public void pay(Order order) {\n        System.out.println(String.format(\"orderNo: %s 已支付了，不需要再支付\",order.getOrderNo()));\n    }\n\n    @Override\n    public void send(Order order) {\n        System.out.println(String.format(\"orderNo: %s 发货了,请注意收货\",order.getOrderNo()));\n        //将当前订单设置为取消状态\n        order.setState(new SendState());\n    }\n}\n```\n\n发货状态的订单不允许进行其他操作\n\n```java\n/**\n * 发货状态状态\n **/\npublic class SendState implements State{\n\n    @Override\n    public void cancel(Order order) {\n        System.out.println(String.format(\"orderNo: %s 已经发货，不允许取消\",order.getOrderNo()));\n    }\n\n    @Override\n    public void pay(Order order) {\n        System.out.println(String.format(\"orderNo: %s 已经发货了，不允许支付\",order.getOrderNo()));\n    }\n\n    @Override\n    public void send(Order order) {\n        System.out.println(String.format(\"orderNo: %s 已发货了\",order.getOrderNo()));\n    }\n}\n```","source":"_posts/设计模式/设计模式之状态模式.md","raw":"---\ntitle: 设计模式之状态模式\ndate: 2018-06-04 15:45:21\ntags:\n- 设计模式\ncategories:\n- 设计模式\n\n---\n\n#  设计模式之状态模式\n\n状态模式将对象的行为抽象为接口，对象不同状态对应的行为封装到具体的状态实现类中，实现了当状态改变时同时改变了它的行为。状态模式允许一个对象基于内部状态而拥有不同的行为\n\n<!--more-->\n\n## 思考\n\n状态模式重在强调对象内部状态的变化改变对象的行为，策略模式重在外部对策略的选择，策略的选择由外部条件决定， 也就是说[算法](http://lib.csdn.net/base/datastructure)的动态的切换。\n\n状态模式是让各个状态对象自己知道其下一个处理的对象是谁，责任链模式中的各个对象并不指定其下一个处理的对象到底是谁，只有在客户端才设定。\n\n## 使用场景\n\n- 使用了大量 if else语句来判断对象状态，并且每个状态对应的操作可以抽象。\n- 对象的行为依赖于它的状态（属性）并且可以根据它的状态改变而改变它的相关行为。 \n\n## 优缺点\n\n- 优点\n\n  1. 将if else判断状态的逻辑封装到了各个子状态中\n  2. 将状态的变换放到了各个子状态中\n\n- 缺点\n\n  1.  状态模式的使用必然会增加系统类和对象的个数\n  2.  状态模式的结构与实现都较为复杂，如果使用不当将导致程序结构和代码的混乱\n\n  \n\n## UML图\n\n\n\n![](http://omdq6di7v.bkt.clouddn.com/18-6-4/90791310.jpg)\n\n**环境类**（Context）:  定义客户感兴趣的接口。维护一个ConcreteState子类的实例，这个实例定义当前状态。\n\n**抽象状态类**（State）:  将状态所对应的各个行为抽象为一个接口 。 \n\n**具体状态类**（ConcreteState）: 状态实现类，提供接口中的各个行为在该状态下的具体实现。\n\n## 代码实现 \n\n抽象状态接口，将订单的各种操作行为抽象到状态接口中，具体行为实现由状态实现类提供\n\n```java\npublic interface State {\n    //取消\n    void cancel(Order order);\n    //支付\n    void pay(Order order);\n    //发货\n    void send(Order order);\n}\n\n```\n\nOrder类，相当于UML图中的context，创建订单需要指定订单的订单号和状态，初始状态为 NomalState，当操作订单行为的时候，使用状态实现类进行调用，每个状态对应的订单行为由各个状态实现类提供\n\n```java\n@Data\npublic class Order {\n    //订单号\n    private String orderNo;\n    //当前状态\n    private State state;\n\n    //默认订单为正常状态\n    public Order(String orderNo) {\n        this(orderNo,new NormalState());\n    }\n\n    public Order(String orderNo,State state) {\n        this.orderNo = orderNo;\n        this.state = state;\n    }\n    //使用内部状态进行取消\n    void cancel() {\n        state.cancel(this);\n    }\n    //使用内部状态进行支付\n    void pay() {\n        state.pay(this);\n    }\n    //使用内部状态进行发货\n    void send() {\n        state.send(this);\n    }\n}\n```\n\n正常状态可以被取消和支付，并负责将订单状态修改为对应的取消状态和已支付状态\n\n```java\n/**\n * 正常状态\n **/\npublic class NormalState implements State{\n    @Override\n    public void cancel(Order order) {\n        System.out.println(String.format(\"orderNo: %s 被取消了\",order.getOrderNo()));\n        //将当前订单设置为取消状态\n        order.setState(new CancelState());\n    }\n\n    @Override\n    public void pay(Order order) {\n        System.out.println(String.format(\"orderNo: %s 支付完成\",order.getOrderNo()));\n        //将当前订单设置为取消状态\n        order.setState(new PaidState());\n    }\n\n    @Override\n    public void send(Order order) {\n        System.out.println(String.format(\"orderNo: %s 未支付，不允许发货\",order.getOrderNo()));\n    }\n}\n```\n\n取消状态不允许再对订单进行任何操作\n\n```java\n/**\n * 取消状态\n **/\npublic class CancelState implements State{\n\n    @Override\n    public void cancel(Order order) {\n        System.out.println(String.format(\"orderNo: %s 已被取消了\",order.getOrderNo()));\n    }\n\n    @Override\n    public void pay(Order order) {\n        System.out.println(String.format(\"orderNo: %s 已被取消了\",order.getOrderNo()));\n    }\n\n    @Override\n    public void send(Order order) {\n        System.out.println(String.format(\"orderNo: %s 已被取消了\",order.getOrderNo()));\n    }\n}\n```\n\n支付状态可以被取消和发货，并负责将订单状态修改为已取消和已发货\n\n```java\n/**\n * 支付状态\n **/\npublic class PaidState implements State{\n\n    @Override\n    public void cancel(Order order) {\n        System.out.println(String.format(\"orderNo: %s 被取消了，退款会在7天内进行\",order.getOrderNo()));\n        //将当前订单设置为取消状态\n        order.setState(new CancelState());\n    }\n\n    @Override\n    public void pay(Order order) {\n        System.out.println(String.format(\"orderNo: %s 已支付了，不需要再支付\",order.getOrderNo()));\n    }\n\n    @Override\n    public void send(Order order) {\n        System.out.println(String.format(\"orderNo: %s 发货了,请注意收货\",order.getOrderNo()));\n        //将当前订单设置为取消状态\n        order.setState(new SendState());\n    }\n}\n```\n\n发货状态的订单不允许进行其他操作\n\n```java\n/**\n * 发货状态状态\n **/\npublic class SendState implements State{\n\n    @Override\n    public void cancel(Order order) {\n        System.out.println(String.format(\"orderNo: %s 已经发货，不允许取消\",order.getOrderNo()));\n    }\n\n    @Override\n    public void pay(Order order) {\n        System.out.println(String.format(\"orderNo: %s 已经发货了，不允许支付\",order.getOrderNo()));\n    }\n\n    @Override\n    public void send(Order order) {\n        System.out.println(String.format(\"orderNo: %s 已发货了\",order.getOrderNo()));\n    }\n}\n```","slug":"设计模式/设计模式之状态模式","published":1,"updated":"2018-09-12T03:03:21.838Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnjf008lwlkvel9mvpjr"},{"title":"设计模式之装饰模式","date":"2018-05-24T09:23:18.000Z","_content":"\n#  设计模式之装饰模式\n\n通过装饰模式可以动态的扩展对象功能。可以在对象执行完相关方法后再执行包装在外面的方法。\n\n<!--more-->\n\n## 认识\n\n透明式装饰模式：装饰对象和被装饰对象实现完全相同的接口，或者装饰对象完全继承被装饰对象，装饰对象没有定义额外的方法实现。\n\n半透明装饰模式：装饰对象在实现被装饰对象的接口或者继承被装饰对象之外，还有单独额外的自定义方法。这时装饰角色实际上已经成为一个适配器角色。**适配器类的接口会比被装饰的目标类接口宽。**\n\n## 思考\n\n- 灵活的为对象添加额外的功能，实现数量、顺序的可动态配置，搭配工厂模式、策略模式，实现灵活组合实现复杂功能。\n- **按照流程拆分功能，将功能面向对象设计，垂直、可选、有序的组合功能**，最先执行的最先被包装\n- AOP的实现\n- 本质：对象动态组合\n\n## 使用场景\n\n- 在不影响其他对象的情况下，以**动态、透明的方式给对象添加职责**\n- 如果不适合使用子类进行扩展功能的时候，使用装饰模式，装饰模式使用**对象组合**方式，避免由于功能复杂需要创建太多子类的问题\n\n## 优缺点\n\n- 优点\n  1. 装饰模式与继承关系的目的都是要扩展对象的功能，装饰模式可以动态的配置关系，而继承关系是静态的，它在系统运行前就决定了，因此装饰模式可以提供比继承更多的灵活性。\n  2. 通过使用不同的具体装饰类以及这些装饰类的排列组合，设计师可以创造出很多不同行为的组合。\n\n\n## UML图\n\n装饰对象和被装饰对象实现同一个接口(或装饰对象继承被装饰对象)，装饰接口中持有一个被装饰对象进行操作\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-20/80820607-file_1490021870955_11e42.png)\n\n- **抽象构件(Component)角色：**给出一个抽象接口，以规范准备接收附加责任的对象。\n- **具体构件(ConcreteComponent)角色：**定义一个将要接收附加责任的类。\n- **装饰(Decorator)角色：**持有一个构件(Component)对象的实例，**实现Component接口**\n- **具体装饰(ConcreteDecorator)角色：** 对持有的Component对象实例进行进一步操作\n\n## 代码实现\n\n装饰对象通过构造函数持有一个被装饰对象，装饰对象和被装饰对象实现同一个接口，或者装饰对象继承被装饰对象，在装饰对象中调用方法时先调用被装饰对象中的方法，然后在执行装饰对象的相关业务代码，相当于对被装饰对象进行一次包装。\n\n由于被装饰对象和装饰对象实现同一个接口，所以在装饰对象的实现类中可以对被装饰对象再次进行包装。这样层级调用，先调用被装饰对象中的方法，然后一层层往上调用。\n\n```java\n//接口\npublic interface Component {    \n    public void sampleOperation();\n}\n//被装饰对象\npublic class ConcreteComponent implements Component {\n    @Override\n    public void sampleOperation() {\n        // 写相关的业务代码\n    }\n}\n//装饰对象 实现被装饰对象实现的接口\npublic class Decorator implements Component{\n    // 持有一个被装饰对象\n    private Component component;\n   \t//通过构造传入\n    public Decorator(Component component){\n        this.component = component;\n    }\n    @Override\n    public void sampleOperation() {\n        // 委派给构件\n        component.sampleOperation();\n    }   \n}\n//装饰对象实现类\npublic class ConcreteDecoratorA extends Decorator {\n\t\n    public ConcreteDecoratorA(Component component) {\n        super(component);\n    }\n    @Override\n    public void sampleOperation() {\n        //先调用被包装对象执行方法\n　　　　　super.sampleOperation();\n        // 写相关的业务代码\n    }\n}\n//装饰对象实现类\npublic class ConcreteDecoratorB extends Decorator {\n\n    public ConcreteDecoratorB(Component component) {\n        super(component);\n    }\n    @Override\n    public void sampleOperation() {\n        //先调用被包装对象执行方法\n　　　　  super.sampleOperation();\n        // 写相关的业务代码\n    }\n}\n```\n\n## 源码分析\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-20/63766348-file_1490023113105_103da.png)\n\n●　　**抽象构件(Component)角色：**由InputStream扮演。这是一个抽象类，为各种子类型提供统一的接口。\n\n●　　**具体构件(ConcreteComponent)角色：**ByteArrayInputStream、FileInputStream、PipedInputStream、StringBufferInputStream直接继承了InputStream，扮演具体构件。它们实现了抽象构件角色所规定的接口。\n\n●　　**抽象装饰(Decorator)角色：**由FilterInputStream扮演。它实现了InputStream所规定的接口。\n\n●　　**具体装饰(ConcreteDecorator)角色：**由几个类扮演，分别是BufferedInputStream、DataInputStream以及两个不常用到的类LineNumberInputStream、PushbackInputStream。","source":"_posts/设计模式/设计模式之装饰模式.md","raw":"---\ntitle: 设计模式之装饰模式\ndate: 2018-05-24 17:23:18\ntags:\n- 设计模式\ncategories:\n- 设计模式\n\n---\n\n#  设计模式之装饰模式\n\n通过装饰模式可以动态的扩展对象功能。可以在对象执行完相关方法后再执行包装在外面的方法。\n\n<!--more-->\n\n## 认识\n\n透明式装饰模式：装饰对象和被装饰对象实现完全相同的接口，或者装饰对象完全继承被装饰对象，装饰对象没有定义额外的方法实现。\n\n半透明装饰模式：装饰对象在实现被装饰对象的接口或者继承被装饰对象之外，还有单独额外的自定义方法。这时装饰角色实际上已经成为一个适配器角色。**适配器类的接口会比被装饰的目标类接口宽。**\n\n## 思考\n\n- 灵活的为对象添加额外的功能，实现数量、顺序的可动态配置，搭配工厂模式、策略模式，实现灵活组合实现复杂功能。\n- **按照流程拆分功能，将功能面向对象设计，垂直、可选、有序的组合功能**，最先执行的最先被包装\n- AOP的实现\n- 本质：对象动态组合\n\n## 使用场景\n\n- 在不影响其他对象的情况下，以**动态、透明的方式给对象添加职责**\n- 如果不适合使用子类进行扩展功能的时候，使用装饰模式，装饰模式使用**对象组合**方式，避免由于功能复杂需要创建太多子类的问题\n\n## 优缺点\n\n- 优点\n  1. 装饰模式与继承关系的目的都是要扩展对象的功能，装饰模式可以动态的配置关系，而继承关系是静态的，它在系统运行前就决定了，因此装饰模式可以提供比继承更多的灵活性。\n  2. 通过使用不同的具体装饰类以及这些装饰类的排列组合，设计师可以创造出很多不同行为的组合。\n\n\n## UML图\n\n装饰对象和被装饰对象实现同一个接口(或装饰对象继承被装饰对象)，装饰接口中持有一个被装饰对象进行操作\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-20/80820607-file_1490021870955_11e42.png)\n\n- **抽象构件(Component)角色：**给出一个抽象接口，以规范准备接收附加责任的对象。\n- **具体构件(ConcreteComponent)角色：**定义一个将要接收附加责任的类。\n- **装饰(Decorator)角色：**持有一个构件(Component)对象的实例，**实现Component接口**\n- **具体装饰(ConcreteDecorator)角色：** 对持有的Component对象实例进行进一步操作\n\n## 代码实现\n\n装饰对象通过构造函数持有一个被装饰对象，装饰对象和被装饰对象实现同一个接口，或者装饰对象继承被装饰对象，在装饰对象中调用方法时先调用被装饰对象中的方法，然后在执行装饰对象的相关业务代码，相当于对被装饰对象进行一次包装。\n\n由于被装饰对象和装饰对象实现同一个接口，所以在装饰对象的实现类中可以对被装饰对象再次进行包装。这样层级调用，先调用被装饰对象中的方法，然后一层层往上调用。\n\n```java\n//接口\npublic interface Component {    \n    public void sampleOperation();\n}\n//被装饰对象\npublic class ConcreteComponent implements Component {\n    @Override\n    public void sampleOperation() {\n        // 写相关的业务代码\n    }\n}\n//装饰对象 实现被装饰对象实现的接口\npublic class Decorator implements Component{\n    // 持有一个被装饰对象\n    private Component component;\n   \t//通过构造传入\n    public Decorator(Component component){\n        this.component = component;\n    }\n    @Override\n    public void sampleOperation() {\n        // 委派给构件\n        component.sampleOperation();\n    }   \n}\n//装饰对象实现类\npublic class ConcreteDecoratorA extends Decorator {\n\t\n    public ConcreteDecoratorA(Component component) {\n        super(component);\n    }\n    @Override\n    public void sampleOperation() {\n        //先调用被包装对象执行方法\n　　　　　super.sampleOperation();\n        // 写相关的业务代码\n    }\n}\n//装饰对象实现类\npublic class ConcreteDecoratorB extends Decorator {\n\n    public ConcreteDecoratorB(Component component) {\n        super(component);\n    }\n    @Override\n    public void sampleOperation() {\n        //先调用被包装对象执行方法\n　　　　  super.sampleOperation();\n        // 写相关的业务代码\n    }\n}\n```\n\n## 源码分析\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-20/63766348-file_1490023113105_103da.png)\n\n●　　**抽象构件(Component)角色：**由InputStream扮演。这是一个抽象类，为各种子类型提供统一的接口。\n\n●　　**具体构件(ConcreteComponent)角色：**ByteArrayInputStream、FileInputStream、PipedInputStream、StringBufferInputStream直接继承了InputStream，扮演具体构件。它们实现了抽象构件角色所规定的接口。\n\n●　　**抽象装饰(Decorator)角色：**由FilterInputStream扮演。它实现了InputStream所规定的接口。\n\n●　　**具体装饰(ConcreteDecorator)角色：**由几个类扮演，分别是BufferedInputStream、DataInputStream以及两个不常用到的类LineNumberInputStream、PushbackInputStream。","slug":"设计模式/设计模式之装饰模式","published":1,"updated":"2018-09-12T03:03:21.839Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnjg008nwlkvdbz825nb"},{"title":"设计模式之观察者模式","date":"2018-05-29T06:15:21.000Z","_content":"\n#  设计模式之观察者模式\n\n观察者模式是对象的行为模式，定义了一种一对多的依赖关系，多个观察者对象同时监听一个主题对象，当主题对象状态发生改变时，会通知所有观察者对象更新。是一种发布-订阅模式。\n\n<!--more-->\n\n## 思考\n\n在观察者模式中，观察者和目标是单向依赖的，只有观察者依赖目标，观察者只能被动的去等到目标的通知，等待目标传值给它。\n\n- 推模型是假定目标知道观察者需要的数据；而拉模型是目标不知道观察者具体需要什么数据，没有办法的情况下，干脆把自身传递给观察者，让观察者自己去按需要取值。\n- 推模型可能会使得观察者对象难以复用，因为观察者的update()方法是按需要定义的参数，可能无法兼顾没有考虑到的使用情况。这就意味着出现新情况的时候，就可能提供新的update()方法，或者是干脆重新实现观察者；而拉模型就不会造成这样的情况，因为拉模型下，update()方法的参数是目标对象本身，观察者可以获取目标对象上的任何非私有属性。\n- 实质：触发联动\n\n## 使用场景\n\n1. 当一个对象的改变需要通知其他对象时选用观察者模式\n2. 当一个抽象模型有两个方面，一个方面的操作依赖另一个方面的状态变化时选用观察者模式\n\n## 优缺点\n\n- 优点\n  1. 实现了观察者和目标之间的解耦合\n  2. 支持广播通知\n\n- 缺点\n\n\n## UML图\n\n定义一个目标抽象类，在抽象类中维护一个观察者的list，通过准备阶段创建观察者add到list中，提供添加和删除观察者的方法，提供通知观察者的方法。\n\n定义一个目标具体实现类，在该实现类中如果发生变化调用notifyObserves通知所有观察者\n\n定义一个观察者接口和一系列观察者实现类对象，提供方法供目标回调\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-23/57916143-file_1490278389038_14d10.png)\n\n●　　**目标(Subject)角色：**抽象主题角色把所有对观察者对象的引用保存在一个聚集（比如ArrayList对象）里，每个主题都可以有任何数量的观察者。抽象主题提供一个接口，可以增加和删除观察者对象，提供目标更新时通知观察者的方法。\n\n　　●　　**目标实现(ConcreteSubject)角色：**具体目标实现，用来维护目标状态，当目标状态发生改变时通知已注册的所有观察者。\n\n　　●　　**抽象观察者(Observer)角色：**为所有的具体观察者定义一个接口，定义目标对象通知观察者时的回调方法。\n\n　　●　　**具体观察者(ConcreteObserver)角色：**存储与主题的状态自恰的状态。具体观察者接收通知进行后续处理。\n\n- 准备阶段\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-23/68981815-file_1490278727523_108ed.png)\n\n- 运行阶段\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-23/8957403-file_1490278682033_156ce.png)\n\n## 代码实现 \n\n### 推模型\n\n目标回调观察者时传入具体的值\n\n```java\n//目标抽象类\npublic abstract class Subject {\n\n\t// 注册的观察者列表\n\tprivate List<Observer> observerList = new ArrayList<Observer>();\n\n\t// 注册观察者\n\tpublic void attach(Observer observer) {\n\t\tobserverList.add(observer);\n\t}\n\n\t// 移除观察者\n\tpublic void detach(Observer observer) {\n\t\tobserverList.remove(observer);\n\t}\n\n\t// 定义通知方法\n\tprotected void nodifyObservers(String newState) {\n\t\tfor(Observer observer:observerList){\n\t\t\tobserver.update(newState);\n\t\t}\n\t}\n}\n//目标具体实现类\npublic class ConcreteSubject extends Subject {\n\tprivate String state;\n\tpublic String getState() {\n\t\treturn state;\n\t}\n\t//目标更新时通知所有观察者\n\tpublic void change(String newState) {\n\t\tstate = newState;\n\t\tSystem.out.println(\"主题状态为：\" + state);\n\t\t// 状态发生改变，通知各个观察者\n\t\tthis.nodifyObservers(state);\n\t}\n\n}\n//观察者接口\npublic interface Observer {\n\n\t//提供方法供目标回调通知并传入值\n\tpublic void update(String state);\n}\n//观察者具体实现类\npublic class ConcreteObserver implements Observer {\n\t\n    //观察者的状态\n    private String observerState;\n    \n    //通过目标回调获取目标传递给回来的值\n    public void update(String state) {\n        /**\n         * 更新观察者的状态，使其与目标的状态保持一致\n         */\n        observerState = state;\n        System.out.println(\"状态为：\"+observerState);\n    }\n}\n//客户端调用\npublic class Client {\n\n\tpublic static void main(String[] args) {\n\t\t//创建目标\n\t\tConcreteSubject subject = new ConcreteSubject();\n\t\t//创建观察者\n\t\tObserver observer1 = new ConcreteObserver();\n\t\tObserver observer2 = new ConcreteObserver();\n\t\t//注册观察者\n\t\tsubject.attach(observer1);\n\t\tsubject.attach(observer2);\n\t\t//更新目标并通知所有观察者\n\t\tsubject.change(\"new\");\n\t\tsubject.detach(observer2);\n\t\tsubject.change(\"again\");\n\t}\n}\n```\n\n### 拉模型\n\n目标回调观察者时将目标对象传递给观察者\n\n```java\n//目标抽象类\npublic abstract class Subject {\n\n\t// 注册的观察者列表\n\tprivate List<Observer> observerList = new ArrayList<Observer>();\n\n\t// 注册观察者\n\tpublic void attach(Observer observer) {\n\t\tobserverList.add(observer);\n\t}\n\n\t// 移除观察者\n\tpublic void detach(Observer observer) {\n\t\tobserverList.remove(observer);\n\t}\n\n\t// 定义通知方法，直接将目标对象回调传递给观察者\n\tprotected void nodifyObservers() {\n\t\tfor(Observer observer:observerList){\n\t\t\tobserver.update(this);\n\t\t}\n\t}\n}\n//目标具体实现类\npublic class ConcreteSubject extends Subject {\n\t\n\tprivate String state;\n\n\tpublic String getState() {\n\t\treturn state;\n\t}\n\n\t//目标更新时通知所有观察者\n\tpublic void change(String newState) {\n\t\tstate = newState;\n\t\tSystem.out.println(\"主题状态为：\" + state);\n\t\t//将目标对象通过回调传递给每个观察者\n\t\tthis.nodifyObservers();\n\t}\n}\n//观察者接口\npublic interface Observer {\n\n\t//提供方法供目标回调通知并传入值\n\tpublic void update(Subject subject);\n}\n//观察者具体实现类\npublic class ConcreteObserver implements Observer {\n\t\n    //观察者的状态\n    private String observerState;\n\n    //通过目标回调获取目标对象\n\t@Override\n\tpublic void update(Subject subject) {\n\t\t//通过目标对象的引用获取目标对象中的值\n\t\tobserverState = ((ConcreteSubject)subject).getState();\n\t\tSystem.out.println(\"状态为：\"+observerState);\n\t}\n}\n//客户端调用\npublic class Client {\n\n\tpublic static void main(String[] args) {\n\t\t//创建目标\n\t\tConcreteSubject subject = new ConcreteSubject();\n\t\t//创建观察者\n\t\tObserver observer1 = new ConcreteObserver();\n\t\tObserver observer2 = new ConcreteObserver();\n\t\t//注册观察者\n\t\tsubject.attach(observer1);\n\t\tsubject.attach(observer2);\n\t\t//更新目标并通知所有观察者\n\t\tsubject.change(\"new\");\n\t\tsubject.detach(observer2);\n\t\tsubject.change(\"again\");\n\t}\n}\n```\n\n### jdk提供的接口\n\n```java\n//目标对象继承Observable接口\npublic class Watched extends Observable接口{\n    \n    private String data = \"\";\n    \n    public String getData() {\n        return data;\n    }\n\n    public void setData(String data) {\n   \n        if(!this.data.equals(data)){\n            this.data = data;\n            setChanged();\n        }\n        notifyObservers();\n    }\n}\n//观察者实现Observer接口\npublic class Watcher implements Observer{\n    \n    public Watcher(Observable o){\n        o.addObserver(this);\n    }\n    \n    @Override\n    public void update(Observable o, Object arg) {  \n        System.out.println(\"状态发生改变：\" + ((Watched)o).getData());\n    }\n}\npublic class Client {\n    public static void main(String[] args) { \n        //创建被观察者对象\n        Watched watched = new Watched();\n        //创建观察者对象，并将被观察者对象登记\n        Observer watcher = new Watcher(watched);\n        //给被观察者状态赋值\n        watched.setData(\"start\");\n        watched.setData(\"run\");\n        watched.setData(\"stop\");\n    }\n}\n```","source":"_posts/设计模式/设计模式之观察者模式.md","raw":"---\ntitle: 设计模式之观察者模式\ndate: 2018-05-29 14:15:21\ntags:\n- 设计模式\ncategories:\n- 设计模式\n\n---\n\n#  设计模式之观察者模式\n\n观察者模式是对象的行为模式，定义了一种一对多的依赖关系，多个观察者对象同时监听一个主题对象，当主题对象状态发生改变时，会通知所有观察者对象更新。是一种发布-订阅模式。\n\n<!--more-->\n\n## 思考\n\n在观察者模式中，观察者和目标是单向依赖的，只有观察者依赖目标，观察者只能被动的去等到目标的通知，等待目标传值给它。\n\n- 推模型是假定目标知道观察者需要的数据；而拉模型是目标不知道观察者具体需要什么数据，没有办法的情况下，干脆把自身传递给观察者，让观察者自己去按需要取值。\n- 推模型可能会使得观察者对象难以复用，因为观察者的update()方法是按需要定义的参数，可能无法兼顾没有考虑到的使用情况。这就意味着出现新情况的时候，就可能提供新的update()方法，或者是干脆重新实现观察者；而拉模型就不会造成这样的情况，因为拉模型下，update()方法的参数是目标对象本身，观察者可以获取目标对象上的任何非私有属性。\n- 实质：触发联动\n\n## 使用场景\n\n1. 当一个对象的改变需要通知其他对象时选用观察者模式\n2. 当一个抽象模型有两个方面，一个方面的操作依赖另一个方面的状态变化时选用观察者模式\n\n## 优缺点\n\n- 优点\n  1. 实现了观察者和目标之间的解耦合\n  2. 支持广播通知\n\n- 缺点\n\n\n## UML图\n\n定义一个目标抽象类，在抽象类中维护一个观察者的list，通过准备阶段创建观察者add到list中，提供添加和删除观察者的方法，提供通知观察者的方法。\n\n定义一个目标具体实现类，在该实现类中如果发生变化调用notifyObserves通知所有观察者\n\n定义一个观察者接口和一系列观察者实现类对象，提供方法供目标回调\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-23/57916143-file_1490278389038_14d10.png)\n\n●　　**目标(Subject)角色：**抽象主题角色把所有对观察者对象的引用保存在一个聚集（比如ArrayList对象）里，每个主题都可以有任何数量的观察者。抽象主题提供一个接口，可以增加和删除观察者对象，提供目标更新时通知观察者的方法。\n\n　　●　　**目标实现(ConcreteSubject)角色：**具体目标实现，用来维护目标状态，当目标状态发生改变时通知已注册的所有观察者。\n\n　　●　　**抽象观察者(Observer)角色：**为所有的具体观察者定义一个接口，定义目标对象通知观察者时的回调方法。\n\n　　●　　**具体观察者(ConcreteObserver)角色：**存储与主题的状态自恰的状态。具体观察者接收通知进行后续处理。\n\n- 准备阶段\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-23/68981815-file_1490278727523_108ed.png)\n\n- 运行阶段\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-23/8957403-file_1490278682033_156ce.png)\n\n## 代码实现 \n\n### 推模型\n\n目标回调观察者时传入具体的值\n\n```java\n//目标抽象类\npublic abstract class Subject {\n\n\t// 注册的观察者列表\n\tprivate List<Observer> observerList = new ArrayList<Observer>();\n\n\t// 注册观察者\n\tpublic void attach(Observer observer) {\n\t\tobserverList.add(observer);\n\t}\n\n\t// 移除观察者\n\tpublic void detach(Observer observer) {\n\t\tobserverList.remove(observer);\n\t}\n\n\t// 定义通知方法\n\tprotected void nodifyObservers(String newState) {\n\t\tfor(Observer observer:observerList){\n\t\t\tobserver.update(newState);\n\t\t}\n\t}\n}\n//目标具体实现类\npublic class ConcreteSubject extends Subject {\n\tprivate String state;\n\tpublic String getState() {\n\t\treturn state;\n\t}\n\t//目标更新时通知所有观察者\n\tpublic void change(String newState) {\n\t\tstate = newState;\n\t\tSystem.out.println(\"主题状态为：\" + state);\n\t\t// 状态发生改变，通知各个观察者\n\t\tthis.nodifyObservers(state);\n\t}\n\n}\n//观察者接口\npublic interface Observer {\n\n\t//提供方法供目标回调通知并传入值\n\tpublic void update(String state);\n}\n//观察者具体实现类\npublic class ConcreteObserver implements Observer {\n\t\n    //观察者的状态\n    private String observerState;\n    \n    //通过目标回调获取目标传递给回来的值\n    public void update(String state) {\n        /**\n         * 更新观察者的状态，使其与目标的状态保持一致\n         */\n        observerState = state;\n        System.out.println(\"状态为：\"+observerState);\n    }\n}\n//客户端调用\npublic class Client {\n\n\tpublic static void main(String[] args) {\n\t\t//创建目标\n\t\tConcreteSubject subject = new ConcreteSubject();\n\t\t//创建观察者\n\t\tObserver observer1 = new ConcreteObserver();\n\t\tObserver observer2 = new ConcreteObserver();\n\t\t//注册观察者\n\t\tsubject.attach(observer1);\n\t\tsubject.attach(observer2);\n\t\t//更新目标并通知所有观察者\n\t\tsubject.change(\"new\");\n\t\tsubject.detach(observer2);\n\t\tsubject.change(\"again\");\n\t}\n}\n```\n\n### 拉模型\n\n目标回调观察者时将目标对象传递给观察者\n\n```java\n//目标抽象类\npublic abstract class Subject {\n\n\t// 注册的观察者列表\n\tprivate List<Observer> observerList = new ArrayList<Observer>();\n\n\t// 注册观察者\n\tpublic void attach(Observer observer) {\n\t\tobserverList.add(observer);\n\t}\n\n\t// 移除观察者\n\tpublic void detach(Observer observer) {\n\t\tobserverList.remove(observer);\n\t}\n\n\t// 定义通知方法，直接将目标对象回调传递给观察者\n\tprotected void nodifyObservers() {\n\t\tfor(Observer observer:observerList){\n\t\t\tobserver.update(this);\n\t\t}\n\t}\n}\n//目标具体实现类\npublic class ConcreteSubject extends Subject {\n\t\n\tprivate String state;\n\n\tpublic String getState() {\n\t\treturn state;\n\t}\n\n\t//目标更新时通知所有观察者\n\tpublic void change(String newState) {\n\t\tstate = newState;\n\t\tSystem.out.println(\"主题状态为：\" + state);\n\t\t//将目标对象通过回调传递给每个观察者\n\t\tthis.nodifyObservers();\n\t}\n}\n//观察者接口\npublic interface Observer {\n\n\t//提供方法供目标回调通知并传入值\n\tpublic void update(Subject subject);\n}\n//观察者具体实现类\npublic class ConcreteObserver implements Observer {\n\t\n    //观察者的状态\n    private String observerState;\n\n    //通过目标回调获取目标对象\n\t@Override\n\tpublic void update(Subject subject) {\n\t\t//通过目标对象的引用获取目标对象中的值\n\t\tobserverState = ((ConcreteSubject)subject).getState();\n\t\tSystem.out.println(\"状态为：\"+observerState);\n\t}\n}\n//客户端调用\npublic class Client {\n\n\tpublic static void main(String[] args) {\n\t\t//创建目标\n\t\tConcreteSubject subject = new ConcreteSubject();\n\t\t//创建观察者\n\t\tObserver observer1 = new ConcreteObserver();\n\t\tObserver observer2 = new ConcreteObserver();\n\t\t//注册观察者\n\t\tsubject.attach(observer1);\n\t\tsubject.attach(observer2);\n\t\t//更新目标并通知所有观察者\n\t\tsubject.change(\"new\");\n\t\tsubject.detach(observer2);\n\t\tsubject.change(\"again\");\n\t}\n}\n```\n\n### jdk提供的接口\n\n```java\n//目标对象继承Observable接口\npublic class Watched extends Observable接口{\n    \n    private String data = \"\";\n    \n    public String getData() {\n        return data;\n    }\n\n    public void setData(String data) {\n   \n        if(!this.data.equals(data)){\n            this.data = data;\n            setChanged();\n        }\n        notifyObservers();\n    }\n}\n//观察者实现Observer接口\npublic class Watcher implements Observer{\n    \n    public Watcher(Observable o){\n        o.addObserver(this);\n    }\n    \n    @Override\n    public void update(Observable o, Object arg) {  \n        System.out.println(\"状态发生改变：\" + ((Watched)o).getData());\n    }\n}\npublic class Client {\n    public static void main(String[] args) { \n        //创建被观察者对象\n        Watched watched = new Watched();\n        //创建观察者对象，并将被观察者对象登记\n        Observer watcher = new Watcher(watched);\n        //给被观察者状态赋值\n        watched.setData(\"start\");\n        watched.setData(\"run\");\n        watched.setData(\"stop\");\n    }\n}\n```","slug":"设计模式/设计模式之观察者模式","published":1,"updated":"2018-09-12T03:03:21.839Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnjg008qwlkvz273h2gw"},{"title":"设计模式之解释器模式","date":"2018-05-29T10:15:32.000Z","_content":"\n#  设计模式之解释器模式\n\n解释器模式是类的行为模式。给定一个语言之后，解释器模式可以定义出其文法的一种表示，并同时提供一个解释器。客户端可以使用这个解释器来解释这个语言中的句子。\n\n<!--more-->\n\n## 思考\n\n本质：分离实现，解释执行\n\n## 使用场景\n\n- 当配置文件中xml的结构发生改变后，能够很方便的获取相应元素、或者是属性的值，而不用再去修改解析xm的程序\n- 适用于语法比较简单，效率要求不是很高的时候\n\n## 优缺点\n\n- 优点：易于实现语法；易于扩展新的语法\n\n- 缺点：不适合复杂的语法\n\n\n## UML图\n\n解释器基本UML图\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-29/55010190-file_1490794941644_104cf.png)\n\n- **抽象表达式(AbstarctExpression)角色：**声明一个所有的具体表达式角色都需要实现的抽象接口。这个接口主要是一个interpret()方法，称做解释操作。\n\n- **终结符表达式(Terminal Expression)角色：**实现了抽象表达式角色所要求的接口，主要是一个interpret()方法；文法中的每一个终结符都有一个具体终结表达式与之相对应。比如有一个简单的公式R=R1+R2，在里面R1和R2就是终结符，对应的解析R1和R2的解释器就是终结符表达式。\n- **非终结符表达式(Nonterminal Expression)角色：**文法中的每一条规则都需要一个具体的非终结符表达式，非终结符表达式一般是文法中的运算符或者其他关键字，比如公式R=R1+R2中，“+\"就是非终结符，解析“+”的解释器就是一个非终结符表达式。\n- **环境(Context)角色：**这个角色的任务一般是用来存放文法中各个终结符所对应的具体值，比如R=R1+R2，我们给R1赋值100，给R2赋值200。这些信息需要存放到环境角色中，很多情况下我们使用Map来充当环境角色就足够了。\n\njava中的逻辑表达符实现\n```\nExpression  ::= Constant | Variable | Or | And | Not\nAnd 　　　　::= Expression 'AND' Expression\nOr　　　　　::= Expression 'OR' Expression\nNot　　　　 ::= 'NOT' Expression\nVariable　　::= 任何标识符\nConstant    ::= 'true' | 'false'\n```\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-29/14847048-file_1490792767386_345.png)\n\n## 代码实现\n\n```java\n//抽象表达式角色\npublic abstract class Expression {\n    // 以环境为准，本方法解释给定的任何一个表达式\n    public abstract boolean interpret(Context ctx);\n    //检验两个表达式在结构上是否相同\n    public abstract boolean equals(Object obj);\n    //返回表达式的hash code\n    public abstract int hashCode();\n    // 将表达式转换成字符串\n    public abstract String toString();\n}\n//终结符表达式\npublic class Constant extends Expression{\n    \n    private boolean value;\n\n    public Constant(boolean value){\n        this.value = value;\n    }\n    @Override\n    public boolean equals(Object obj) {\n        if(obj != null && obj instanceof Constant){\n            return this.value == ((Constant)obj).value;\n        }\n        return false;\n    }\n    @Override\n    public int hashCode() {\n        return this.toString().hashCode();\n    }\n    @Override\n    public boolean interpret(Context ctx) {\n        return value;\n    }\n    @Override\n    public String toString() {\n        return new Boolean(value).toString();\n    }\n}\n//终结符表达式\npublic class Variable extends Expression {\n\n    private String name;\n\n    public Variable(String name){\n        this.name = name;\n    }\n    @Override\n    public boolean equals(Object obj) {\n        \n        if(obj != null && obj instanceof Variable)\n        {\n            return this.name.equals(\n                    ((Variable)obj).name);\n        }\n        return false;\n    }\n    @Override\n    public int hashCode() {\n        return this.toString().hashCode();\n    }\n    @Override\n    public String toString() {\n        return name;\n    }\n    @Override\n    public boolean interpret(Context ctx) {\n        return ctx.lookup(this);\n    }\n}\n//非终结符表达式\npublic class And extends Expression {\n\n    private Expression left,right;\n    \n    public And(Expression left , Expression right){\n        this.left = left;\n        this.right = right;\n    }\n    @Override\n    public boolean equals(Object obj) {\n        if(obj != null && obj instanceof And)\n        {\n            return left.equals(((And)obj).left) &&\n                right.equals(((And)obj).right);\n        }\n        return false;\n    }\n    @Override\n    public int hashCode() {\n        return this.toString().hashCode();\n    }\n    @Override\n    public boolean interpret(Context ctx) {\n        \n        return left.interpret(ctx) && right.interpret(ctx);\n    }\n    @Override\n    public String toString() {\n        return \"(\" + left.toString() + \" AND \" + right.toString() + \")\";\n    }\n}\n//非终结符表达式\npublic class Or extends Expression {\n    private Expression left,right;\n\n    public Or(Expression left , Expression right){\n        this.left = left;\n        this.right = right;\n    }\n    @Override\n    public boolean equals(Object obj) {\n        if(obj != null && obj instanceof Or)\n        {\n            return this.left.equals(((Or)obj).left) && this.right.equals(((Or)obj).right);\n        }\n        return false;\n    }\n    @Override\n    public int hashCode() {\n        return this.toString().hashCode();\n    }\n    @Override\n    public boolean interpret(Context ctx) {\n        return left.interpret(ctx) || right.interpret(ctx);\n    }\n    @Override\n    public String toString() {\n        return \"(\" + left.toString() + \" OR \" + right.toString() + \")\";\n    }\n}\n//非终结符表达式\npublic class Not extends Expression {\n\n    private Expression exp;\n    \n    public Not(Expression exp){\n        this.exp = exp;\n    }\n    @Override\n    public boolean equals(Object obj) {\n        if(obj != null && obj instanceof Not)\n        {\n            return exp.equals(\n                    ((Not)obj).exp);\n        }\n        return false;\n    }\n    @Override\n    public int hashCode() {\n        return this.toString().hashCode();\n    }\n    @Override\n    public boolean interpret(Context ctx) {\n        return !exp.interpret(ctx);\n    }\n    @Override\n    public String toString() {\n        return \"(Not \" + exp.toString() + \")\";\n    }\n}\n//环境(Context)类定义出从变量到布尔值的一个映射\npublic class Context {\n\n    private Map<Variable,Boolean> map = new HashMap<Variable,Boolean>();\n    \n    public void assign(Variable var , boolean value){\n        map.put(var, new Boolean(value));\n    }\n    \n    public boolean lookup(Variable var) throws IllegalArgumentException{\n        Boolean value = map.get(var);\n        if(value == null){\n            throw new IllegalArgumentException();\n        }\n        return value.booleanValue();\n    }\n}\n//客户端\npublic class Client {\n\n    public static void main(String[] args) {\n        Context ctx = new Context();\n        Variable x = new Variable(\"x\");\n        Variable y = new Variable(\"y\");\n        Constant c = new Constant(true);\n        ctx.assign(x, false);\n        ctx.assign(y, true);\n        \n        Expression exp = new Or(new And(c,x) , new And(y,new Not(x)));\n        System.out.println(\"x=\" + x.interpret(ctx));\n        System.out.println(\"y=\" + y.interpret(ctx));\n        System.out.println(exp.toString() + \"=\" + exp.interpret(ctx));\n    }\n}\n/**输出结果**/\nx=false\ny=true\n((true AND x) OR (y AND (Not x)))=true\n```","source":"_posts/设计模式/设计模式之解释器模式.md","raw":"---\ntitle: 设计模式之解释器模式\ndate: 2018-05-29 18:15:32\ntags:\n- 设计模式\ncategories:\n- 设计模式\n\n---\n\n#  设计模式之解释器模式\n\n解释器模式是类的行为模式。给定一个语言之后，解释器模式可以定义出其文法的一种表示，并同时提供一个解释器。客户端可以使用这个解释器来解释这个语言中的句子。\n\n<!--more-->\n\n## 思考\n\n本质：分离实现，解释执行\n\n## 使用场景\n\n- 当配置文件中xml的结构发生改变后，能够很方便的获取相应元素、或者是属性的值，而不用再去修改解析xm的程序\n- 适用于语法比较简单，效率要求不是很高的时候\n\n## 优缺点\n\n- 优点：易于实现语法；易于扩展新的语法\n\n- 缺点：不适合复杂的语法\n\n\n## UML图\n\n解释器基本UML图\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-29/55010190-file_1490794941644_104cf.png)\n\n- **抽象表达式(AbstarctExpression)角色：**声明一个所有的具体表达式角色都需要实现的抽象接口。这个接口主要是一个interpret()方法，称做解释操作。\n\n- **终结符表达式(Terminal Expression)角色：**实现了抽象表达式角色所要求的接口，主要是一个interpret()方法；文法中的每一个终结符都有一个具体终结表达式与之相对应。比如有一个简单的公式R=R1+R2，在里面R1和R2就是终结符，对应的解析R1和R2的解释器就是终结符表达式。\n- **非终结符表达式(Nonterminal Expression)角色：**文法中的每一条规则都需要一个具体的非终结符表达式，非终结符表达式一般是文法中的运算符或者其他关键字，比如公式R=R1+R2中，“+\"就是非终结符，解析“+”的解释器就是一个非终结符表达式。\n- **环境(Context)角色：**这个角色的任务一般是用来存放文法中各个终结符所对应的具体值，比如R=R1+R2，我们给R1赋值100，给R2赋值200。这些信息需要存放到环境角色中，很多情况下我们使用Map来充当环境角色就足够了。\n\njava中的逻辑表达符实现\n```\nExpression  ::= Constant | Variable | Or | And | Not\nAnd 　　　　::= Expression 'AND' Expression\nOr　　　　　::= Expression 'OR' Expression\nNot　　　　 ::= 'NOT' Expression\nVariable　　::= 任何标识符\nConstant    ::= 'true' | 'false'\n```\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-29/14847048-file_1490792767386_345.png)\n\n## 代码实现\n\n```java\n//抽象表达式角色\npublic abstract class Expression {\n    // 以环境为准，本方法解释给定的任何一个表达式\n    public abstract boolean interpret(Context ctx);\n    //检验两个表达式在结构上是否相同\n    public abstract boolean equals(Object obj);\n    //返回表达式的hash code\n    public abstract int hashCode();\n    // 将表达式转换成字符串\n    public abstract String toString();\n}\n//终结符表达式\npublic class Constant extends Expression{\n    \n    private boolean value;\n\n    public Constant(boolean value){\n        this.value = value;\n    }\n    @Override\n    public boolean equals(Object obj) {\n        if(obj != null && obj instanceof Constant){\n            return this.value == ((Constant)obj).value;\n        }\n        return false;\n    }\n    @Override\n    public int hashCode() {\n        return this.toString().hashCode();\n    }\n    @Override\n    public boolean interpret(Context ctx) {\n        return value;\n    }\n    @Override\n    public String toString() {\n        return new Boolean(value).toString();\n    }\n}\n//终结符表达式\npublic class Variable extends Expression {\n\n    private String name;\n\n    public Variable(String name){\n        this.name = name;\n    }\n    @Override\n    public boolean equals(Object obj) {\n        \n        if(obj != null && obj instanceof Variable)\n        {\n            return this.name.equals(\n                    ((Variable)obj).name);\n        }\n        return false;\n    }\n    @Override\n    public int hashCode() {\n        return this.toString().hashCode();\n    }\n    @Override\n    public String toString() {\n        return name;\n    }\n    @Override\n    public boolean interpret(Context ctx) {\n        return ctx.lookup(this);\n    }\n}\n//非终结符表达式\npublic class And extends Expression {\n\n    private Expression left,right;\n    \n    public And(Expression left , Expression right){\n        this.left = left;\n        this.right = right;\n    }\n    @Override\n    public boolean equals(Object obj) {\n        if(obj != null && obj instanceof And)\n        {\n            return left.equals(((And)obj).left) &&\n                right.equals(((And)obj).right);\n        }\n        return false;\n    }\n    @Override\n    public int hashCode() {\n        return this.toString().hashCode();\n    }\n    @Override\n    public boolean interpret(Context ctx) {\n        \n        return left.interpret(ctx) && right.interpret(ctx);\n    }\n    @Override\n    public String toString() {\n        return \"(\" + left.toString() + \" AND \" + right.toString() + \")\";\n    }\n}\n//非终结符表达式\npublic class Or extends Expression {\n    private Expression left,right;\n\n    public Or(Expression left , Expression right){\n        this.left = left;\n        this.right = right;\n    }\n    @Override\n    public boolean equals(Object obj) {\n        if(obj != null && obj instanceof Or)\n        {\n            return this.left.equals(((Or)obj).left) && this.right.equals(((Or)obj).right);\n        }\n        return false;\n    }\n    @Override\n    public int hashCode() {\n        return this.toString().hashCode();\n    }\n    @Override\n    public boolean interpret(Context ctx) {\n        return left.interpret(ctx) || right.interpret(ctx);\n    }\n    @Override\n    public String toString() {\n        return \"(\" + left.toString() + \" OR \" + right.toString() + \")\";\n    }\n}\n//非终结符表达式\npublic class Not extends Expression {\n\n    private Expression exp;\n    \n    public Not(Expression exp){\n        this.exp = exp;\n    }\n    @Override\n    public boolean equals(Object obj) {\n        if(obj != null && obj instanceof Not)\n        {\n            return exp.equals(\n                    ((Not)obj).exp);\n        }\n        return false;\n    }\n    @Override\n    public int hashCode() {\n        return this.toString().hashCode();\n    }\n    @Override\n    public boolean interpret(Context ctx) {\n        return !exp.interpret(ctx);\n    }\n    @Override\n    public String toString() {\n        return \"(Not \" + exp.toString() + \")\";\n    }\n}\n//环境(Context)类定义出从变量到布尔值的一个映射\npublic class Context {\n\n    private Map<Variable,Boolean> map = new HashMap<Variable,Boolean>();\n    \n    public void assign(Variable var , boolean value){\n        map.put(var, new Boolean(value));\n    }\n    \n    public boolean lookup(Variable var) throws IllegalArgumentException{\n        Boolean value = map.get(var);\n        if(value == null){\n            throw new IllegalArgumentException();\n        }\n        return value.booleanValue();\n    }\n}\n//客户端\npublic class Client {\n\n    public static void main(String[] args) {\n        Context ctx = new Context();\n        Variable x = new Variable(\"x\");\n        Variable y = new Variable(\"y\");\n        Constant c = new Constant(true);\n        ctx.assign(x, false);\n        ctx.assign(y, true);\n        \n        Expression exp = new Or(new And(c,x) , new And(y,new Not(x)));\n        System.out.println(\"x=\" + x.interpret(ctx));\n        System.out.println(\"y=\" + y.interpret(ctx));\n        System.out.println(exp.toString() + \"=\" + exp.interpret(ctx));\n    }\n}\n/**输出结果**/\nx=false\ny=true\n((true AND x) OR (y AND (Not x)))=true\n```","slug":"设计模式/设计模式之解释器模式","published":1,"updated":"2018-09-12T03:03:21.840Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnji008twlkvk7i62bd8"},{"title":"设计模式之设计原则","date":"2018-05-23T08:19:04.000Z","_content":"\n#  设计模式之设计原则\n\n在产品的开发迭代中，需求修改是经常遇到的，一旦需求改变了，那么程序代码也需要跟着做出相应的调整，在程序开发中前人总结出了几个设计原则来应对这种变化，基于这几种原则来进行程序设计能够更加快速、安全去应对各种变化。\n\n<!--more-->\n\n## 设计原则目的\n\n- 将变化和不变分离，尽量降低变化的可能，缩小变化的影响范围\n- 避免修改原有代码而通过添加额外的类来实现变化\n\n### 一、单一职责原则\n\n永远不要让一个类存在多个改变的理由。尽量降低变化的可能\n\n### 二、接口隔离原则\n\n尽量保证接口中只有用户关心的方法，避免用户去实现不关心的接口。将接口的粒度控制到最小，这样以后修改的可能就会更小\n- 提高内聚，减少对外交互，如果用户实现了不关心的接口方法，如果方法发生变化，导致用户也需跟着改动 \n- 接口尽量小，但是要有限度。对接口进行细化可以提高程序设计灵活性是不挣的事实，但是如果过小，则会造成接口数量过多，使设计复杂化。所以一定要适度。\n\n### 三、迪米特法则(最少知识原则)\n\n一个对象应当对其他对象有尽可能少的依赖，降低依赖对象改变引起其他的对象的改动\n\n- 门面模式和中介者模式。\n- 单一职责原则和接口隔离原则\n\n### 四、开闭原则\n\n软件实体应当对扩展开放，对修改关闭，尽量保证原有逻辑的正确性,降低影响范围\n- 抽离逻辑骨架，定义为接口，接口是稳定的，具体的细节可以通过添加实现类来扩展。\n- 直接提供一套新的接口及实现\n\n### 五、依赖倒转原则\n\n抽象不应该依赖细节，细节应该依赖抽象，面向接口编程。依赖不变的，不要依赖变动的\n\n- 依赖抽象，当需要改变细节时，只需要再添加一种新的实现类，然后将依赖修改为新的实现类对象\n\n- 在开发中，经常会定义很多接口，然后写一种实现，虽然很多时候只有一种实现，但是谁能保证会不会再多出一种实现，一旦需要修改细节实现，只需要添加一种实现类，如 Dao层，可以提供多种数据来源的具体实现，Service层只需要依赖Dao提供的接口，接口时不会变的。\n\n\n### 六、里氏替换原则\n\n任何时候都可以用子类型替换掉父类型。 里氏替换原则通俗的来讲就是：**子类可以扩展父类的功能，但不能改变父类原有的功能**。最终目的就是为了实现开闭原则。\n- 子类可以实现父类的抽象方法，但不能覆盖父类的非抽象方法。\n- 子类中可以增加自己特有的方法。\n- 当子类的方法重载父类的方法时，子类方法的参数要是父类方法参数的父类。\n- 当子类的方法实现父类的抽象方法时，方法的返回值要是父类的返回值的子类。\n- 如果非要重写父类的方法，比较通用的做法是：原来的父类和子类都继承一个更通俗的基类，原有的继承关系去掉，采用依赖、聚合，组合等关系代替。\n\n## 设计模式\n\n为了更好的是遵循和实现设计原则，前人总结了一些设计模式\n\n![](http://omdq6di7v.bkt.clouddn.com/18-6-26/15781999.jpg)\n\n","source":"_posts/设计模式/设计模式之设计原则.md","raw":"---\ntitle: 设计模式之设计原则\ndate: 2018-05-23 16:19:04\ntags:\n- 设计模式\ncategories:\n- 设计模式\n\n---\n\n#  设计模式之设计原则\n\n在产品的开发迭代中，需求修改是经常遇到的，一旦需求改变了，那么程序代码也需要跟着做出相应的调整，在程序开发中前人总结出了几个设计原则来应对这种变化，基于这几种原则来进行程序设计能够更加快速、安全去应对各种变化。\n\n<!--more-->\n\n## 设计原则目的\n\n- 将变化和不变分离，尽量降低变化的可能，缩小变化的影响范围\n- 避免修改原有代码而通过添加额外的类来实现变化\n\n### 一、单一职责原则\n\n永远不要让一个类存在多个改变的理由。尽量降低变化的可能\n\n### 二、接口隔离原则\n\n尽量保证接口中只有用户关心的方法，避免用户去实现不关心的接口。将接口的粒度控制到最小，这样以后修改的可能就会更小\n- 提高内聚，减少对外交互，如果用户实现了不关心的接口方法，如果方法发生变化，导致用户也需跟着改动 \n- 接口尽量小，但是要有限度。对接口进行细化可以提高程序设计灵活性是不挣的事实，但是如果过小，则会造成接口数量过多，使设计复杂化。所以一定要适度。\n\n### 三、迪米特法则(最少知识原则)\n\n一个对象应当对其他对象有尽可能少的依赖，降低依赖对象改变引起其他的对象的改动\n\n- 门面模式和中介者模式。\n- 单一职责原则和接口隔离原则\n\n### 四、开闭原则\n\n软件实体应当对扩展开放，对修改关闭，尽量保证原有逻辑的正确性,降低影响范围\n- 抽离逻辑骨架，定义为接口，接口是稳定的，具体的细节可以通过添加实现类来扩展。\n- 直接提供一套新的接口及实现\n\n### 五、依赖倒转原则\n\n抽象不应该依赖细节，细节应该依赖抽象，面向接口编程。依赖不变的，不要依赖变动的\n\n- 依赖抽象，当需要改变细节时，只需要再添加一种新的实现类，然后将依赖修改为新的实现类对象\n\n- 在开发中，经常会定义很多接口，然后写一种实现，虽然很多时候只有一种实现，但是谁能保证会不会再多出一种实现，一旦需要修改细节实现，只需要添加一种实现类，如 Dao层，可以提供多种数据来源的具体实现，Service层只需要依赖Dao提供的接口，接口时不会变的。\n\n\n### 六、里氏替换原则\n\n任何时候都可以用子类型替换掉父类型。 里氏替换原则通俗的来讲就是：**子类可以扩展父类的功能，但不能改变父类原有的功能**。最终目的就是为了实现开闭原则。\n- 子类可以实现父类的抽象方法，但不能覆盖父类的非抽象方法。\n- 子类中可以增加自己特有的方法。\n- 当子类的方法重载父类的方法时，子类方法的参数要是父类方法参数的父类。\n- 当子类的方法实现父类的抽象方法时，方法的返回值要是父类的返回值的子类。\n- 如果非要重写父类的方法，比较通用的做法是：原来的父类和子类都继承一个更通俗的基类，原有的继承关系去掉，采用依赖、聚合，组合等关系代替。\n\n## 设计模式\n\n为了更好的是遵循和实现设计原则，前人总结了一些设计模式\n\n![](http://omdq6di7v.bkt.clouddn.com/18-6-26/15781999.jpg)\n\n","slug":"设计模式/设计模式之设计原则","published":1,"updated":"2018-09-12T03:03:21.840Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnjj008wwlkvaf8t3dr5"},{"title":"设计模式之访问者模式","date":"2018-05-29T10:10:28.000Z","_content":"\n#  设计模式之访问者模式\n\n访问者模式是对象的行为模式。访问者模式的目的是封装一些施加于某种数据结构元素之上的操作。一旦这些操作需要修改的话，接受这个操作的数据结构则可以保持不变。**变化的是访问者，不变的是被访问者** \n\n<!--more-->\n\n## 思考\n\n- 本质是：预留通路，回调实现\n- 有条件的接收访问，如果不满足条件，禁止访问\n\n## 使用场景\n\n- 对象结构很少变动，对对象的操作经常改变的时候可以封装操作使用访问者模式\n\n- 对对象结构中的各个元素有不同的操作时，可以给各个元素封装不同的操作使用访问者模式\n\n## 优缺点\n\n- 优点\n  1. **好的扩展性**:能够在不修改对象结构中的元素的情况下，为对象结构中的元素添加新的功能。\n  2. **好的复用性**:可以通过访问者来定义整个对象结构通用的功能，从而提高复用程度。\n  3. **分离无关行为**:可以通过访问者来分离无关的行为，把相关的行为封装在一起，构成一个访问者，这样每一个访问者的功能都比较单一。\n\n- 缺点\n  1. **对象结构变化很困难**:对象结构发生了改变，访问者的接口和访问者的实现都要发生相应的改变，代价太高\n  2. **破坏封装**:访问者模式通常需要对象结构开放内部数据给访问者和ObjectStructrue，这破坏了对象的封装性。\n\n## UML图\n\n数据结构的每一个节点都可以接受一个访问者的调用，然后节点向访问者对象传入节点对象，而访问者对象则反过来执行节点对象的操作。这样的过程叫做“双重分派”。**节点调用访问者，将它自己传入，访问者通过传入的节点对象执行节点的相关操作** 。访问者模式的示意性类图如下所示：\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-29/49295680-file_1490797959324_15643.png)\n\n- **抽象访问者(Visitor)角色：**声明了一个或者多个方法操作，形成所有的具体访问者角色必须实现的接口。\n- **具体访问者(ConcreteVisitor)角色：**实现抽象访问者所声明的接口，也就是抽象访问者所声明的各个访问操作。\n- **抽象节点(Node)角色：**声明一个接受操作，**接受一个访问者对象作为一个参数**。\n- **具体节点(ConcreteNode)角色：**实现了抽象节点所规定的接受操作。\n- **结构对象(ObjectStructure)角色：**有如下的责任，可以遍历结构中的所有元素；如果需要，提供一个高层次的接口让访问者对象可以访问每一个元素；如果需要，可以设计成一个复合对象或者一个聚集，如List或Set。\n\n执行顺序图\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-29/82837176-file_1490798801355_3a46.png)\n\n## 代码实现\n\n\n\n```java\n//访问者接口，为每个节点实体重载提供了接口\npublic interface Visitor {\n    //对应于NodeA的访问操作\n    public void visit(NodeA node);\n    //对应于NodeB的访问操作\n    public void visit(NodeB node);\n}\n\n//具体访问者\npublic class VisitorA implements Visitor {\n    //对应于NodeA的访问操作\n    @Override\n    public void visit(NodeA node) {\n        System.out.println(node.operationA());\n    }\n    //对应于NodeB的访问操作\n    @Override\n    public void visit(NodeB node) {\n        System.out.println(node.operationB());\n    }\n}\n//具体访问者\npublic class VisitorB implements Visitor {\n    //对应于NodeA的访问操作\n    @Override\n    public void visit(NodeA node) {\n        System.out.println(node.operationA());\n    }\n    //对应于NodeB的访问操作\n    @Override\n    public void visit(NodeB node) {\n        System.out.println(node.operationB());\n    }\n}\n//抽象节点\npublic abstract class Node {\n    //接受操作\n    public abstract void accept(Visitor visitor);\n}\n//具体节点类NodeA\npublic class NodeA extends Node{\n    //接受访问者\n    @Override\n    public void accept(Visitor visitor) {\n        visitor.visit(this);\n    }\n    //NodeA特有的方法\n    public String operationA(){\n        return \"NodeA\";\n    }\n}\n//具体节点类NodeB\npublic class NodeB extends Node{\n   //接受访问者\n    @Override\n    public void accept(Visitor visitor) {\n        visitor.visit(this);\n    }\n    // NodeB特有的方法\n    public String operationB(){\n        return \"NodeB\";\n    }\n}\n//结构对象角色类，这个结构对象角色持有一个聚集，并向外界提供add()方法作为对聚集的管理操作。通过调用这个方法，可以动态地增加一个新的节点。\npublic class ObjectStructure {\n    //聚合节点\n    private List<Node> nodes = new ArrayList<Node>();\n    \n    // 循环访问多个节点\n    public void action(Visitor visitor){\n        \n        for(Node node : nodes)\n        {\n            node.accept(visitor);\n        }\n        \n    }\n    // 添加一个新节点元素\n    public void add(Node node){\n        nodes.add(node);\n    }\n}\n//客户端\npublic class Client {\n\n    public static void main(String[] args) {\n        //创建一个结构对象\n        ObjectStructure os = new ObjectStructure();\n        //给结构增加一个节点\n        os.add(new NodeA());\n        //给结构增加一个节点\n        os.add(new NodeB());\n        //创建一个访问者\n        Visitor visitor = new VisitorA();\n        os.action(visitor);\n    }\n}\n```","source":"_posts/设计模式/设计模式之访问者模式.md","raw":"---\ntitle: 设计模式之访问者模式\ndate: 2018-05-29 18:10:28\ntags:\n- 设计模式\ncategories:\n- 设计模式\n\n---\n\n#  设计模式之访问者模式\n\n访问者模式是对象的行为模式。访问者模式的目的是封装一些施加于某种数据结构元素之上的操作。一旦这些操作需要修改的话，接受这个操作的数据结构则可以保持不变。**变化的是访问者，不变的是被访问者** \n\n<!--more-->\n\n## 思考\n\n- 本质是：预留通路，回调实现\n- 有条件的接收访问，如果不满足条件，禁止访问\n\n## 使用场景\n\n- 对象结构很少变动，对对象的操作经常改变的时候可以封装操作使用访问者模式\n\n- 对对象结构中的各个元素有不同的操作时，可以给各个元素封装不同的操作使用访问者模式\n\n## 优缺点\n\n- 优点\n  1. **好的扩展性**:能够在不修改对象结构中的元素的情况下，为对象结构中的元素添加新的功能。\n  2. **好的复用性**:可以通过访问者来定义整个对象结构通用的功能，从而提高复用程度。\n  3. **分离无关行为**:可以通过访问者来分离无关的行为，把相关的行为封装在一起，构成一个访问者，这样每一个访问者的功能都比较单一。\n\n- 缺点\n  1. **对象结构变化很困难**:对象结构发生了改变，访问者的接口和访问者的实现都要发生相应的改变，代价太高\n  2. **破坏封装**:访问者模式通常需要对象结构开放内部数据给访问者和ObjectStructrue，这破坏了对象的封装性。\n\n## UML图\n\n数据结构的每一个节点都可以接受一个访问者的调用，然后节点向访问者对象传入节点对象，而访问者对象则反过来执行节点对象的操作。这样的过程叫做“双重分派”。**节点调用访问者，将它自己传入，访问者通过传入的节点对象执行节点的相关操作** 。访问者模式的示意性类图如下所示：\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-29/49295680-file_1490797959324_15643.png)\n\n- **抽象访问者(Visitor)角色：**声明了一个或者多个方法操作，形成所有的具体访问者角色必须实现的接口。\n- **具体访问者(ConcreteVisitor)角色：**实现抽象访问者所声明的接口，也就是抽象访问者所声明的各个访问操作。\n- **抽象节点(Node)角色：**声明一个接受操作，**接受一个访问者对象作为一个参数**。\n- **具体节点(ConcreteNode)角色：**实现了抽象节点所规定的接受操作。\n- **结构对象(ObjectStructure)角色：**有如下的责任，可以遍历结构中的所有元素；如果需要，提供一个高层次的接口让访问者对象可以访问每一个元素；如果需要，可以设计成一个复合对象或者一个聚集，如List或Set。\n\n执行顺序图\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-29/82837176-file_1490798801355_3a46.png)\n\n## 代码实现\n\n\n\n```java\n//访问者接口，为每个节点实体重载提供了接口\npublic interface Visitor {\n    //对应于NodeA的访问操作\n    public void visit(NodeA node);\n    //对应于NodeB的访问操作\n    public void visit(NodeB node);\n}\n\n//具体访问者\npublic class VisitorA implements Visitor {\n    //对应于NodeA的访问操作\n    @Override\n    public void visit(NodeA node) {\n        System.out.println(node.operationA());\n    }\n    //对应于NodeB的访问操作\n    @Override\n    public void visit(NodeB node) {\n        System.out.println(node.operationB());\n    }\n}\n//具体访问者\npublic class VisitorB implements Visitor {\n    //对应于NodeA的访问操作\n    @Override\n    public void visit(NodeA node) {\n        System.out.println(node.operationA());\n    }\n    //对应于NodeB的访问操作\n    @Override\n    public void visit(NodeB node) {\n        System.out.println(node.operationB());\n    }\n}\n//抽象节点\npublic abstract class Node {\n    //接受操作\n    public abstract void accept(Visitor visitor);\n}\n//具体节点类NodeA\npublic class NodeA extends Node{\n    //接受访问者\n    @Override\n    public void accept(Visitor visitor) {\n        visitor.visit(this);\n    }\n    //NodeA特有的方法\n    public String operationA(){\n        return \"NodeA\";\n    }\n}\n//具体节点类NodeB\npublic class NodeB extends Node{\n   //接受访问者\n    @Override\n    public void accept(Visitor visitor) {\n        visitor.visit(this);\n    }\n    // NodeB特有的方法\n    public String operationB(){\n        return \"NodeB\";\n    }\n}\n//结构对象角色类，这个结构对象角色持有一个聚集，并向外界提供add()方法作为对聚集的管理操作。通过调用这个方法，可以动态地增加一个新的节点。\npublic class ObjectStructure {\n    //聚合节点\n    private List<Node> nodes = new ArrayList<Node>();\n    \n    // 循环访问多个节点\n    public void action(Visitor visitor){\n        \n        for(Node node : nodes)\n        {\n            node.accept(visitor);\n        }\n        \n    }\n    // 添加一个新节点元素\n    public void add(Node node){\n        nodes.add(node);\n    }\n}\n//客户端\npublic class Client {\n\n    public static void main(String[] args) {\n        //创建一个结构对象\n        ObjectStructure os = new ObjectStructure();\n        //给结构增加一个节点\n        os.add(new NodeA());\n        //给结构增加一个节点\n        os.add(new NodeB());\n        //创建一个访问者\n        Visitor visitor = new VisitorA();\n        os.action(visitor);\n    }\n}\n```","slug":"设计模式/设计模式之访问者模式","published":1,"updated":"2018-09-12T03:03:21.840Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnjk008zwlkvkjo1cv11"},{"title":"设计模式之责任链模式","date":"2018-05-29T11:32:21.000Z","_content":"\n#  设计模式之责任链模式\n\n责任链模式是一种对象的行为模式。在责任链模式里，每个环节都有下一个环节的引用。请求在这个链上传递，直到链上的某一个环节决定处理此请求,这使得系统可以在不影响客户端的情况下动态地重新组织和分配责任。\n\n<!--more-->\n\n## 思考\n\n- 责任链模式跟装饰模式区别\n\n## 使用场景\n\n\n\n## 优缺点\n\n- 优点\n\n   -   请求者和接收者松散耦合\n   -   动态组合职责\n\n- 缺点\n\n   - 产生很多细粒度对象\n   - 不一定能被处理\n\n## UML图\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-11-19/33015956.jpg)\n\n责任链模式涉及到的角色如下所示：\n\n- 抽象处理者(Handler)角色：定义出一个责任链各环节处理请求的接口方法。接口可以定义 出一个方法以设定和返回对责任链下一个环节的引用。\n\n- 具体处理者(ConcreteHandler)角色：具体处理者获取执行后，获取责任链中下一个环节，判断是否存在，存在，使用下个环节继续调用，否则就返回\n\n## 代码实现\n\n- 责任链各环节接口\n\n    ```java\n    public abstract class Handler {\n        \n        //持有责任链下一个环节的对象\n        protected Handler next;\n        //责任链各环节执行的方法接口\n        public abstract void handleRequest();\n        //获取下一环节对象\n        public Handler getNext() {\n            return next;\n        }\n        //赋值方法，设置后继的责任对象\n        public void setNext(Handler next) {\n            this.next = next;\n        }\n        \n    }\n    \n    ```\n- 具体实现类\n\n    ```java\n    public class ConcreteHandler extends Handler {\n        //处理方法，调用此方法处理请求\n        @Override\n        public void handleRequest() {\n            /**\n             * 判断是否有后继的责任对象\n             * 如果有，就转发请求给后继的责任对象\n             * 如果没有，则处理请求\n             */\n            if(getNext() != null)\n            {            \n                getNext().handleRequest();            \n            }else\n            {            \n                System.out.println(\"处理请求\");\n            }\n        }\n    }\n    ```\n- 客户端\n\n    ```java\n    public class Client {\n        public static void main(String[] args) {\n            //组装责任链\n            Handler handler1 = new ConcreteHandler();\n            Handler handler2 = new ConcreteHandler();\n            handler1.setSuccessor(handler2);\n            //提交请求\n            handler1.handleRequest();\n        }\n    }\n    ```","source":"_posts/设计模式/设计模式之责任链模式.md","raw":"---\ntitle: 设计模式之责任链模式\ndate: 2018-05-29 19:32:21\ntags:\n- 设计模式\ncategories:\n- 设计模式\n\n---\n\n#  设计模式之责任链模式\n\n责任链模式是一种对象的行为模式。在责任链模式里，每个环节都有下一个环节的引用。请求在这个链上传递，直到链上的某一个环节决定处理此请求,这使得系统可以在不影响客户端的情况下动态地重新组织和分配责任。\n\n<!--more-->\n\n## 思考\n\n- 责任链模式跟装饰模式区别\n\n## 使用场景\n\n\n\n## 优缺点\n\n- 优点\n\n   -   请求者和接收者松散耦合\n   -   动态组合职责\n\n- 缺点\n\n   - 产生很多细粒度对象\n   - 不一定能被处理\n\n## UML图\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-11-19/33015956.jpg)\n\n责任链模式涉及到的角色如下所示：\n\n- 抽象处理者(Handler)角色：定义出一个责任链各环节处理请求的接口方法。接口可以定义 出一个方法以设定和返回对责任链下一个环节的引用。\n\n- 具体处理者(ConcreteHandler)角色：具体处理者获取执行后，获取责任链中下一个环节，判断是否存在，存在，使用下个环节继续调用，否则就返回\n\n## 代码实现\n\n- 责任链各环节接口\n\n    ```java\n    public abstract class Handler {\n        \n        //持有责任链下一个环节的对象\n        protected Handler next;\n        //责任链各环节执行的方法接口\n        public abstract void handleRequest();\n        //获取下一环节对象\n        public Handler getNext() {\n            return next;\n        }\n        //赋值方法，设置后继的责任对象\n        public void setNext(Handler next) {\n            this.next = next;\n        }\n        \n    }\n    \n    ```\n- 具体实现类\n\n    ```java\n    public class ConcreteHandler extends Handler {\n        //处理方法，调用此方法处理请求\n        @Override\n        public void handleRequest() {\n            /**\n             * 判断是否有后继的责任对象\n             * 如果有，就转发请求给后继的责任对象\n             * 如果没有，则处理请求\n             */\n            if(getNext() != null)\n            {            \n                getNext().handleRequest();            \n            }else\n            {            \n                System.out.println(\"处理请求\");\n            }\n        }\n    }\n    ```\n- 客户端\n\n    ```java\n    public class Client {\n        public static void main(String[] args) {\n            //组装责任链\n            Handler handler1 = new ConcreteHandler();\n            Handler handler2 = new ConcreteHandler();\n            handler1.setSuccessor(handler2);\n            //提交请求\n            handler1.handleRequest();\n        }\n    }\n    ```","slug":"设计模式/设计模式之责任链模式","published":1,"updated":"2018-09-12T03:03:21.840Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnjn0092wlkvala5bca8"},{"title":"设计模式之迭代器模式","date":"2018-05-29T10:22:43.000Z","_content":"\n#  设计模式之迭代器模式\n\n迭代子模式是对象的行为模式。迭代子模式可以顺序地访问一个聚合对象中的元素而不必暴露聚合对象的内部表示\n\n<!--more-->\n\n## 思考\n\n迭代器的关键思想就是把对聚合对象的遍历和访问从聚合对象中分离出来，放入单独的迭代器中处理。这样聚合对象职责会简单些，聚合对象和迭代器可以独立、灵活的扩展。\n\n本质是：控制访问聚合对象中的元素。\n\n## 使用场景\n\n- 当想要访问一个聚合对象，而又不想暴露它的内部表示的时候，可以让客户端通过迭代器访问，而不去关心聚合对象的内部实现\n- 增加一种遍历聚合对象的方式的时候可以使用迭代器模式\n- 为一类对象提供相同的遍历方式的时候使用迭代器模式，如List接口下所有的实现类都可以使用Itorator进行遍历。\n\n## 优缺点\n\n- 优点：更好的封装性，简化了聚合对象\n\n\n## UML图\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-28/90026272-file_1490676535269_96e1.jpg)\n\n- 抽象迭代子(Iterator)角色：此抽象角色定义出遍历元素所需的接口。\n- 具体迭代子(ConcreteIterator)角色：此角色实现了Iterator接口，并保持迭代过程中的游标位置。\n- 聚合(Aggregate)角色：此抽象角色给出创建迭代子(Iterator)对象的接口。\n- 具体聚合(ConcreteAggregate)角色：实现了创建迭代子(Iterator)对象的接口，返回一个合适的具体迭代子实例。\n- 客户端(Client)角色：持有对聚集及其迭代子对象的引用，调用迭代子对象的迭代接口，也有可能通过迭代子操作聚集元素的增加和删除。\n\n## 代码实现\n\n可以参考List接口下实现类迭代器的实现\n\n```java\n//抽象聚合对象类\npublic abstract class Aggregate {\n    //工厂方法，创建相应迭代子对象的接口\n    public abstract Iterator createIterator();\n}\n//聚合对象子类\npublic class ConcreteAggregate extends Aggregate {\n    \n    private Object[] objArray = null;\n    // 创建迭代器，传入聚合对象的具体内容\n    public ConcreteAggregate(Object[] objArray){\n        this.objArray = objArray;\n    }\n    \n    @Override\n    public Iterator createIterator() {\n        \n        return new ConcreteIterator(this);\n    }\n    //取值方法：向外界提供聚集元素\n    public Object getElement(int index){\n        \n        if(index < objArray.length){\n            return objArray[index];\n        }else{\n            return null;\n        }\n    }\n    //取值方法：向外界提供聚集的大小\n    public int size(){\n        return objArray.length;\n    }\n}\n//迭代器接口\npublic interface Iterator {\n    //迭代方法：移动到第一个元素\n    public void first();\n    //迭代方法：移动到下一个元素\n    public void next();\n    //迭代方法：是否为最后一个元素\n    public boolean isDone();\n    //迭代方法：返还当前元素\n    public Object currentItem();\n}\n//具体迭代器\npublic class ConcreteIterator implements Iterator {\n    //持有被迭代的具体的聚合对象\n    private ConcreteAggregate agg;\n    //内部索引，记录当前迭代到的索引位置\n    private int index = 0;\n    //记录当前聚集对象的大小\n    private int size = 0;\n    \n    public ConcreteIterator(ConcreteAggregate agg){\n        this.agg = agg;\n        this.size = agg.size();\n        index = 0;\n    }\n    //迭代方法：返还当前元素\n    @Override\n    public Object currentItem() {\n        return agg.getElement(index);\n    }\n    //迭代方法：移动到第一个元素\n    @Override\n    public void first() {\n        \n        index = 0;\n    }\n    //迭代方法：是否为最后一个元素\n    @Override\n    public boolean isDone() {\n        return (index >= size);\n    }\n    // 迭代方法：移动到下一个元素\n    @Override\n    public void next() {\n        if(index < size)\n        {\n            index ++;\n        }\n    }\n}\n//客户端\npublic class Client {\n    public static void main(String[] args) {\n         Object[] objArray = {\"One\",\"Two\",\"Three\",\"Four\",\"Five\",\"Six\"};\n        //创建聚合对象\n        Aggregate agg = new ConcreteAggregate(objArray);\n        //获取聚合对象的迭代器\n        Iterator it = agg.createIterator();\n        //循环输出聚合对象中的值\n        while(!it.isDone()){\n            System.out.println(it.currentItem());\n            it.next();\n        }\n    }\n}\n```","source":"_posts/设计模式/设计模式之迭代器模式.md","raw":"---\ntitle: 设计模式之迭代器模式\ndate: 2018-05-29 18:22:43\ntags:\n- 设计模式\ncategories:\n- 设计模式\n\n---\n\n#  设计模式之迭代器模式\n\n迭代子模式是对象的行为模式。迭代子模式可以顺序地访问一个聚合对象中的元素而不必暴露聚合对象的内部表示\n\n<!--more-->\n\n## 思考\n\n迭代器的关键思想就是把对聚合对象的遍历和访问从聚合对象中分离出来，放入单独的迭代器中处理。这样聚合对象职责会简单些，聚合对象和迭代器可以独立、灵活的扩展。\n\n本质是：控制访问聚合对象中的元素。\n\n## 使用场景\n\n- 当想要访问一个聚合对象，而又不想暴露它的内部表示的时候，可以让客户端通过迭代器访问，而不去关心聚合对象的内部实现\n- 增加一种遍历聚合对象的方式的时候可以使用迭代器模式\n- 为一类对象提供相同的遍历方式的时候使用迭代器模式，如List接口下所有的实现类都可以使用Itorator进行遍历。\n\n## 优缺点\n\n- 优点：更好的封装性，简化了聚合对象\n\n\n## UML图\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-28/90026272-file_1490676535269_96e1.jpg)\n\n- 抽象迭代子(Iterator)角色：此抽象角色定义出遍历元素所需的接口。\n- 具体迭代子(ConcreteIterator)角色：此角色实现了Iterator接口，并保持迭代过程中的游标位置。\n- 聚合(Aggregate)角色：此抽象角色给出创建迭代子(Iterator)对象的接口。\n- 具体聚合(ConcreteAggregate)角色：实现了创建迭代子(Iterator)对象的接口，返回一个合适的具体迭代子实例。\n- 客户端(Client)角色：持有对聚集及其迭代子对象的引用，调用迭代子对象的迭代接口，也有可能通过迭代子操作聚集元素的增加和删除。\n\n## 代码实现\n\n可以参考List接口下实现类迭代器的实现\n\n```java\n//抽象聚合对象类\npublic abstract class Aggregate {\n    //工厂方法，创建相应迭代子对象的接口\n    public abstract Iterator createIterator();\n}\n//聚合对象子类\npublic class ConcreteAggregate extends Aggregate {\n    \n    private Object[] objArray = null;\n    // 创建迭代器，传入聚合对象的具体内容\n    public ConcreteAggregate(Object[] objArray){\n        this.objArray = objArray;\n    }\n    \n    @Override\n    public Iterator createIterator() {\n        \n        return new ConcreteIterator(this);\n    }\n    //取值方法：向外界提供聚集元素\n    public Object getElement(int index){\n        \n        if(index < objArray.length){\n            return objArray[index];\n        }else{\n            return null;\n        }\n    }\n    //取值方法：向外界提供聚集的大小\n    public int size(){\n        return objArray.length;\n    }\n}\n//迭代器接口\npublic interface Iterator {\n    //迭代方法：移动到第一个元素\n    public void first();\n    //迭代方法：移动到下一个元素\n    public void next();\n    //迭代方法：是否为最后一个元素\n    public boolean isDone();\n    //迭代方法：返还当前元素\n    public Object currentItem();\n}\n//具体迭代器\npublic class ConcreteIterator implements Iterator {\n    //持有被迭代的具体的聚合对象\n    private ConcreteAggregate agg;\n    //内部索引，记录当前迭代到的索引位置\n    private int index = 0;\n    //记录当前聚集对象的大小\n    private int size = 0;\n    \n    public ConcreteIterator(ConcreteAggregate agg){\n        this.agg = agg;\n        this.size = agg.size();\n        index = 0;\n    }\n    //迭代方法：返还当前元素\n    @Override\n    public Object currentItem() {\n        return agg.getElement(index);\n    }\n    //迭代方法：移动到第一个元素\n    @Override\n    public void first() {\n        \n        index = 0;\n    }\n    //迭代方法：是否为最后一个元素\n    @Override\n    public boolean isDone() {\n        return (index >= size);\n    }\n    // 迭代方法：移动到下一个元素\n    @Override\n    public void next() {\n        if(index < size)\n        {\n            index ++;\n        }\n    }\n}\n//客户端\npublic class Client {\n    public static void main(String[] args) {\n         Object[] objArray = {\"One\",\"Two\",\"Three\",\"Four\",\"Five\",\"Six\"};\n        //创建聚合对象\n        Aggregate agg = new ConcreteAggregate(objArray);\n        //获取聚合对象的迭代器\n        Iterator it = agg.createIterator();\n        //循环输出聚合对象中的值\n        while(!it.isDone()){\n            System.out.println(it.currentItem());\n            it.next();\n        }\n    }\n}\n```","slug":"设计模式/设计模式之迭代器模式","published":1,"updated":"2018-09-12T03:03:21.841Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnjp0095wlkv9ych2xcn"},{"title":"设计模式之适配器模式","date":"2018-05-24T10:04:22.000Z","_content":"\n#  设计模式之适配器模式\n\n适配器模式是将一个类的接口变为客户端想要的另外一个接口，从而使原本因接口不匹配无法在一起工作的两个类能够在一起工作。适配器的目的是复用已有的功能。\n\n<!--more-->\n\n## 认识\n\n适配器分为**类适配器**和**对象适配器**两种\n\n**缺省适配**:为一个接口提供缺省实现，一般是一个抽象类\n\n**适配器模式跟代理模式的不同之处**：适配器模式中适配器和被适配对象中的接口方法不一致，适配器对被适配对象中的接口进行了改造或者扩展。代理模式中代理对象和被代理对象实现同一个接口，可以相互替换，代理对象只是对被代理对象中接口方法中的逻辑进行了改变，如添加权限控制。\n\n## 思考\n\n适配器模式可以对一个接口的所有子类进行适配，对象适配器中持有一个父类指针。不需要单独去对每个子类建立适配器。\n\n适配器模式实质：**转换接口，复用功能**，通过适配器将老的接口实现类中的方法转换为新的接口中的方法\n\n优先使用对象适配器，多用合成/聚合，少用继承。\n\n## 使用场景\n\n如果定义了新的接口跟已存在一个实现类不兼容，但是又在新的接口中又想使用实现类中方法，这时使用适配器模式实现复用实现类中的功能。\n\n## 优缺点\n\n- 优点\n  1. 更好的复用性：能够兼容使用老的接口\n  2. 开闭原则：避免了对老接口的修改，通过添加适配器实现兼容，达到更好的扩展性\n\n- 缺点\n  1. 过多的使用适配器模式，会导致调用零乱，明明调用A接口，在A接口中实际调用的是B接口，脱离控制。如果不是很有必要，可以不使用适配器，而是对系统进行重构。\n\n## UML图\n\n### 类适配器：\n\n采用继承方式，即适配器继承被适配类\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-21/7902768-file_1490106907233_16c5a.png)\n\n- 目标接口(Target):客户端真正想要的接口\n- 被适配接口(Adaptee):已有的接口实现类，与客户端最新需要的接口不兼容\n- 适配器(Adapter):适配器，实现Target和继承Adaptee，客户端调动Adapter，既可以调用Target中的接口方法，也可以调用Adapter继承Adaptee中老的方法\n\n### 对象适配器：\n\n使用对象动态组合方式，即适配器持有一个被适配对象\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-21/39701848-file_1490106909171_501e.png)\n\n- 目标接口(Target):客户端真正想要的接口\n- 被适配接口(Adaptee):已有的接口实现类，与客户端最新需要的接口不兼容\n- 适配器(Adapter):适配器，实现Target，持有一个Adaptee对象，对于新的接口，调用Adapter中实现的方法，对于老的方法，使用Adaptee对象进行调用\n\n### 缺省适配\n\n很多情况下，接口中定义了特别多方法，而一个类去实现一个接口，必须要实现所有的方法，但是有些类只是使用到了接口中很少的方法，对于不使用的方法就只能空着，这样会对客户端的调用造成困扰。这时就需要使用一个抽象类去实现接口，在抽象类中给出所有方法的基本实现。这样这个抽象类的子类就只需要关注自己关心的方法。**缺省适配的用意是为了避免子类去处理自己不关注的接口方法**\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-21/40142879-file_1490108070925_11a99.png)\n\n## 代码实现\n\n### 类适配器：\n\n适配器继承被适配对象，实现目标接口，客户端使用适配器进行调用，对于目标接口中新的方法，适配器进行实现，对于老的接口方法，调用适配器继承而来的被适配类中的方法，从而实现接口兼容。\n\n```java\n//客户端需要的接口\npublic interface Target {\n    //这是源类Adaptee也有的方法\n    public void sampleOperation1(); \n    //这是源类Adapteee没有的方法\n    public void sampleOperation2(); \n}\n//已经存在的接口实现，这个接口实现需要被适配\npublic class Adaptee {\n    public void sampleOperation1(){}\n}\n//适配器，继承被适配类，实现目标接口\npublic class Adapter extends Adaptee implements Target {\n    //由于源类Adaptee没有方法sampleOperation2(), 因此适配器补充上这个方法\n    @Override\n    public void sampleOperation2() {\n        //写相关的代码\n    }\n}\n```\n\n### 对象适配器：\n\n适配器实现目标对象，通过构造方法持有一个被适配对象，客户端使用适配器进行调用，对于新的接口调用适配器中的方法，对于老的接口实现，适配器使用被适配对象调用被适配对象中的方法，从而实现接口兼容。\n\n```java\n//客户端需要的接口\npublic interface Target {\n\tpublic void request1();\n  \tpublic void request2();\n}\n//已经存在的接口，这个接口需要被适配\npublic class Adaptee {\n\t//原本已经存在，已经实现的方法\n\tpublic void request1() {\n\t\t//具体的功能处理\n\t}\n}\n//适配器\npublic class Adapter implements Target {\n\t//持有需要被适配的接口对象\n\tprivate Adaptee adaptee;\n\t/**\n\t * 构造方法，传入需要被适配的对象\n\t * @param adaptee 需要被适配的对象\n\t */\n\tpublic Adapter(Adaptee adaptee) {\n\t\tthis.adaptee = adaptee;\n\t}\n\n\tpublic void request1() {\n\t\t//可能转调已经实现了的方法，进行适配\n\t\tadaptee.request1();\n\t}\n \tpublic void request2() {\n\t\t//业务代码\n\t}\n}\n//使用适配器的客户端\npublic class Client {\t\n\tpublic static void main(String[] args) {\n\t\t//创建需被适配的对象\n\t\tAdaptee adaptee = new Adaptee();\n\t\t//创建客户端需要调用的接口对象\n\t\tTarget target = new Adapter(adaptee);\n\t\t//请求处理\n\t\ttarget.request();\n\t}\n}\n\n```\n\n### 缺省适配：\n\n使用抽象类实现接口，对接口中方法进行默认实现。","source":"_posts/设计模式/设计模式之适配器模式.md","raw":"---\ntitle: 设计模式之适配器模式\ndate: 2018-05-24 18:04:22\ntags:\n- 设计模式\ncategories:\n- 设计模式\n\n---\n\n#  设计模式之适配器模式\n\n适配器模式是将一个类的接口变为客户端想要的另外一个接口，从而使原本因接口不匹配无法在一起工作的两个类能够在一起工作。适配器的目的是复用已有的功能。\n\n<!--more-->\n\n## 认识\n\n适配器分为**类适配器**和**对象适配器**两种\n\n**缺省适配**:为一个接口提供缺省实现，一般是一个抽象类\n\n**适配器模式跟代理模式的不同之处**：适配器模式中适配器和被适配对象中的接口方法不一致，适配器对被适配对象中的接口进行了改造或者扩展。代理模式中代理对象和被代理对象实现同一个接口，可以相互替换，代理对象只是对被代理对象中接口方法中的逻辑进行了改变，如添加权限控制。\n\n## 思考\n\n适配器模式可以对一个接口的所有子类进行适配，对象适配器中持有一个父类指针。不需要单独去对每个子类建立适配器。\n\n适配器模式实质：**转换接口，复用功能**，通过适配器将老的接口实现类中的方法转换为新的接口中的方法\n\n优先使用对象适配器，多用合成/聚合，少用继承。\n\n## 使用场景\n\n如果定义了新的接口跟已存在一个实现类不兼容，但是又在新的接口中又想使用实现类中方法，这时使用适配器模式实现复用实现类中的功能。\n\n## 优缺点\n\n- 优点\n  1. 更好的复用性：能够兼容使用老的接口\n  2. 开闭原则：避免了对老接口的修改，通过添加适配器实现兼容，达到更好的扩展性\n\n- 缺点\n  1. 过多的使用适配器模式，会导致调用零乱，明明调用A接口，在A接口中实际调用的是B接口，脱离控制。如果不是很有必要，可以不使用适配器，而是对系统进行重构。\n\n## UML图\n\n### 类适配器：\n\n采用继承方式，即适配器继承被适配类\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-21/7902768-file_1490106907233_16c5a.png)\n\n- 目标接口(Target):客户端真正想要的接口\n- 被适配接口(Adaptee):已有的接口实现类，与客户端最新需要的接口不兼容\n- 适配器(Adapter):适配器，实现Target和继承Adaptee，客户端调动Adapter，既可以调用Target中的接口方法，也可以调用Adapter继承Adaptee中老的方法\n\n### 对象适配器：\n\n使用对象动态组合方式，即适配器持有一个被适配对象\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-21/39701848-file_1490106909171_501e.png)\n\n- 目标接口(Target):客户端真正想要的接口\n- 被适配接口(Adaptee):已有的接口实现类，与客户端最新需要的接口不兼容\n- 适配器(Adapter):适配器，实现Target，持有一个Adaptee对象，对于新的接口，调用Adapter中实现的方法，对于老的方法，使用Adaptee对象进行调用\n\n### 缺省适配\n\n很多情况下，接口中定义了特别多方法，而一个类去实现一个接口，必须要实现所有的方法，但是有些类只是使用到了接口中很少的方法，对于不使用的方法就只能空着，这样会对客户端的调用造成困扰。这时就需要使用一个抽象类去实现接口，在抽象类中给出所有方法的基本实现。这样这个抽象类的子类就只需要关注自己关心的方法。**缺省适配的用意是为了避免子类去处理自己不关注的接口方法**\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-21/40142879-file_1490108070925_11a99.png)\n\n## 代码实现\n\n### 类适配器：\n\n适配器继承被适配对象，实现目标接口，客户端使用适配器进行调用，对于目标接口中新的方法，适配器进行实现，对于老的接口方法，调用适配器继承而来的被适配类中的方法，从而实现接口兼容。\n\n```java\n//客户端需要的接口\npublic interface Target {\n    //这是源类Adaptee也有的方法\n    public void sampleOperation1(); \n    //这是源类Adapteee没有的方法\n    public void sampleOperation2(); \n}\n//已经存在的接口实现，这个接口实现需要被适配\npublic class Adaptee {\n    public void sampleOperation1(){}\n}\n//适配器，继承被适配类，实现目标接口\npublic class Adapter extends Adaptee implements Target {\n    //由于源类Adaptee没有方法sampleOperation2(), 因此适配器补充上这个方法\n    @Override\n    public void sampleOperation2() {\n        //写相关的代码\n    }\n}\n```\n\n### 对象适配器：\n\n适配器实现目标对象，通过构造方法持有一个被适配对象，客户端使用适配器进行调用，对于新的接口调用适配器中的方法，对于老的接口实现，适配器使用被适配对象调用被适配对象中的方法，从而实现接口兼容。\n\n```java\n//客户端需要的接口\npublic interface Target {\n\tpublic void request1();\n  \tpublic void request2();\n}\n//已经存在的接口，这个接口需要被适配\npublic class Adaptee {\n\t//原本已经存在，已经实现的方法\n\tpublic void request1() {\n\t\t//具体的功能处理\n\t}\n}\n//适配器\npublic class Adapter implements Target {\n\t//持有需要被适配的接口对象\n\tprivate Adaptee adaptee;\n\t/**\n\t * 构造方法，传入需要被适配的对象\n\t * @param adaptee 需要被适配的对象\n\t */\n\tpublic Adapter(Adaptee adaptee) {\n\t\tthis.adaptee = adaptee;\n\t}\n\n\tpublic void request1() {\n\t\t//可能转调已经实现了的方法，进行适配\n\t\tadaptee.request1();\n\t}\n \tpublic void request2() {\n\t\t//业务代码\n\t}\n}\n//使用适配器的客户端\npublic class Client {\t\n\tpublic static void main(String[] args) {\n\t\t//创建需被适配的对象\n\t\tAdaptee adaptee = new Adaptee();\n\t\t//创建客户端需要调用的接口对象\n\t\tTarget target = new Adapter(adaptee);\n\t\t//请求处理\n\t\ttarget.request();\n\t}\n}\n\n```\n\n### 缺省适配：\n\n使用抽象类实现接口，对接口中方法进行默认实现。","slug":"设计模式/设计模式之适配器模式","published":1,"updated":"2018-09-12T03:03:21.841Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnjq0098wlkvqbc474p9"},{"title":"设计模式之构建者模式","date":"2018-05-24T02:50:31.000Z","_content":"\n#  设计模式之构建者模式\n\n当创建一个对象的时候，需要外部提供特别多的参数来决定构建对象的细节，这时就可以使用构建者模式。\n\n<!--more-->\n\n## 认识\n\n- 构建者模式可以**分步骤**构建**复杂对象**，**构建的过程是固定不变的director实现，变化的部分放到builder中实现**，定义多个builder的实现类实现不同的过程，而director调用的builder是不变化的\n- director类似一个工厂模式的实现，在director调用不同的builder实现进行构造。保证director的逻辑不要变化，将变化封装到builder实现类中。\n\n\n## 思考\n\n- 构建者模式是将一个复杂对象的构建和它的表示分离，使得同样的构建过程可以创建不同的表示。抽象工厂可以操作多个产品，而构建者只可以操作一个产品\n\n- **与工厂模式区别是**，工厂模式创建对象时并不需要客户端提供特别多的信息，而构建者模式需要客户端提供创建对象的细节内容。\n\n## 优缺点\n\n- 优点\n  1. 暴露了创建对象的细节，这样使得建造者模式更加灵活，可替换。\n  2. 链式创建对象，具有分步骤创建对象的思想\n  3. 客户端和和产品实现类解耦\n\n- 缺点\n  1. 将对象的创建细节暴露\n\n## 使用场景\n\n1. 需要生成的产品对象有复杂的内部结构。如果很简单的话，那么使用这个模式可能就没有必要了\n2. 需要生成的产品对象的属性相互依赖，建造者模式可以强迫生成顺序\n3. 使用链式结构\n\n## UML图\n\n- **产品类(Product)：**创建产品类往往很复杂，要么需要很多参数，要么需要指定的顺序，要么需要很多权限判断。\n- **抽象建造者(Builder)：**一般至少会有两个抽象方法，一个用来建造产品，一个是用来返回产品。具体的构建细节交由实现类实现，这样更容易实现扩展。\n- **建造者(ConcreateBuilder)：**两项任务：组建产品 和 返回组建好的产品。\n- **导演类(Director)：**负责调用适当的建造者来组建产品，导演类一般不与产品类发生依赖关系，与导演类直接交互的是建造者类。一般来说，导演类被用来封装程序中**易变**的部分。\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-16/78066064-file_1489639950386_1218f.jpg)\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-16/96081028-file_1489641617104_8b91.jpg)\n\n## 代码实现\n\n```java\nclass Product {  \n    private String name;  \n    private String type;  \n    public void showProduct(){  \n        System.out.println(\"名称：\"+name);  \n        System.out.println(\"型号：\"+type);  \n    }  \n    public void setName(String name) {  \n        this.name = name;  \n    }  \n    public void setType(String type) {  \n        this.type = type;  \n    }  \n}  \n  \nabstract class Builder {  \n    public abstract void setPart(String arg1, String arg2);  \n    public abstract Product getProduct();  \n}  \nclass ConcreteBuilder extends Builder {  \n    //构建器中new一个产品对象，也可以通过构造方法传入\n    private Product product = new Product();  \n    //提供返回产品的方法\n    public Product getProduct() {  \n        return this.product;  \n    }  \n  \t//buildName 返回this.product 链式结构\n    public Product buildName(String name) {  \n        this.product.setName(name); \n     \treturn this.product; \n    }\n     //buildType 返回this.product 链式结构\n  \tpublic Product buildType(String type) {  \n        this.product.setType(type); \n     \treturn this.product; \n    }  \n}  \n//Director通过Builder创建对象 Director 也可以理解为一个工厂模式的实现\npublic class Director {  \n    private Builder builder = new ConcreteBuilder();  \n    public Product getAProduct(){  \n        builder.buildName(\"宝马汽车\").build(\"X7\");  \n        return builder.getProduct();  \n    }  \n    public Product getBProduct(){  \n        builder.buildName(\"奥迪汽车\").build(\"Q5\");\n        return builder.getProduct();  \n    }  \n}  \n//客户端调用Director\npublic class Client {  \n    public static void main(String[] args){  \n        Director director = new Director();  \n        Product product1 = director.getAProduct();  \n        product1.showProduct();  \n  \n        Product product2 = director.getBProduct();  \n        product2.showProduct();  \n    }  \n} \n```\n\n## 源码例子\n\nmybatis中大量使用了构建者模式,例如构造Configuration对象\n\n```java\npublic abstract class BaseBuilder {\n  protected final Configuration configuration;\n  protected final TypeAliasRegistry typeAliasRegistry;\n  protected final TypeHandlerRegistry typeHandlerRegistry;\n\n  public BaseBuilder(Configuration configuration) {\n    this.configuration = configuration;\n    this.typeAliasRegistry = this.configuration.getTypeAliasRegistry();\n    this.typeHandlerRegistry = this.configuration.getTypeHandlerRegistry();\n  }\n\n  public Configuration getConfiguration() {\n    return configuration;\n  }\n}\n//在XMLConfigBuilder对Configuration的各个组件进行组装\npublic class XMLConfigBuilder extends BaseBuilder {\n\n  private boolean parsed;\n  private XPathParser parser;\n  private String environment;\n  private ReflectorFactory localReflectorFactory = new DefaultReflectorFactory();\n  private XMLConfigBuilder(XPathParser parser, String environment, Properties props) {\n    super(new Configuration());\n    ErrorContext.instance().resource(\"SQL Mapper Configuration\");\n    this.configuration.setVariables(props);\n    this.parsed = false;\n    this.environment = environment;\n    this.parser = parser;\n  }\n\n  private void parseConfiguration(XNode root) {\n    try {\n      //issue #117 read properties first\n      propertiesElement(root.evalNode(\"properties\"));\n      typeAliasesElement(root.evalNode(\"typeAliases\"));\n      pluginElement(root.evalNode(\"plugins\"));\n      objectFactoryElement(root.evalNode(\"objectFactory\"));\n      objectWrapperFactoryElement(root.evalNode(\"objectWrapperFactory\"));\n      reflectionFactoryElement(root.evalNode(\"reflectionFactory\"));\n      settingsElement(root.evalNode(\"settings\"));\n      // read it after objectFactory and objectWrapperFactory issue #631\n      environmentsElement(root.evalNode(\"environments\"));\n      databaseIdProviderElement(root.evalNode(\"databaseIdProvider\"));\n      typeHandlerElement(root.evalNode(\"typeHandlers\"));\n      mapperElement(root.evalNode(\"mappers\"));\n    } catch (Exception e) {\n      throw new BuilderException(\"Error parsing SQL Mapper Configuration. Cause: \" + e, e);\n    }\n  }\n}\n```\n\n这种构造器模式的使用,实现了显示与构建行为的分离\n\n```java\npublic final class Environment {\n  private final String id;\n  private final TransactionFactory transactionFactory;\n  private final DataSource dataSource;\n\n  public Environment(String id, TransactionFactory transactionFactory, DataSource dataSource) {\n    if (id == null) {\n      throw new IllegalArgumentException(\"Parameter 'id' must not be null\");\n    }\n    if (transactionFactory == null) {\n        throw new IllegalArgumentException(\"Parameter 'transactionFactory' must not be null\");\n    }\n    this.id = id;\n    if (dataSource == null) {\n      throw new IllegalArgumentException(\"Parameter 'dataSource' must not be null\");\n    }\n    this.transactionFactory = transactionFactory;\n    this.dataSource = dataSource;\n  }\n\n  public static class Builder {\n      private String id;\n      private TransactionFactory transactionFactory;\n      private DataSource dataSource;\n\n    public Builder(String id) {\n      this.id = id;\n    }\n\n    public Builder transactionFactory(TransactionFactory transactionFactory) {\n      this.transactionFactory = transactionFactory;\n      return this;\n    }\n\n    public Builder dataSource(DataSource dataSource) {\n      this.dataSource = dataSource;\n      return this;\n    }\n\n    public String id() {\n      return this.id;\n    }\n\n    public Environment build() {\n        //可以在此处添加创建对象的一些限制条件\n      return new Environment(this.id, this.transactionFactory, this.dataSource);\n    }\n\n  }\n\n  public String getId() {\n    return this.id;\n  }\n\n  public TransactionFactory getTransactionFactory() {\n    return this.transactionFactory;\n  }\n\n  public DataSource getDataSource() {\n    return this.dataSource;\n  }\n}\n\npublic class client{\n    public void run(){\n         Environment.Builder environmentBuilder = new Environment.Builder(id)\n              .transactionFactory(txFactory)\n              .dataSource(dataSource);\n         Environment ev = environmentBuilder.build();\n    }\n}\n```","source":"_posts/设计模式/设计模式之构建者模式.md","raw":"---\ntitle: 设计模式之构建者模式\ndate: 2018-05-24 10:50:31\ntags:\n- 设计模式\ncategories:\n- 设计模式\n\n---\n\n#  设计模式之构建者模式\n\n当创建一个对象的时候，需要外部提供特别多的参数来决定构建对象的细节，这时就可以使用构建者模式。\n\n<!--more-->\n\n## 认识\n\n- 构建者模式可以**分步骤**构建**复杂对象**，**构建的过程是固定不变的director实现，变化的部分放到builder中实现**，定义多个builder的实现类实现不同的过程，而director调用的builder是不变化的\n- director类似一个工厂模式的实现，在director调用不同的builder实现进行构造。保证director的逻辑不要变化，将变化封装到builder实现类中。\n\n\n## 思考\n\n- 构建者模式是将一个复杂对象的构建和它的表示分离，使得同样的构建过程可以创建不同的表示。抽象工厂可以操作多个产品，而构建者只可以操作一个产品\n\n- **与工厂模式区别是**，工厂模式创建对象时并不需要客户端提供特别多的信息，而构建者模式需要客户端提供创建对象的细节内容。\n\n## 优缺点\n\n- 优点\n  1. 暴露了创建对象的细节，这样使得建造者模式更加灵活，可替换。\n  2. 链式创建对象，具有分步骤创建对象的思想\n  3. 客户端和和产品实现类解耦\n\n- 缺点\n  1. 将对象的创建细节暴露\n\n## 使用场景\n\n1. 需要生成的产品对象有复杂的内部结构。如果很简单的话，那么使用这个模式可能就没有必要了\n2. 需要生成的产品对象的属性相互依赖，建造者模式可以强迫生成顺序\n3. 使用链式结构\n\n## UML图\n\n- **产品类(Product)：**创建产品类往往很复杂，要么需要很多参数，要么需要指定的顺序，要么需要很多权限判断。\n- **抽象建造者(Builder)：**一般至少会有两个抽象方法，一个用来建造产品，一个是用来返回产品。具体的构建细节交由实现类实现，这样更容易实现扩展。\n- **建造者(ConcreateBuilder)：**两项任务：组建产品 和 返回组建好的产品。\n- **导演类(Director)：**负责调用适当的建造者来组建产品，导演类一般不与产品类发生依赖关系，与导演类直接交互的是建造者类。一般来说，导演类被用来封装程序中**易变**的部分。\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-16/78066064-file_1489639950386_1218f.jpg)\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-16/96081028-file_1489641617104_8b91.jpg)\n\n## 代码实现\n\n```java\nclass Product {  \n    private String name;  \n    private String type;  \n    public void showProduct(){  \n        System.out.println(\"名称：\"+name);  \n        System.out.println(\"型号：\"+type);  \n    }  \n    public void setName(String name) {  \n        this.name = name;  \n    }  \n    public void setType(String type) {  \n        this.type = type;  \n    }  \n}  \n  \nabstract class Builder {  \n    public abstract void setPart(String arg1, String arg2);  \n    public abstract Product getProduct();  \n}  \nclass ConcreteBuilder extends Builder {  \n    //构建器中new一个产品对象，也可以通过构造方法传入\n    private Product product = new Product();  \n    //提供返回产品的方法\n    public Product getProduct() {  \n        return this.product;  \n    }  \n  \t//buildName 返回this.product 链式结构\n    public Product buildName(String name) {  \n        this.product.setName(name); \n     \treturn this.product; \n    }\n     //buildType 返回this.product 链式结构\n  \tpublic Product buildType(String type) {  \n        this.product.setType(type); \n     \treturn this.product; \n    }  \n}  \n//Director通过Builder创建对象 Director 也可以理解为一个工厂模式的实现\npublic class Director {  \n    private Builder builder = new ConcreteBuilder();  \n    public Product getAProduct(){  \n        builder.buildName(\"宝马汽车\").build(\"X7\");  \n        return builder.getProduct();  \n    }  \n    public Product getBProduct(){  \n        builder.buildName(\"奥迪汽车\").build(\"Q5\");\n        return builder.getProduct();  \n    }  \n}  \n//客户端调用Director\npublic class Client {  \n    public static void main(String[] args){  \n        Director director = new Director();  \n        Product product1 = director.getAProduct();  \n        product1.showProduct();  \n  \n        Product product2 = director.getBProduct();  \n        product2.showProduct();  \n    }  \n} \n```\n\n## 源码例子\n\nmybatis中大量使用了构建者模式,例如构造Configuration对象\n\n```java\npublic abstract class BaseBuilder {\n  protected final Configuration configuration;\n  protected final TypeAliasRegistry typeAliasRegistry;\n  protected final TypeHandlerRegistry typeHandlerRegistry;\n\n  public BaseBuilder(Configuration configuration) {\n    this.configuration = configuration;\n    this.typeAliasRegistry = this.configuration.getTypeAliasRegistry();\n    this.typeHandlerRegistry = this.configuration.getTypeHandlerRegistry();\n  }\n\n  public Configuration getConfiguration() {\n    return configuration;\n  }\n}\n//在XMLConfigBuilder对Configuration的各个组件进行组装\npublic class XMLConfigBuilder extends BaseBuilder {\n\n  private boolean parsed;\n  private XPathParser parser;\n  private String environment;\n  private ReflectorFactory localReflectorFactory = new DefaultReflectorFactory();\n  private XMLConfigBuilder(XPathParser parser, String environment, Properties props) {\n    super(new Configuration());\n    ErrorContext.instance().resource(\"SQL Mapper Configuration\");\n    this.configuration.setVariables(props);\n    this.parsed = false;\n    this.environment = environment;\n    this.parser = parser;\n  }\n\n  private void parseConfiguration(XNode root) {\n    try {\n      //issue #117 read properties first\n      propertiesElement(root.evalNode(\"properties\"));\n      typeAliasesElement(root.evalNode(\"typeAliases\"));\n      pluginElement(root.evalNode(\"plugins\"));\n      objectFactoryElement(root.evalNode(\"objectFactory\"));\n      objectWrapperFactoryElement(root.evalNode(\"objectWrapperFactory\"));\n      reflectionFactoryElement(root.evalNode(\"reflectionFactory\"));\n      settingsElement(root.evalNode(\"settings\"));\n      // read it after objectFactory and objectWrapperFactory issue #631\n      environmentsElement(root.evalNode(\"environments\"));\n      databaseIdProviderElement(root.evalNode(\"databaseIdProvider\"));\n      typeHandlerElement(root.evalNode(\"typeHandlers\"));\n      mapperElement(root.evalNode(\"mappers\"));\n    } catch (Exception e) {\n      throw new BuilderException(\"Error parsing SQL Mapper Configuration. Cause: \" + e, e);\n    }\n  }\n}\n```\n\n这种构造器模式的使用,实现了显示与构建行为的分离\n\n```java\npublic final class Environment {\n  private final String id;\n  private final TransactionFactory transactionFactory;\n  private final DataSource dataSource;\n\n  public Environment(String id, TransactionFactory transactionFactory, DataSource dataSource) {\n    if (id == null) {\n      throw new IllegalArgumentException(\"Parameter 'id' must not be null\");\n    }\n    if (transactionFactory == null) {\n        throw new IllegalArgumentException(\"Parameter 'transactionFactory' must not be null\");\n    }\n    this.id = id;\n    if (dataSource == null) {\n      throw new IllegalArgumentException(\"Parameter 'dataSource' must not be null\");\n    }\n    this.transactionFactory = transactionFactory;\n    this.dataSource = dataSource;\n  }\n\n  public static class Builder {\n      private String id;\n      private TransactionFactory transactionFactory;\n      private DataSource dataSource;\n\n    public Builder(String id) {\n      this.id = id;\n    }\n\n    public Builder transactionFactory(TransactionFactory transactionFactory) {\n      this.transactionFactory = transactionFactory;\n      return this;\n    }\n\n    public Builder dataSource(DataSource dataSource) {\n      this.dataSource = dataSource;\n      return this;\n    }\n\n    public String id() {\n      return this.id;\n    }\n\n    public Environment build() {\n        //可以在此处添加创建对象的一些限制条件\n      return new Environment(this.id, this.transactionFactory, this.dataSource);\n    }\n\n  }\n\n  public String getId() {\n    return this.id;\n  }\n\n  public TransactionFactory getTransactionFactory() {\n    return this.transactionFactory;\n  }\n\n  public DataSource getDataSource() {\n    return this.dataSource;\n  }\n}\n\npublic class client{\n    public void run(){\n         Environment.Builder environmentBuilder = new Environment.Builder(id)\n              .transactionFactory(txFactory)\n              .dataSource(dataSource);\n         Environment ev = environmentBuilder.build();\n    }\n}\n```","slug":"设计模式/设计模式之构建者模式","published":1,"updated":"2018-09-12T03:03:21.837Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnjr009bwlkvtra47vs5"},{"title":"设计模式之门面模式","date":"2018-05-24T09:12:11.000Z","_content":"\n#  设计模式之门面模式\n\n提供一个门面去调用系统各个子模块，客户端调用门面，减少客户端与系统中各个子模块的交互，松散耦合。提现了迪米特法则。\n\n<!--more-->\n\n## 思考\n\n- Facade知道各个子模块，而各个子模块不应该知道Facade的存在\n- 客户端也可以直接调用各个子模块，**有外观也可以不使用**\n\n## 使用场景\n\n当需要调用系统内部多个子模块的时候，为了避免客户端分别调用子模块，提供一个门面，让门面分别去调用各个子模块，然后客户端直接调用门面，隐藏内部的细节。\n\n## 优缺点\n\n- 优点\n  1. **松散耦合**：松散了客户端与子系统的耦合关系，让子系统内部的模块能更容易扩展和维护\n  2. **简单易用**：门面模式让子系统更加易用，客户端不再需要了解子系统内部的实现，也不需要跟众多子系统内部的模块进行交互，只需要跟门面类交互就可以了\n  3. **更好的划分访问层次**：通过合理使用Facade，可以帮助我们更好地划分访问的层次。有些方法是对系统外的，有些方法是系统内部使用的。把需要暴露给外部的功能集中到门面中，这样既方便客户端使用，也很好地隐藏了内部的细节。\n\n\n## UML图\n\n门面模式是对象的结构模式，外部与一个子系统的通信必须通过一个统一的门面对象进行。门面模式提供一个高层次的接口，使得子系统更易于使用。\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-17/2122883-file_1489761989307_9ec.png)\n\n门面(facade)： 客户端通过门面，访问内部系统的各个模块。\n\n子系统(SubSystem)：每个子系统都可以被客户端直接调用，或者被门面角色调用。**子系统并不知道门面的存在，对于子系统而言，门面仅仅是另外一个客户端而已**。\n\n## 代码实现\n\n```java\npublic class ModuleA {\n    //示意方法\n    public void testA(){\n        System.out.println(\"调用ModuleA中的testA方法\");\n    }\n}\npublic class ModuleB {\n    //示意方法\n    public void testB(){\n        System.out.println(\"调用ModuleB中的testB方法\");\n    }\n}\npublic class ModuleC {\n    //示意方法\n    public void testC(){\n        System.out.println(\"调用ModuleC中的testC方法\");\n    }\n}\npublic class Facade {\n    //示意方法，满足客户端需要的功能\n    public void test(){\n        ModuleA a = new ModuleA();\n        a.testA();\n        ModuleB b = new ModuleB();\n        b.testB();\n        ModuleC c = new ModuleC();\n        c.testC();\n    }\n}\n```\n","source":"_posts/设计模式/设计模式之门面模式.md","raw":"---\ntitle: 设计模式之门面模式\ndate: 2018-05-24 17:12:11\ntags:\n- 设计模式\ncategories:\n- 设计模式\n\n---\n\n#  设计模式之门面模式\n\n提供一个门面去调用系统各个子模块，客户端调用门面，减少客户端与系统中各个子模块的交互，松散耦合。提现了迪米特法则。\n\n<!--more-->\n\n## 思考\n\n- Facade知道各个子模块，而各个子模块不应该知道Facade的存在\n- 客户端也可以直接调用各个子模块，**有外观也可以不使用**\n\n## 使用场景\n\n当需要调用系统内部多个子模块的时候，为了避免客户端分别调用子模块，提供一个门面，让门面分别去调用各个子模块，然后客户端直接调用门面，隐藏内部的细节。\n\n## 优缺点\n\n- 优点\n  1. **松散耦合**：松散了客户端与子系统的耦合关系，让子系统内部的模块能更容易扩展和维护\n  2. **简单易用**：门面模式让子系统更加易用，客户端不再需要了解子系统内部的实现，也不需要跟众多子系统内部的模块进行交互，只需要跟门面类交互就可以了\n  3. **更好的划分访问层次**：通过合理使用Facade，可以帮助我们更好地划分访问的层次。有些方法是对系统外的，有些方法是系统内部使用的。把需要暴露给外部的功能集中到门面中，这样既方便客户端使用，也很好地隐藏了内部的细节。\n\n\n## UML图\n\n门面模式是对象的结构模式，外部与一个子系统的通信必须通过一个统一的门面对象进行。门面模式提供一个高层次的接口，使得子系统更易于使用。\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-17/2122883-file_1489761989307_9ec.png)\n\n门面(facade)： 客户端通过门面，访问内部系统的各个模块。\n\n子系统(SubSystem)：每个子系统都可以被客户端直接调用，或者被门面角色调用。**子系统并不知道门面的存在，对于子系统而言，门面仅仅是另外一个客户端而已**。\n\n## 代码实现\n\n```java\npublic class ModuleA {\n    //示意方法\n    public void testA(){\n        System.out.println(\"调用ModuleA中的testA方法\");\n    }\n}\npublic class ModuleB {\n    //示意方法\n    public void testB(){\n        System.out.println(\"调用ModuleB中的testB方法\");\n    }\n}\npublic class ModuleC {\n    //示意方法\n    public void testC(){\n        System.out.println(\"调用ModuleC中的testC方法\");\n    }\n}\npublic class Facade {\n    //示意方法，满足客户端需要的功能\n    public void test(){\n        ModuleA a = new ModuleA();\n        a.testA();\n        ModuleB b = new ModuleB();\n        b.testB();\n        ModuleC c = new ModuleC();\n        c.testC();\n    }\n}\n```\n","slug":"设计模式/设计模式之门面模式","published":1,"updated":"2018-09-12T03:03:21.841Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnjs009ewlkvks617bmh"},{"title":"设计模式之简单工厂模式","date":"2018-05-23T08:41:21.000Z","_content":"\n#  设计模式之简单工厂模式\n\n封装创建对象的细节，外部调用只需要关心自己想要什么和最终能得到什么结果，而不需要关心实现的过程。\n\n<!--more-->\n\n## 认识\n\n在工厂类中提供一个工厂方法，根据参数类型实例化不同的对象返回给客户端。封装了创建对象的细节。\n\n## 思考\n\n- 定义：提供一个创建对象实例的功能，无须关心细节和具体实现。\n- 面向接口编程，只知道接口，不知道实现类\n- 本质是：选择实现\n\n## 使用场景\n\n1. 当需要封装实现细节，外部不知道具体实现只能通过接口来操作封装体的时候，可以选择简单工厂，让客户端通过简单工厂提供的方法获取相应的接口实现。\n2. 当想要把创建对象的职责、权限集中在内部管理和控制时，选择简单工厂，例如简单工厂加单例模式控制创建对象。\n\n## 优缺点\n\n- 优点\n  1. 封装实现细节\n  2. 解耦\n\n- 缺点\n  1. 增加客户端复杂度\n  2. 不方便扩展子工厂\n\n## UML图\n\n客户端只能够访问接口和工厂类，具体实现细节对客户端透明，工厂方法一般都是静态的，根据客户端调用传入的参数去实例化不同的实现类对象。\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-15/22164466-file_1489555555197_12d8.png)\n\n## 代码实现\n\n在工厂方法中也可以通过读取外部配置文件中的class name进行反射创建对象，实现可配置。例如将数据库驱动的class 配置在外部properties中，在工厂方法中读取到驱动类反射创建，之后想更改驱动的时候直接更改配置文件即可。\n\n```java\n//静态工厂\npublic class Factory {\n    public static IOperate createClass(String regix){\n        IOperate operate =null;\n        char myRegix = regix.charAt(0);\n        switch(myRegix){\n        case '+' :\n            operate = new Add();\n            break;\n        case '-' :\n            operate = new Sub();\n            break;\n        case '*' :\n            operate = new Mul();\n            break;\n        case '/' :\n            operate = new Div();\n            break;\n        default :\n            throw new RuntimeException(\"你输出的运算符不符合该计算器\");\n        }\n        return  operate;\n    }\n    public Factory() {\n    }\n}\n// 接口\npublic interface IOperate {\n    public double firstNum = 0;\n    public double secondNum = 0;\n    public double getResult(double firstNum,double secondNum);\n}\n//实现类\nclass Add implements IOperate{\n    public double getResult(double firstNum, double secondNum) {\n        double result = firstNum + secondNum;\n        return result;\n    }\n}\nclass Sub implements IOperate{\n    public double getResult(double firstNum, double secondNum) {\n        double result = firstNum - secondNum;\n        return result;\n    }\n}\nclass Mul implements IOperate{\n    public double getResult(double firstNum, double secondNum) {\n        double result = firstNum * secondNum;\n        return result;\n    }\n}\nclass Div implements IOperate{\n    public double getResult(double firstNum, double secondNum) {\n        if(secondNum == 0){\n            throw new RuntimeException(\"被除数不能为0\");\n        }\n        double result = firstNum / secondNum;\n        return result;\n    }\n}\n```\n\n","source":"_posts/设计模式/设计模式之简单工厂模式.md","raw":"---\ntitle: 设计模式之简单工厂模式\ndate: 2018-05-23 16:41:21\ntags:\n- 设计模式\ncategories:\n- 设计模式\n\n---\n\n#  设计模式之简单工厂模式\n\n封装创建对象的细节，外部调用只需要关心自己想要什么和最终能得到什么结果，而不需要关心实现的过程。\n\n<!--more-->\n\n## 认识\n\n在工厂类中提供一个工厂方法，根据参数类型实例化不同的对象返回给客户端。封装了创建对象的细节。\n\n## 思考\n\n- 定义：提供一个创建对象实例的功能，无须关心细节和具体实现。\n- 面向接口编程，只知道接口，不知道实现类\n- 本质是：选择实现\n\n## 使用场景\n\n1. 当需要封装实现细节，外部不知道具体实现只能通过接口来操作封装体的时候，可以选择简单工厂，让客户端通过简单工厂提供的方法获取相应的接口实现。\n2. 当想要把创建对象的职责、权限集中在内部管理和控制时，选择简单工厂，例如简单工厂加单例模式控制创建对象。\n\n## 优缺点\n\n- 优点\n  1. 封装实现细节\n  2. 解耦\n\n- 缺点\n  1. 增加客户端复杂度\n  2. 不方便扩展子工厂\n\n## UML图\n\n客户端只能够访问接口和工厂类，具体实现细节对客户端透明，工厂方法一般都是静态的，根据客户端调用传入的参数去实例化不同的实现类对象。\n\n![image](http://omdq6di7v.bkt.clouddn.com/17-3-15/22164466-file_1489555555197_12d8.png)\n\n## 代码实现\n\n在工厂方法中也可以通过读取外部配置文件中的class name进行反射创建对象，实现可配置。例如将数据库驱动的class 配置在外部properties中，在工厂方法中读取到驱动类反射创建，之后想更改驱动的时候直接更改配置文件即可。\n\n```java\n//静态工厂\npublic class Factory {\n    public static IOperate createClass(String regix){\n        IOperate operate =null;\n        char myRegix = regix.charAt(0);\n        switch(myRegix){\n        case '+' :\n            operate = new Add();\n            break;\n        case '-' :\n            operate = new Sub();\n            break;\n        case '*' :\n            operate = new Mul();\n            break;\n        case '/' :\n            operate = new Div();\n            break;\n        default :\n            throw new RuntimeException(\"你输出的运算符不符合该计算器\");\n        }\n        return  operate;\n    }\n    public Factory() {\n    }\n}\n// 接口\npublic interface IOperate {\n    public double firstNum = 0;\n    public double secondNum = 0;\n    public double getResult(double firstNum,double secondNum);\n}\n//实现类\nclass Add implements IOperate{\n    public double getResult(double firstNum, double secondNum) {\n        double result = firstNum + secondNum;\n        return result;\n    }\n}\nclass Sub implements IOperate{\n    public double getResult(double firstNum, double secondNum) {\n        double result = firstNum - secondNum;\n        return result;\n    }\n}\nclass Mul implements IOperate{\n    public double getResult(double firstNum, double secondNum) {\n        double result = firstNum * secondNum;\n        return result;\n    }\n}\nclass Div implements IOperate{\n    public double getResult(double firstNum, double secondNum) {\n        if(secondNum == 0){\n            throw new RuntimeException(\"被除数不能为0\");\n        }\n        double result = firstNum / secondNum;\n        return result;\n    }\n}\n```\n\n","slug":"设计模式/设计模式之简单工厂模式","published":1,"updated":"2018-09-12T03:03:21.838Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnju009hwlkvjb7zzv0f"},{"title":"设计模式之组合模式","date":"2018-05-25T09:23:18.000Z","_content":"\n#  设计模式之组合模式\n\n组合模式组合多个对象形成树形结构以表示“整体-部分”的结构层次。\n\n<!--more-->\n\n## 认识\n\n组合模式让我们能用树形方式创建对象的结构，树里面包含了Composite以及Leaf的对象。使用组合结构，我们能把相同的操作应用在Composite和Leaf上，即大多数情况下，我们可以忽略Composite和Leaf之间的差别，以相同的方式使用它们。为了保持透明性，Leaf和Composite都要继承或实现Component。\n\n## 思考\n\n- 组合对象的关键在于它定义了一个抽象构建类，它既可表示叶子对象，也可表示容器对象，客户仅仅需要针对这个抽象构建进行编程，无须知道他是叶子对象还是容器对象，都是一致对待。\n- 叶子对象和组合对象实现相同的接口。这就是组合模式能够将叶子节点和对象节点进行一致处理的原因。\n\n## 使用场景\n\n- 需要表示一个对象整体或部分层次，在具有整体和部分的层次结构中，希望通过一种方式忽略整体与部分的差异，可以一致地对待它们。\n- 让客户能够忽略不同对象层次的变化，客户端可以针对抽象构件编程，无须关心对象层次结构的细节。\n\n## 优缺点\n\n- 优点  \n  1. 可以清楚地定义分层次的复杂对象，表示对象的全部或部分层次，使得增加新构件也更容易。\n  2. 客户端调用简单，客户端可以一致的使用组合结构或其中单个对象。\n  3. 定义了包含叶子对象和容器对象的类层次结构，叶子对象可以被组合成更复杂的容器对象，而这个容器对象又可以被组合，这样不断递归下去，可以形成复杂的树形结构。\n  4. 更容易在组合体内加入对象构件，客户端不必因为加入了新的对象构件而更改原有代码。\n\n\n## UML图\n\n- 叶子节点和非叶子节点都实现接口，叶子节点不能再添加节点\n\n![](http://omdq6di7v.bkt.clouddn.com/18-5-28/5914931.jpg)\n\n- 抽象构件角色(Component)：为组合中的对象声明接口， 在适当的情况下，也可实现所有类共有接口的缺省行为。\n- 树叶构件角色(Leaf)：在组合中表示叶节点对象，没有子节点，实现抽象构件角色声明的接口。\n- 树枝构件角色(Composite)：在组合中表示分支节点对象，有子节点，实现抽象构件角色声明的接口；存储子部件。\n\n## 代码实现\n\n- 接口\n\n  ```java\n  public interface Component\n  {\n  \tpublic void doSomething();\n  }\n  ```\n\n- 叶子节点\n\n  ```java\n  public class Leaf implements Component  \n  {  \n      @Override  \n      public void doSomething()  \n      {  \n        System.out.println(\"Leaf doSomething\");  \n      }  \n  }  \n  ```\n\n- 枝干节点\n\n  ```java\n  public class Composite implements Component  \n  {  \n      List<Component> childs = new ArrayList<Component>();  \n      public void add(Component child)  \n      {  \n          this.childs.add(child);  \n      }  \n      public void remove(Component child)  \n      {  \n          this.childs.remove(child);  \n      }  \n      public Component getChild(int i)  \n      {  \n          return this.childs.get(i);  \n      }    \n      @Override  \n      public void doSomething()  \n      {  \n          for (Component child : childs)  \n              child.doSomething();  \n      }   \n  }  \n  ```\n\n- client\n\n  ```java\n  public class Client  \n  {  \n      public static void main(String[] args)  \n      {  \n          Component leaf1=new Leaf();  \n          Component leaf2=new Leaf();  \n          Component leaf3=new Leaf();  \n          Composite composite1=new Composite();  \n          Composite composite2=new Composite();  \n            \n          composite2.add(leaf2);  \n          composite2.add(leaf3);  \n          composite1.add(leaf1);  \n          composite1.add(composite2);          \n          composite1.doSomething();          \n      }   \n  }  \n  ```","source":"_posts/设计模式/设计模式之组合模式.md","raw":"---\ntitle: 设计模式之组合模式\ndate: 2018-05-25 17:23:18\ntags:\n- 设计模式\ncategories:\n- 设计模式\n\n---\n\n#  设计模式之组合模式\n\n组合模式组合多个对象形成树形结构以表示“整体-部分”的结构层次。\n\n<!--more-->\n\n## 认识\n\n组合模式让我们能用树形方式创建对象的结构，树里面包含了Composite以及Leaf的对象。使用组合结构，我们能把相同的操作应用在Composite和Leaf上，即大多数情况下，我们可以忽略Composite和Leaf之间的差别，以相同的方式使用它们。为了保持透明性，Leaf和Composite都要继承或实现Component。\n\n## 思考\n\n- 组合对象的关键在于它定义了一个抽象构建类，它既可表示叶子对象，也可表示容器对象，客户仅仅需要针对这个抽象构建进行编程，无须知道他是叶子对象还是容器对象，都是一致对待。\n- 叶子对象和组合对象实现相同的接口。这就是组合模式能够将叶子节点和对象节点进行一致处理的原因。\n\n## 使用场景\n\n- 需要表示一个对象整体或部分层次，在具有整体和部分的层次结构中，希望通过一种方式忽略整体与部分的差异，可以一致地对待它们。\n- 让客户能够忽略不同对象层次的变化，客户端可以针对抽象构件编程，无须关心对象层次结构的细节。\n\n## 优缺点\n\n- 优点  \n  1. 可以清楚地定义分层次的复杂对象，表示对象的全部或部分层次，使得增加新构件也更容易。\n  2. 客户端调用简单，客户端可以一致的使用组合结构或其中单个对象。\n  3. 定义了包含叶子对象和容器对象的类层次结构，叶子对象可以被组合成更复杂的容器对象，而这个容器对象又可以被组合，这样不断递归下去，可以形成复杂的树形结构。\n  4. 更容易在组合体内加入对象构件，客户端不必因为加入了新的对象构件而更改原有代码。\n\n\n## UML图\n\n- 叶子节点和非叶子节点都实现接口，叶子节点不能再添加节点\n\n![](http://omdq6di7v.bkt.clouddn.com/18-5-28/5914931.jpg)\n\n- 抽象构件角色(Component)：为组合中的对象声明接口， 在适当的情况下，也可实现所有类共有接口的缺省行为。\n- 树叶构件角色(Leaf)：在组合中表示叶节点对象，没有子节点，实现抽象构件角色声明的接口。\n- 树枝构件角色(Composite)：在组合中表示分支节点对象，有子节点，实现抽象构件角色声明的接口；存储子部件。\n\n## 代码实现\n\n- 接口\n\n  ```java\n  public interface Component\n  {\n  \tpublic void doSomething();\n  }\n  ```\n\n- 叶子节点\n\n  ```java\n  public class Leaf implements Component  \n  {  \n      @Override  \n      public void doSomething()  \n      {  \n        System.out.println(\"Leaf doSomething\");  \n      }  \n  }  \n  ```\n\n- 枝干节点\n\n  ```java\n  public class Composite implements Component  \n  {  \n      List<Component> childs = new ArrayList<Component>();  \n      public void add(Component child)  \n      {  \n          this.childs.add(child);  \n      }  \n      public void remove(Component child)  \n      {  \n          this.childs.remove(child);  \n      }  \n      public Component getChild(int i)  \n      {  \n          return this.childs.get(i);  \n      }    \n      @Override  \n      public void doSomething()  \n      {  \n          for (Component child : childs)  \n              child.doSomething();  \n      }   \n  }  \n  ```\n\n- client\n\n  ```java\n  public class Client  \n  {  \n      public static void main(String[] args)  \n      {  \n          Component leaf1=new Leaf();  \n          Component leaf2=new Leaf();  \n          Component leaf3=new Leaf();  \n          Composite composite1=new Composite();  \n          Composite composite2=new Composite();  \n            \n          composite2.add(leaf2);  \n          composite2.add(leaf3);  \n          composite1.add(leaf1);  \n          composite1.add(composite2);          \n          composite1.doSomething();          \n      }   \n  }  \n  ```","slug":"设计模式/设计模式之组合模式","published":1,"updated":"2018-09-12T03:03:21.839Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjnvlfnjv009kwlkv4syxvj1f"}],"PostAsset":[{"_id":"source/_posts/hexo-theme-beantech/home_posts_tag-false.png","slug":"home_posts_tag-false.png","post":"cjnvlfnek000gwlkvrjy0xqfv","modified":0,"renderable":0},{"_id":"source/_posts/hexo-theme-beantech/home_posts_tag-true.png","slug":"home_posts_tag-true.png","post":"cjnvlfnek000gwlkvrjy0xqfv","modified":0,"renderable":0},{"_id":"source/_posts/hexo-theme-beantech/Demo.png","slug":"Demo.png","post":"cjnvlfnek000gwlkvrjy0xqfv","modified":0,"renderable":0}],"PostCategory":[{"post_id":"cjnvlfndy0001wlkvcf3u63l2","category_id":"cjnvlfne30003wlkvgf7yyd8b","_id":"cjnvlfnek000dwlkv7lb1chr9"},{"post_id":"cjnvlfne10002wlkvyvx00snh","category_id":"cjnvlfneh0008wlkv2dchkkuv","_id":"cjnvlfnen000jwlkvya6tbxm7"},{"post_id":"cjnvlfnef0007wlkvvat16z8y","category_id":"cjnvlfnek000ewlkvhktbnamo","_id":"cjnvlfneu000pwlkv1own644p"},{"post_id":"cjnvlfnei000bwlkvcdomqm85","category_id":"cjnvlfnen000kwlkvl21n1xo0","_id":"cjnvlfnex000vwlkv3m5krtom"},{"post_id":"cjnvlfneq000owlkvstnnk9fv","category_id":"cjnvlfneh0008wlkv2dchkkuv","_id":"cjnvlfnez000zwlkvawu6x2n9"},{"post_id":"cjnvlfnew000uwlkv77t959cz","category_id":"cjnvlfnek000ewlkvhktbnamo","_id":"cjnvlfnf10012wlkvdouk1o2v"},{"post_id":"cjnvlfneo000mwlkv7guevbds","category_id":"cjnvlfneu000qwlkvtq81ksfn","_id":"cjnvlfnf20015wlkv06nrjqcq"},{"post_id":"cjnvlfnev000swlkvkmgga9ui","category_id":"cjnvlfney000xwlkvo6ssy1px","_id":"cjnvlfnf30018wlkvzl3zhtpb"},{"post_id":"cjnvlfnex000wwlkvk4oh5n1m","category_id":"cjnvlfnf10013wlkvhgb828hf","_id":"cjnvlfnf4001cwlkvez0aasuz"},{"post_id":"cjnvlfnf00011wlkvn4l848kr","category_id":"cjnvlfnf30019wlkvnzwyvbgr","_id":"cjnvlfnf5001fwlkvxnlvb9l3"},{"post_id":"cjnvlfnge001swlkvqeynj8rt","category_id":"cjnvlfnek000ewlkvhktbnamo","_id":"cjnvlfngi001xwlkv2l1bwhlb"},{"post_id":"cjnvlfngf001twlkvu51vko8b","category_id":"cjnvlfnek000ewlkvhktbnamo","_id":"cjnvlfngj001zwlkvpxdd4yxc"},{"post_id":"cjnvlfngg001vwlkvvaq4q6wh","category_id":"cjnvlfnek000ewlkvhktbnamo","_id":"cjnvlfngm0023wlkv0o5o7t6s"},{"post_id":"cjnvlfngh001wwlkvw2p4phbo","category_id":"cjnvlfnek000ewlkvhktbnamo","_id":"cjnvlfngn0026wlkv2qkrfwna"},{"post_id":"cjnvlfngi001ywlkvhufvk1gk","category_id":"cjnvlfnek000ewlkvhktbnamo","_id":"cjnvlfngp002awlkvahqta4v4"},{"post_id":"cjnvlfngl0022wlkvg7mlleuh","category_id":"cjnvlfnek000ewlkvhktbnamo","_id":"cjnvlfngr002dwlkv1myzxkxp"},{"post_id":"cjnvlfngm0025wlkvrovcbq6i","category_id":"cjnvlfnek000ewlkvhktbnamo","_id":"cjnvlfngt002gwlkvrg4251bd"},{"post_id":"cjnvlfngo0029wlkvfqhvlrdm","category_id":"cjnvlfnek000ewlkvhktbnamo","_id":"cjnvlfngu002jwlkv35nocdl5"},{"post_id":"cjnvlfngq002cwlkvguj1ujbx","category_id":"cjnvlfnek000ewlkvhktbnamo","_id":"cjnvlfngw002mwlkvv486keyo"},{"post_id":"cjnvlfngs002fwlkvtrfyfvhy","category_id":"cjnvlfnek000ewlkvhktbnamo","_id":"cjnvlfngx002pwlkvxcewmo1v"},{"post_id":"cjnvlfngu002iwlkv70jfn52w","category_id":"cjnvlfnek000ewlkvhktbnamo","_id":"cjnvlfngz002swlkvf4f7c4w7"},{"post_id":"cjnvlfngx002owlkvg80a48x8","category_id":"cjnvlfnek000ewlkvhktbnamo","_id":"cjnvlfnh1002xwlkv80luuoeq"},{"post_id":"cjnvlfngy002rwlkvbq2gt7ut","category_id":"cjnvlfnek000ewlkvhktbnamo","_id":"cjnvlfnh20030wlkvgap7oijm"},{"post_id":"cjnvlfngz002uwlkvfo6l3hys","category_id":"cjnvlfnek000ewlkvhktbnamo","_id":"cjnvlfnh40034wlkvw542ko6t"},{"post_id":"cjnvlfnh0002wwlkvaxitq9os","category_id":"cjnvlfne30003wlkvgf7yyd8b","_id":"cjnvlfnh50037wlkvoznqu1oq"},{"post_id":"cjnvlfnh1002zwlkvo4olhpt6","category_id":"cjnvlfnf30019wlkvnzwyvbgr","_id":"cjnvlfnh6003awlkvd111woqp"},{"post_id":"cjnvlfnh20033wlkvo4vbhv8h","category_id":"cjnvlfnf30019wlkvnzwyvbgr","_id":"cjnvlfnh7003dwlkv5s0oiao9"},{"post_id":"cjnvlfnh40036wlkvreoa2v50","category_id":"cjnvlfne30003wlkvgf7yyd8b","_id":"cjnvlfnh9003gwlkvp8la4tun"},{"post_id":"cjnvlfnh50038wlkv8chkpg1i","category_id":"cjnvlfne30003wlkvgf7yyd8b","_id":"cjnvlfnha003kwlkv2oj9vab6"},{"post_id":"cjnvlfnh7003cwlkvrtoip116","category_id":"cjnvlfne30003wlkvgf7yyd8b","_id":"cjnvlfnhc003mwlkvwo11clgw"},{"post_id":"cjnvlfnh8003fwlkv1d3b46cy","category_id":"cjnvlfne30003wlkvgf7yyd8b","_id":"cjnvlfnhd003qwlkvb0q7wxd0"},{"post_id":"cjnvlfnh9003iwlkvyorqkcn9","category_id":"cjnvlfne30003wlkvgf7yyd8b","_id":"cjnvlfnhf003swlkvttjxrvc8"},{"post_id":"cjnvlfnha003lwlkvppmwcqfi","category_id":"cjnvlfne30003wlkvgf7yyd8b","_id":"cjnvlfnhh003wwlkv6lw1grfe"},{"post_id":"cjnvlfnhd003owlkvfxmqri8d","category_id":"cjnvlfne30003wlkvgf7yyd8b","_id":"cjnvlfnhi003zwlkvhkufnoae"},{"post_id":"cjnvlfnhe003rwlkvqntln98w","category_id":"cjnvlfne30003wlkvgf7yyd8b","_id":"cjnvlfnhk0043wlkvnr3a8fy2"},{"post_id":"cjnvlfnhg003vwlkvid4c3hmk","category_id":"cjnvlfne30003wlkvgf7yyd8b","_id":"cjnvlfnhl0047wlkvip7lqhrf"},{"post_id":"cjnvlfnhl004awlkv1bpmi7y4","category_id":"cjnvlfne30003wlkvgf7yyd8b","_id":"cjnvlfnhp004hwlkvrkd58tkn"},{"post_id":"cjnvlfnhh003ywlkv9me6281h","category_id":"cjnvlfnhk0044wlkvtj1mx115","_id":"cjnvlfnhq004mwlkvnp6ofsh4"},{"post_id":"cjnvlfnhj0042wlkv0uwu1vje","category_id":"cjnvlfnhn004cwlkvt7k3lsyu","_id":"cjnvlfnhr004pwlkvrxj9mon1"},{"post_id":"cjnvlfnhp004lwlkvlrnlu6eb","category_id":"cjnvlfne30003wlkvgf7yyd8b","_id":"cjnvlfnhu004wwlkvx84wvpil"},{"post_id":"cjnvlfnhk0046wlkv6hwnnvf9","category_id":"cjnvlfnhp004iwlkv8psja3jj","_id":"cjnvlfnhv0050wlkvmvaef53x"},{"post_id":"cjnvlfnhr004owlkv4h1v3ojq","category_id":"cjnvlfne30003wlkvgf7yyd8b","_id":"cjnvlfnhx0054wlkvgjgfqito"},{"post_id":"cjnvlfnhs004twlkvhh10iybn","category_id":"cjnvlfne30003wlkvgf7yyd8b","_id":"cjnvlfnhy0058wlkvjejzhrez"},{"post_id":"cjnvlfnhm004bwlkvprg5ez39","category_id":"cjnvlfnhp004iwlkv8psja3jj","_id":"cjnvlfni0005cwlkvvdfi0616"},{"post_id":"cjnvlfnht004vwlkv3xb6ipuw","category_id":"cjnvlfne30003wlkvgf7yyd8b","_id":"cjnvlfni1005fwlkvzvuoh1lt"},{"post_id":"cjnvlfnhv004zwlkvan4l18hb","category_id":"cjnvlfne30003wlkvgf7yyd8b","_id":"cjnvlfni3005jwlkvlqdxanq9"},{"post_id":"cjnvlfnhn004ewlkvsn2tfhv3","category_id":"cjnvlfnhp004iwlkv8psja3jj","_id":"cjnvlfni3005mwlkvqfcwc3gm"},{"post_id":"cjnvlfnhw0053wlkvthjkxwqm","category_id":"cjnvlfne30003wlkvgf7yyd8b","_id":"cjnvlfni4005pwlkvqx4ca2ol"},{"post_id":"cjnvlfnhy0057wlkvtppkuia8","category_id":"cjnvlfne30003wlkvgf7yyd8b","_id":"cjnvlfni6005swlkvajnxplun"},{"post_id":"cjnvlfnho004gwlkvy3hsido6","category_id":"cjnvlfnhp004iwlkv8psja3jj","_id":"cjnvlfni7005vwlkvtyge0oep"},{"post_id":"cjnvlfnhz005bwlkvhajjcwti","category_id":"cjnvlfne30003wlkvgf7yyd8b","_id":"cjnvlfni8005ywlkv69uvz6kz"},{"post_id":"cjnvlfni0005ewlkvrqmgmckd","category_id":"cjnvlfne30003wlkvgf7yyd8b","_id":"cjnvlfni90061wlkv4xe6qbyr"},{"post_id":"cjnvlfni2005iwlkvmhcg8xh5","category_id":"cjnvlfne30003wlkvgf7yyd8b","_id":"cjnvlfnia0064wlkvhfdhkq5i"},{"post_id":"cjnvlfni3005lwlkvn10xlovu","category_id":"cjnvlfne30003wlkvgf7yyd8b","_id":"cjnvlfnib0067wlkv1gnznmsb"},{"post_id":"cjnvlfni4005owlkvzjfn4hi5","category_id":"cjnvlfne30003wlkvgf7yyd8b","_id":"cjnvlfnid006awlkvh9qrvbw9"},{"post_id":"cjnvlfni5005rwlkvhm7gmk8q","category_id":"cjnvlfne30003wlkvgf7yyd8b","_id":"cjnvlfnie006dwlkv6qcs3661"},{"post_id":"cjnvlfni6005uwlkvqglxflg5","category_id":"cjnvlfne30003wlkvgf7yyd8b","_id":"cjnvlfnie006gwlkvft9s8xrl"},{"post_id":"cjnvlfni7005xwlkvpyleilhg","category_id":"cjnvlfne30003wlkvgf7yyd8b","_id":"cjnvlfnif006kwlkv9a2hztza"},{"post_id":"cjnvlfni80060wlkv8e8agnjv","category_id":"cjnvlfne30003wlkvgf7yyd8b","_id":"cjnvlfnig006owlkv9wcijwt3"},{"post_id":"cjnvlfni90063wlkvq7tszqir","category_id":"cjnvlfne30003wlkvgf7yyd8b","_id":"cjnvlfnih006swlkvjwmpophp"},{"post_id":"cjnvlfnib0066wlkvijxa2wqe","category_id":"cjnvlfnhp004iwlkv8psja3jj","_id":"cjnvlfnij006wwlkvlrlop10l"},{"post_id":"cjnvlfnic0069wlkviph19zuf","category_id":"cjnvlfne30003wlkvgf7yyd8b","_id":"cjnvlfnij006zwlkv0c4wy7de"},{"post_id":"cjnvlfnid006cwlkvz51lmaxv","category_id":"cjnvlfne30003wlkvgf7yyd8b","_id":"cjnvlfnil0073wlkvytaet2kd"},{"post_id":"cjnvlfnif006jwlkvk01zat4w","category_id":"cjnvlfne30003wlkvgf7yyd8b","_id":"cjnvlfnim0077wlkvyickb0e2"},{"post_id":"cjnvlfnie006fwlkvuqffdl4f","category_id":"cjnvlfnig006mwlkvs0fwrify","_id":"cjnvlfnin007bwlkvyp6waskp"},{"post_id":"cjnvlfnij006ywlkvzkwxcl5b","category_id":"cjnvlfnii006vwlkvd7ko77eo","_id":"cjnvlfnip007fwlkvvobgokpq"},{"post_id":"cjnvlfnig006nwlkvz4uikg2t","category_id":"cjnvlfnii006vwlkvd7ko77eo","_id":"cjnvlfnir007jwlkv5t0eoqqa"},{"post_id":"cjnvlfnik0072wlkvroyryj7s","category_id":"cjnvlfnii006vwlkvd7ko77eo","_id":"cjnvlfnis007mwlkv2alxw3hr"},{"post_id":"cjnvlfnil0076wlkvwhku4n91","category_id":"cjnvlfnii006vwlkvd7ko77eo","_id":"cjnvlfnit007qwlkvy03bjy9z"},{"post_id":"cjnvlfnih006qwlkvn496rd9t","category_id":"cjnvlfnii006vwlkvd7ko77eo","_id":"cjnvlfniu007swlkvnskfwbuo"},{"post_id":"cjnvlfnin007awlkvmo40etvu","category_id":"cjnvlfnii006vwlkvd7ko77eo","_id":"cjnvlfniv007vwlkvqnns0x2y"},{"post_id":"cjnvlfnio007ewlkvl6yc9aym","category_id":"cjnvlfnii006vwlkvd7ko77eo","_id":"cjnvlfniv007xwlkvq4yb6pgj"},{"post_id":"cjnvlfnii006uwlkvevim1f9h","category_id":"cjnvlfnii006vwlkvd7ko77eo","_id":"cjnvlfniv0080wlkvkdqrszu0"},{"post_id":"cjnvlfnip007iwlkvy6bhrafk","category_id":"cjnvlfne30003wlkvgf7yyd8b","_id":"cjnvlfniv0082wlkvgg5n4rmo"},{"post_id":"cjnvlfnis007lwlkvfs4oidul","category_id":"cjnvlfnii006vwlkvd7ko77eo","_id":"cjnvlfniw0085wlkv203ib728"},{"post_id":"cjnvlfnit007owlkvosrq1i17","category_id":"cjnvlfnii006vwlkvd7ko77eo","_id":"cjnvlfniw0087wlkv9fxzb19a"},{"post_id":"cjnvlfnjb008iwlkvtwe7lwt4","category_id":"cjnvlfnii006vwlkvd7ko77eo","_id":"cjnvlfnjg008owlkvrvrc63m8"},{"post_id":"cjnvlfnjd008jwlkvq1jdt4ie","category_id":"cjnvlfnii006vwlkvd7ko77eo","_id":"cjnvlfnjh008rwlkvl3zhu4op"},{"post_id":"cjnvlfnjf008lwlkvel9mvpjr","category_id":"cjnvlfnii006vwlkvd7ko77eo","_id":"cjnvlfnji008uwlkv5vl47rog"},{"post_id":"cjnvlfnjg008nwlkvdbz825nb","category_id":"cjnvlfnii006vwlkvd7ko77eo","_id":"cjnvlfnjj008xwlkvl65gspoa"},{"post_id":"cjnvlfnjg008qwlkvz273h2gw","category_id":"cjnvlfnii006vwlkvd7ko77eo","_id":"cjnvlfnjm0090wlkvzkleihl8"},{"post_id":"cjnvlfnji008twlkvk7i62bd8","category_id":"cjnvlfnii006vwlkvd7ko77eo","_id":"cjnvlfnjn0093wlkvbld2w1as"},{"post_id":"cjnvlfnjj008wwlkvaf8t3dr5","category_id":"cjnvlfnii006vwlkvd7ko77eo","_id":"cjnvlfnjp0096wlkvl4n0mtmc"},{"post_id":"cjnvlfnjk008zwlkvkjo1cv11","category_id":"cjnvlfnii006vwlkvd7ko77eo","_id":"cjnvlfnjq0099wlkvby5p9p72"},{"post_id":"cjnvlfnjn0092wlkvala5bca8","category_id":"cjnvlfnii006vwlkvd7ko77eo","_id":"cjnvlfnjr009cwlkvmv31bpcn"},{"post_id":"cjnvlfnjp0095wlkv9ych2xcn","category_id":"cjnvlfnii006vwlkvd7ko77eo","_id":"cjnvlfnjt009fwlkv8r8zeaup"},{"post_id":"cjnvlfnjq0098wlkvqbc474p9","category_id":"cjnvlfnii006vwlkvd7ko77eo","_id":"cjnvlfnjv009iwlkvj3nmz2is"},{"post_id":"cjnvlfnjr009bwlkvtra47vs5","category_id":"cjnvlfnii006vwlkvd7ko77eo","_id":"cjnvlfnjv009lwlkvbshau993"},{"post_id":"cjnvlfnjs009ewlkvks617bmh","category_id":"cjnvlfnii006vwlkvd7ko77eo","_id":"cjnvlfnjw009nwlkv5su8i6s0"},{"post_id":"cjnvlfnju009hwlkvjb7zzv0f","category_id":"cjnvlfnii006vwlkvd7ko77eo","_id":"cjnvlfnjw009pwlkvepsozxmz"},{"post_id":"cjnvlfnjv009kwlkv4syxvj1f","category_id":"cjnvlfnii006vwlkvd7ko77eo","_id":"cjnvlfnjw009qwlkv0qfv4s3j"}],"PostTag":[{"post_id":"cjnvlfndy0001wlkvcf3u63l2","tag_id":"cjnvlfne70004wlkv4xll9p82","_id":"cjnvlfnei000awlkvtp1m3plt"},{"post_id":"cjnvlfne10002wlkvyvx00snh","tag_id":"cjnvlfneh0009wlkvece75j5l","_id":"cjnvlfnem000hwlkve7dhgsjc"},{"post_id":"cjnvlfnef0007wlkvvat16z8y","tag_id":"cjnvlfnek000fwlkvrj321bww","_id":"cjnvlfnep000nwlkvdvjt9rdc"},{"post_id":"cjnvlfnei000bwlkvcdomqm85","tag_id":"cjnvlfneo000lwlkvtqgpap9b","_id":"cjnvlfnew000twlkvuhn42xre"},{"post_id":"cjnvlfnek000gwlkvrjy0xqfv","tag_id":"cjnvlfneu000rwlkv2sggvfxl","_id":"cjnvlfnf20016wlkv8z1natew"},{"post_id":"cjnvlfnek000gwlkvrjy0xqfv","tag_id":"cjnvlfnez000ywlkvm7jv2os9","_id":"cjnvlfnf30017wlkv4i313ntj"},{"post_id":"cjnvlfnem000iwlkvlrm7cwyo","tag_id":"cjnvlfnf20014wlkvqrtp8p5f","_id":"cjnvlfnf4001bwlkvyvgvdbx1"},{"post_id":"cjnvlfneo000mwlkv7guevbds","tag_id":"cjnvlfnf3001awlkvdocirtkb","_id":"cjnvlfnf5001ewlkvjgt28lvj"},{"post_id":"cjnvlfneq000owlkvstnnk9fv","tag_id":"cjnvlfnf4001dwlkvh65akoza","_id":"cjnvlfnf5001hwlkvj1ru2yxk"},{"post_id":"cjnvlfnev000swlkvkmgga9ui","tag_id":"cjnvlfnf5001gwlkvbh8eirb2","_id":"cjnvlfnf5001jwlkvo48eulzd"},{"post_id":"cjnvlfnew000uwlkv77t959cz","tag_id":"cjnvlfnf5001iwlkvv80ykzpl","_id":"cjnvlfnf5001lwlkvfmmjhagw"},{"post_id":"cjnvlfnex000wwlkvk4oh5n1m","tag_id":"cjnvlfnf5001kwlkvk9yhaozv","_id":"cjnvlfnf6001nwlkv8a3pdru0"},{"post_id":"cjnvlfnf00011wlkvn4l848kr","tag_id":"cjnvlfnf6001mwlkvg9fe02ih","_id":"cjnvlfnf6001owlkvnkefak23"},{"post_id":"cjnvlfngh001wwlkvw2p4phbo","tag_id":"cjnvlfngg001uwlkvnqvtf2q2","_id":"cjnvlfngl0021wlkv1xfxhtad"},{"post_id":"cjnvlfnge001swlkvqeynj8rt","tag_id":"cjnvlfngg001uwlkvnqvtf2q2","_id":"cjnvlfngm0024wlkvf7yeya8x"},{"post_id":"cjnvlfngi001ywlkvhufvk1gk","tag_id":"cjnvlfngg001uwlkvnqvtf2q2","_id":"cjnvlfngo0028wlkv1wpybmvo"},{"post_id":"cjnvlfngl0022wlkvg7mlleuh","tag_id":"cjnvlfngg001uwlkvnqvtf2q2","_id":"cjnvlfngq002bwlkvzrqjn4gs"},{"post_id":"cjnvlfngf001twlkvu51vko8b","tag_id":"cjnvlfngg001uwlkvnqvtf2q2","_id":"cjnvlfngs002ewlkvqnv7mb06"},{"post_id":"cjnvlfngm0025wlkvrovcbq6i","tag_id":"cjnvlfngg001uwlkvnqvtf2q2","_id":"cjnvlfngt002hwlkv3knm0sbq"},{"post_id":"cjnvlfngo0029wlkvfqhvlrdm","tag_id":"cjnvlfngg001uwlkvnqvtf2q2","_id":"cjnvlfngv002kwlkvq2vohfb7"},{"post_id":"cjnvlfngg001vwlkvvaq4q6wh","tag_id":"cjnvlfngg001uwlkvnqvtf2q2","_id":"cjnvlfngx002nwlkvgzz39js6"},{"post_id":"cjnvlfngq002cwlkvguj1ujbx","tag_id":"cjnvlfngg001uwlkvnqvtf2q2","_id":"cjnvlfngy002qwlkvd0vx1g62"},{"post_id":"cjnvlfngs002fwlkvtrfyfvhy","tag_id":"cjnvlfngg001uwlkvnqvtf2q2","_id":"cjnvlfngz002twlkvjmujjk02"},{"post_id":"cjnvlfngu002iwlkv70jfn52w","tag_id":"cjnvlfngg001uwlkvnqvtf2q2","_id":"cjnvlfnh0002vwlkv0hxepxms"},{"post_id":"cjnvlfngx002owlkvg80a48x8","tag_id":"cjnvlfngg001uwlkvnqvtf2q2","_id":"cjnvlfnh1002ywlkv1i84lpq0"},{"post_id":"cjnvlfngy002rwlkvbq2gt7ut","tag_id":"cjnvlfngg001uwlkvnqvtf2q2","_id":"cjnvlfnh20032wlkvvn3pbzdo"},{"post_id":"cjnvlfngz002uwlkvfo6l3hys","tag_id":"cjnvlfngg001uwlkvnqvtf2q2","_id":"cjnvlfnh40035wlkvby3hcoo4"},{"post_id":"cjnvlfnh40036wlkvreoa2v50","tag_id":"cjnvlfnh20031wlkvl8xpop1m","_id":"cjnvlfnh7003bwlkvwdzujsfg"},{"post_id":"cjnvlfnh0002wwlkvaxitq9os","tag_id":"cjnvlfnh20031wlkvl8xpop1m","_id":"cjnvlfnh8003ewlkvvnqxz6hl"},{"post_id":"cjnvlfnh1002zwlkvo4olhpt6","tag_id":"cjnvlfnh60039wlkvf3d4e0z4","_id":"cjnvlfnha003jwlkvqwa6mv4l"},{"post_id":"cjnvlfnh20033wlkvo4vbhv8h","tag_id":"cjnvlfnh60039wlkvf3d4e0z4","_id":"cjnvlfnhd003pwlkvue234ejc"},{"post_id":"cjnvlfnhd003owlkvfxmqri8d","tag_id":"cjnvlfnhc003nwlkvasoepxg2","_id":"cjnvlfnhg003uwlkv6kf6sob4"},{"post_id":"cjnvlfnh50038wlkv8chkpg1i","tag_id":"cjnvlfnhc003nwlkvasoepxg2","_id":"cjnvlfnhh003xwlkvgdki4ul6"},{"post_id":"cjnvlfnhe003rwlkvqntln98w","tag_id":"cjnvlfnhc003nwlkvasoepxg2","_id":"cjnvlfnhi0041wlkvi1k5h3b0"},{"post_id":"cjnvlfnhg003vwlkvid4c3hmk","tag_id":"cjnvlfnhc003nwlkvasoepxg2","_id":"cjnvlfnhk0045wlkvko02s5bw"},{"post_id":"cjnvlfnh7003cwlkvrtoip116","tag_id":"cjnvlfnhc003nwlkvasoepxg2","_id":"cjnvlfnhl0049wlkvp25hd62u"},{"post_id":"cjnvlfnh8003fwlkv1d3b46cy","tag_id":"cjnvlfnhc003nwlkvasoepxg2","_id":"cjnvlfnho004fwlkvo00ccq8h"},{"post_id":"cjnvlfnh8003fwlkv1d3b46cy","tag_id":"cjnvlfnhl0048wlkvrvm317jw","_id":"cjnvlfnhp004jwlkvoqhjbg8f"},{"post_id":"cjnvlfnhm004bwlkvprg5ez39","tag_id":"cjnvlfnh20031wlkvl8xpop1m","_id":"cjnvlfnhq004nwlkv8hawhcq9"},{"post_id":"cjnvlfnhn004ewlkvsn2tfhv3","tag_id":"cjnvlfnh20031wlkvl8xpop1m","_id":"cjnvlfnhs004rwlkvj14gfigo"},{"post_id":"cjnvlfnh9003iwlkvyorqkcn9","tag_id":"cjnvlfnhc003nwlkvasoepxg2","_id":"cjnvlfnht004uwlkvlhnr7q82"},{"post_id":"cjnvlfnho004gwlkvy3hsido6","tag_id":"cjnvlfnh20031wlkvl8xpop1m","_id":"cjnvlfnhu004ywlkvrh2oep4n"},{"post_id":"cjnvlfnhp004lwlkvlrnlu6eb","tag_id":"cjnvlfnhl0048wlkvrvm317jw","_id":"cjnvlfnhw0052wlkvzhl6py6j"},{"post_id":"cjnvlfnha003lwlkvppmwcqfi","tag_id":"cjnvlfnhc003nwlkvasoepxg2","_id":"cjnvlfnhx0056wlkv2rhoy77l"},{"post_id":"cjnvlfnhr004owlkv4h1v3ojq","tag_id":"cjnvlfnhl0048wlkvrvm317jw","_id":"cjnvlfnhz005awlkvdclyjxvk"},{"post_id":"cjnvlfnhs004twlkvhh10iybn","tag_id":"cjnvlfnhl0048wlkvrvm317jw","_id":"cjnvlfni0005dwlkvjhmljmai"},{"post_id":"cjnvlfnht004vwlkv3xb6ipuw","tag_id":"cjnvlfnhl0048wlkvrvm317jw","_id":"cjnvlfni2005hwlkv3cqd91er"},{"post_id":"cjnvlfnhh003ywlkv9me6281h","tag_id":"cjnvlfnhs004swlkvxbbcbe38","_id":"cjnvlfni3005kwlkvkk2ssv5w"},{"post_id":"cjnvlfnhv004zwlkvan4l18hb","tag_id":"cjnvlfnhl0048wlkvrvm317jw","_id":"cjnvlfni4005nwlkvycbjbrui"},{"post_id":"cjnvlfnhw0053wlkvthjkxwqm","tag_id":"cjnvlfnhl0048wlkvrvm317jw","_id":"cjnvlfni5005qwlkvop9qaq6f"},{"post_id":"cjnvlfnhj0042wlkv0uwu1vje","tag_id":"cjnvlfnhv0051wlkvw3hn7gwl","_id":"cjnvlfni6005twlkvd4qsje7g"},{"post_id":"cjnvlfnhy0057wlkvtppkuia8","tag_id":"cjnvlfnhl0048wlkvrvm317jw","_id":"cjnvlfni7005wwlkvlsoczbll"},{"post_id":"cjnvlfnhz005bwlkvhajjcwti","tag_id":"cjnvlfnhl0048wlkvrvm317jw","_id":"cjnvlfni8005zwlkv4ohedg22"},{"post_id":"cjnvlfnhk0046wlkv6hwnnvf9","tag_id":"cjnvlfnh20031wlkvl8xpop1m","_id":"cjnvlfni90062wlkv478e4nnd"},{"post_id":"cjnvlfnhk0046wlkv6hwnnvf9","tag_id":"cjnvlfnhz0059wlkv1ua01nyo","_id":"cjnvlfnib0065wlkvyd6ong92"},{"post_id":"cjnvlfni0005ewlkvrqmgmckd","tag_id":"cjnvlfnhl0048wlkvrvm317jw","_id":"cjnvlfnic0068wlkv8e15ywud"},{"post_id":"cjnvlfni2005iwlkvmhcg8xh5","tag_id":"cjnvlfnhl0048wlkvrvm317jw","_id":"cjnvlfnid006bwlkvb6y37u8z"},{"post_id":"cjnvlfnhl004awlkv1bpmi7y4","tag_id":"cjnvlfni1005gwlkv5oxt5t6l","_id":"cjnvlfnie006ewlkv4941ewht"},{"post_id":"cjnvlfni3005lwlkvn10xlovu","tag_id":"cjnvlfnhl0048wlkvrvm317jw","_id":"cjnvlfnif006hwlkv8wb6haz8"},{"post_id":"cjnvlfni4005owlkvzjfn4hi5","tag_id":"cjnvlfnhl0048wlkvrvm317jw","_id":"cjnvlfnig006lwlkv49y7hx3x"},{"post_id":"cjnvlfni5005rwlkvhm7gmk8q","tag_id":"cjnvlfnhl0048wlkvrvm317jw","_id":"cjnvlfnih006pwlkv4p6bqzta"},{"post_id":"cjnvlfni6005uwlkvqglxflg5","tag_id":"cjnvlfnhl0048wlkvrvm317jw","_id":"cjnvlfnii006twlkvkkrrs8ze"},{"post_id":"cjnvlfni7005xwlkvpyleilhg","tag_id":"cjnvlfnhl0048wlkvrvm317jw","_id":"cjnvlfnij006xwlkvlk4obuqf"},{"post_id":"cjnvlfni80060wlkv8e8agnjv","tag_id":"cjnvlfnhl0048wlkvrvm317jw","_id":"cjnvlfnik0071wlkvf6qd997s"},{"post_id":"cjnvlfni90063wlkvq7tszqir","tag_id":"cjnvlfnhl0048wlkvrvm317jw","_id":"cjnvlfnil0075wlkvln2vwh7a"},{"post_id":"cjnvlfnib0066wlkvijxa2wqe","tag_id":"cjnvlfnh20031wlkvl8xpop1m","_id":"cjnvlfnim0079wlkv4vliy7ku"},{"post_id":"cjnvlfnic0069wlkviph19zuf","tag_id":"cjnvlfnhl0048wlkvrvm317jw","_id":"cjnvlfnio007dwlkvdssx1zvj"},{"post_id":"cjnvlfnid006cwlkvz51lmaxv","tag_id":"cjnvlfnhl0048wlkvrvm317jw","_id":"cjnvlfnip007gwlkv3m0pybfg"},{"post_id":"cjnvlfnid006cwlkvz51lmaxv","tag_id":"cjnvlfnif006iwlkvzgbskv4r","_id":"cjnvlfnir007kwlkv6uxpxcoe"},{"post_id":"cjnvlfnie006fwlkvuqffdl4f","tag_id":"cjnvlfnih006rwlkvcq3dg395","_id":"cjnvlfnit007nwlkvtqn4sgku"},{"post_id":"cjnvlfnif006jwlkvk01zat4w","tag_id":"cjnvlfnhl0048wlkvrvm317jw","_id":"cjnvlfniu007rwlkvyjxjuwfu"},{"post_id":"cjnvlfnif006jwlkvk01zat4w","tag_id":"cjnvlfnik0070wlkvcrp9o0xx","_id":"cjnvlfniu007twlkvmrqhd8x1"},{"post_id":"cjnvlfnif006jwlkvk01zat4w","tag_id":"cjnvlfnim0078wlkvyfks5l4g","_id":"cjnvlfniv007wwlkvqayqn1o0"},{"post_id":"cjnvlfnip007iwlkvy6bhrafk","tag_id":"cjnvlfnhl0048wlkvrvm317jw","_id":"cjnvlfniv007ywlkv3u312yxm"},{"post_id":"cjnvlfnis007lwlkvfs4oidul","tag_id":"cjnvlfnip007hwlkv3254opdr","_id":"cjnvlfniv0081wlkvalulh3jj"},{"post_id":"cjnvlfnig006nwlkvz4uikg2t","tag_id":"cjnvlfnip007hwlkv3254opdr","_id":"cjnvlfniw0083wlkvpkav39du"},{"post_id":"cjnvlfnit007owlkvosrq1i17","tag_id":"cjnvlfnip007hwlkv3254opdr","_id":"cjnvlfniw0086wlkvktt5albb"},{"post_id":"cjnvlfnih006qwlkvn496rd9t","tag_id":"cjnvlfnip007hwlkv3254opdr","_id":"cjnvlfniw0088wlkvhyqerm9l"},{"post_id":"cjnvlfnii006uwlkvevim1f9h","tag_id":"cjnvlfnip007hwlkv3254opdr","_id":"cjnvlfniw008awlkvjzgktlj3"},{"post_id":"cjnvlfnij006ywlkvzkwxcl5b","tag_id":"cjnvlfnip007hwlkv3254opdr","_id":"cjnvlfnix008bwlkvccoth3bd"},{"post_id":"cjnvlfnik0072wlkvroyryj7s","tag_id":"cjnvlfnip007hwlkv3254opdr","_id":"cjnvlfnix008dwlkv1thl4b7w"},{"post_id":"cjnvlfnil0076wlkvwhku4n91","tag_id":"cjnvlfnip007hwlkv3254opdr","_id":"cjnvlfnix008ewlkv1062f7n1"},{"post_id":"cjnvlfnin007awlkvmo40etvu","tag_id":"cjnvlfnip007hwlkv3254opdr","_id":"cjnvlfniy008gwlkvg7oaq55e"},{"post_id":"cjnvlfnio007ewlkvl6yc9aym","tag_id":"cjnvlfnip007hwlkv3254opdr","_id":"cjnvlfniy008hwlkvu5f7n8x6"},{"post_id":"cjnvlfnjb008iwlkvtwe7lwt4","tag_id":"cjnvlfnip007hwlkv3254opdr","_id":"cjnvlfnje008kwlkvotxj3bxz"},{"post_id":"cjnvlfnjd008jwlkvq1jdt4ie","tag_id":"cjnvlfnip007hwlkv3254opdr","_id":"cjnvlfnjf008mwlkvwf5xh4w7"},{"post_id":"cjnvlfnjf008lwlkvel9mvpjr","tag_id":"cjnvlfnip007hwlkv3254opdr","_id":"cjnvlfnjg008pwlkvmd6bo6j0"},{"post_id":"cjnvlfnjg008nwlkvdbz825nb","tag_id":"cjnvlfnip007hwlkv3254opdr","_id":"cjnvlfnjh008swlkv80pzpuer"},{"post_id":"cjnvlfnjg008qwlkvz273h2gw","tag_id":"cjnvlfnip007hwlkv3254opdr","_id":"cjnvlfnjj008vwlkv3ngrlf7j"},{"post_id":"cjnvlfnji008twlkvk7i62bd8","tag_id":"cjnvlfnip007hwlkv3254opdr","_id":"cjnvlfnjk008ywlkved7zuuzm"},{"post_id":"cjnvlfnjj008wwlkvaf8t3dr5","tag_id":"cjnvlfnip007hwlkv3254opdr","_id":"cjnvlfnjn0091wlkvvzrmtaka"},{"post_id":"cjnvlfnjk008zwlkvkjo1cv11","tag_id":"cjnvlfnip007hwlkv3254opdr","_id":"cjnvlfnjp0094wlkvq676f78x"},{"post_id":"cjnvlfnjn0092wlkvala5bca8","tag_id":"cjnvlfnip007hwlkv3254opdr","_id":"cjnvlfnjq0097wlkvvojfdlnn"},{"post_id":"cjnvlfnjp0095wlkv9ych2xcn","tag_id":"cjnvlfnip007hwlkv3254opdr","_id":"cjnvlfnjq009awlkv33bh272b"},{"post_id":"cjnvlfnjq0098wlkvqbc474p9","tag_id":"cjnvlfnip007hwlkv3254opdr","_id":"cjnvlfnjr009dwlkvo87fzxrm"},{"post_id":"cjnvlfnjr009bwlkvtra47vs5","tag_id":"cjnvlfnip007hwlkv3254opdr","_id":"cjnvlfnju009gwlkv48cfzuyl"},{"post_id":"cjnvlfnjs009ewlkvks617bmh","tag_id":"cjnvlfnip007hwlkv3254opdr","_id":"cjnvlfnjv009jwlkvr514h9kg"},{"post_id":"cjnvlfnju009hwlkvjb7zzv0f","tag_id":"cjnvlfnip007hwlkv3254opdr","_id":"cjnvlfnjw009mwlkvjgedkt44"},{"post_id":"cjnvlfnjv009kwlkv4syxvj1f","tag_id":"cjnvlfnip007hwlkv3254opdr","_id":"cjnvlfnjw009owlkvbinw0ghu"}],"Tag":[{"name":"代码片段","_id":"cjnvlfne70004wlkv4xll9p82"},{"name":"Git","_id":"cjnvlfneh0009wlkvece75j5l"},{"name":"elasticSearch","_id":"cjnvlfnek000fwlkvrj321bww"},{"name":"docker","_id":"cjnvlfneo000lwlkvtqgpap9b"},{"name":"Hexo","_id":"cjnvlfneu000rwlkv2sggvfxl"},{"name":"Blog","_id":"cjnvlfnez000ywlkvm7jv2os9"},{"name":"hexo","_id":"cjnvlfnf20014wlkvqrtp8p5f"},{"name":"Maven","_id":"cjnvlfnf3001awlkvdocirtkb"},{"name":"homebrew","_id":"cjnvlfnf4001dwlkvh65akoza"},{"name":"shiro","_id":"cjnvlfnf5001gwlkvbh8eirb2"},{"name":"spark","_id":"cjnvlfnf5001iwlkvv80ykzpl"},{"name":"思考","_id":"cjnvlfnf5001kwlkvk9yhaozv"},{"name":"问题排查","_id":"cjnvlfnf6001mwlkvg9fe02ih"},{"name":"hbase","_id":"cjnvlfngg001uwlkvnqvtf2q2"},{"name":"spring","_id":"cjnvlfnh20031wlkvl8xpop1m"},{"name":"反射","_id":"cjnvlfnh60039wlkvf3d4e0z4"},{"name":"java8","_id":"cjnvlfnhc003nwlkvasoepxg2"},{"name":"多线程","_id":"cjnvlfnhl0048wlkvrvm317jw"},{"name":"linux","_id":"cjnvlfnhs004swlkvxbbcbe38"},{"name":"mysql","_id":"cjnvlfnhv0051wlkvw3hn7gwl"},{"name":"spring-boot","_id":"cjnvlfnhz0059wlkv1ua01nyo"},{"name":"netty","_id":"cjnvlfni1005gwlkv5oxt5t6l"},{"name":"源码解析","_id":"cjnvlfnif006iwlkvzgbskv4r"},{"name":"mybatis","_id":"cjnvlfnih006rwlkvcq3dg395"},{"name":"集合","_id":"cjnvlfnik0070wlkvcrp9o0xx"},{"name":"数据结构","_id":"cjnvlfnim0078wlkvyfks5l4g"},{"name":"设计模式","_id":"cjnvlfnip007hwlkv3254opdr"}]}}